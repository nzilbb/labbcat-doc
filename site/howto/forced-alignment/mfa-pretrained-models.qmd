---
format:
  html:
    toc: true
  pdf: 
    toc: false
#    fontfamily: libertinus
---
# MFA and Pretrained Acoustic Models

The *Montreal Forced Aligner* (MFA) is a third-party tool developed by Michael McAuliffe and others for time aligning orthographic and phonological forms from a pronunciation dictionary to orthographically transcribed audio files. It is 
[open source software](https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/main/LICENSE) 
based on the 
[Kaldi ASR toolkit](http://kaldi-asr.org/).

LaBB-CAT includes a layer manager module called "MFA Manager" which integrates with MFA in order to facilitate forced alignment of LaBB-CAT corpus data.

The layer manager can work in two modes:

- *Train and Align* - acoustic models are trained on the data you want to align, which can be in any language as long as you have a pronunciation dictionary for it.
- *Pre-trained Models/Dictionaries* - pre-trained models and pronunciation dictionaries are supplied by the Montreal Forced Aligner and used for forced alignment. Languages for which dictionaries are available listed on the MFA website and include:
    - English
    - French
    - German
    - Brazilian Portuguese
    - Spanish
    - Catalan

These instructions assume that your corpus is in one of these languages, and uses the *Pre-trained Models/Dictionaries* approach...

{{< pagebreak >}}

## MFA Installation

{{< include fragment-mfa-installation.qmd >}}

{{< pagebreak >}}

## Layer Manager Installation

{{< include fragment-mfa-annotator-installation.qmd >}}

## Forced Alignment

Once you've

1. Now you need to add a phrase layer for the HTK configuration:
    - **Layer ID**: `mfa`
    - **Type**: *Text*
    - **Alignment**: *Intervals*
    - **Manager**: *MFA Manager*
    - **Generate**: *always*
    - **Description**: *MFA alignment time*
1. When you configure the layer, set the following options:
    - **Dictionary Name**: the dictionary language, e.g. *english_uk_mfa*
    - **Pretrained Acoustic Models**: the models language, e.g. *english_mfa*
    - The rest of the options can be left as their default values.
    - If you're curious about what the configuration options do, hover your mouse over each option to see a `tool tip' that describes what the option is for.
1. Press *Set Parameters*
1. Press *Regenerate*  
   You will see a progress bar while LaBB-CAT force-aligns all the transcripts in the corpus, which may take a few minutes.
1. When the layer manager has finished, you'll see a message saying:  
   *Complete - words and phones from selected utterances are now aligned.*

::: {.callout-tip}

Not all MFA pre-trained acoustic models can be used with all dictionaries.

Apart from matching the language (e.g. English-trained acoustic models should be used only with English dictionaries), the phoneme symbol sets must also match. 

MFA uses several symbol sets, including:

- IPA - model and dictionary names ending in `..._mfa`
- ARPAbet - model and dictionary names ending in `..._arpa`

So if you use an acoustic model ending in `...arpa`, then the dictionary you choose must also end in `...arpa`.

See the MFA documentation on models and dictionaries for more detailed information:\
<https://mfa-models.readthedocs.io>


:::