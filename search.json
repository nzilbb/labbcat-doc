[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About\nThis is the documentation for the LaBB-CAT corpus management system.\nAuthor: Robert Fromont\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "worksheets/demo/2-layers.html",
    "href": "worksheets/demo/2-layers.html",
    "title": "2 - Searching Annotation Layers",
    "section": "",
    "text": "So far we have only searched the orthography layer - i.e.¬†the ordinary spellings of words. But LaBB-CAT has been configured to generate a number of other annotation layers, which we will now explore.\n\nIf you still have the results page open from the last worksheet, close it to return to the search page.  \n\nThe annotation layers are grouped into a number of ‚Äòprojects‚Äô to avoid clutter. We will initially be interested in the layers related to syntax.\n\nBelow the Pattern heading on the search page are four columns of checkboxes. The first column is labelled Projects, and the other columns have checkboxes for annotation layers of different granularities.\n\nTick the syntax project.\nSome additional layers will appear in the layer list on the right.\nTick the pos layer.\nYou will see that the ‚Äòsearch matrix‚Äô is now two layers high and two words wide.\n\n\nThe pos layer contains part-of-speech annotations that were automatically generated by the Stanford POS Tagger, which is free software developed by The Stanford Natural Languages Processing Group for tagging words in various languages with their parts of speech.\nWe are going to use the pos layer to identify ‚Äú‚Ä¶quake‚Äù words that are followed by any verb‚Ä¶\n\nThe pos box on the right has a  button.\nHover your mouse over it to see what it does, and then click it.\nA panel will open that lists all the part-of-speech labels used by the Stanford POS Tagger, categorised by type.\nHover your mouse over different part-of-speech labels, and category names, to see what they represent.\nClick the VERB link.\nA regular expression will be added to the pos search matrix that will identify any of the verb-type part-of-speech labels.\nPress the  button to close the Symbol Selector.\nDelete the is|was test from the orthography box above.\n\n\n\nPress Search.\nYou will see ‚Äò‚Ä¶quake‚Äô words followed by different verbs.\nClick on the first result in the list.\n\nThis displays the transcript like you‚Äôve seen before, except that now each word token has a part-of-speech tag above it. Some words have multiple tags (look for words with apostrophes).",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "2 - Searching Annotation Layers"
    ]
  },
  {
    "objectID": "worksheets/demo/2-layers.html#word-frequency",
    "href": "worksheets/demo/2-layers.html#word-frequency",
    "title": "2 - Searching Annotation Layers",
    "section": "Word Frequency",
    "text": "Word Frequency\n\nScroll to the top of the transcript you have open and select the Layers tab.\nYou will see a list of layer checkboxes, which determine which annotation layers are displayed.\nUnder projects to the left, tick the checkbox labelled ‚Äúfrequency‚Äù.\nThis will reveal new options under layers.\nTick the cobuild frequency layer.\nAfter a short delay, each word will have a number above it.\n\nThe words have been tagged with their frequencies available in the CELEX lexicon, which come from the Collins Birmingham University International Language Database (COBUILD) corpus.\n\nTick the word frequency layer\nA second set of numbers will appear; this is the number of times the word appears in this demo corpus.\n\nThe word frequency layer annotations were added automatically by a module called the ‚ÄòFrequency Layer Manager‚Äô which also keeps a straight word-list with word counts for each corpus‚Ä¶\n\nClick the home menu option at the top.\nClick the Frequency Layer Manager icon.\nYou will see a drop-down box with each frequency layer in it.\nSelect Word Frequency and press Select.\nPress the Export button at the bottom.\nSave and open the resulting CSV file.\nYou will see an alphabetical list of all the distinct words in the database, and next to each, a count of the number of tokens of that type.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "2 - Searching Annotation Layers"
    ]
  },
  {
    "objectID": "worksheets/demo/2-layers.html#keyness",
    "href": "worksheets/demo/2-layers.html#keyness",
    "title": "2 - Searching Annotation Layers",
    "section": "Keyness",
    "text": "Keyness\nIn addition to calculating word frequencies for direct analysis, frequencies can be compared to a reference corpus to calculated their log-likelihood ‚Äòkeyness‚Äô; a measure of whether the word is unusually frequent (a high positive keyness) or unusually infrequent (a low negative keyness).\n\n\n\n\n\n\nNote\n\n\n\nSee Rayson, P. and Garside, R. (2000). Comparing corpora using frequency profiling. In proceedings of the workshop on Comparing Corpora, held in conjunction with the 38th annual meeting of the Association for Computational Linguistics (ACL 2000). 1-8 October 2000, Hong Kong, pp.¬†1 - 6.\n\n\nThe Demo LaBB-CAT has been configured to compute keyness compared to the frequencies available in the COBUILD corpus.\n\nSelect the home link on the menu.\nClick the ‚ÄòKeyness‚Äô icon.\nYou will see a form that allows you to search for particular spelling patterns, or export a list.\nPress the Search button without filling in the Pattern box, to list all words above the default Keyness threshold.\n\nA list of words will be displayed, each word with its keyness metric. The high-positive words (which are unusually frequent) are listed first, with the low-negative words (unusually infrequent) below.\n\nUnsurprisingly for this speech corpus, as compared to the mostly-written COBUILD corpus, words with high keyness include filled pauses like ‚Äúum‚Äù and ‚Äúahh‚Äù, other words more likely in informal speech like ‚Äúgonna‚Äù and ‚Äúyeah‚Äù, topic-specific words like ‚Äúearthquake‚Äù and ‚Äúaftershocks‚Äù, and Canterbury place-names like ‚ÄúChristchurch‚Äù and ‚ÄúBrooklands‚Äù.\nThe Frequency Layer Manager can be configured to compute keyness of the data compared to any corpus for which you have word frequency data, or if you have several corpora within one LaBB-CAT database, each corpus can be compared to all the rest.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "2 - Searching Annotation Layers"
    ]
  },
  {
    "objectID": "worksheets/demo/2-layers.html#linguistic-inquiry-and-word-count",
    "href": "worksheets/demo/2-layers.html#linguistic-inquiry-and-word-count",
    "title": "2 - Searching Annotation Layers",
    "section": "Linguistic Inquiry and Word Count",
    "text": "Linguistic Inquiry and Word Count\nLinguistic Inquiry and Word Count (LIWC) text analysis can be done with the LIWC Layer Manager and categorised word lists.\n\n\n\n\n\n\nNote\n\n\n\nSee: https://www.liwc.app/help/howitworks\nOr: Tausczik & Pennebaker (2010) The Psychological Meaning of Words: LIWC and Computerized Text Analysis Methods Journal of Language and Social Psychology 29 (1) 24-54\n\n\nLIWC involves calculating the percentage of words in different categories. Categorised word lists can be compiled by hand, and needn‚Äôt be restricted to the categories shown here.\nLIWC text analysis has been done on the Demo LaBB-CAT database, and also on the COBUILD corpus as a comparison corpus.\n\nSelect the home option on the menu.\nClick the ‚ÄòLIWC‚Äô icon.\nYou will see a horizontal bar graph: each bar represents category of words, with the bar length representing the percentage of that category‚Äôs usage in the database.\nTick the Cobuild checkbox on the left.\nBars representing the percentages for the COBUILD corpus will be added to the graph, for comparison.\nPress the Export button.\nSave and open the resulting CSV file.\nYou will see that the file contains the list of categories, with two percentages for each category, first the percentage for the LaBB-CAT data, and then the percentage for the COBUILD corpus.\n\nThe bar graph can be used to clearly visualise similarities and differences between the corpora. The CSV file is useful for further analysis, or different visualisation options, using other tools.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "2 - Searching Annotation Layers"
    ]
  },
  {
    "objectID": "worksheets/demo/2-layers.html#forced-alignment",
    "href": "worksheets/demo/2-layers.html#forced-alignment",
    "title": "2 - Searching Annotation Layers",
    "section": "Forced Alignment",
    "text": "Forced Alignment\nForced alignment is the automated processing of recordings of utterances and their orthographic transcripts in order to determine the start and end times of the individual speech sounds within words (phones).\nLaBB-CAT can integrate with a number of forced alignment systems, including the Hidden Markov Model Toolkit (HTK), which is a speech recognition toolkit developed at Cambridge University.\nIn order to do forced alignment, HTK needs the following ingredients:\n\na set of recordings broken up into short utterances,\northographic transcriptions of each utterance, and\nphonemic transcriptions of each of the words in each utterance.\n\nIn the demo database you have all of these three ingredients (pronunciations have been taken from the CELEX lexicon), and the data has already been force-aligned using HTK.\nWe will now explore some of the uses of force-aligned data.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "2 - Searching Annotation Layers"
    ]
  },
  {
    "objectID": "worksheets/demo/2-layers.html#searching",
    "href": "worksheets/demo/2-layers.html#searching",
    "title": "2 - Searching Annotation Layers",
    "section": "Searching",
    "text": "Searching\n\nSelect the search option on the menu at the top.\nTick the segment layer, which is the layer that stores the force-aligned phones produced by HTK.\n\nNow we‚Äôre going to do a search for tokens of the TRAP vowel /√¶/.\n\nThe segment box has a  button to the right of it.\nHover the mouse over it to see what it says, and then press it.\nYou will see that a box opens with a bunch of phoneme symbols on it.\nOn the ‚ÄòMonophthong‚Äô line, find the TRAP vowel √¶ and click it.\nYou will see that a { appears in the box.\n\nThe phonemic transcriptions used for forced-alignment came from the CELEX lexicon, and CELEX doesn‚Äôt use IPA symbols directly, it actually uses the ‚ÄòDISC‚Äô encoding for phoneme labels, which uses ordinary ‚Äòtypewriter‚Äô characters (ASCII), and uses exactly one character per phoneme. The DISC symbols are used for the segment layer labels.\nAs you can see in the table below, many of the correspondences between IPA and DISC are straightforward, but IPA symbols that involve unusual characters or more than one character have non-obvious DISC symbols.\n\n\n\nIPA\nDISC\n¬†\n¬†\nIPA\nDISC\n¬†\n\n\np\np\npat\n¬†\n…™\nI\nKIT\n\n\nb\nb\nbad\n¬†\nŒµ\nE\nDRESS\n\n\nt\nt\ntack\n¬†\n√¶\n{\nTRAP\n\n\nd\nd\ndad\n¬†\n å\nV\nSTRUT\n\n\nk\nk\ncad\n¬†\n…í\nQ\nLOT\n\n\ng\ng\ngame\n¬†\n ä\nU\nFOOT\n\n\n≈ã\nN\nbang\n¬†\n…ô\n@\nanother\n\n\nm\nm\nmat\n¬†\ni:\ni\nFLEECE\n\n\nn\nn\nnat\n¬†\nŒ±:¬†\n#\nSTART\n\n\nl\nl\nlad\n¬†\n…î:\n$\nTHOUGHT\n\n\nr\nr\nrat\n¬†\nu:\nu\nGOOSE\n\n\nf\nf\nfat\n¬†\n…ú:\n3\nNURSE\n\n\nv\nv\nvat\n¬†\ne…™\n1\nFACE\n\n\nŒ∏\nT\nthin\n¬†\nŒ±…™\n2\nPRICE\n\n\n√∞\nD\nthen\n¬†\n…î…™\n4\nCHOICE\n\n\ns\ns\nsap\n¬†\n…ô ä\n5\nGOAT\n\n\nz\nz\nzap\n¬†\nŒ± ä\n6\nMOUTH\n\n\n‚à´\nS\nsheep\n¬†\n…™…ô\n7\nNEAR\n\n\n í\nZ\nmeasure\n¬†\nŒµ…ô\n8\nSQUARE\n\n\nj\nj\nyank\n¬†\n ä…ô\n9\nCURE\n\n\nx\nx\nloch\n¬†\n√¶\nc\ntimbre\n\n\nh\nh\nhad\n¬†\n…ëÃÉÀê\nq\nd√©tente\n\n\nw\nw\nwet\n¬†\n√¶ÃÉÀê\n0\nlingerie\n\n\n ß\nJ\ncheap\n¬†\n…íÃÉÀê\n~\nbouillon\n\n\n §\n_\njeep\n¬†\n¬†\n¬†\n¬†\n\n\n≈ãÃ©\nC\nbacon\n¬†\n¬†\n¬†\n¬†\n\n\nmÃ©\nF\nidealism\n¬†\n¬†\n¬†\n¬†\n\n\nnÃ©\nH\nburden\n¬†\n¬†\n¬†\n¬†\n\n\nlÃ©\nP\ndangle\n¬†\n¬†\n¬†\n¬†\n\n\n\nThe symbol for the TRAP vowel /√¶/ is { which is why clicking √¶ in the Phoneme Symbol Selector adds a { to the search pattern.\n\nPress Search.\nYou will see that all the matches include /√¶/ somewhere in the word.\nImmediately to the right of the CSV Export button there is a  button.\nHover your mouse over it to see what it does, and then press it.\n\nYou will see several columns of checkboxes for selecting:\n\nparticipant attributes\ntranscript attributes\nannotations\n\nThese can all be exported with the CSV results.\n\nUnder Participant tick gender and age_category.\nUnder Transcript tick syllables per minute.\nUnder Span tick type\nUnder Phrase tick syllables per minute\nUnder Word tick cobuild frequency\nAbove the checkboxes, press the CSV Export button, and open the resulting CSV file.\n\nYou will see that, in addition to the columns you‚Äôve seen before, the CSV file also includes:\n\nparticipant_gender - the gender of the person speaking;\nparticipant_age_category - their age bracket;\ntranscript_syllables per minute - the overall articulation rate throughout the whole recording;\nTarget type - a manually added annotation that labels what type of experience is being described;\nTarget syllables per minute - the local articularion rate, during the utterance in which the match was uttered;\nTarget cobuild frequency - the frequency of the word in the COBUILD corpus;\nTarget segment - the label of the vowel you searched for;\nTarget segment start - the start time of the vowel;\nTarget segment end - the end time of the vowel.\n\nThis means you can include this data in any analysis you subsequently perform on the results data.\nYou have seen that after forced alignment, it‚Äôs possible to identify tokens of individual speech sounds. You can also match for the context of the speech sounds within the word.\n\nClose the results tab and return to the search page.\n\nYou will see that on the left edge of the segment box there is an open padlock icon.\n\nHover your mouse over the padlock to see what it says, and then click it.\nThe padlock closes.\nPress Search.\nThere are much fewer matches now, as you‚Äôll see only words where the matched segment is at the beginning of the word.\nClose the results tab and return to the search page.\n\nYou can also match patterns of multiple segments within the word. Let‚Äôs say we‚Äôre interested in words that start with the TRAP vowel, followed by /n/. We can use the segment layer to search on the basis of pronunciation, matching multiple segments within the word.\n\n\nInside the segment box, immediately to the right of the Phoneme Symbol Selector button is a small  button .\nPress it.\nYou will see that this adds another segment column within the word.\nEnter n in the second segment box.\n\nPress Search and check the results are what you would expect.\n\n\n\nYou can also export segment tokens that match search patterns to a CSV file, including the start/end times for analysis or further processing. In fact, you can also export other annotations, and transcript/participant attributes.\n\n\nOn the results page, press the CSV Export button.\nSave and open the resulting file.\n\nAs youve seen before, the last two columns are:\n\nTarget segment start - the start time of the vowel;\nTarget segment end - the end time of the vowel.\n\nThese can be used for calculating vowel duration, but also for acoustic measurement of the matched segments‚Ä¶",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "2 - Searching Annotation Layers"
    ]
  },
  {
    "objectID": "worksheets/demo/2-layers.html#acoustic-measurement",
    "href": "worksheets/demo/2-layers.html#acoustic-measurement",
    "title": "2 - Searching Annotation Layers",
    "section": "Acoustic Measurement",
    "text": "Acoustic Measurement\nGiven a CSV file with token start/end times, LaBB-CAT can extract acoustic measurements on the speech sounds using Praat.\n\n\n\n\n\n\nNote\n\n\n\nThe following steps work even if you don‚Äôt have Praat installed on your own computer, because Praat is used on the LaBB-CAT server ‚Ä¶\n\n\n\nIn LaBB-CAT, select the extract menu option.\nSelect the process with praat option.\nClick Browse and select the CSV results that you saved above.\nYou will see a form to fill in, and the first couple of settings (Transcript Name column and Participant column) should be already filled in).\nFor the Start Time column, ensure that the Target segment start option is selected.\nFor the End Time column, ensure the Target segment end option is selected.\n\nThese two settings define the start/end times of the vowel For some measurements you might extract from Praat, processing signal that includes surrounding context is usually a good idea. You‚Äôll see there‚Äôs a setting for that (which you can leave at the default of 0.025s), and you will see options for various measurements.\nThe default options are for F1 and F2 only, but if you feel like getting other measurements, feel free to tick those options too. You can expand each section with the  button to reveal more settings, which allow you to specify more detail about how Praat should do its computations. Again, feel free to look at those and try different settings.\n\nPress Process.\nYou will see a progress bar while LaBB-CAT generates Praat scripts and runs them.\nOnce Praat has finished processing the intervals, you will get a CSV file (you might have to click the CSV file with measurements link) - save and open it.\n\n\n\n\n\n\n\nTip\n\n\n\nYou may find that the CSV text data displays directly in your browser window.\nIf this happens, just save the file with the  keys, and open it with Excel or whatever program you have to open CSV files.\n\n\nYou will see that it‚Äôs a copy of the CSV file you uploaded, with some extra columns added on the right.\nDepending on your settings, this will include at least one column per measurement you selected (for formant measurmenets, there is also a column that contains the time at which the measurements were taken), and a final column called Error which is hopefully blank, but which might contain errors reported back by Praat (e.g.¬†if it couldn‚Äôt find the audio file or ran into any other problem during processing).",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "2 - Searching Annotation Layers"
    ]
  },
  {
    "objectID": "worksheets/demo/2-layers.html#praat-browser-integration",
    "href": "worksheets/demo/2-layers.html#praat-browser-integration",
    "title": "2 - Searching Annotation Layers",
    "section": "Praat Browser Integration",
    "text": "Praat Browser Integration\n\n\n\n\n\n\nNote\n\n\n\nThe following steps work only if:\n\nif you Java and Praat installed on your own computer, and\nyou‚Äôre using a Chrome, Edge, or Firefox (i.e.¬†not Safari)\n\nIf you don‚Äôt use Praat, or don‚Äôt have Praat or Java installed, you can skip this section.\n\n\nWe have previously seen that any transcript can be exported as a Praat TextGrid from the formats menu, so you can export a TextGrid and open it in Praat (if you have it installed on your computer) to check the segment layer alignments.\nLaBB-CAT also integrates directly with Praat. With Praat integration installed, you can inspect alignments directly from the transcript page, and with sufficient access, you can also correct them by moving the alignments in Praat and then saving them back to LaBB-CAT.\n\n\n\n\n\n\nImportant\n\n\n\nLaBB-CAT‚Äôs browser integration with Praat currently does not work with Safari, so if you‚Äôre using a Mac, ensure you try the steps below in Google Chrome or Mozilla Firefox.\n\n\nFirst, the LaBB-CAT/Praat integration has to be set up; this only has to be done once:\n\nOpen any transcript.\nOn the Layers tab tick the segment layer.\n(If there are other layers preselected, you can un-tick them)\nAfter a short delay, you will see a phonemic transcription below each word in the transcript ‚Äì these are the phone annotations created by HTK.\nOn the top-right of the transcript page, above the playback controls, there‚Äôs a Praat icon  - click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\n\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\n\nOnce you‚Äôve installed the browser extension, return to the transcript page.\nPress OK on the message that appears, to reload the page.\nClick on any line, and select the ‚ÄòOpen Text Grid in Praat‚Äô option on the menu.\n\nYou will see a page with three-step instructions for finishing the Praat integration.\nAssuming you already have Praat and Java installed, you just have to do the third step. i.e.¬†download and run a program called ‚Äúinstall-jsendpraat.jar‚Äù.\n\nClick the install-jsendpraat.jar link, save the resulting file.\nDouble-click the program you just saved.\nOn the window that appears, press the Install button.\n\n\n\n\n\n\n\nNoteMac Installation\n\n\n\n\n\nWhen you try to run install-jsendpraat.jar on a Mac, you may see the following message:\n\nIf so:\n\nPress Done.\nClick the Apple icon on the top left corner of the screen to open the menu.\nSelect System Settings‚Ä¶\nOn the left hand side, select the Privacy and Security option.\nScroll to the bottom of the page.\nUnder Security you should seem a message saying\n‚Äúinstall-sendpraat.jar‚Äù was blocked to protect your Mac\n\nPress Open Anyway\nYou will see a warning message:\n\nPress Open Anyway\nYou may see a further prompt to allow this:\n\n\nFinally you should see the installer open:\n\nThen you can press Install.\n\n\n\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\nIf in doubt, check the  online help on the transcript page; it has a section explaining how to set up Praat integration on various browsers and operating systems.\n\nClose the instructions page.\n\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶\n\nBack in the transcript page you had open earlier, click on any line, and select the Open Text Grid option on the menu.\nAfter a short delay, Praat should open, and show you a spectrogram of the line‚Äôs audio, with a TextGrid below that includes the words and the segments.\nIf you click on a word, and hit the tabtab key, the word‚Äôs interval is played. Try out various words, and see what you think about how accurate HTK has been with its alignment.\nTry this out with different lines in the transcript.\nYou will see that in some cases the alignment is pretty good, and in other cases, it‚Äôs not so good. In the not-so-good cases, see if you can figure out why HTK got it wrong.\n\nIf you had ‚Äòedit‚Äô rather than ‚Äòread-only‚Äô permissions in LaBB-CAT, then each time you opened an utterance in Praat, a button would appear in the transcript to the left of the line, labelled Import Changes. This button would allow you to save any adjustments you might want to make to the alignments back into the LaBB-CAT database.\n\nThis mechanism can also be used to add other annotations from Praat into LaBB-CAT annotation layers.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "2 - Searching Annotation Layers"
    ]
  },
  {
    "objectID": "worksheets/course/5-manual-annotation.html",
    "href": "worksheets/course/5-manual-annotation.html",
    "title": "5. Manual Annotation",
    "section": "",
    "text": "5. Manual Annotation\nNow we‚Äôre going to create our own layer for manual annotations, and explore ways of populating it. Let‚Äôs say we‚Äôre interested in the pronunciation of the vowel in the word ‚Äúthe‚Äù when the following word starts with a vowel. We‚Äôre going to:\n\nCreate a layer for annotations on tokens of the word ‚Äúthe‚Äù.\nSearch for tokens using word orthography, and identify ‚Äòfalse positives‚Äô (e.g.¬†cases like ‚Äú‚Ä¶the one‚Ä¶‚Äù where the spelling of the following word starts with a vowel but it‚Äôs not pronounced as a vowel).\nFor the ‚Äòtrue positives‚Äô, perform some auditory analysis (i.e. listen to them) and tag each token accordingly.\n\n\n\nTo embark on this mini project, we‚Äôre first going to create a ‚Äòproject‚Äô in LaBB-CAT to categorize our annotations.\nSelect the projects link on the menu.\nAdd a project called ‚Äúthe‚Äù with a description something like Pronunciation of the vowel in the when followed by a word-initial vowel, by filling in the form and pressing the New button.\n\nNow we‚Äôre going to create a layer to store our annotations‚Ä¶\n\nSelect on the word layers option on the menu.\nYou will see a list of existing word layers, including the orthography layer, the lexical layer, etc.\nThe row of column headings at the top is also a form for adding a new layer.\nFill in the top row with the following details:\n\nLayer ID: the\nType: Text\nAlignment: None (our annotations are simply tags on words, inheriting their start/end times from the word token they tag)\nManager: don‚Äôt select any manager, as we‚Äôll be adding manual annotations, rather than automatically generated ones\nGenerate: don‚Äôt select any option (this setting is only relevant for managed layers, so it doesn‚Äôt actually matter what you select here)\nProject: the\nDescription: \"the\" followed by a word-initial vowel\n\nPress New to add the layer.\n\nNow we‚Äôre ready to find some tokens‚Ä¶\n\nSelect participants on the menu.\nWe‚Äôre going to search all male monolinguals, so filter by the appropriate attribute values if they‚Äôre not already filtered, and then press Layered Search.\nSearch for instances of the word ‚Äúthe‚Äù followed immediately by a word starting with a vowel, on the orthography layer.\nExport the results to a CSV file and open it.\n\nNow we‚Äôre going to annotate the CSV file to identify false positives.\n\nAdd a column to the right-hand side of the spreadsheet, called ‚ÄúThe‚Äù - i.e.¬†on the first line, in the cell to the right the last column header, enter the word The\n\nFor each row in the spreadsheet check the contents of the ‚ÄúMatch transcript‚Äù column, and decide whether the match is a ‚Äòfalse positive‚Äô or not. False positives are cases like ‚Äúthe one‚Äù, where the second word actually starts with a non-vowel sound (i.e.¬†the word ‚Äúone‚Äù actually starts with a /w/ phoneme).\nFor false positives, enter FP in your new ‚ÄúThe‚Äù column. For all the others, enter TP.\nSave the CSV file.\nYou may be asked if you want to change the format of the file. Resist the temptation to do this - we are going to upload this file into LaBB-CAT, and it can only understand CSV files.\n\nNow that we‚Äôve annotated our results, we‚Äôre going to to load our annotations into the new layer we created in LaBB-CAT‚Ä¶\n\nIn LaBB-CAT, select the upload menu option.\nSelect the upload csv annotations option.\nPress Choose File and select the annotated CSV file you just saved.\nPress Upload.\nOn the form that appears, you can leave the default choices for the options. Just ensure that the Tag Words option is selected at the top, and at the bottom the The column in the spreadsheet is mapped to the the layer in LaBB-CAT.\nClick Insert Annotations.\nYou will see a message about how many annotations were added. Now, within LaBB-CAT, each token mentioned in your CSV file has been tagged with either ‚ÄúTP‚Äù or ‚ÄúFP‚Äù\n\nNow that we‚Äôve seen one way to add annotations to the database, using CSV files, we will try another way - editing word annotations directly from the interactive transcript.\nWe‚Äôre going to find our ‚Äòtrue positive‚Äô tokens of the word ‚Äúthe‚Äù, and annotate each depending on how the speaker pronounces it in the recording.\n\nIn LaBB-CAT, select the search menu option, which by default searches utterances of all participants.\nThis time we‚Äôre going to search for the true-positive annotations we just inserted.\nThere‚Äôs now a ‚ÄúProjects‚Äù to the left of the layer checkboxes which includes the ‚Äúthe‚Äù project we added at the start. Tick that project, so that the layer associated with it is displayed in the list of Word layers to the right.\nTick your custom layer (called ‚Äúthe‚Äù) in the Word column.\nYour search matrix is now two layers high by one word wide.\nSearch for TP on the the layer.\nThe results page should show you all the words you annotated with TP in your CSV file above.\nClick on the first match.\nThis will open the interactive transcript for the match. You‚Äôll be able to see not only the transcript text, but also the TP/FP tags you have added.\nClick on the first match in the transcript, and select the Play option to play the line.\nListen carefully to see whether the speaker pronounces the word ‚Äúthe‚Äù like ‚Äúthee‚Äù or not. If they do, we‚Äôre going to annotate the word with the code i. Otherwise we‚Äôre going to annotate it with the code @.\nHover your mouse pointer over the TP tag above the matched word, and you will see a small button appear with the icon of a pencil on it . Hover your mouse pointer over the button to see what it does, and then press it. The TP tag will now appear in a text box that allows you to change the label.\nWe‚Äôre going to change the ‚ÄúTP‚Äù annotation depending on the pronunciation of the token. So replace ‚ÄúTP‚Äù with i or @ as appropriate.\nPress the Save button  to save your annotation to the database.\nYou will see an alert asking if you‚Äôre sure. Press OK.\nFind the next match result - it will be highlighted.\nAnnotate the next match in exactly the same way - play the utterance, listen to the pronunciation, and change the TP to an appropriate code.\nSimilarly annotate the rest of the matches in the transcript.\nOnce you‚Äôve annotated the last match in the transcript, close the browser‚Äôs tab.\nThis will take you back to the search results page.\nYou‚Äôve already annotated all the matches in the first transcript, so move to the next transcript in the results list, and click the first match.\nAnnotate all the ‚ÄúTP‚Äù tokens in the transcript.\nRepeat the above steps until you‚Äôve annotated all the matches.\n\nYou‚Äôve now used two methods for annotating words. Although this is a small, toy example, you can hopefully see that you could manage a larger annotation project involving much more tokens, possibly multiple annotators, and working either offline (with a CSV file and maybe extracted WAV files) or online (directly in the interactive transcript page), as preferred.\nThere are other ways to add manual annotations, which relate to concrete points or intervals in time during the recording. We will see how to do this later‚Ä¶\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "5. Manual Annotation"
    ]
  },
  {
    "objectID": "worksheets/course/2-setting-up.html",
    "href": "worksheets/course/2-setting-up.html",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "In this exercise you will:\n\nDefine corpora\nDefine transcript types\nDefine speaker meta data\n\nAfter this you will have an empty LaBB-CAT database set up ready to upload transcripts into.\nNow that the software is installed, we will set up a basic structure for receiving data:\n\nOpen LaBB-CAT.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you will be running LaBB-CAT on your own computer, you may need to start LaBB-CAT, and this will open your browser on the LaBB-CAT start page.\nIf you are using a LaBB-CAT server that‚Äôs already been installed for you elsewhere, you will have been given a link or URL to use; open your browser on that page now.\n\n\n\nThe start page has a link on it called Where do I start? - you may like to click on this link and read the first section, which explains a little about how to navigate around LaBB-CAT and where to find online help and hints.¬†\nClick back on the start page of LaBB-CAT (the page with the Where do I start? link).\n\nNow we will set up some corpus names‚Ä¶\n\nOn the menu at the top, select the corpora option.\nThis page shows a list of current corpora, which only contains one corpus, called corpus.\nAbove the corpus corpus, there‚Äôs a form that you can fill in to add a new corpus. Fill in the following information:\n\nName : QB\nLanguage : English\nDescription : Quakebox recordings\n\nPress the New button to add the ‚ÄúQB‚Äù corpus.\nYou should see a message at the top of the page saying Record created and now the QB corpus is in the list, under the ‚Äúcorpus‚Äù corpus.\nAdd another corpus called UC with the description Campus recordings.\nWe won‚Äôt actually be using the corpus called corpus, so we want to delete it. To do this, press the Delete button to the right of the corpus corpus in the list.\nYou will be asked Are you sure you want to delete corpus? You are sure, so press OK.\nThe row will be deleted from the list.\n\nNow you have some corpora set up with the names you‚Äôve provided.\nThe data we are using is a collection of stories about peoples‚Äô experiences during the devastating earthquakes that hit the Canterbury region of New Zealand in 2010 and 2011. Some recordings are interviews, where an interviewer asks the participant questions, and others are monologues. Now we‚Äôre going to set up these two transcript types‚Ä¶\n\nSelect the transcript types option in the menu at the top of the page.\nYou will see a list of transcript types, although there‚Äôs currently only one type in the list, called interview.\nAbove this, fill in the empty Type box with the word: monologue\nPress the New button.\nYou will notice that now the list has two transcript types, interview and monologue. A Save button has appeared, because your changes aren‚Äôt yet saved to LaBB-CAT.\nPress the Save button.\nYou will see a message at the top saying Layer saved: transcript_type.\n\n\nNow that we have both corpora and transcript types, we‚Äôre going to set up meta-data options for the participants in our corpus‚Ä¶\n\nSelect the participant attributes menu option.\nYou will see a list of fields or attributes that participants (or speakers) can have. There are currently only three attributes:\n\nGender - i.e.¬†whether the participant is female or male or something else¬†\nBirth Year - i.e.¬†the year the participant was born¬†\nNotes - general arbitrary notes\n\n\nFor our corpus data, we don‚Äôt have the exact year of birth. Instead we have the age of the participant, defined by various age group categories.\n\nAs with previous pages, the headings at the top are also a form you can fill in to add a new row, which we will now fill in with the following information:\n\nAttribute ID : ageCategory\nType : Select (this is because we want to be able to select from a list of possible values)¬†\nLayer Label : Age\nAccess : Public\nSearchability : Searchable (so that it appears on the search page)\nCategory : General\nDescription : Age Category\n\n\n\n\n\n\n\n\nTip\n\n\n\n If you want more information about what each of these are for, check the online help for this page.\n\n\n\nPress the New button to add the attribute.\nYou will see a message saying Layer added: participant_ageCategory and the new attribute will now appear at the bottom of the list. Now we need to define the options for it‚Ä¶\nTo the right of the Age attribute‚Äôs Category there‚Äôs an icon like a tag üè∑.\nHover your mouse over this icon to see what it does.\nPress the Valid labels icon.\nThis shows a (currently empty) list of options for the participant_ageCategory attribute.\nIn the blank Label box, enter: 18-25\nPress the New button to add the option.\nYou will see that ‚Äú18-25‚Äù appears twice on the row that‚Äôs added:\n\nOn the left is the value that is saved in LaBB-CAT‚Äôs database.\nOn the right is an editable description that is displayed in various places in LaBB-CAT, which can be used to provide a little further explanation about the value.\n\nChange the Description to 18-25 years.\nIn the Label row at the top, enter: 26-35\nPress the New button to add the option.\nChange the Description to 26-35 years\nSimilarly, add the following age categories:\n\n36-45\n46-55\n56-65\n66-75\n76-85\n\nAdd a final option:\n\nLabel : 85+\nDescription : 85 years or more\n\nLastly, press the New button without filling in a Label to add a ‚Äòdefault‚Äô option for participants with missing data.\nPress the Save to save all your changes to LaBB-CAT.\nYou will see a message saying Layer saved: participant_ageCategory\nNow select the participant attributes option on the menu to return the list of all attributes.\n\n\nWe are going to add a few more attributes, but they will be ‚Äòfree text‚Äô fields without predefined options.\n\nAdd another attribute, called ethnicity. For ‚ÄòType‚Äô select String, and make it Public and Searchable.\nSimilarly, add the following Public Searchable String attribute:\n\nlanguagesSpoken - a list of languages they speak\n‚Ä¶ and the following Not Searchable attributes:\ngrewUp - what country they grew up in\ngrewUpRegion - what region of New Zealand they grew up in\ngrewUpTown - what town or city they grew up in\n\nLastly, as we will not be using it, delete the Birth Year attribute.\n\nNow you have an empty database for which you‚Äôve:\n\ncreated two corpora, QB and UC,\ncreated a new transcript type, so that we can have monologues as well as interviews, and\ncreated some new attributes for participants, so we can record the ages of our speakers, their place of origin, and the languages they speak, in addition to their genders.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "2. Setting Up"
    ]
  },
  {
    "objectID": "worksheets/course/2-setting-up.html#setting-up",
    "href": "worksheets/course/2-setting-up.html#setting-up",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "In this exercise you will:\n\nDefine corpora\nDefine transcript types\nDefine speaker meta data\n\nAfter this you will have an empty LaBB-CAT database set up ready to upload transcripts into.\nNow that the software is installed, we will set up a basic structure for receiving data:\n\nOpen LaBB-CAT.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you will be running LaBB-CAT on your own computer, you may need to start LaBB-CAT, and this will open your browser on the LaBB-CAT start page.\nIf you are using a LaBB-CAT server that‚Äôs already been installed for you elsewhere, you will have been given a link or URL to use; open your browser on that page now.\n\n\n\nThe start page has a link on it called Where do I start? - you may like to click on this link and read the first section, which explains a little about how to navigate around LaBB-CAT and where to find online help and hints.¬†\nClick back on the start page of LaBB-CAT (the page with the Where do I start? link).\n\nNow we will set up some corpus names‚Ä¶\n\nOn the menu at the top, select the corpora option.\nThis page shows a list of current corpora, which only contains one corpus, called corpus.\nAbove the corpus corpus, there‚Äôs a form that you can fill in to add a new corpus. Fill in the following information:\n\nName : QB\nLanguage : English\nDescription : Quakebox recordings\n\nPress the New button to add the ‚ÄúQB‚Äù corpus.\nYou should see a message at the top of the page saying Record created and now the QB corpus is in the list, under the ‚Äúcorpus‚Äù corpus.\nAdd another corpus called UC with the description Campus recordings.\nWe won‚Äôt actually be using the corpus called corpus, so we want to delete it. To do this, press the Delete button to the right of the corpus corpus in the list.\nYou will be asked Are you sure you want to delete corpus? You are sure, so press OK.\nThe row will be deleted from the list.\n\nNow you have some corpora set up with the names you‚Äôve provided.\nThe data we are using is a collection of stories about peoples‚Äô experiences during the devastating earthquakes that hit the Canterbury region of New Zealand in 2010 and 2011. Some recordings are interviews, where an interviewer asks the participant questions, and others are monologues. Now we‚Äôre going to set up these two transcript types‚Ä¶\n\nSelect the transcript types option in the menu at the top of the page.\nYou will see a list of transcript types, although there‚Äôs currently only one type in the list, called interview.\nAbove this, fill in the empty Type box with the word: monologue\nPress the New button.\nYou will notice that now the list has two transcript types, interview and monologue. A Save button has appeared, because your changes aren‚Äôt yet saved to LaBB-CAT.\nPress the Save button.\nYou will see a message at the top saying Layer saved: transcript_type.\n\n\nNow that we have both corpora and transcript types, we‚Äôre going to set up meta-data options for the participants in our corpus‚Ä¶\n\nSelect the participant attributes menu option.\nYou will see a list of fields or attributes that participants (or speakers) can have. There are currently only three attributes:\n\nGender - i.e.¬†whether the participant is female or male or something else¬†\nBirth Year - i.e.¬†the year the participant was born¬†\nNotes - general arbitrary notes\n\n\nFor our corpus data, we don‚Äôt have the exact year of birth. Instead we have the age of the participant, defined by various age group categories.\n\nAs with previous pages, the headings at the top are also a form you can fill in to add a new row, which we will now fill in with the following information:\n\nAttribute ID : ageCategory\nType : Select (this is because we want to be able to select from a list of possible values)¬†\nLayer Label : Age\nAccess : Public\nSearchability : Searchable (so that it appears on the search page)\nCategory : General\nDescription : Age Category\n\n\n\n\n\n\n\n\nTip\n\n\n\n If you want more information about what each of these are for, check the online help for this page.\n\n\n\nPress the New button to add the attribute.\nYou will see a message saying Layer added: participant_ageCategory and the new attribute will now appear at the bottom of the list. Now we need to define the options for it‚Ä¶\nTo the right of the Age attribute‚Äôs Category there‚Äôs an icon like a tag üè∑.\nHover your mouse over this icon to see what it does.\nPress the Valid labels icon.\nThis shows a (currently empty) list of options for the participant_ageCategory attribute.\nIn the blank Label box, enter: 18-25\nPress the New button to add the option.\nYou will see that ‚Äú18-25‚Äù appears twice on the row that‚Äôs added:\n\nOn the left is the value that is saved in LaBB-CAT‚Äôs database.\nOn the right is an editable description that is displayed in various places in LaBB-CAT, which can be used to provide a little further explanation about the value.\n\nChange the Description to 18-25 years.\nIn the Label row at the top, enter: 26-35\nPress the New button to add the option.\nChange the Description to 26-35 years\nSimilarly, add the following age categories:\n\n36-45\n46-55\n56-65\n66-75\n76-85\n\nAdd a final option:\n\nLabel : 85+\nDescription : 85 years or more\n\nLastly, press the New button without filling in a Label to add a ‚Äòdefault‚Äô option for participants with missing data.\nPress the Save to save all your changes to LaBB-CAT.\nYou will see a message saying Layer saved: participant_ageCategory\nNow select the participant attributes option on the menu to return the list of all attributes.\n\n\nWe are going to add a few more attributes, but they will be ‚Äòfree text‚Äô fields without predefined options.\n\nAdd another attribute, called ethnicity. For ‚ÄòType‚Äô select String, and make it Public and Searchable.\nSimilarly, add the following Public Searchable String attribute:\n\nlanguagesSpoken - a list of languages they speak\n‚Ä¶ and the following Not Searchable attributes:\ngrewUp - what country they grew up in\ngrewUpRegion - what region of New Zealand they grew up in\ngrewUpTown - what town or city they grew up in\n\nLastly, as we will not be using it, delete the Birth Year attribute.\n\nNow you have an empty database for which you‚Äôve:\n\ncreated two corpora, QB and UC,\ncreated a new transcript type, so that we can have monologues as well as interviews, and\ncreated some new attributes for participants, so we can record the ages of our speakers, their place of origin, and the languages they speak, in addition to their genders.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "2. Setting Up"
    ]
  },
  {
    "objectID": "worksheets/course/1-installation.html",
    "href": "worksheets/course/1-installation.html",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "In this exercise you will install the LaBB-CAT software.\n\n\n\n\n\n\nNote\n\n\n\nYou should only follow these steps if you will be running LaBB-CAT on your own computer.\nIf you are using a LaBB-CAT server that‚Äôs already been installed for you elsewhere, you can skip with exercise.\n\n\nAfter this you will have an empty LaBB-CAT database set up ready to set up.\n\nYou have a file called install-labbcat.jar - double click this file to start the installer.\nIf you are using OS X, you may see a message that the file can‚Äôt be opened:\n\nIf this happens:\n\nClick the Apple icon in the top left corner of the screen.\nSelect System Preferences\nClick Security & Privacy\nNear the bottom it says ‚Äúinstall-labbcat.jar‚Äô‚Äô was blocked from opening because it is not from an identified developer.\n\nClick Open Anyway\nYou may see another warning about the program being downloaded from the internet\n\nClick Open\n\n\n\nClick Start\nYou will see the progress bar move as files are installed. Once this is finished, you‚Äôll see a message saying Installation complete.\nClick Finished to close the installer.\n\nThe software is now installed. LaBB-CAT is a browser-based system, which means that it works as a mini web server on your computer, and you need to access it using your web browser.\nEach time you want to use LaBB-CAT, you must start it up, and which you‚Äôve finished, you close it down again.\nTo start LaBB-CAT, click the LaBB-CAT icon in your applications area.\n\nOn Windows, open the Start menu and type LaBB-CAT.\nOn OS X you will find LaBB-CAT in your Applications folder.\n\nA window called ‚ÄúLaBB-CAT Server‚Äù will open, and after a short delay, your default web browser will open on a page called ‚ÄúLaBB-CAT‚Äù (The first time only, this page will initially display the LaBB-CAT licence).\n\nNow that the software is installed, we will set up a basic structure for receiving data, in the following exercise.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "1. Installation"
    ]
  },
  {
    "objectID": "worksheets/course/1-installation.html#installation",
    "href": "worksheets/course/1-installation.html#installation",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "In this exercise you will install the LaBB-CAT software.\n\n\n\n\n\n\nNote\n\n\n\nYou should only follow these steps if you will be running LaBB-CAT on your own computer.\nIf you are using a LaBB-CAT server that‚Äôs already been installed for you elsewhere, you can skip with exercise.\n\n\nAfter this you will have an empty LaBB-CAT database set up ready to set up.\n\nYou have a file called install-labbcat.jar - double click this file to start the installer.\nIf you are using OS X, you may see a message that the file can‚Äôt be opened:\n\nIf this happens:\n\nClick the Apple icon in the top left corner of the screen.\nSelect System Preferences\nClick Security & Privacy\nNear the bottom it says ‚Äúinstall-labbcat.jar‚Äô‚Äô was blocked from opening because it is not from an identified developer.\n\nClick Open Anyway\nYou may see another warning about the program being downloaded from the internet\n\nClick Open\n\n\n\nClick Start\nYou will see the progress bar move as files are installed. Once this is finished, you‚Äôll see a message saying Installation complete.\nClick Finished to close the installer.\n\nThe software is now installed. LaBB-CAT is a browser-based system, which means that it works as a mini web server on your computer, and you need to access it using your web browser.\nEach time you want to use LaBB-CAT, you must start it up, and which you‚Äôve finished, you close it down again.\nTo start LaBB-CAT, click the LaBB-CAT icon in your applications area.\n\nOn Windows, open the Start menu and type LaBB-CAT.\nOn OS X you will find LaBB-CAT in your Applications folder.\n\nA window called ‚ÄúLaBB-CAT Server‚Äù will open, and after a short delay, your default web browser will open on a page called ‚ÄúLaBB-CAT‚Äù (The first time only, this page will initially display the LaBB-CAT licence).\n\nNow that the software is installed, we will set up a basic structure for receiving data, in the following exercise.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "1. Installation"
    ]
  },
  {
    "objectID": "worksheets/course/8b-forced-alignment-mfa.html",
    "href": "worksheets/course/8b-forced-alignment-mfa.html",
    "title": "8b. MFA",
    "section": "",
    "text": "The Montreal Forced Aligner (MFA) is a 3rd-party tool developed by Michael McAuliffe and others that can use words with phonemic transcriptions, and the corresponding audio, to force-align words and phones; i.e.¬†determine the start and end time of each speech sound within each word, and thus the start/end times of the words.\nThe annotator can work in two modes:\n\nTrain and Align - acoustic models are trained on the data you want to align, which can be in any language as long as you have a pronunciation dictionary for it.\nPre-trained Models/Dictionaries - pre-trained models and pronunciation dictionaries are supplied by the Montreal Forced Aligner and used for forced alignment. Languages for which dictionaries are available include:\n\nEnglish\nFrench\nGerman\nBrazilian Portuguese\nSpanish\nCatalan\n\n\nAs the data we have is in English, we will use the Pre-trained Models/Dictionaries approach in this exercise.\nIn this exercise you will\n\ninstall the MFA Layer Manager,\nforce-align the speech of all of the participants in your database, and\ncheck and manually correct the alignments.\n\n\n\n\n\n\n\nImportant\n\n\n\nIn this exercise, you will set up Praat Integration in your web browser. There is currently no Praat integration support for Microsoft‚Äôs Edge‚Äô browser, so if you normally use ‚ÄòEdge‚Äô on Windows, you may need to swap to another browser for this exercise - e.g. Google Chrome, or Mozilla Firefox.\n\n\n\n\n\n\nMFA is a 3rd-party tool (https://montrealcorpustools.github.io/Montreal-Forced-Aligner/) that LaBB-CAT integrates with via a Layer Manager module. MFA is not included as part of LaBB-CAT, and so it must be installed on the server you have installed LaBB-CAT on before you can integrate LaBB-CAT with it.\nIf MFA has not been installed already, please follow the following steps, depending on the operatings system of your LaBB-CAT server:\n\n\n\n\n\n\nNoteLinux\n\n\n\n\n\nTo install the Montreal Forced Aligner on Linux systems for all users, so that your web server can access it if required:\n\nDownload Miniconda:\nwget https://repo.anaconda.com/miniconda/Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nStart the installer:\nsudo bash Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nWhen asked the location to install Miniconda, use:\n/opt/conda\nWhen asked whether the installer should initialize Miniconda, this is unnecessary so you can respond no\nChange ownership of the conda files):\nsudo chown -R $USERNAME:$USERNAME /opt/conda\nMake conda accessible to all users (so you web server can access MFA):\nchmod -R go-w /opt/conda\nchmod -R go+rX /opt/conda\nInstall the Montreal Forced Aligner\n/opt/conda/bin/conda create -n aligner -c conda-forge montreal-forced-aligner=3.2.1\n\n\n\n\n\n\n\n\n\n\nNoteWindows\n\n\n\n\n\nTo install the Montreal Forced Aligner on Windows systems for all users, so that your web server can access it if required:\n\nDownload the Miniconda installer:¬†¬†¬†\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\nStart the installer by double-clicking it.\nWhen asked, select the ‚ÄúInstall for all users‚Äù option. This will install conda somewhere like\nC:\\ProgramData\\Miniconda3\nWhen asked, tick the add to PATH option.\nInstall the Montreal Forced Aligner by specifying a path to the environment\nconda create -c conda-forge -p C:\\ProgramData\\Miniconda3\\envs\\aligner montreal-forced-aligner=3.2.1\n\nIf you have problems getting MFA working on Windows, check Troubleshooting on Windows section of the MFA Installation instructions.\n\n\n\n\n\n\n\n\n\nNoteDocker Container\n\n\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, it can download and install Miniconda and MFA itself, as part of the process of installing the MFA Manager (below)\nThere is no need for a separate installation of the MFA software.\n\n\n\n\n\n\nOnce MFA has been installed, you have to install the MFA Manager, which is the LaBB-CAT module that provides MFA with all the data it needs, and then saves to alignments MFA produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link at the bottom.\nFind MFA Manager in the list, and press its Install button and then press Install again.\n\nAs long as MFA has been installed for all users, you should see a box that‚Äôs already filled in with the location that MFA was installed to in the Path to MFA box.\n\nIf the Path to MFA box is empty and there‚Äôs an Attempt to Install MFA button, press the button, and LaBB-CAT will try to install MFA on the server for you. This process can take a few minutes, and the Configure button will be disabled until it‚Äôs finished.\nPress Configure to continue the layer manager installation.\nYou will see a window open with some information about integrating with MFA, including the information you‚Äôve already read above.\nNow you need to add a phrase layer for the MFA configuration:\n\nLayer ID: mfa\nType: Text\nAlignment: Intervals\nManager: MFA Manager\nGenerate: always\nDescription: MFA alignment time\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nInitially, there will be a ‚Äòspinner‚Äô and the form will be disabled while LaBB-CAT is making internet requests in order to retrieve lists of available dictionaries and acoustic models.\nThis process may take a few seconds, depending on LaBB-CAT‚Äôs connection to the internet.\n\n\n\nWhen you configure the layer, set the following options:\n\nDictionary Name: english_mfa\nPretrained Acoustic Models: english_mfa\nThe rest of the options can be left as their default values.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a ‚Äòtool tip‚Äô that describes what the option is for.\n\n\n\nPress Set Parameters\nWe will not press Regenerate to force-align the whole corpus just yet. We need to tweak a few other settings, and then align a single participant‚Äôs speech.\n\nWhen forced-alignment is done, the resulting aligned phones will be saved on the segment layer. By default, this has it‚Äôs type set to Phonological, which assumes that the phoneme symbols will be those defined by the CELEX DISC encoding. However, MFA uses its own phoneme symbols, which are different from the CELEX DISC ones.\nTo make later processing easier, we‚Äôre going to change the type of the segment layer to Text, and let LaBB-CAT know what the possible phoneme labels are.\n\nSelect the segment layers menu option.\nYou will see a single layer listed, called segment.\nChange the Type of the segment layer to Text.\nPress Save.\nA new icon appears with a tag  icon - if you hover the mouse over this button, you‚Äôll see it‚Äôs for setting Valid labels.\nPress the Valid labels icon\nYou will see a page that allows you to add a list of possible labels.\nBut we don‚Äôt know what the valid labels are yet. The labels used by MFA depend on the dictionary/models selected when defining the layer. The details for all dictionaries are in MFA Models documentation.\nOpen the MFA Models documentation for english_mfa.\nYou will see a page that includes information about the dictionary including the Phones used by it.\nSelect and copy the list of phones used by the english_mfa dictionary - i.e.¬†all of these:\n\na aj aw aÀê b b ≤ c c ∞ d d í d ≤ e ej f f ≤ h i iÀê j \nk k ∞ l m m ≤ mÃ© n nÃ© o ow p p ∞ p ≤ s t t É t ∞ t ≤\nu uÀê v v ≤ w z √¶ √ß √∞ ≈ã …ê …ë …ëÀê …í …íÀê …î …îj  …ô …ôw \n…ö …õ …õÀê …ú …úÀê …ù …ü …° …™ …´ …´Ã© …± …≤ …π …æ  É  â  âÀê  ä  é  í  î Œ∏\n\nBack in the Valid Labels page in LaBB-CAT, paste all of the phone symbols into the box labelled Label\n\nPress New.\nYou will see that all of the labels are separately added to the list of valid labels.\n\n\nDefining this list for the segment layer means that, when you search the segment layer for specific phones, LaBB-CAT can display a clickable list of possibilities.\n\nAt the bottom of the list, there‚Äôs a Save button. Press it to save your changes.\n\n\n\n\n\n\nSelect the participants option on the menu.\nFind the participant UC207YW and tick their checkbox.\n\n\n\n\n\n\n\nNote\n\n\n\nAlthough we‚Äôre only going to force-align the utterances of a single speaker in this exercise, you can align the utterances of multiple speakers at once, by ticking all their checkboxes on the participants page before continuing with the next step‚Ä¶\n\n\n\nPress the All Utterances button above the list of participants\nPress List.\nYou will see a progress bar while all their utterances are identified. Then a results page will be displayed, listing the first 20 utterances.\nPress the Mfa button at the bottom.\nYou will see a progress bar appear, while LaBB-CAT gathers the files that MFA needs, runs MFA, and parses the resulting alignments. This will take a few minutes.\n\n\n\n\nOnce forced alignment is complete, you can inspect/correct alignments using LaBB-CAT‚Äôs integration with Praat.\n\nGo to the transcripts page and open the UC207YW.eaf transcript.\nTick both the mfa layer and the segment layer.¬†\nYou will see which lines have been force-aligned, as they have an MFA timestamp, and have the segment layer filled in.\n\n\nThe interactive transcript page doesn‚Äôt show you the alignments of the words or phones, but you can see those using Praat. You can open individual utterances in Praat directly from the transcript page, but first, the LaBB-CAT/Praat integration has to be set up; this only has to be done once:\n\nOn the top-right of the page, above the playback controls, there‚Äôs a Praat icon ¬†- click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\nYou may be asked whether to allow the ‚ÄúLaBB-CAT Integration Applet‚Äù to run. If you tick the ‚ÄúDo not show this again‚Äù option, then this message will not appear every time you open a transcript.\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\n\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶\n\nClick on a line that has been aligned, and select the Open Text Grid in Praat option on the menu.\nYou may be asked you if want to allow access to the ‚ÄúLaBB-CAT Integration Applet‚Äù - if so, tick ‚ÄúDo not show this again‚Äù, and click Allow.\nPraat should open, and show you a spectrogram of the line‚Äôs audio, with a TextGrid below that includes the words and the segments.\nIf you click on a word, and hit the tabtab key, the word‚Äôs interval is played. Try out various words, and see what you think about how accurate HTK has been with its alignment.\nTry this out with different lines in the transcript.\nYou will see that in some cases the alignment is pretty good, and in other cases, it‚Äôs not so good. In the not-so-good cases, see if you can figure out why HTK got it wrong.\n\n\nYou may have noticed that, each time you open an utterance in Praat, a button appears in the transcript to the left of the line, labelled Import Changes. This button allows you to save any adjustments you might want to make to the alignments back into the LaBB-CAT database.\n\nIf you feel confident using Praat, open an utterance TextGrid, adjust the alignments of the words an phones so that they‚Äôre more accurate, and then click the Import Changes button in the transcript.\n\n\n\n\n\n\n\nWarning\n\n\n\nThese changes are flagged as manual edits, so if forced-alignment is run again, they will not be over-written with new bad alignments. Therefore it‚Äôs important that the changes you make are actually improvements, because HTK will never change them again.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThere are some rules about what you can change:\n\nYou‚Äôre not allowed to add or delete words (if this is necessary, it should be done by correcting the transcript instead).\nAll the phones must be within the bounds of their own word.\nThe start of the first phone should line up with the start of the word, and the end of the last phone should line up with the end of the word.\nYou should not change the alignment of the utterance itself (which would only be possible if you select the Open Text Grid incl.¬†¬± 1 utterance in Praat option).\n\n\n\nIn this exercise, you have seen how MFA can be used to compute word and phone alignments automatically from your data, and when using a pronunciation dictionary and pre-trained acoustic models, the process is very straightforward.\nSuch dictionaries/models are only available for a limited number of languages, but if you have a pronunciation dictionary for the language your corpus uses, MFA can also be used to train its own acoustic models from your corpus, and then use them for forced alignment. This process involves a fair amount of careful transcription, tagging, and dictionary filling.\nPerfect automatic alignments are not guaranteed, but LaBB-CAT has a mechanism for manually correcting poor alignments.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8b. MFA"
    ]
  },
  {
    "objectID": "worksheets/course/8b-forced-alignment-mfa.html#installation",
    "href": "worksheets/course/8b-forced-alignment-mfa.html#installation",
    "title": "8b. MFA",
    "section": "",
    "text": "MFA is a 3rd-party tool (https://montrealcorpustools.github.io/Montreal-Forced-Aligner/) that LaBB-CAT integrates with via a Layer Manager module. MFA is not included as part of LaBB-CAT, and so it must be installed on the server you have installed LaBB-CAT on before you can integrate LaBB-CAT with it.\nIf MFA has not been installed already, please follow the following steps, depending on the operatings system of your LaBB-CAT server:\n\n\n\n\n\n\nNoteLinux\n\n\n\n\n\nTo install the Montreal Forced Aligner on Linux systems for all users, so that your web server can access it if required:\n\nDownload Miniconda:\nwget https://repo.anaconda.com/miniconda/Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nStart the installer:\nsudo bash Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nWhen asked the location to install Miniconda, use:\n/opt/conda\nWhen asked whether the installer should initialize Miniconda, this is unnecessary so you can respond no\nChange ownership of the conda files):\nsudo chown -R $USERNAME:$USERNAME /opt/conda\nMake conda accessible to all users (so you web server can access MFA):\nchmod -R go-w /opt/conda\nchmod -R go+rX /opt/conda\nInstall the Montreal Forced Aligner\n/opt/conda/bin/conda create -n aligner -c conda-forge montreal-forced-aligner=3.2.1\n\n\n\n\n\n\n\n\n\n\nNoteWindows\n\n\n\n\n\nTo install the Montreal Forced Aligner on Windows systems for all users, so that your web server can access it if required:\n\nDownload the Miniconda installer:¬†¬†¬†\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\nStart the installer by double-clicking it.\nWhen asked, select the ‚ÄúInstall for all users‚Äù option. This will install conda somewhere like\nC:\\ProgramData\\Miniconda3\nWhen asked, tick the add to PATH option.\nInstall the Montreal Forced Aligner by specifying a path to the environment\nconda create -c conda-forge -p C:\\ProgramData\\Miniconda3\\envs\\aligner montreal-forced-aligner=3.2.1\n\nIf you have problems getting MFA working on Windows, check Troubleshooting on Windows section of the MFA Installation instructions.\n\n\n\n\n\n\n\n\n\nNoteDocker Container\n\n\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, it can download and install Miniconda and MFA itself, as part of the process of installing the MFA Manager (below)\nThere is no need for a separate installation of the MFA software.\n\n\n\n\n\n\nOnce MFA has been installed, you have to install the MFA Manager, which is the LaBB-CAT module that provides MFA with all the data it needs, and then saves to alignments MFA produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link at the bottom.\nFind MFA Manager in the list, and press its Install button and then press Install again.\n\nAs long as MFA has been installed for all users, you should see a box that‚Äôs already filled in with the location that MFA was installed to in the Path to MFA box.\n\nIf the Path to MFA box is empty and there‚Äôs an Attempt to Install MFA button, press the button, and LaBB-CAT will try to install MFA on the server for you. This process can take a few minutes, and the Configure button will be disabled until it‚Äôs finished.\nPress Configure to continue the layer manager installation.\nYou will see a window open with some information about integrating with MFA, including the information you‚Äôve already read above.\nNow you need to add a phrase layer for the MFA configuration:\n\nLayer ID: mfa\nType: Text\nAlignment: Intervals\nManager: MFA Manager\nGenerate: always\nDescription: MFA alignment time\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nInitially, there will be a ‚Äòspinner‚Äô and the form will be disabled while LaBB-CAT is making internet requests in order to retrieve lists of available dictionaries and acoustic models.\nThis process may take a few seconds, depending on LaBB-CAT‚Äôs connection to the internet.\n\n\n\nWhen you configure the layer, set the following options:\n\nDictionary Name: english_mfa\nPretrained Acoustic Models: english_mfa\nThe rest of the options can be left as their default values.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a ‚Äòtool tip‚Äô that describes what the option is for.\n\n\n\nPress Set Parameters\nWe will not press Regenerate to force-align the whole corpus just yet. We need to tweak a few other settings, and then align a single participant‚Äôs speech.\n\nWhen forced-alignment is done, the resulting aligned phones will be saved on the segment layer. By default, this has it‚Äôs type set to Phonological, which assumes that the phoneme symbols will be those defined by the CELEX DISC encoding. However, MFA uses its own phoneme symbols, which are different from the CELEX DISC ones.\nTo make later processing easier, we‚Äôre going to change the type of the segment layer to Text, and let LaBB-CAT know what the possible phoneme labels are.\n\nSelect the segment layers menu option.\nYou will see a single layer listed, called segment.\nChange the Type of the segment layer to Text.\nPress Save.\nA new icon appears with a tag  icon - if you hover the mouse over this button, you‚Äôll see it‚Äôs for setting Valid labels.\nPress the Valid labels icon\nYou will see a page that allows you to add a list of possible labels.\nBut we don‚Äôt know what the valid labels are yet. The labels used by MFA depend on the dictionary/models selected when defining the layer. The details for all dictionaries are in MFA Models documentation.\nOpen the MFA Models documentation for english_mfa.\nYou will see a page that includes information about the dictionary including the Phones used by it.\nSelect and copy the list of phones used by the english_mfa dictionary - i.e.¬†all of these:\n\na aj aw aÀê b b ≤ c c ∞ d d í d ≤ e ej f f ≤ h i iÀê j \nk k ∞ l m m ≤ mÃ© n nÃ© o ow p p ∞ p ≤ s t t É t ∞ t ≤\nu uÀê v v ≤ w z √¶ √ß √∞ ≈ã …ê …ë …ëÀê …í …íÀê …î …îj  …ô …ôw \n…ö …õ …õÀê …ú …úÀê …ù …ü …° …™ …´ …´Ã© …± …≤ …π …æ  É  â  âÀê  ä  é  í  î Œ∏\n\nBack in the Valid Labels page in LaBB-CAT, paste all of the phone symbols into the box labelled Label\n\nPress New.\nYou will see that all of the labels are separately added to the list of valid labels.\n\n\nDefining this list for the segment layer means that, when you search the segment layer for specific phones, LaBB-CAT can display a clickable list of possibilities.\n\nAt the bottom of the list, there‚Äôs a Save button. Press it to save your changes.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8b. MFA"
    ]
  },
  {
    "objectID": "worksheets/course/8b-forced-alignment-mfa.html#alignment",
    "href": "worksheets/course/8b-forced-alignment-mfa.html#alignment",
    "title": "8b. MFA",
    "section": "",
    "text": "Select the participants option on the menu.\nFind the participant UC207YW and tick their checkbox.\n\n\n\n\n\n\n\nNote\n\n\n\nAlthough we‚Äôre only going to force-align the utterances of a single speaker in this exercise, you can align the utterances of multiple speakers at once, by ticking all their checkboxes on the participants page before continuing with the next step‚Ä¶\n\n\n\nPress the All Utterances button above the list of participants\nPress List.\nYou will see a progress bar while all their utterances are identified. Then a results page will be displayed, listing the first 20 utterances.\nPress the Mfa button at the bottom.\nYou will see a progress bar appear, while LaBB-CAT gathers the files that MFA needs, runs MFA, and parses the resulting alignments. This will take a few minutes.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8b. MFA"
    ]
  },
  {
    "objectID": "worksheets/course/8b-forced-alignment-mfa.html#inspectioncorrection",
    "href": "worksheets/course/8b-forced-alignment-mfa.html#inspectioncorrection",
    "title": "8b. MFA",
    "section": "",
    "text": "Once forced alignment is complete, you can inspect/correct alignments using LaBB-CAT‚Äôs integration with Praat.\n\nGo to the transcripts page and open the UC207YW.eaf transcript.\nTick both the mfa layer and the segment layer.¬†\nYou will see which lines have been force-aligned, as they have an MFA timestamp, and have the segment layer filled in.\n\n\nThe interactive transcript page doesn‚Äôt show you the alignments of the words or phones, but you can see those using Praat. You can open individual utterances in Praat directly from the transcript page, but first, the LaBB-CAT/Praat integration has to be set up; this only has to be done once:\n\nOn the top-right of the page, above the playback controls, there‚Äôs a Praat icon ¬†- click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\nYou may be asked whether to allow the ‚ÄúLaBB-CAT Integration Applet‚Äù to run. If you tick the ‚ÄúDo not show this again‚Äù option, then this message will not appear every time you open a transcript.\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\n\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶\n\nClick on a line that has been aligned, and select the Open Text Grid in Praat option on the menu.\nYou may be asked you if want to allow access to the ‚ÄúLaBB-CAT Integration Applet‚Äù - if so, tick ‚ÄúDo not show this again‚Äù, and click Allow.\nPraat should open, and show you a spectrogram of the line‚Äôs audio, with a TextGrid below that includes the words and the segments.\nIf you click on a word, and hit the tabtab key, the word‚Äôs interval is played. Try out various words, and see what you think about how accurate HTK has been with its alignment.\nTry this out with different lines in the transcript.\nYou will see that in some cases the alignment is pretty good, and in other cases, it‚Äôs not so good. In the not-so-good cases, see if you can figure out why HTK got it wrong.\n\n\nYou may have noticed that, each time you open an utterance in Praat, a button appears in the transcript to the left of the line, labelled Import Changes. This button allows you to save any adjustments you might want to make to the alignments back into the LaBB-CAT database.\n\nIf you feel confident using Praat, open an utterance TextGrid, adjust the alignments of the words an phones so that they‚Äôre more accurate, and then click the Import Changes button in the transcript.\n\n\n\n\n\n\n\nWarning\n\n\n\nThese changes are flagged as manual edits, so if forced-alignment is run again, they will not be over-written with new bad alignments. Therefore it‚Äôs important that the changes you make are actually improvements, because HTK will never change them again.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThere are some rules about what you can change:\n\nYou‚Äôre not allowed to add or delete words (if this is necessary, it should be done by correcting the transcript instead).\nAll the phones must be within the bounds of their own word.\nThe start of the first phone should line up with the start of the word, and the end of the last phone should line up with the end of the word.\nYou should not change the alignment of the utterance itself (which would only be possible if you select the Open Text Grid incl.¬†¬± 1 utterance in Praat option).\n\n\n\nIn this exercise, you have seen how MFA can be used to compute word and phone alignments automatically from your data, and when using a pronunciation dictionary and pre-trained acoustic models, the process is very straightforward.\nSuch dictionaries/models are only available for a limited number of languages, but if you have a pronunciation dictionary for the language your corpus uses, MFA can also be used to train its own acoustic models from your corpus, and then use them for forced alignment. This process involves a fair amount of careful transcription, tagging, and dictionary filling.\nPerfect automatic alignments are not guaranteed, but LaBB-CAT has a mechanism for manually correcting poor alignments.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8b. MFA"
    ]
  },
  {
    "objectID": "worksheets/course/7a-lexicon-celex.html",
    "href": "worksheets/course/7a-lexicon-celex.html",
    "title": "7a. CELEX",
    "section": "",
    "text": "LaBB-CAT can be integrated with the CELEX lexicon, which can be purchased from the Linguistic Data Consortium (LDC) and includes lemma, part of speech, morphological, phonological, and frequency information for English, German, and Dutch.\n(If you don‚Äôt have CELEX, there is an alternative version of this exercise that uses the free ‚ÄòCMU Pronunouncing Dictionary‚Äô lexicon, which you can work through instead.)\nIn this exercise you will:\n\nInstall the CELEX layer manager\nUse it to create new annotations for word morphology, syntactic category, and phonology\nCompute speech rate in syllables per minute\nIncorporate the new layers in more sophisticated searches\n\n\n\nThe first thing we‚Äôre going to do is install the CELEX layer manager.\nThis requires having the LDC‚Äôs CELEX data files on your computer, which will be processed by the layer manager in order to insert the data into the LaBB-CAT database. If you received the CELEX files in a ZIP file, you need to unzip that into a folder, and remember the location of that folder, as you‚Äôll need it during the installation process.\n\nFirst of all, create a new project called CELEX with a description: CELEX Annotations\nClick the layer managers menu option.\nClick the List of layer managers that are not yet installed link near the bottom.\nFind ‚ÄúCELEX English‚Äù in the list, and click its Install button.\nYou will see a form asking for various details. You can leave most of these with their default values. The one exception is the CELEX ¬†ENGLISH data folder option.\nSet the CELEX ENGLISH data folder parameter to the directory path that leads to the CELEX files on your LaBB-CAT computer.\nClick Install.\nYou will see a progress bar while the layer manager loads the data from the CELEX files into the LaBB-CAT database. This will take a few minutes.\nOnce it‚Äôs finished, you will see a new window open with information about the CELEX English layer manager.\nReading this information page, you will see some instructions on how to create CELEX annotation layers - leave this tab open for now, as we‚Äôre going to need those instructions next.\n\n\n\n\nNow that we‚Äôve installed the layer manager, we‚Äôll create our first annotations from CELEX - a layer with morphological annotations.\n\nFollow the instructions on the information page to create a layer for word morphology - i.e.:\n\nLayer ID: morphology\nType: Text\nAlignment: None\nManager: CELEX English\nProject: CELEX\nDescript Morphological parses\n...configured with the Morphology option selected, and the default values for everything else.\n\n\n\n\n\n\n\n\nTip\n\n\n\n If you‚Äôre curious about what the configuration options do, and how you can test out the results of your configuration, check the online help page when you are configuring the layer.\n\n\n\nOnce the layer has finished generating, select the transcripts menu option, and open the first transcript in the list.\nOn the Layers tab, tick the CELEX project, and then tick your new morphology layer.\nYou will see that each word is tagged with morphological information.\n\nIf you were to do a search for words ending in ‚Äúing‚Äù on the orthography layer, you would get both gerunds like ‚Äúcoming‚Äù and also words like ‚Äúthing‚Äù and ‚Äúanything‚Äù whose ‚Äúing‚Äù is part of the base word, not a morphological affix. You can now tell these apart in searches, by searching the morphology layer for words that end in ‚Äú+ing‚Äù.\n\nDo a search on the orthography layer of words ending in ‚Äúing‚Äù. Leave the results tab open, so you can compare these results with the next search ‚Ä¶\nNow do a search on the morphology layer of words ending in ‚Äú+ing‚Äù, and compare the results.\n\n\n\n\n\n\n\nImportant\n\n\n\nRemember that in regular expressions the ‚Äòplus‚Äô character + has a special meaning - it means ‚Äúone or more of the previous thing‚Äù.\nIn order to search for a literal ‚Äú+‚Äù in the annotation, you have to ‚Äòescape‚Äô the +. Consult the Regular Expression section of the help page to figure out how to do that.\n\n\n\n\n\nNow we will create a layer for syntactic categories from CELEX.\n\nCreate a new layer for annotating words with their syntactic categories from CELEX:\n\nLayer ID: syntacticCategory\nType: Text\nAlignment: None\nManager: CELEX English\nProject: CELEX\nDescription: All possible syntactic categories\n...configured with the Syntax option ticked, and the default values for everything else.\n\nOnce the layer has finished generating, go to the search page and do a search for the word ‚Äúfine‚Äù on the orthography layer.\nOpen the transcript of the first match.\nOn the Layers tab, tick the syntactic category layer to display the annotations that have just been computed.\nNow find your instance of the word ‚Äúfine‚Äù again (it‚Äôs highlighted in the transcript text).\nYou will see that it has ‚ÄúA‚Äù for adjective above it.\nClick on the word ‚Äúfine‚Äù and select the Edit option on the menu that appears.\nNow look for the syntacticCategory layer. You will see that, in addition to ‚ÄúA‚Äù, there are several other annotations that are invisible on the transcript.\nThese are all the possible syntactic categories for the word ‚Äúfine‚Äù ordered most-frequent first. Only the first one is displayed in the transcript, but when you do searches, all of them are searched.\nOn the search page, do a search for fine on the orthography layer and A on the syntactic category layer in the same column.\nThis has the effect of ‚ÄòANDing‚Äô together the patterns for a single word, so it will give you words that have ‚Äúfine‚Äù on the orthography layer have A on the syntacticCategory* layer.\n\nDo another search, for fine on the orthography layer and V on the syntacticCategory layer.\nNotice that the results are the same. This is because all of the instances of ‚Äúfine‚Äù are marked as ‚Äòpossibly an adjective‚Äô and also ‚Äòpossibly a verb‚Äô.\n\nAs you can see, simply tagging tokens with all possible syntactic categories from the CELEX lexicon leads to search results that are heavy on false positives. In order to tag tokens with a single syntactic category, we would need to perform ‚Äòdisambiguation‚Äô by taking the surrounding transcript into account, in order to decide which of all the possibilities is the correct syntactic category. LaBB-CAT has two layer managers that perform such part-of-speech tagging: the ‚ÄúStanfordPosTagger‚Äù and the ‚ÄúMorTagger‚Äù. Neither of these use the exact same syntactic labels that are used by CELEX.\n\n\n\nCELEX can be used to retrieve syllable-counts for words, which in turn can be used, with duration information, to compute speech rate. For each line in each transcript, we already have the start time and the end time, from which we can calculate the duration of the line. All we need now is the number of syllables per line, and we can compute the syllables-per-minute speech rate for each line.\n\nCreate a new word layer:\n\nLayer ID: syllableCount\nType: Number\nAlignment: None\nManager: CELEX English\nProject: CELEX\nDescription: Number of syllables\n...configured with the Syllable count option ticked\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nEnsure the First match only option is ticked for this layer.\n If you‚Äôre not sure why, this is explained in the online help for the layer configuration page.\n\n\n\nOnce the layer has finished generating, have a look at a transcript or two to check the results.\nClick the phrase layers menu option.\nAdd a new phrase layer for speech rate. Key points are:\n\nThe layer manager to use is the Statistics Layer Manager.\nThe layer to summarize should be the syllableCount layer.\nThe statistic to compute is Label-Sum Rate (per minute)\n\n\n\n\n\n\nTip\n\n\n\n If in doubt, the online help may help.\n\n\nYou can calculate over whatever scopes you like, but if you select Utterances this will give you a local speech rate which might be useful when looking at individual search results, and Participants might be interesting if you want to compare speech rate between speakers.\n\nHave a look in a transcript or two, and a participant or two, to see what the annotations you just generated look like.\n\n\n\n\nNow we‚Äôre going to create a phonemic-transcription layer.\n\nCreate a new word layer, called phonemes, similar to previous CELEX layers. Key points are:\n\nThe layer type should be set to Phonological.\nThe Phonology option should be selected in the layer configuration.\nMake sure the Pronounce Event Override option is ticked.\nThis means that if the original ELAN transcript contained a ‚Äòpronounce‚Äô annotation for a word (these are marked in ELAN with square brackets), specifying its pronunciation, then the ‚Äòpronounce‚Äô annotation is used instead of the phonemic transcription from CELEX.\nEnsure the Generates Segments option is un-ticked.\nThis option allows the layer manager to create segment (sub-word) annotations from the phonemic transcriptions, but we don‚Äôt want this because in the next exercise, we‚Äôre going to get HTK to do that instead.\n\nOnce the layer is finished generating, go to a transcript to see what it looks like.\n\nYou will notice that the annotations are displayed using IPA symbols. However, CELEX doesn‚Äôt use IPA symbols directly, it actually uses the ‚ÄòDISC‚Äô encoding for phonemes, which uses ordinary ‚Äòtypewriter‚Äô characters (ASCII), and uses exactly one character per phoneme. The IPA symbols are being displayed by LaBB-CAT to provide a linguist-friendly interpretation of the phonemic transcription. But you can disable this to see the underlying DISC characters by de-selecting the ‚Äòinterpretation‚Äô option on the layer in the transcript.\n\nOn the Layers tab, immediately to the right of the phonemes layer, there is a tags icon .\nHover the mouse over it to check the description, and then click it.\n\nYou may find that this is somewhat harder to read. Diphthongs are generally represented by digits, schwa is @, and various other characters are used to represent affricates, etc.\nIt‚Äôs nice to display the IPA symbols, but it‚Äôs important to understand the DISC symbols (shown in table below, because they are what we have to use when searching on the phonemes layer, which we are going to try now.\n\n\n\n\nIPA\nDISC\n¬†\n¬†\nIPA\nDISC\n¬†\n\n\np\np\npat\n¬†\n…™\nI\nKIT\n\n\nb\nb\nbad\n¬†\nŒµ\nE\nDRESS\n\n\nt\nt\ntack\n¬†\n√¶\n{\nTRAP\n\n\nd\nd\ndad\n¬†\n å\nV\nSTRUT\n\n\nk\nk\ncad\n¬†\n…í\nQ\nLOT\n\n\ng\ng\ngame\n¬†\n ä\nU\nFOOT\n\n\n≈ã\nN\nbang\n¬†\n…ô\n@\nanother\n\n\nm\nm\nmat\n¬†\ni:\ni\nFLEECE\n\n\nn\nn\nnat\n¬†\nŒ±:¬†\n#\nSTART\n\n\nl\nl\nlad\n¬†\n…î:\n$\nTHOUGHT\n\n\nr\nr\nrat\n¬†\nu:\nu\nGOOSE\n\n\nf\nf\nfat\n¬†\n…ú:\n3\nNURSE\n\n\nv\nv\nvat\n¬†\ne…™\n1\nFACE\n\n\nŒ∏\nT\nthin\n¬†\nŒ±…™\n2\nPRICE\n\n\n√∞\nD\nthen\n¬†\n…î…™\n4\nCHOICE\n\n\ns\ns\nsap\n¬†\n…ô ä\n5\nGOAT\n\n\nz\nz\nzap\n¬†\nŒ± ä\n6\nMOUTH\n\n\n‚à´\nS\nsheep\n¬†\n…™…ô\n7\nNEAR\n\n\n í\nZ\nmeasure\n¬†\nŒµ…ô\n8\nSQUARE\n\n\nj\nj\nyank\n¬†\n ä…ô\n9\nCURE\n\n\nx\nx\nloch\n¬†\n√¶\nc\ntimbre\n\n\nh\nh\nhad\n¬†\n…ëÃÉÀê\nq\nd√©tente\n\n\nw\nw\nwet\n¬†\n√¶ÃÉÀê\n0\nlingerie\n\n\n ß\nJ\ncheap\n¬†\n…íÃÉÀê\n~\nbouillon\n\n\n §\n_\njeep\n¬†\n¬†\n¬†\n¬†\n\n\n≈ãÃ©\nC\nbacon\n¬†\n¬†\n¬†\n¬†\n\n\nmÃ©\nF\nidealism\n¬†\n¬†\n¬†\n¬†\n\n\nnÃ©\nH\nburden\n¬†\n¬†\n¬†\n¬†\n\n\nlÃ©\nP\ndangle\n¬†\n¬†\n¬†\n¬†\n\n\n\n\nGo to the search page.\nCreate a search matrix that‚Äôs two words wide, and includes the orthography and phonemes layers.\n\nNow we‚Äôre going to do a search for the word ‚Äúthe‚Äù followed by a word that starts with schwa.\n\nType the in the first orthography box.\nClick the second box on the phonemes layer, but don‚Äôt enter anything in the box yet.\nThe box has a little  button to the right of it.\nHover the mouse over it to see what it says, and then click it.\nYou will see that a section opens with a bunch of phoneme symbols on it.\nFind the schwa symbol …ô and click it.\nYou will see that a @ symbol appears in the box.\n@ is the DISC symbol for …ô, so in order to search for schwa, we have to use it in our search pattern.\nWe want words that start with schwa, so type .* after the @ symbol.\nClick Search.\n\nYou will see that some of the words being matched are words that you might not normally think start with a schwa. LaBB-CAT is matching words against all their possible phonemic transcriptions, so if CELEX has multiple possible pronunciations for a word, and one of them starts with schwa, it will be matched.\nYou can check this by clicking on a match, and then hovering your mouse over the phonemic transcription above the matching token. This displays all the annotations for the given token, i.e.¬†in this case all the possible pronunciations of that word.\nNow that we have phonemic transcripts, we can do a better job of the search we tried in an earlier exercise ‚Äì ‚Äúthe‚Äù followed by a word starting with a vowel‚Ä¶\n\nChange your search so that, instead of just @ at the beginning of the word, it matches any vowel.\n\nYou could use the square-brackets [] at the start of your pattern, and type all vowel symbols inside them - Note that the vowels in the DISC representation extend beyond a, e, i, o, and u - you should add in all the vowels you see in the list that appears when you expand the IPA helper, including all the diphthongs.\nAlternatively, you can simply click the VOWEL link in the ‚ÄòPhoneme Symbol Selector‚Äô, which will add all the DISC vowels for you, already enclosed in square-brackets.\n\nRun the search and check that it‚Äôs giving you what you expect. Notice that now there are no ‚Äòfalse positives‚Äô like ‚Äúthe one‚Äù that we were getting when searching by orthography alone.\n\nNow that you‚Äôve generated a few different layers, and have seen how the search matrix works, you might want to try out some of the following searches, or invent some others:\n\nInstances of an article followed by a noun\nWords which have the DRESS vowel as the second phoneme\nThe word ‚Äúthe‚Äù followed by a word beginning with the phoneme /k/\nWords ending with schwa, followed by words beginning with /p/ or /b/\nWords that begin with ‚Äúk‚Äù in their spelling, but begin with the phoneme /n/\nWords that begin with ‚Äúk‚Äù in their spelling, but do not begin with the phoneme /n/\nPlurals that end in /s/ or /z/ or /…™z/",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "7. Lexicons",
      "7a. CELEX"
    ]
  },
  {
    "objectID": "worksheets/course/7a-lexicon-celex.html#installation",
    "href": "worksheets/course/7a-lexicon-celex.html#installation",
    "title": "7a. CELEX",
    "section": "",
    "text": "The first thing we‚Äôre going to do is install the CELEX layer manager.\nThis requires having the LDC‚Äôs CELEX data files on your computer, which will be processed by the layer manager in order to insert the data into the LaBB-CAT database. If you received the CELEX files in a ZIP file, you need to unzip that into a folder, and remember the location of that folder, as you‚Äôll need it during the installation process.\n\nFirst of all, create a new project called CELEX with a description: CELEX Annotations\nClick the layer managers menu option.\nClick the List of layer managers that are not yet installed link near the bottom.\nFind ‚ÄúCELEX English‚Äù in the list, and click its Install button.\nYou will see a form asking for various details. You can leave most of these with their default values. The one exception is the CELEX ¬†ENGLISH data folder option.\nSet the CELEX ENGLISH data folder parameter to the directory path that leads to the CELEX files on your LaBB-CAT computer.\nClick Install.\nYou will see a progress bar while the layer manager loads the data from the CELEX files into the LaBB-CAT database. This will take a few minutes.\nOnce it‚Äôs finished, you will see a new window open with information about the CELEX English layer manager.\nReading this information page, you will see some instructions on how to create CELEX annotation layers - leave this tab open for now, as we‚Äôre going to need those instructions next.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "7. Lexicons",
      "7a. CELEX"
    ]
  },
  {
    "objectID": "worksheets/course/7a-lexicon-celex.html#morphology",
    "href": "worksheets/course/7a-lexicon-celex.html#morphology",
    "title": "7a. CELEX",
    "section": "",
    "text": "Now that we‚Äôve installed the layer manager, we‚Äôll create our first annotations from CELEX - a layer with morphological annotations.\n\nFollow the instructions on the information page to create a layer for word morphology - i.e.:\n\nLayer ID: morphology\nType: Text\nAlignment: None\nManager: CELEX English\nProject: CELEX\nDescript Morphological parses\n...configured with the Morphology option selected, and the default values for everything else.\n\n\n\n\n\n\n\n\nTip\n\n\n\n If you‚Äôre curious about what the configuration options do, and how you can test out the results of your configuration, check the online help page when you are configuring the layer.\n\n\n\nOnce the layer has finished generating, select the transcripts menu option, and open the first transcript in the list.\nOn the Layers tab, tick the CELEX project, and then tick your new morphology layer.\nYou will see that each word is tagged with morphological information.\n\nIf you were to do a search for words ending in ‚Äúing‚Äù on the orthography layer, you would get both gerunds like ‚Äúcoming‚Äù and also words like ‚Äúthing‚Äù and ‚Äúanything‚Äù whose ‚Äúing‚Äù is part of the base word, not a morphological affix. You can now tell these apart in searches, by searching the morphology layer for words that end in ‚Äú+ing‚Äù.\n\nDo a search on the orthography layer of words ending in ‚Äúing‚Äù. Leave the results tab open, so you can compare these results with the next search ‚Ä¶\nNow do a search on the morphology layer of words ending in ‚Äú+ing‚Äù, and compare the results.\n\n\n\n\n\n\n\nImportant\n\n\n\nRemember that in regular expressions the ‚Äòplus‚Äô character + has a special meaning - it means ‚Äúone or more of the previous thing‚Äù.\nIn order to search for a literal ‚Äú+‚Äù in the annotation, you have to ‚Äòescape‚Äô the +. Consult the Regular Expression section of the help page to figure out how to do that.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "7. Lexicons",
      "7a. CELEX"
    ]
  },
  {
    "objectID": "worksheets/course/7a-lexicon-celex.html#syntactic-categories",
    "href": "worksheets/course/7a-lexicon-celex.html#syntactic-categories",
    "title": "7a. CELEX",
    "section": "",
    "text": "Now we will create a layer for syntactic categories from CELEX.\n\nCreate a new layer for annotating words with their syntactic categories from CELEX:\n\nLayer ID: syntacticCategory\nType: Text\nAlignment: None\nManager: CELEX English\nProject: CELEX\nDescription: All possible syntactic categories\n...configured with the Syntax option ticked, and the default values for everything else.\n\nOnce the layer has finished generating, go to the search page and do a search for the word ‚Äúfine‚Äù on the orthography layer.\nOpen the transcript of the first match.\nOn the Layers tab, tick the syntactic category layer to display the annotations that have just been computed.\nNow find your instance of the word ‚Äúfine‚Äù again (it‚Äôs highlighted in the transcript text).\nYou will see that it has ‚ÄúA‚Äù for adjective above it.\nClick on the word ‚Äúfine‚Äù and select the Edit option on the menu that appears.\nNow look for the syntacticCategory layer. You will see that, in addition to ‚ÄúA‚Äù, there are several other annotations that are invisible on the transcript.\nThese are all the possible syntactic categories for the word ‚Äúfine‚Äù ordered most-frequent first. Only the first one is displayed in the transcript, but when you do searches, all of them are searched.\nOn the search page, do a search for fine on the orthography layer and A on the syntactic category layer in the same column.\nThis has the effect of ‚ÄòANDing‚Äô together the patterns for a single word, so it will give you words that have ‚Äúfine‚Äù on the orthography layer have A on the syntacticCategory* layer.\n\nDo another search, for fine on the orthography layer and V on the syntacticCategory layer.\nNotice that the results are the same. This is because all of the instances of ‚Äúfine‚Äù are marked as ‚Äòpossibly an adjective‚Äô and also ‚Äòpossibly a verb‚Äô.\n\nAs you can see, simply tagging tokens with all possible syntactic categories from the CELEX lexicon leads to search results that are heavy on false positives. In order to tag tokens with a single syntactic category, we would need to perform ‚Äòdisambiguation‚Äô by taking the surrounding transcript into account, in order to decide which of all the possibilities is the correct syntactic category. LaBB-CAT has two layer managers that perform such part-of-speech tagging: the ‚ÄúStanfordPosTagger‚Äù and the ‚ÄúMorTagger‚Äù. Neither of these use the exact same syntactic labels that are used by CELEX.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "7. Lexicons",
      "7a. CELEX"
    ]
  },
  {
    "objectID": "worksheets/course/7a-lexicon-celex.html#syllable-count-and-speech-rate",
    "href": "worksheets/course/7a-lexicon-celex.html#syllable-count-and-speech-rate",
    "title": "7a. CELEX",
    "section": "",
    "text": "CELEX can be used to retrieve syllable-counts for words, which in turn can be used, with duration information, to compute speech rate. For each line in each transcript, we already have the start time and the end time, from which we can calculate the duration of the line. All we need now is the number of syllables per line, and we can compute the syllables-per-minute speech rate for each line.\n\nCreate a new word layer:\n\nLayer ID: syllableCount\nType: Number\nAlignment: None\nManager: CELEX English\nProject: CELEX\nDescription: Number of syllables\n...configured with the Syllable count option ticked\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nEnsure the First match only option is ticked for this layer.\n If you‚Äôre not sure why, this is explained in the online help for the layer configuration page.\n\n\n\nOnce the layer has finished generating, have a look at a transcript or two to check the results.\nClick the phrase layers menu option.\nAdd a new phrase layer for speech rate. Key points are:\n\nThe layer manager to use is the Statistics Layer Manager.\nThe layer to summarize should be the syllableCount layer.\nThe statistic to compute is Label-Sum Rate (per minute)\n\n\n\n\n\n\nTip\n\n\n\n If in doubt, the online help may help.\n\n\nYou can calculate over whatever scopes you like, but if you select Utterances this will give you a local speech rate which might be useful when looking at individual search results, and Participants might be interesting if you want to compare speech rate between speakers.\n\nHave a look in a transcript or two, and a participant or two, to see what the annotations you just generated look like.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "7. Lexicons",
      "7a. CELEX"
    ]
  },
  {
    "objectID": "worksheets/course/7a-lexicon-celex.html#phonology",
    "href": "worksheets/course/7a-lexicon-celex.html#phonology",
    "title": "7a. CELEX",
    "section": "",
    "text": "Now we‚Äôre going to create a phonemic-transcription layer.\n\nCreate a new word layer, called phonemes, similar to previous CELEX layers. Key points are:\n\nThe layer type should be set to Phonological.\nThe Phonology option should be selected in the layer configuration.\nMake sure the Pronounce Event Override option is ticked.\nThis means that if the original ELAN transcript contained a ‚Äòpronounce‚Äô annotation for a word (these are marked in ELAN with square brackets), specifying its pronunciation, then the ‚Äòpronounce‚Äô annotation is used instead of the phonemic transcription from CELEX.\nEnsure the Generates Segments option is un-ticked.\nThis option allows the layer manager to create segment (sub-word) annotations from the phonemic transcriptions, but we don‚Äôt want this because in the next exercise, we‚Äôre going to get HTK to do that instead.\n\nOnce the layer is finished generating, go to a transcript to see what it looks like.\n\nYou will notice that the annotations are displayed using IPA symbols. However, CELEX doesn‚Äôt use IPA symbols directly, it actually uses the ‚ÄòDISC‚Äô encoding for phonemes, which uses ordinary ‚Äòtypewriter‚Äô characters (ASCII), and uses exactly one character per phoneme. The IPA symbols are being displayed by LaBB-CAT to provide a linguist-friendly interpretation of the phonemic transcription. But you can disable this to see the underlying DISC characters by de-selecting the ‚Äòinterpretation‚Äô option on the layer in the transcript.\n\nOn the Layers tab, immediately to the right of the phonemes layer, there is a tags icon .\nHover the mouse over it to check the description, and then click it.\n\nYou may find that this is somewhat harder to read. Diphthongs are generally represented by digits, schwa is @, and various other characters are used to represent affricates, etc.\nIt‚Äôs nice to display the IPA symbols, but it‚Äôs important to understand the DISC symbols (shown in table below, because they are what we have to use when searching on the phonemes layer, which we are going to try now.\n\n\n\n\nIPA\nDISC\n¬†\n¬†\nIPA\nDISC\n¬†\n\n\np\np\npat\n¬†\n…™\nI\nKIT\n\n\nb\nb\nbad\n¬†\nŒµ\nE\nDRESS\n\n\nt\nt\ntack\n¬†\n√¶\n{\nTRAP\n\n\nd\nd\ndad\n¬†\n å\nV\nSTRUT\n\n\nk\nk\ncad\n¬†\n…í\nQ\nLOT\n\n\ng\ng\ngame\n¬†\n ä\nU\nFOOT\n\n\n≈ã\nN\nbang\n¬†\n…ô\n@\nanother\n\n\nm\nm\nmat\n¬†\ni:\ni\nFLEECE\n\n\nn\nn\nnat\n¬†\nŒ±:¬†\n#\nSTART\n\n\nl\nl\nlad\n¬†\n…î:\n$\nTHOUGHT\n\n\nr\nr\nrat\n¬†\nu:\nu\nGOOSE\n\n\nf\nf\nfat\n¬†\n…ú:\n3\nNURSE\n\n\nv\nv\nvat\n¬†\ne…™\n1\nFACE\n\n\nŒ∏\nT\nthin\n¬†\nŒ±…™\n2\nPRICE\n\n\n√∞\nD\nthen\n¬†\n…î…™\n4\nCHOICE\n\n\ns\ns\nsap\n¬†\n…ô ä\n5\nGOAT\n\n\nz\nz\nzap\n¬†\nŒ± ä\n6\nMOUTH\n\n\n‚à´\nS\nsheep\n¬†\n…™…ô\n7\nNEAR\n\n\n í\nZ\nmeasure\n¬†\nŒµ…ô\n8\nSQUARE\n\n\nj\nj\nyank\n¬†\n ä…ô\n9\nCURE\n\n\nx\nx\nloch\n¬†\n√¶\nc\ntimbre\n\n\nh\nh\nhad\n¬†\n…ëÃÉÀê\nq\nd√©tente\n\n\nw\nw\nwet\n¬†\n√¶ÃÉÀê\n0\nlingerie\n\n\n ß\nJ\ncheap\n¬†\n…íÃÉÀê\n~\nbouillon\n\n\n §\n_\njeep\n¬†\n¬†\n¬†\n¬†\n\n\n≈ãÃ©\nC\nbacon\n¬†\n¬†\n¬†\n¬†\n\n\nmÃ©\nF\nidealism\n¬†\n¬†\n¬†\n¬†\n\n\nnÃ©\nH\nburden\n¬†\n¬†\n¬†\n¬†\n\n\nlÃ©\nP\ndangle\n¬†\n¬†\n¬†\n¬†\n\n\n\n\nGo to the search page.\nCreate a search matrix that‚Äôs two words wide, and includes the orthography and phonemes layers.\n\nNow we‚Äôre going to do a search for the word ‚Äúthe‚Äù followed by a word that starts with schwa.\n\nType the in the first orthography box.\nClick the second box on the phonemes layer, but don‚Äôt enter anything in the box yet.\nThe box has a little  button to the right of it.\nHover the mouse over it to see what it says, and then click it.\nYou will see that a section opens with a bunch of phoneme symbols on it.\nFind the schwa symbol …ô and click it.\nYou will see that a @ symbol appears in the box.\n@ is the DISC symbol for …ô, so in order to search for schwa, we have to use it in our search pattern.\nWe want words that start with schwa, so type .* after the @ symbol.\nClick Search.\n\nYou will see that some of the words being matched are words that you might not normally think start with a schwa. LaBB-CAT is matching words against all their possible phonemic transcriptions, so if CELEX has multiple possible pronunciations for a word, and one of them starts with schwa, it will be matched.\nYou can check this by clicking on a match, and then hovering your mouse over the phonemic transcription above the matching token. This displays all the annotations for the given token, i.e.¬†in this case all the possible pronunciations of that word.\nNow that we have phonemic transcripts, we can do a better job of the search we tried in an earlier exercise ‚Äì ‚Äúthe‚Äù followed by a word starting with a vowel‚Ä¶\n\nChange your search so that, instead of just @ at the beginning of the word, it matches any vowel.\n\nYou could use the square-brackets [] at the start of your pattern, and type all vowel symbols inside them - Note that the vowels in the DISC representation extend beyond a, e, i, o, and u - you should add in all the vowels you see in the list that appears when you expand the IPA helper, including all the diphthongs.\nAlternatively, you can simply click the VOWEL link in the ‚ÄòPhoneme Symbol Selector‚Äô, which will add all the DISC vowels for you, already enclosed in square-brackets.\n\nRun the search and check that it‚Äôs giving you what you expect. Notice that now there are no ‚Äòfalse positives‚Äô like ‚Äúthe one‚Äù that we were getting when searching by orthography alone.\n\nNow that you‚Äôve generated a few different layers, and have seen how the search matrix works, you might want to try out some of the following searches, or invent some others:\n\nInstances of an article followed by a noun\nWords which have the DRESS vowel as the second phoneme\nThe word ‚Äúthe‚Äù followed by a word beginning with the phoneme /k/\nWords ending with schwa, followed by words beginning with /p/ or /b/\nWords that begin with ‚Äúk‚Äù in their spelling, but begin with the phoneme /n/\nWords that begin with ‚Äúk‚Äù in their spelling, but do not begin with the phoneme /n/\nPlurals that end in /s/ or /z/ or /…™z/",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "7. Lexicons",
      "7a. CELEX"
    ]
  },
  {
    "objectID": "worksheets/course/7b-lexicon-cmudict.html",
    "href": "worksheets/course/7b-lexicon-cmudict.html",
    "title": "7b. CMU Pronouncing Dictionary",
    "section": "",
    "text": "7b. CMU Pronouncing Dictionary\nLaBB-CAT can be integrated with the CMU Pronouncing Dictionary, which is a free pronunciation dictionary of English maintained by the Speech Group in the School of Computer Science at Carnegie Mellon University. The pronunciations are based on ‚ÄòAmerican English‚Äô, so are suitable for ‚ÄòAmerican English‚Äô recordings.\nIt can also serve as a free alternative to the CELEX lexicon (which is based on ‚ÄòBritish English‚Äô), for those that have not purchased CELEX, although is less ideal for ‚Äònon-rhotic‚Äô varieties of English.\nIn this exercise you will:\n\nInstall the CMU Pronouncing Dictionary layer manager\nUse it to create new annotations for word pronunciations\nIncorporate the new layers in more sophisticated searches\n\n\nThe first thing we‚Äôre going to do is install the CMU Dict layer manager‚Ä¶\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link near the bottom.\nFind ‚ÄúCMU Pronouncing Dictionary‚Äù in the list, and press its Install button, Install again, and then the Configure button. You will see a progress bar while the layer manager loads the data from the dictionary file into the LaBB-CAT database. This will take a minute or so.\nOnce it‚Äôs finished, you will see a page with information about the CMU Pronouncing Dictionary layer manager.\n\nNow that we‚Äôve installed the layer manager, we‚Äôll create a layer that contains word pronunciations.\n\nAdd a word layer managed by the CMU Pronouncing Dictionary for word pronunciation - i.e.:\n\nLayer ID: phonemes\nType: Phonological\nAlignment: None\nManager: CMU Pronouncing Dictionary\nDescription: CMU Pronouncing Dictionary pronunciations\n...configured with the Encoding: field set to CELEX DISC, and the default values for everything else.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a ‚Äòtool tip‚Äô that describes what the option is for.\n\n\n\nOnce the layer has finished generating, select the transcripts menu option, and find and open NB926_IsobelleDoig.eaf.\nTick your new phonemes layer.\nYou will see that each word is tagged with a phonemic transcription.\n\nYou will notice that the annotations are displayed using IPA symbols. However, the layer manager doesn‚Äôt use IPA symbols directly, it actually uses the ‚ÄòDISC‚Äô encoding for phonemes, which uses ordinary ‚Äòtypewriter‚Äô characters (ASCII), and uses exactly one character per phoneme.\nThe IPA symbols are being displayed by LaBB-CAT to provide a linguist-friendly interpretation of the phonemic transcription. But you can see the underlying DISC characters by disabling the ‚Äòinterpretation‚Äô option on the layer in the transcript.\n\nOn the Layers tab, to the right of the name of the phonemes layer, there is a small ‚Äòinterpretation‚Äô  selector.\nHover your mouse over the icon to see what it does.\nClick the selector to disable it, to see what the layer manager is actually producing.\n\nYou may find that this is somewhat harder to read. Diphthongs are generally represented by digits, and various other characters are used to represent affricates, etc.\nIt‚Äôs nice to display the IPA symbols, but it‚Äôs important to understand the DISC symbols (shown in the table below), because they are what we have to use when searching on the phonemes layer, which we are going to try now.\nAs you may have seen on the layer configuration page, there is another possible representation of the pronunciations, called ‚ÄòARPABET‚Äô; this is what is used in the original dictionary file published by CMU, and uses up to three uppercase characters per phoneme. While we‚Äôre not using ARPABET in this exercise, you can use it if you like, and the ARPABET symbols are included in the table. In the table, you will see that there are gaps where no ARPABET version of the phoneme is shown; this means that the CMU Pronouncing Dictionary contains no entries that include that phoneme.\n\n\n\n\nIPA\nDISC\nARPABET\n¬†\n¬†\nIPA\nDISC\nARPABET\n¬†\n\n\np\np\nP\npat\n¬†\n…™\nI\nIH\nKIT\n\n\nb\nb\nB\nbad\n¬†\nŒµ\nE\nEH\nDRESS\n\n\nt\nt\nT\ntack\n¬†\n√¶\n{\nAE\nTRAP\n\n\nd\nd\nD\ndad\n¬†\n å\nV\nAH\nSTRUT\n\n\nk\nk\nK\ncad\n¬†\n…í\nQ\nAH\nLOT\n\n\ng\ng\nG\ngame\n¬†\n ä\nU\nUH\nFOOT\n\n\n≈ã\nN\nNG\nbang\n¬†\n…ô\n@\n[vowel ending in 0]\nanother\n\n\nm\nm\nM\nmat\n¬†\ni:\ni\nIY\nFLEECE\n\n\nn\nn\nN\nnat\n¬†\nŒ±:¬†\n#\nAA\nfather\n\n\nl\nl\nL\nlad\n¬†\n…î:\n$\nAO\nTHOUGHT\n\n\nr\nr\nR\nrat\n¬†\nu:\nu\nUW\nGOOSE\n\n\nf\nf\nF\nfat\n¬†\n…ú:\n3\nER\nNURSE\n\n\nv\nv\nV\nvat\n¬†\ne…™\n1\nEY\nFACE\n\n\nŒ∏\nT\nTH\nthin\n¬†\nŒ±…™\n2\nAY\nPRICE\n\n\n√∞\nD\nDH\nthen\n¬†\n…î…™\n4\nOY\nCHOICE\n\n\ns\ns\nS\nsap\n¬†\n…ô ä\n5\nOW\nGOAT\n\n\nz\nz\nZ\nzap\n¬†\nŒ± ä\n6\nAW\nMOUTH\n\n\n‚à´\nS\nSH\nsheep\n¬†\n…™…ô\n7\n¬†\nNEAR\n\n\n í\nZ\nZH\nmeasure\n¬†\nŒµ…ô\n8\n¬†\nSQUARE\n\n\nj\nj\nY\nyank\n¬†\n ä…ô\n9\n¬†\nCURE\n\n\nx\nx\n¬†\nloch\n¬†\n√¶\nc\n¬†\ntimbre\n\n\nh\nh\nHH\nhad\n¬†\n…ëÃÉÀê\nq\n¬†\nd√©tente\n\n\nw\nw\nW\nwet\n¬†\n√¶ÃÉÀê\n0\n¬†\nlingerie\n\n\n ß\nJ\nCH\ncheap\n¬†\n…íÃÉÀê\n~\n¬†\nbouillon\n\n\n §\n_\nJH\njeep\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\n≈ãÃ©\nC\n¬†\nbacon\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nmÃ©\nF\n¬†\nidealism\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nnÃ©\nH\n¬†\nburden\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nlÃ©\nP\n¬†\n¬†dangle\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\n\nIn the transcript, you may notice there are gaps in the layer - i.e.¬†words that are not tagged with a pronunciation.\nFor example, around the middle of the transcript, the word ‚Äúcompactums‚Äù is not tagged, because the CMU Pronouncing Dictionary has no entry for that word.\nThere are various possible solutions for this, but one is to tag word tokens with their pronunciations directly in the transcript. This has been done in the case of ‚Äúcompactums‚Äù; manual pronunciation tags are saved on the pronounce layer\n\nScroll to the top of the transcript, un-tick the phonemes layer and tick the pronounce layer.\nWhen the transcript re-loads to show the pronounce layer tags, find ‚Äúcompactums‚Äù again.\n\nYou will see it has been tagged with an annotation labelled ‚Äúk…ômp√¶kt…ômz‚Äù, which was manually added by the transcriber of the transcript, in the original ELAN file.\nWe want all pronunciations to be present on the phonemes layer, which is currently managed by the CMU Pronouncing Dictionary layer manager. LaBB-CAT allows layers to have more than one layer manager, however; a layer can have a main layer manager, and a number of ‚Äòauxiliary‚Äô managers that perform extra annotation tasks.\nWe are going to add an auxiliary layer manager to the phonemes layer, which will copy any pronounce annotations it finds to the phonemes layer. This will fill in the gaps in the CMU Pronouncing dictionary, at least for the tokens that have manual pronounce tags.\n\nSelect the word layers option on the menu.\nOn the phonemes layer row, there are a number of buttons on the right, including one with a  icon. Hover your mouse over this button to see what it does, and then press it.\nYou will see a page explaining that will copy any manually tagged pronunciations from the from the pronounce layer into the phonemes.\nPres yes to continue.\nYou will see a progress bar while the auxiliary layer manager copies the pronounce annotations to the phonemes layer.\nWhen it‚Äôs finished, select the transcripts menu option, and open NB926_IsobelleDoig.eaf again.\nTick the phonemes layer.\nFind the word ‚Äúcompactums‚Äù in the transcript.\n\nYou will see it now has a phonemes tag, just like the rest of the word tokens.\n\nSelect the search option from the menu.\nSearch your new phonemes layer for words that start with h\n\nYou will see that the results contain words that you might not expect, like ‚Äúwhere‚Äù, ‚Äúwhich‚Äù and ‚Äúwhen‚Äù.\n\nClick one of these unexpected results, to open the transcript.\nYou will see that, in the transcript, the pronunciation appears to start with /w/, not with /h/.\nHover your mouse pointer over the phonemes tag you can see.\nYou will see that above the pronunciation that starts with /w/, another annotation appears that starts with /h/.\n\nThis word has multiple phonemes tags and hovering the mouse reveals all of them.\nOnly the first one is displayed in the transcript by default, but when you do searches, all of them are searched. This can result in unexpected matches like this, but it can be useful, as it ensures that when you search for a particular phonemic pattern, all possible tokens are returned, not just those that match on the most ‚Äònormal‚Äô transcription.\nNow we‚Äôre going to try to do a search for the word ‚Äúthe‚Äù followed by a word that starts with schwa.\n\nSelect the search option from the menu.\nCreate a search matrix that‚Äôs two words wide, and includes the orthography and phonemes layers.\nType the in the first orthography box.\nClick the second box on the phonemes layer, but don‚Äôt enter anything in the box yet.\nThe box has a  button to the right of it.\nHover the mouse over it to see what it says, and then click it.\nYou will see that a section opens with a bunch of phoneme symbols on it.\nFind the schwa symbol …ô and click it.\nYou will see that an @ symbol appears in the box.\n@ is the DISC symbol for /…ô/, so in order to search for schwa, we have to use it in our search pattern.\nWe want words that start with schwa, so type .* after the @ symbol.\nClick Search.\n\nIf you check the table above, you will see that …ô has no specific representation in ARPABET. This means that no CMU Pronouncing Dictionary pronunciations include schwa explicitly. Instead, ‚Äòunstressed‚Äô versions of other vowels are used. For example, the word ‚Äútranscription‚Äù is transcribed T R AE2 N S K R IH1 P SH AH0 N in the original dictionary file; the final vowel AH is the ‚ÄòSTRUT‚Äô vowel, and the 0 means it‚Äôs ‚Äòunstressed‚Äô. The layer manager translates this to DISC as tr{nskrIpS@n.\nNow that we have phonemic transcripts, we can do a better job of the search we tried in the first exercise - ‚Äúthe‚Äù followed by a word starting with a vowel‚Ä¶\n\nChange your search so that, instead of just @ at the beginning of the word, it matches any vowel.\n\n\n\n\n\n\n\nTip\n\n\n\nYou could use the square-brackets [] at the start of your pattern, and type all vowel symbols inside them ‚Äì note that the vowels in the DISC representation extend beyond a, e, i, o, and u ‚Äì you should add in all the vowels you see in the list that appears when you expand the IPA helper, including all the diphthongs.\nAlternatively, you can simply click the VOWEL link in the ‚ÄòPhoneme symbol selector‚Äô, which will add all the DISC vowels for you, already enclosed in square-brackets.\n\n\n\nRun the search and check that it‚Äôs giving you what you expect. Notice that now there are no ‚Äòfalse positives‚Äô like ‚Äúthe one‚Äù that we were getting when searching by orthography alone.\n\nNow that you‚Äôve generated a few different layers, and have seen how the search matrix works, you might want to try out some of the following searches, or invent some others:\n\nWords which have the DRESS vowel as the second phoneme\nThe word ‚Äúthe‚Äù followed by a word beginning with the phoneme /k/\nWords ending with a front vowel, followed by words beginning with /p/ or /b/\nWords that begin with ‚Äúk‚Äù in their spelling, but begin with the phoneme /n/\nWords that begin with ‚Äúk‚Äù in their spelling, but do not begin with the phoneme /n/\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "7. Lexicons",
      "7b. CMU Pronouncing Dictionary"
    ]
  },
  {
    "objectID": "worksheets/course/8-forced-alignment.html",
    "href": "worksheets/course/8-forced-alignment.html",
    "title": "8. Forced Alignment",
    "section": "",
    "text": "8. Forced Alignment\nForced alignment is the process of automatically determining the start and end times of words, and the phones within each word.\nThe options for forced alignment are:\n\nHTK - the Hidden Markov Model Toolkit\nMFA - the Montreal Forced Aligner\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/2-upload-data.html",
    "href": "worksheets/express-tutorial/2-upload-data.html",
    "title": "Upload Data",
    "section": "",
    "text": "In this exercise you will:\n\nSet up the basic structure of your database\nUpload a transcript manually\nUpload many transcripts at once using the batch uploader\nImport participant meta-data from a CSV file\n\nAfter this you will have a small corpus in your LaBB-CAT database.\nBefore you start, download and unzip QuakeStories.zip so you've got the demonstration data for uploading to your corpus.\n\n\n\nIn LaBB-CAT you can organise your transcripts and recordings into different sub-collections or ‚Äòcorpora‚Äô, and also categorise them by the type of speech they contain.\nWe are going up upload recordings that were made in two different locations, and we are going to set them up each as their own corpus, so first we will set up some corpus names‚Ä¶\n\nIn LaBB-CAT, select the corpora option from the menu at the top.\nThis page shows a list of current corpora, which only contains one corpus, called corpus.\nAbove the ‚Äúcorpus‚Äù corpus, the column headings double as a form that you can fill in to add a new corpus. Fill in the following information:\n\nName : QB\nLanguage : English\nDescription : Quakebox recordings\n\nPress the New button to add the ‚ÄúQB‚Äù corpus.\nYou should see a message at the top of the page saying Record created and now the QB corpus is in the list, under the ‚Äúcorpus‚Äù corpus.\nAdd another corpus called ‚ÄúUC‚Äù with the description ‚ÄúCampus recordings‚Äù.\nWe won‚Äôt actually be using the corpus called ‚Äúcorpus‚Äù, so we want to delete it.\nTo do this, press the Delete button to the right of the corpus corpus in the list.\nYou will be asked Are you sure you want to delete corpus?\nYou are sure, so press OK.\nThe row will be deleted from the list.\n\nNow you have some corpora set up with the names you‚Äôve provided.\nThe data we are using is a collection of stories about peoples‚Äô experiences during the devastating earthquakes that hit the Canterbury region of New Zealand in 2010 and 2011. Some recordings are interviews, where an interviewer asks the participant questions, and others are monologues.\nNow we‚Äôre going to set up these two transcript types‚Ä¶\n\nSelect the transcript types option from the menu at the top.\nYou will see a list of transcript types, although there‚Äôs currently only one type in the list, called interview.\nAbove this, fill in the empty Type box with the word: monologue\nPress the New button.\nYou will notice that now the list has two transcript types, interview and monologue. A Save button has appeared, because your changes aren‚Äôt yet saved to LaBB-CAT.\nPress the Save button.\nYou will see a message at the top saying Layer saved: transcript_type.\n\n\nNow that we have a basic structure for the data, we are going to look at how to upload data‚Ä¶\n\n\n\n\nIn LaBB-CAT, select the transcripts option in the menu.\nPress the Upload Transcript icon.\nYou will see a page with some options to select on the top left, buttons on the top right, and in a middle, a rectangle with a dashed border; this is the ‚Äòupload queue‚Äô, which lists files we want to upload.\nIn the top left corner of the ‚Äòupload queue‚Äô rectangle, there‚Äôs a Choose Files button; press it, and select the file in the ‚ÄúQuakeStories‚Äù folder called BR178LK_MargaretSpencer.eaf\n\nYou will see that the transcript file is listed in the ‚Äòupload queue‚Äô. We want to upload not only the transcript, but also its associated media files. Each transcript has an audio file and a video file, and you want to upload both.\n\nPress Choose Files button again, and in the same ‚ÄúQuakeStories‚Äù folder click the file called BR178LK_MargaretSpencer.mp4, then hold down the  key on your keyboard and click the file called BR178LK_MargaretSpencer.wav so that both files are selected.\nThen press Open (or in some browsers the button to select files is labelled Upload).\nYou will see that next to the BR178LK_MargaretSpencer.eaf transcriopt, under the Media heading, two media types are now show; ‚Äúmp4‚Äù and ‚Äúwav‚Äù.\nTo the right of this, ensure the Corpus option is QB\nAlso ensure the Type option is interview\nLeave the other options with the default values and press the Upload button above.\nYou will see that, on the right, a progress bar shows 50% progress, and below the transcript in the upload queue, a number of options have appeared.\n\nEach ELAN transcript has a number of Tiers defined in it:\n\none for the participant's utterances,\nanother for an ‚Äòinterviewer‚Äô if there is one,‚Ä∫\none for noise annotations,\none for transcriber comments, and\none for topic annotations.\n\nEach tier must be mapped to a LaBB-CAT annotation layer.\nLaBB-CAT has analysed the structure of the ELAN transcript and pre-selected some default options for layer mappings. For this data, these defaults are correct, so you needn‚Äôt change anything.\n\n\nPress Save to continue.\nYou will see that the progress bar on the right continues, and after a short delay, the progress is complete, and the Status is listed as ‚ÄúFinished.‚Äù\nThe name of the transcript on the left, BR178LK_MargaretSpencer.eaf, is now a link. Click it.\n\nYou will see a page with transcript text, and the video appears in the top right corner of the page.\n\nPress the play button on the video.\nAs the video plays, you will see the current utterance highlighted in the transcript. You will also see that the current utterance appears as closed captions in the video. You can use the video controls as normal, including the full-screen button to make the video occupy the whole screen.\nPause the recording.\nClick one of the transcript lines further down the transcript.\nA menu will appear.\nSelect the ‚ÄòPlay‚Äô option on the menu.\nYou will see that playback starts at that line. Playback will stop when the participant finishes the utterance.\nSelect the Formats tab at the top of the transcript.\nYou will see a list of formats for exporting the transcript to.\nSelect Plain Text Document\nSave the resulting file and then open it.\nYou will see the transcript in plain-text form.\nIf you have Praat installed on your computer, click the formats link, and select the Praat Text Grid option. Save the resulting file on your desktop, and then open it with Praat.\nYou will see that the TextGrid has various tiers, one for whole utterances (or two if there are two speakers), and one for individual words (or two if there are two speakers).\nBack on the transcript page, select the Attributes tab at the top right.\nThis will display the attributes for the transcript (some of the attribute values are not set because the information was not in the .eaf transcript file)\nNow select the Participants tab on the top right.\nThis will list both participants in the recording, the main participant, and the interviewer.\nClick BR178LK_MargaretSpencer.\nThis will display the participant meta-data. There‚Äôs not much here yet; we will be adding participant attributes soon. However, we can at least set the participant‚Äôs gender now.\nBR178LK_MargaretSpencer is ‚ÄòFemale‚Äô, so set her attributes to reflect that, and press Save.\n\nYou have now manually uploaded one transcript, checked the ELAN-tier to LaBB-CAT layer mappings and manually specified the meta-data for one participant.\n\n\n\nIf you already have a collection of transcripts and media files (which we have for these exercises), and they are systematically organized (which they are), you may be able to save some manual uploading work by uploading them using the ‚Äòautomated upload‚Äô option.\n\nWhen you clicked the name of the transcript to open it after uploading, a new browser tab was opened. Close that tab now to take you back to the upload queue.\nMost of the transcripts we are going to upload are monologues, so in the Defaults box on the top left, set Transcript Type to monologue.\nOpen Windows Explorer or Finder, and navigate to the LaBB-CAT Workshop data folder.\nDrag the folder called ‚ÄúQuakeStories‚Äù, and drop it on to LaBB-CAT, on to the upload queue area below the buttons (the rectangle with the dashed border).\n\nThe upload queue will now contain a longer list of transcripts. Each transcript should have a value filled in for each column - Transcript, Media, Corpus, Episode, and Type.\n\n\nThe first transcript, BR178LK_MargaretSpencer.eaf, has already been uploaded, and we don‚Äôt want to upload it again. Remove it from the list by using the ‚ûñ button on the right hand side of that row.\n\nWhen we uploaded manually before, we saw a list of ELAN tiers and their correspondences to LaBB-CAT layers. The options had default values, but we had to manually confirm the choices that LaBB-CAT had made about how to interpret the ELAN tiers.\nThe Automated Upload option allows LaBB-CAT to automatically use these default selections, instead of asking us to manually confirm them for every transcript. For this corpus, the default options that LaBB-CAT automatically selects will always be correct.\n\nTick the Automated Upload checkbox in the Defaults box on the top left.\nPress the Upload button above the list.\nYou will see that in the Status column, the text changes to ‚ÄúUploading‚Ä¶‚Äù for the first transcript. The progress bar progresses, and once it's complete, the next transcript changes to ‚ÄúTransferring‚Äù, and so on.\n\n\n\n\n\n\n\nTip\n\n\n\nWhile the files are uploading, click  the online help link at the top of the page to the right of the menu and check preconditions for uploading, and other functions the upload page can perform.\n\n\n\nOnce the uploader is finished, you will receive a CSV ‚Äòupload report‚Äô file that lists the files you uploaded and their upload status. (If there had been any problems with the upload, the resulting error messages would be included in this report for following up.)\nYou can verify that all the transcripts are there by selecting the transcripts option on the menu in LaBB-CAT.\nYou should see a list of twenty transcripts.\nUse the Transcript box to find UC013AM_Dom.eaf\n(you can type just part of the name if you like).\npress the Attributes icon for UC013AM_Dom.eaf\n(on the far right of the row).\nChange Transcript type to interview and press Save.\nSimilarly, the following transcripts are interviews, so change their type accordingly\n\nUC215YW_DanielaMaoate-Cox.eaf\nUC226AD.eaf\n\n\n\n\n\nThe transcripts are now in the database, but the meta-data for the participants hasn‚Äôt been set yet (because it‚Äôs not contained in the ELAN files). We could manually add this for each speaker using the participants page, but fortunately we have it stored in a spreadsheet (actually, a CSV text file) that we can upload in one go.\n\nIn LaBB-CAT, select the participants option on the menu.\nYou will see a list of all the participants in the transcripts we just uploaded. You‚Äôll notice that only one participant has Gender set: BR178LK_MargaretSpencer who we manually edited earlier.\nPress the Upload Participant Data icon at the bottom.\nPress Choose File, and select the file in the LaBB-CAT Exercises data folder called participants.csv\nPress Upload\nYou will now see a list of the columns from the spreadsheet.\n\nFirstly, ensure that the Participant identity column is set to name.\nThis ensures that the ‚Äúname‚Äù column in the spreadsheet will be used to match names of existing participants in the LaBB-CAT database.\n\nBelow Participant identity column is listed each column from the spreadsheet, with an arrow pointing to a dropdown box. The box contains various options, including each of the participant attributes set up in LaBB-CAT, an ignore option, and create a new attribute option.\n\nMost likely, the only correct option is ‚ÄòGender‚Äô, as that‚Äôs the only participant attribute that has already been set up in LaBB-CAT.\nSet the other options as follows:\n\n\nThe CSV column name: ‚Üí ignore because it‚Äôs the Participant Identity Column identified above\n(The CSV column gender: ‚Üí the Gender LaBB-CAT attribute\nThe CSV column ageCategory: ‚Üí create new attribute called:\nLabel: Age Category, Attribute ID: ageCategory\nThe CSV column ethnicity: ‚Üí create new attribute called:\nLabel: Ethnicity, Attribute ID: ethnicity\nThe CSV column grewUp: ‚Üí create new attribute called:\nLabel: Country, Attribute ID: grewUp\nThe CSV column grewUpRegion: ‚Üí create new attribute called:\nLabel: Region, Attribute ID: grewUpRegion\nThe CSV column grewUpTown: ‚Üí create new attribute called:\nLabel: Town, Attribute ID: grewUpTown\nThe CSV column languagesSpoken: ‚Üí create new attribute called:\nLabel: Languages, Attribute ID: languagesSpoken\n\nPress import.\nYou should see a page with information about how many attributes/participants were added/updated.\n\nParticipant Attributes have now been automatically defined, but we‚Äôll tweak their settings a little:\n\nSelect the participant attributes option on the menu. You will see a list of participant attributes which each participant can have values for.\nThe new attributes you just created from the participants.csv file should be listed along with a few others.\nWe will not be using the Birth Year attribute, so press its Delete button.\nOn the ageCategory row, set ‚ÄòType‚Äô to Select, which means there‚Äôs a predefined closed-set of possibilities.\nOn the ageCategory row, set ‚ÄòSearchability‚Äô to Searchable.\nThis will ensure that it‚Äôs shown as a column on the participants page.\nSimilarly set the languagesSpoken participant attribute to Searchable.\nPress Save at the bottom.\nThe ageCategory row now has a ‚Äòtag‚Äô icon on the right hand side, next to the Delete button.\nHover the mouse over the icon to see what it does, and then press it.\n\nThis page lists all the valid values for the ageCategory participant attribute, although the list is currently empty.\n\nHover your mouse over the Generate button on the right to see what it does, and then press it. This will populate the list by looking up the values participants already have for this attribute.\nPress the New button at the top, to add a row with a blank label.\nThis allows participants to have no ageCateory value set, e.g.¬†we don‚Äôt know the ages of the interviewers in our transcripts, so they will have this attribute set as blank.\nPress the Save button.\n\nTo check the participant attributes really are now defined and loaded:\n\nSelect the participants option on the menu. You will see a list of speakers, and page links at the bottom.\n\nThe page also includes participant attribute values where they are known, and you should now see that the attributes of main participants are set (although interviewer data is not).\n\nYou now have a small database with a number of transcripts, recordings, and speakers in it, so we can start creating some annotations‚Ä¶",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Upload Data"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/2-upload-data.html#corpus-structure",
    "href": "worksheets/express-tutorial/2-upload-data.html#corpus-structure",
    "title": "Upload Data",
    "section": "",
    "text": "In LaBB-CAT you can organise your transcripts and recordings into different sub-collections or ‚Äòcorpora‚Äô, and also categorise them by the type of speech they contain.\nWe are going up upload recordings that were made in two different locations, and we are going to set them up each as their own corpus, so first we will set up some corpus names‚Ä¶\n\nIn LaBB-CAT, select the corpora option from the menu at the top.\nThis page shows a list of current corpora, which only contains one corpus, called corpus.\nAbove the ‚Äúcorpus‚Äù corpus, the column headings double as a form that you can fill in to add a new corpus. Fill in the following information:\n\nName : QB\nLanguage : English\nDescription : Quakebox recordings\n\nPress the New button to add the ‚ÄúQB‚Äù corpus.\nYou should see a message at the top of the page saying Record created and now the QB corpus is in the list, under the ‚Äúcorpus‚Äù corpus.\nAdd another corpus called ‚ÄúUC‚Äù with the description ‚ÄúCampus recordings‚Äù.\nWe won‚Äôt actually be using the corpus called ‚Äúcorpus‚Äù, so we want to delete it.\nTo do this, press the Delete button to the right of the corpus corpus in the list.\nYou will be asked Are you sure you want to delete corpus?\nYou are sure, so press OK.\nThe row will be deleted from the list.\n\nNow you have some corpora set up with the names you‚Äôve provided.\nThe data we are using is a collection of stories about peoples‚Äô experiences during the devastating earthquakes that hit the Canterbury region of New Zealand in 2010 and 2011. Some recordings are interviews, where an interviewer asks the participant questions, and others are monologues.\nNow we‚Äôre going to set up these two transcript types‚Ä¶\n\nSelect the transcript types option from the menu at the top.\nYou will see a list of transcript types, although there‚Äôs currently only one type in the list, called interview.\nAbove this, fill in the empty Type box with the word: monologue\nPress the New button.\nYou will notice that now the list has two transcript types, interview and monologue. A Save button has appeared, because your changes aren‚Äôt yet saved to LaBB-CAT.\nPress the Save button.\nYou will see a message at the top saying Layer saved: transcript_type.\n\n\nNow that we have a basic structure for the data, we are going to look at how to upload data‚Ä¶",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Upload Data"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/2-upload-data.html#manual-upload",
    "href": "worksheets/express-tutorial/2-upload-data.html#manual-upload",
    "title": "Upload Data",
    "section": "",
    "text": "In LaBB-CAT, select the transcripts option in the menu.\nPress the Upload Transcript icon.\nYou will see a page with some options to select on the top left, buttons on the top right, and in a middle, a rectangle with a dashed border; this is the ‚Äòupload queue‚Äô, which lists files we want to upload.\nIn the top left corner of the ‚Äòupload queue‚Äô rectangle, there‚Äôs a Choose Files button; press it, and select the file in the ‚ÄúQuakeStories‚Äù folder called BR178LK_MargaretSpencer.eaf\n\nYou will see that the transcript file is listed in the ‚Äòupload queue‚Äô. We want to upload not only the transcript, but also its associated media files. Each transcript has an audio file and a video file, and you want to upload both.\n\nPress Choose Files button again, and in the same ‚ÄúQuakeStories‚Äù folder click the file called BR178LK_MargaretSpencer.mp4, then hold down the  key on your keyboard and click the file called BR178LK_MargaretSpencer.wav so that both files are selected.\nThen press Open (or in some browsers the button to select files is labelled Upload).\nYou will see that next to the BR178LK_MargaretSpencer.eaf transcriopt, under the Media heading, two media types are now show; ‚Äúmp4‚Äù and ‚Äúwav‚Äù.\nTo the right of this, ensure the Corpus option is QB\nAlso ensure the Type option is interview\nLeave the other options with the default values and press the Upload button above.\nYou will see that, on the right, a progress bar shows 50% progress, and below the transcript in the upload queue, a number of options have appeared.\n\nEach ELAN transcript has a number of Tiers defined in it:\n\none for the participant's utterances,\nanother for an ‚Äòinterviewer‚Äô if there is one,‚Ä∫\none for noise annotations,\none for transcriber comments, and\none for topic annotations.\n\nEach tier must be mapped to a LaBB-CAT annotation layer.\nLaBB-CAT has analysed the structure of the ELAN transcript and pre-selected some default options for layer mappings. For this data, these defaults are correct, so you needn‚Äôt change anything.\n\n\nPress Save to continue.\nYou will see that the progress bar on the right continues, and after a short delay, the progress is complete, and the Status is listed as ‚ÄúFinished.‚Äù\nThe name of the transcript on the left, BR178LK_MargaretSpencer.eaf, is now a link. Click it.\n\nYou will see a page with transcript text, and the video appears in the top right corner of the page.\n\nPress the play button on the video.\nAs the video plays, you will see the current utterance highlighted in the transcript. You will also see that the current utterance appears as closed captions in the video. You can use the video controls as normal, including the full-screen button to make the video occupy the whole screen.\nPause the recording.\nClick one of the transcript lines further down the transcript.\nA menu will appear.\nSelect the ‚ÄòPlay‚Äô option on the menu.\nYou will see that playback starts at that line. Playback will stop when the participant finishes the utterance.\nSelect the Formats tab at the top of the transcript.\nYou will see a list of formats for exporting the transcript to.\nSelect Plain Text Document\nSave the resulting file and then open it.\nYou will see the transcript in plain-text form.\nIf you have Praat installed on your computer, click the formats link, and select the Praat Text Grid option. Save the resulting file on your desktop, and then open it with Praat.\nYou will see that the TextGrid has various tiers, one for whole utterances (or two if there are two speakers), and one for individual words (or two if there are two speakers).\nBack on the transcript page, select the Attributes tab at the top right.\nThis will display the attributes for the transcript (some of the attribute values are not set because the information was not in the .eaf transcript file)\nNow select the Participants tab on the top right.\nThis will list both participants in the recording, the main participant, and the interviewer.\nClick BR178LK_MargaretSpencer.\nThis will display the participant meta-data. There‚Äôs not much here yet; we will be adding participant attributes soon. However, we can at least set the participant‚Äôs gender now.\nBR178LK_MargaretSpencer is ‚ÄòFemale‚Äô, so set her attributes to reflect that, and press Save.\n\nYou have now manually uploaded one transcript, checked the ELAN-tier to LaBB-CAT layer mappings and manually specified the meta-data for one participant.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Upload Data"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/2-upload-data.html#automated-upload",
    "href": "worksheets/express-tutorial/2-upload-data.html#automated-upload",
    "title": "Upload Data",
    "section": "",
    "text": "If you already have a collection of transcripts and media files (which we have for these exercises), and they are systematically organized (which they are), you may be able to save some manual uploading work by uploading them using the ‚Äòautomated upload‚Äô option.\n\nWhen you clicked the name of the transcript to open it after uploading, a new browser tab was opened. Close that tab now to take you back to the upload queue.\nMost of the transcripts we are going to upload are monologues, so in the Defaults box on the top left, set Transcript Type to monologue.\nOpen Windows Explorer or Finder, and navigate to the LaBB-CAT Workshop data folder.\nDrag the folder called ‚ÄúQuakeStories‚Äù, and drop it on to LaBB-CAT, on to the upload queue area below the buttons (the rectangle with the dashed border).\n\nThe upload queue will now contain a longer list of transcripts. Each transcript should have a value filled in for each column - Transcript, Media, Corpus, Episode, and Type.\n\n\nThe first transcript, BR178LK_MargaretSpencer.eaf, has already been uploaded, and we don‚Äôt want to upload it again. Remove it from the list by using the ‚ûñ button on the right hand side of that row.\n\nWhen we uploaded manually before, we saw a list of ELAN tiers and their correspondences to LaBB-CAT layers. The options had default values, but we had to manually confirm the choices that LaBB-CAT had made about how to interpret the ELAN tiers.\nThe Automated Upload option allows LaBB-CAT to automatically use these default selections, instead of asking us to manually confirm them for every transcript. For this corpus, the default options that LaBB-CAT automatically selects will always be correct.\n\nTick the Automated Upload checkbox in the Defaults box on the top left.\nPress the Upload button above the list.\nYou will see that in the Status column, the text changes to ‚ÄúUploading‚Ä¶‚Äù for the first transcript. The progress bar progresses, and once it's complete, the next transcript changes to ‚ÄúTransferring‚Äù, and so on.\n\n\n\n\n\n\n\nTip\n\n\n\nWhile the files are uploading, click  the online help link at the top of the page to the right of the menu and check preconditions for uploading, and other functions the upload page can perform.\n\n\n\nOnce the uploader is finished, you will receive a CSV ‚Äòupload report‚Äô file that lists the files you uploaded and their upload status. (If there had been any problems with the upload, the resulting error messages would be included in this report for following up.)\nYou can verify that all the transcripts are there by selecting the transcripts option on the menu in LaBB-CAT.\nYou should see a list of twenty transcripts.\nUse the Transcript box to find UC013AM_Dom.eaf\n(you can type just part of the name if you like).\npress the Attributes icon for UC013AM_Dom.eaf\n(on the far right of the row).\nChange Transcript type to interview and press Save.\nSimilarly, the following transcripts are interviews, so change their type accordingly\n\nUC215YW_DanielaMaoate-Cox.eaf\nUC226AD.eaf",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Upload Data"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/2-upload-data.html#participant-data-import",
    "href": "worksheets/express-tutorial/2-upload-data.html#participant-data-import",
    "title": "Upload Data",
    "section": "",
    "text": "The transcripts are now in the database, but the meta-data for the participants hasn‚Äôt been set yet (because it‚Äôs not contained in the ELAN files). We could manually add this for each speaker using the participants page, but fortunately we have it stored in a spreadsheet (actually, a CSV text file) that we can upload in one go.\n\nIn LaBB-CAT, select the participants option on the menu.\nYou will see a list of all the participants in the transcripts we just uploaded. You‚Äôll notice that only one participant has Gender set: BR178LK_MargaretSpencer who we manually edited earlier.\nPress the Upload Participant Data icon at the bottom.\nPress Choose File, and select the file in the LaBB-CAT Exercises data folder called participants.csv\nPress Upload\nYou will now see a list of the columns from the spreadsheet.\n\nFirstly, ensure that the Participant identity column is set to name.\nThis ensures that the ‚Äúname‚Äù column in the spreadsheet will be used to match names of existing participants in the LaBB-CAT database.\n\nBelow Participant identity column is listed each column from the spreadsheet, with an arrow pointing to a dropdown box. The box contains various options, including each of the participant attributes set up in LaBB-CAT, an ignore option, and create a new attribute option.\n\nMost likely, the only correct option is ‚ÄòGender‚Äô, as that‚Äôs the only participant attribute that has already been set up in LaBB-CAT.\nSet the other options as follows:\n\n\nThe CSV column name: ‚Üí ignore because it‚Äôs the Participant Identity Column identified above\n(The CSV column gender: ‚Üí the Gender LaBB-CAT attribute\nThe CSV column ageCategory: ‚Üí create new attribute called:\nLabel: Age Category, Attribute ID: ageCategory\nThe CSV column ethnicity: ‚Üí create new attribute called:\nLabel: Ethnicity, Attribute ID: ethnicity\nThe CSV column grewUp: ‚Üí create new attribute called:\nLabel: Country, Attribute ID: grewUp\nThe CSV column grewUpRegion: ‚Üí create new attribute called:\nLabel: Region, Attribute ID: grewUpRegion\nThe CSV column grewUpTown: ‚Üí create new attribute called:\nLabel: Town, Attribute ID: grewUpTown\nThe CSV column languagesSpoken: ‚Üí create new attribute called:\nLabel: Languages, Attribute ID: languagesSpoken\n\nPress import.\nYou should see a page with information about how many attributes/participants were added/updated.\n\nParticipant Attributes have now been automatically defined, but we‚Äôll tweak their settings a little:\n\nSelect the participant attributes option on the menu. You will see a list of participant attributes which each participant can have values for.\nThe new attributes you just created from the participants.csv file should be listed along with a few others.\nWe will not be using the Birth Year attribute, so press its Delete button.\nOn the ageCategory row, set ‚ÄòType‚Äô to Select, which means there‚Äôs a predefined closed-set of possibilities.\nOn the ageCategory row, set ‚ÄòSearchability‚Äô to Searchable.\nThis will ensure that it‚Äôs shown as a column on the participants page.\nSimilarly set the languagesSpoken participant attribute to Searchable.\nPress Save at the bottom.\nThe ageCategory row now has a ‚Äòtag‚Äô icon on the right hand side, next to the Delete button.\nHover the mouse over the icon to see what it does, and then press it.\n\nThis page lists all the valid values for the ageCategory participant attribute, although the list is currently empty.\n\nHover your mouse over the Generate button on the right to see what it does, and then press it. This will populate the list by looking up the values participants already have for this attribute.\nPress the New button at the top, to add a row with a blank label.\nThis allows participants to have no ageCateory value set, e.g.¬†we don‚Äôt know the ages of the interviewers in our transcripts, so they will have this attribute set as blank.\nPress the Save button.\n\nTo check the participant attributes really are now defined and loaded:\n\nSelect the participants option on the menu. You will see a list of speakers, and page links at the bottom.\n\nThe page also includes participant attribute values where they are known, and you should now see that the attributes of main participants are set (although interviewer data is not).\n\nYou now have a small database with a number of transcripts, recordings, and speakers in it, so we can start creating some annotations‚Ä¶",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Upload Data"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/1-installation.html",
    "href": "worksheets/express-tutorial/1-installation.html",
    "title": "Installing LaBB-CAT",
    "section": "",
    "text": "LaBB-CAT is a web-browser based application, and is primarily designed to run on a central web server accessible over the internet, so that multiple collaborators can easily work on the same corpus data from different locations.\nHowever, it is possible to have a ‚Äòprivate‚Äô installation of LaBB-CAT which runs directly on your personal computer. These instructions explain how to achieve that.\n\n\nOn Windows, before you can install LaBB-CAT, you first must have Java installed.\n\n\nUse the following steps to check whether you already have Java installed.\n\nPress the  Start menu button.\nType Control Panel\nSelect the Control Panel option that appears.\n\nType Java\n\nIf a Java icon appears as shown in Figure¬†1, then you already have Java, and can skip section 2.\n\n\n\n\n\n\nFigure¬†1: Java in the Control Panel\n\n\n\nIf there‚Äôs no Java icon in the Control Panel, follow the steps in the next section to install it.\n\n\n\n\nOpen the Java website in your browser:\nhttps://www.java.com/\nPress the Download Java button.\nPress the Download Java button on the next page and save the resulting installer file.\nClick the installer to run it.\n\n\n\n\n\n\n\nFigure¬†2: The Java installer\n\n\n\n\nPress Install.\n\n\n\n\n\n\n\nFigure¬†3: Java installation is complete\n\n\n\n\nPress Close.\n\n\n\n\nOnce Java is installed, you can install LaBB-CAT:\n\nOpen the following page in your web browser:\nhttps://sourceforge.net/projects/labbcat/files/install/\nThis page has all versions of the LaBB-CAT installer, both for personal computer installations\nand also for web-server installations. The the files are listed most recent first.\nDownload the first file named install-labbcat_yyyymmdd.jar (where yyyymmdd are numbers).\nDouble-click on the file you just downloaded to open it.\n\nYou should see the LaBB-CAT installer program (Figure¬†4).\n\n\n\n\n\n\nFigure¬†4: LaBB-CAT Installer\n\n\n\n\nPress Start.\n\nYou should see a progress bar while components are installed and files are copied.\nOnce the installation is finished, the progress bar will be all blue, and there will be a button labelled Finished (Figure¬†15).\n\n\n\n\n\n\nFigure¬†5: Installer finished\n\n\n\n\nPress Finished.\n\nThe LaBB-CAT Server application will appear, as shown in Figure¬†6.\n\n\n\n\n\n\nFigure¬†6: LaBB-CAT Server\n\n\n\nThen your default web browser will open on your LaBB-CAT home page, as shown in Figure¬†7.\n\n\n\n\n\n\nFigure¬†7: LaBB-CAT is successfully installed and running\n\n\n\n\nIf you are shown the LaBB-CAT Licence page, scroll to the bottom and press I Agree.\n\nAs seen in Figure¬†8, in your Start Menu, you will see that there is a LaBB-CAT app that can be used to start and access LaBB-CAT from now on.\n\n\n\n\n\n\nFigure¬†8: Use Start/LaBB-CAT to open LaBB-CAT\n\n\n\nThis starts the LaBB-CAT Server app (Figure¬†6), which must be running when you‚Äôre using LaBB-CAT. It can be closed once you‚Äôve finished working with LaBB-CAT.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLaBB-CAT can only be installed on newer M-series Macs.\nThese instructions will not work for older Intel-based Macs. Sorry!\n\n\nOn OS X, there are two prerequisites that must be installed before you can install LaBB-CAT:\n\nHomebrew\nJava\n\nYou may already have one or other of these installed; if so, you can skip the corresponding section below.\n\n\nHomebrew is a ‚Äòpackage manager‚Äô for Mac computers, which allows you to install other programes, including Java.\n\nOpen the following page in your web browser:\nhttps://github.com/Homebrew/brew/releases/latest\nScroll down to the Assets section.\n\nClick the file called Homebrew-n.n.n.pkg (where n.n.n is the version number) to download the file.\nOnce the file has been downloaded, double-click on it to run the installer.\n\nClick Continue, Continue, Agree and Install to complete the installation.\n\n\n\n\n\nOpen Launchpad and type Terminal.\nDouble click Terminal to open a command shell.\nType in the following command:\nbrew install openjdk\nPress the returnreturn key on your keyboard to enter the command.\nSome text will appear in the Terminal window while Homebrew downloads everything it needs to install Java\nOnce it‚Äôs finished, you‚Äôll see the % shell prompt again.\n\n\n\n\n\n\n\nFigure¬†9: brew install openjdk\n\n\n\n\n\n\nOnce Homebew and Java are installed, you can install LaBB-CAT:\n\nOpen the following page in your web browser:\nhttps://sourceforge.net/projects/labbcat/files/install/\nThis page has all versions of the LaBB-CAT installer, both for personal computer installations\nand also for web-server installations. The the files are listed most recent first.\nDownload the first file named install-labbcat_yyyymmdd.jar (where yyyymmdd are numbers).\nDouble-click on the file you just downloaded to open it.\nMost likely you will see a message that the files was ‚ÄúNot Opened‚Äù as show in Figure¬†10.\n\n\n\n\n\n\n\nFigure¬†10: install-labbcat‚Ä¶jar Not Opened\n\n\n\n\nGo to the Apple menu and select System Settings.\nSelect the section labelled Privacy and Security.\nScroll to the bottom and under the Security heading you will see a message saying that install-labbcat_yyyymmdd.jar ‚Äúwas blocked to protect your Mac.‚Äù as shown in Figure¬†11\n\n\n\n\n\n\n\nFigure¬†11: Privacy and Security: Open Anyway\n\n\n\n\nPress Open Anyway.\nYou will see another warning message as shown in Figure¬†12\n\n\n\n\n\n\n\nFigure¬†12: Open Anyway (again)\n\n\n\n\nPress Open Anyway.\nYou may see a request for Java to access your Downloads folder like in Figure¬†13.\n\n\n\n\n\n\n\nFigure¬†13: Allow Java access to Downloads\n\n\n\n\nIf so, press Allow.\n\nYou should see the LaBB-CAT installer program (Figure¬†14).\n\n\n\n\n\n\nFigure¬†14: LaBB-CAT Installer\n\n\n\n\nPress Start.\n\nYou should see a progress bar while components are installed and files are copied.\nOnce the installation is finished, the progress bar will be all blue, and there will be a button labelled Finished (Figure¬†15).\n\n\n\n\n\n\nFigure¬†15: Installer finished\n\n\n\n\nPress Finished.\n\nYour default web browser will open on your LaBB-CAT home page, as show in Figure¬†16.\n\n\n\n\n\n\nFigure¬†16: LaBB-CAT is successfully installed and running\n\n\n\n\nIf you a shown the LaBB-CAT Licence page, scroll to the bottom and press I Agree.\n\nAs seen in Figure¬†17, in your Applications folder, you will see that there is a LaBB-CAT entry that can be used to access LaBB-CAT from now on.\n\n\n\n\n\n\nFigure¬†17: Use Applications/LaBB-CAT to open LaBB-CAT\n\n\n\n\n\n\n\nIn future you may want to uninstall LaBB-CAT, in which case you can use the same installer you used to install it.\nIf you run install-labbcat_yyyymmdd.jar and LaBB-CAT is already installed, after pressing Start it will offer further options.\n\n\n\nRunning install-labbcat_yyyymmdd.jar when LaBB-CAT is already installed\n\n\nThe options are:\n\nUpgrade ‚Äì Install this version of LaBB-CAT, keeping all your corpus data intact.\nReplace ‚Äì Install LaBB-CAT afresh, deleting all your existing corpus data and leaving you with an empty LaBB-CAT installation.\nUninstall ‚Äì Remove LaBB-CAT from your personal computer.\nCancel ‚Äì Close the installer without taking any action.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Installing LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/1-installation.html#windows",
    "href": "worksheets/express-tutorial/1-installation.html#windows",
    "title": "Installing LaBB-CAT",
    "section": "",
    "text": "On Windows, before you can install LaBB-CAT, you first must have Java installed.\n\n\nUse the following steps to check whether you already have Java installed.\n\nPress the  Start menu button.\nType Control Panel\nSelect the Control Panel option that appears.\n\nType Java\n\nIf a Java icon appears as shown in Figure¬†1, then you already have Java, and can skip section 2.\n\n\n\n\n\n\nFigure¬†1: Java in the Control Panel\n\n\n\nIf there‚Äôs no Java icon in the Control Panel, follow the steps in the next section to install it.\n\n\n\n\nOpen the Java website in your browser:\nhttps://www.java.com/\nPress the Download Java button.\nPress the Download Java button on the next page and save the resulting installer file.\nClick the installer to run it.\n\n\n\n\n\n\n\nFigure¬†2: The Java installer\n\n\n\n\nPress Install.\n\n\n\n\n\n\n\nFigure¬†3: Java installation is complete\n\n\n\n\nPress Close.\n\n\n\n\nOnce Java is installed, you can install LaBB-CAT:\n\nOpen the following page in your web browser:\nhttps://sourceforge.net/projects/labbcat/files/install/\nThis page has all versions of the LaBB-CAT installer, both for personal computer installations\nand also for web-server installations. The the files are listed most recent first.\nDownload the first file named install-labbcat_yyyymmdd.jar (where yyyymmdd are numbers).\nDouble-click on the file you just downloaded to open it.\n\nYou should see the LaBB-CAT installer program (Figure¬†4).\n\n\n\n\n\n\nFigure¬†4: LaBB-CAT Installer\n\n\n\n\nPress Start.\n\nYou should see a progress bar while components are installed and files are copied.\nOnce the installation is finished, the progress bar will be all blue, and there will be a button labelled Finished (Figure¬†15).\n\n\n\n\n\n\nFigure¬†5: Installer finished\n\n\n\n\nPress Finished.\n\nThe LaBB-CAT Server application will appear, as shown in Figure¬†6.\n\n\n\n\n\n\nFigure¬†6: LaBB-CAT Server\n\n\n\nThen your default web browser will open on your LaBB-CAT home page, as shown in Figure¬†7.\n\n\n\n\n\n\nFigure¬†7: LaBB-CAT is successfully installed and running\n\n\n\n\nIf you are shown the LaBB-CAT Licence page, scroll to the bottom and press I Agree.\n\nAs seen in Figure¬†8, in your Start Menu, you will see that there is a LaBB-CAT app that can be used to start and access LaBB-CAT from now on.\n\n\n\n\n\n\nFigure¬†8: Use Start/LaBB-CAT to open LaBB-CAT\n\n\n\nThis starts the LaBB-CAT Server app (Figure¬†6), which must be running when you‚Äôre using LaBB-CAT. It can be closed once you‚Äôve finished working with LaBB-CAT.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Installing LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/1-installation.html#mac",
    "href": "worksheets/express-tutorial/1-installation.html#mac",
    "title": "Installing LaBB-CAT",
    "section": "",
    "text": "Important\n\n\n\nLaBB-CAT can only be installed on newer M-series Macs.\nThese instructions will not work for older Intel-based Macs. Sorry!\n\n\nOn OS X, there are two prerequisites that must be installed before you can install LaBB-CAT:\n\nHomebrew\nJava\n\nYou may already have one or other of these installed; if so, you can skip the corresponding section below.\n\n\nHomebrew is a ‚Äòpackage manager‚Äô for Mac computers, which allows you to install other programes, including Java.\n\nOpen the following page in your web browser:\nhttps://github.com/Homebrew/brew/releases/latest\nScroll down to the Assets section.\n\nClick the file called Homebrew-n.n.n.pkg (where n.n.n is the version number) to download the file.\nOnce the file has been downloaded, double-click on it to run the installer.\n\nClick Continue, Continue, Agree and Install to complete the installation.\n\n\n\n\n\nOpen Launchpad and type Terminal.\nDouble click Terminal to open a command shell.\nType in the following command:\nbrew install openjdk\nPress the returnreturn key on your keyboard to enter the command.\nSome text will appear in the Terminal window while Homebrew downloads everything it needs to install Java\nOnce it‚Äôs finished, you‚Äôll see the % shell prompt again.\n\n\n\n\n\n\n\nFigure¬†9: brew install openjdk\n\n\n\n\n\n\nOnce Homebew and Java are installed, you can install LaBB-CAT:\n\nOpen the following page in your web browser:\nhttps://sourceforge.net/projects/labbcat/files/install/\nThis page has all versions of the LaBB-CAT installer, both for personal computer installations\nand also for web-server installations. The the files are listed most recent first.\nDownload the first file named install-labbcat_yyyymmdd.jar (where yyyymmdd are numbers).\nDouble-click on the file you just downloaded to open it.\nMost likely you will see a message that the files was ‚ÄúNot Opened‚Äù as show in Figure¬†10.\n\n\n\n\n\n\n\nFigure¬†10: install-labbcat‚Ä¶jar Not Opened\n\n\n\n\nGo to the Apple menu and select System Settings.\nSelect the section labelled Privacy and Security.\nScroll to the bottom and under the Security heading you will see a message saying that install-labbcat_yyyymmdd.jar ‚Äúwas blocked to protect your Mac.‚Äù as shown in Figure¬†11\n\n\n\n\n\n\n\nFigure¬†11: Privacy and Security: Open Anyway\n\n\n\n\nPress Open Anyway.\nYou will see another warning message as shown in Figure¬†12\n\n\n\n\n\n\n\nFigure¬†12: Open Anyway (again)\n\n\n\n\nPress Open Anyway.\nYou may see a request for Java to access your Downloads folder like in Figure¬†13.\n\n\n\n\n\n\n\nFigure¬†13: Allow Java access to Downloads\n\n\n\n\nIf so, press Allow.\n\nYou should see the LaBB-CAT installer program (Figure¬†14).\n\n\n\n\n\n\nFigure¬†14: LaBB-CAT Installer\n\n\n\n\nPress Start.\n\nYou should see a progress bar while components are installed and files are copied.\nOnce the installation is finished, the progress bar will be all blue, and there will be a button labelled Finished (Figure¬†15).\n\n\n\n\n\n\nFigure¬†15: Installer finished\n\n\n\n\nPress Finished.\n\nYour default web browser will open on your LaBB-CAT home page, as show in Figure¬†16.\n\n\n\n\n\n\nFigure¬†16: LaBB-CAT is successfully installed and running\n\n\n\n\nIf you a shown the LaBB-CAT Licence page, scroll to the bottom and press I Agree.\n\nAs seen in Figure¬†17, in your Applications folder, you will see that there is a LaBB-CAT entry that can be used to access LaBB-CAT from now on.\n\n\n\n\n\n\nFigure¬†17: Use Applications/LaBB-CAT to open LaBB-CAT",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Installing LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/1-installation.html#uninstalling-labb-cat",
    "href": "worksheets/express-tutorial/1-installation.html#uninstalling-labb-cat",
    "title": "Installing LaBB-CAT",
    "section": "",
    "text": "In future you may want to uninstall LaBB-CAT, in which case you can use the same installer you used to install it.\nIf you run install-labbcat_yyyymmdd.jar and LaBB-CAT is already installed, after pressing Start it will offer further options.\n\n\n\nRunning install-labbcat_yyyymmdd.jar when LaBB-CAT is already installed\n\n\nThe options are:\n\nUpgrade ‚Äì Install this version of LaBB-CAT, keeping all your corpus data intact.\nReplace ‚Äì Install LaBB-CAT afresh, deleting all your existing corpus data and leaving you with an empty LaBB-CAT installation.\nUninstall ‚Äì Remove LaBB-CAT from your personal computer.\nCancel ‚Äì Close the installer without taking any action.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Installing LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/5-bas-webmaus.html",
    "href": "worksheets/express-tutorial/5-bas-webmaus.html",
    "title": "Forced Alignment",
    "section": "",
    "text": "The Bavarian Archive for Speech Signals (BAS) has kindly published a set of speech processing web services including one for for forced alignment called WebMAUS. You can use this service yourself directly, using your web browser, but LaBB-CAT also has a module for using it automatically, called the BAS Services Manager.\n\n\n\n\n\n\nCaution\n\n\n\nUsing WebMAUS for forced alignment requires LaBB-CAT to send your recordings and transcripts over the internet to a third party.\nAlthough the BAS Web Services Terms of Service make clear that uploaded data is deleted after 24 hours, using the service is only suitable in situations in which you have consent from participants to do so.\n(We do have such permission for the recordings used in this exercise.)\n\n\n\n\nLaBB-CAT has a specialised ‚Äòlayer manager‚Äô module for integrating with the BAS Web Services.\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, click the List of layer managers that are not yet installed link.\nLook for BAS Web Services Manager in the list, and press its Install button.\nFollow the ‚Äúterms of usage‚Äù link and read the terms.\nClose the terms page, returning to LaBB-CAT.\nTick the ‚ÄúAccept Terms of Usage‚Äù option.\nPress Install.\n\nYou will see a page of information about the Layer Manager.\n\n\n\nForced alignment is a process that works on each ‚Äòutterance‚Äô the recording - i.e.¬†each line in the transcript. As it processes all the words on a line at once, we need to create a ‚Äòphrase‚Äô layer.\n\nSelect the phrase layers option on the menu\nAt the top of the page, there‚Äôs a blank form for creating a new layer; fill in the following details:\n\nLayer ID: MAUS\nType: Text\nAlignment: Intervals\nManager: BAS Web Services Manager\nGenerate: Always\nDescription: WebMAUS forced alignment\n\nPress New.\nYou will see a form that allows you to configure the layer; hover the mouse pointer over each setting to see what its purpose is.\nThe main choice is the Phoneme encoding; choose DISC for this setting.\nPress Set Parameters\n\nWe are going to force-align only a single participant‚Äôs for now, so don‚Äôt click Regenerate on this page.\n\n\n\n\nSelect the participants option on the menu at the top.\nTick the checkbox next to the first participant‚Äôs name.\nPress the All Utterances button above.\nPress List.\nLaBB-CAT will identify all the selected participant‚Äôs utterances, and then list the first twenty.\nPress the MAUS button at the bottom of the page.\n\nLaBB-CAT will now upload each utterance ‚Äì both the audio and the transcript ‚Äì to the BAS Web Services server. LaBB-CAT must be able to access the internet for this to work, so if there is no internet connectivity, forced alignment will fail at this point.\nOnce WebMAUS has completed the forced alignment, LaBB-CAT downloads the resulting phone alignment times, and saves them in the segment layer.\n\n\n\nOnce forced alignment is complete, you can inspect/correct alignments using LaBB-CAT‚Äôs integration with Praat.\n\n\n\n\n\n\nTip\n\n\n\nYou can follow the following steps without having to wait for the forced alignment to complete.\nProcessing will continue even if you leave the current page.\nIf you later want to check back on the progress of the forced alignment task select the activity option on the menu. If the task is still running, a progress bar will be shown there.\n\n\n\nSelect the transcripts option on the menu.\nOpen the transcript you aligned.\nOn the Layers tab at the top, tick both the MAUS layer and the segment layer.\nYou will see which lines have been force-aligned, as they have a timestamp, and have the segment layer filled in.\n\nThe interactive transcript page doesn‚Äôt show you the alignments of the words or phones, but you can see those using Praat. You can open individual utterances in Praat directly from the transcript page, but first, the LaBB-CAT/Praat integration has to be set up; this only has to be done once:\n\nOn the top-right of the page, above the playback controls, there‚Äôs a Praat icon ¬†- click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\n\n\n\n\n\n\n\nTip\n\n\n\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\n\n\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶\n\nClick on a line that has been aligned, and select the Open TextGrid option on the menu.\nPraat should open, and show you a spectrogram of the line‚Äôs audio, with a TextGrid below that includes the words and the segments.\nIf you click on a word, and hit the tabtab key, the word‚Äôs interval is played. Try out various words, and see what you think about how accurate the forced aligner has been.\n\nTry this out with different lines in the transcript. You will see that in some cases the alignment is pretty good, and in other cases, it‚Äôs not so good. In the not-so-good cases, see if you can figure out why the forced aligner got it wrong.\nYou may have noticed that, each time you open an utterance in Praat, a button appears in the transcript to the left of the line, labelled Import Changes. This button allows you to save any adjustments you might want to make to the alignments back into the LaBB-CAT database.\n\nIf you feel confident using Praat, open an utterance TextGrid, adjust the alignments of the words an phones so that they‚Äôre more accurate, and then press the Import Changes button in the transcript.\n\n\n\n\n\n\n\nWarning\n\n\n\nThese changes are flagged as manual edits, so if forced-alignment is run again, they will not be over-written with new bad alignments. Therefore it‚Äôs important that the changes you make are actually improvements, because automated forced alignment will never change them again.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThere are some rules about what you can change when correcting word/segment alignments:\n\nYou‚Äôre not allowed to add or delete words (if this is necessary, it should be done by correcting the transcript instead).\nAll the segments must be within the bounds of their own word.\nThe start of the first phone should line up with the start of the word, and the end of the last phone should line up with the end of the word.\nYou should not change the alignment of the utterance itself (which would only be possible if you select the Open Text Grid incl.¬†¬± 1 utterance in Praat option).\n\n\n\n\n\n\n\nNow that WebMAUS has created individually aligned phones in the corpus, those speech sounds can be searched and their labels and alignment information exported.\nLet‚Äôs say you‚Äôre particularly interested in the NEAR /…™…ô/ and SQUARE /…õ…ô/ monophthongs. You can now identify and extract instances of those phonemes, using their CELEX DISC labels 7 and 8.\n\nSelect the search option on the menu.\nTick the segment layer.\n\nThe segments layer contains annotations at the sub-word level - i.e.¬†there are potentially multiple annotations per word, each annotation representing a single phone of the word. On the search page you will see that, as with other layers, there is a box on the segments layer for a regular expression.\nAs with other patterns in the search matrix, the pattern that you enter in the box is matched against individual annotations. So if you enter 7 (i.e.¬†CELEX DISC for /…™…ô/) in the in the box, it will match each ‚ÄòNEAR‚Äô vowel segment in each word in the database.\n\n\n\n\n\n\nImportant\n\n\n\nIf you enter a pattern that would match more than a single character on this layer (i.e.¬†more than a single phoneme) then no search results will be returned, because each annotation on this layer is only a single character long (remember the DISC encoding uses one character per phoneme).\nFor example, if you enter n7 for your search, intending to match all instances of the word ‚Äúnear‚Äù, then no results will be returned, because no single segment will ever match that pattern.\nYou can match multiple segments, by adding another segment box using the  button in it, and entering for example n in the first box and 7 in the second box.\n\n\n\nWe want to search for all instances of the ‚ÄòNEAR‚Äô and ‚ÄòSQUARE‚Äô vowels, so enter [78] in the segment pattern box.\nPress Search\nAfter a short delay, you should see a list of words that have either /…™…ô/ or /…õ…ô/.\n\nYou can export all these vowel tokens to a CSV file for analysis or further processing\n\nPress the CSV Export button.\nSave and open the resulting file.\n\nYou will see that the file includes the following columns:\n\nTarget segment ‚Äì the label of the phone that matched the search pattern,\nTarget segment start ‚Äì the start time of the phone and\nTarget segment end ‚Äì the end time of the phone, as determined by WebMAUS.\n\nThis data can be used directly to calculate vowel duration, and in combination with Praat to make acoustic measurements.\n\n\n\nThe CSV file includes the columns ‚ÄúTarget segments start‚Äù and ‚ÄúTarget segments end‚Äù; these columns have the start and end time of the matching segment tokens. Given this information, LaBB-CAT can extract acoustic measurements on the speech sounds using Praat.\n\nIn LaBB-CAT, select the extract menu option.\nClick the process with praat option.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you have no process with praat option, and you have LaBB-CAT installed locally on your own computer (as opposed to it running on a server you access over the internet):\n\nFind out where Praat is installed on your own computer.\nOn a Windows computer this might be somewhere like C:\\Program Files\\Praat\nOn a Mac this will probably be /Applications\nSelect the system attributes option on the LaBB-CAT menu.\nIn the Praat Path box, enter the location you found above.\nPress the Save button at the bottom right of the page.\n\nThen go back the the upload page, and you should find that the process with praat option has appeared.\n\n\n\nPress Browse or Choose File and select the CSV results that you saved above.\nYou will see a form to fill in, and the first couple of settings (Transcript Name column and Participant column should be already filled in).\nFor the Start Time column, ensure that the Target segment start option is selected.\nFor the End Time column, ensure the Target segment end option is selected.\n\nThese two settings define the start/end times of the phone. For some measurements you might extract from Praat, processing signal that includes surrounding context is usually a good idea. You‚Äôll see there‚Äôs a setting for that (which you can leave at the default of 0.025s), and you will see options for various measurements.\nThe default options are for F1 and F2 only, but if you feel like getting other measurements, feel free to tick those options too. You can expand each section with the ‚ñ∫ button to reveal more settings, which allow you to specify more detail about how Praat should do its computations. Again, feel free to look at those and try different settings.\n\nPress Process.\nYou will see a progress bar while LaBB-CAT generates Praat scripts and runs them.\nOnce Praat has finished processing the intervals, you will get a CSV file (you might have to click the CSV file with measurements link) - save and open it.\n\nYou will see that it‚Äôs a copy of the CSV file you uploaded, with some extra columns added on the right.\nDepending on your settings, this will include at least one column per measurement you selected (the formant columns also include a column containing the time at which the measurements were taken), and a final column called Error which is hopefully blank, but which might contain errors reported back by Praat (e.g.¬†if it couldn‚Äôt find the audio file or ran into any other problem during processing).\n\nIn this exercise, you have seen how WebMAUS can be used to compute word and phone alignments automatically from your data. Perfect automatic labels and alignments are not guaranteed, but LaBB-CAT has a mechanism for manually correcting poor alignments.\nOnce forced alignment has been done, individual speech sounds can be identified by searching, extracted, and measured using Praat.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/5-bas-webmaus.html#install-the-layer-manager",
    "href": "worksheets/express-tutorial/5-bas-webmaus.html#install-the-layer-manager",
    "title": "Forced Alignment",
    "section": "",
    "text": "LaBB-CAT has a specialised ‚Äòlayer manager‚Äô module for integrating with the BAS Web Services.\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, click the List of layer managers that are not yet installed link.\nLook for BAS Web Services Manager in the list, and press its Install button.\nFollow the ‚Äúterms of usage‚Äù link and read the terms.\nClose the terms page, returning to LaBB-CAT.\nTick the ‚ÄúAccept Terms of Usage‚Äù option.\nPress Install.\n\nYou will see a page of information about the Layer Manager.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/5-bas-webmaus.html#set-up-a-layer-for-triggering-forced-alignment",
    "href": "worksheets/express-tutorial/5-bas-webmaus.html#set-up-a-layer-for-triggering-forced-alignment",
    "title": "Forced Alignment",
    "section": "",
    "text": "Forced alignment is a process that works on each ‚Äòutterance‚Äô the recording - i.e.¬†each line in the transcript. As it processes all the words on a line at once, we need to create a ‚Äòphrase‚Äô layer.\n\nSelect the phrase layers option on the menu\nAt the top of the page, there‚Äôs a blank form for creating a new layer; fill in the following details:\n\nLayer ID: MAUS\nType: Text\nAlignment: Intervals\nManager: BAS Web Services Manager\nGenerate: Always\nDescription: WebMAUS forced alignment\n\nPress New.\nYou will see a form that allows you to configure the layer; hover the mouse pointer over each setting to see what its purpose is.\nThe main choice is the Phoneme encoding; choose DISC for this setting.\nPress Set Parameters\n\nWe are going to force-align only a single participant‚Äôs for now, so don‚Äôt click Regenerate on this page.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/5-bas-webmaus.html#forced-alignment-1",
    "href": "worksheets/express-tutorial/5-bas-webmaus.html#forced-alignment-1",
    "title": "Forced Alignment",
    "section": "",
    "text": "Select the participants option on the menu at the top.\nTick the checkbox next to the first participant‚Äôs name.\nPress the All Utterances button above.\nPress List.\nLaBB-CAT will identify all the selected participant‚Äôs utterances, and then list the first twenty.\nPress the MAUS button at the bottom of the page.\n\nLaBB-CAT will now upload each utterance ‚Äì both the audio and the transcript ‚Äì to the BAS Web Services server. LaBB-CAT must be able to access the internet for this to work, so if there is no internet connectivity, forced alignment will fail at this point.\nOnce WebMAUS has completed the forced alignment, LaBB-CAT downloads the resulting phone alignment times, and saves them in the segment layer.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/5-bas-webmaus.html#inspectioncorrection",
    "href": "worksheets/express-tutorial/5-bas-webmaus.html#inspectioncorrection",
    "title": "Forced Alignment",
    "section": "",
    "text": "Once forced alignment is complete, you can inspect/correct alignments using LaBB-CAT‚Äôs integration with Praat.\n\n\n\n\n\n\nTip\n\n\n\nYou can follow the following steps without having to wait for the forced alignment to complete.\nProcessing will continue even if you leave the current page.\nIf you later want to check back on the progress of the forced alignment task select the activity option on the menu. If the task is still running, a progress bar will be shown there.\n\n\n\nSelect the transcripts option on the menu.\nOpen the transcript you aligned.\nOn the Layers tab at the top, tick both the MAUS layer and the segment layer.\nYou will see which lines have been force-aligned, as they have a timestamp, and have the segment layer filled in.\n\nThe interactive transcript page doesn‚Äôt show you the alignments of the words or phones, but you can see those using Praat. You can open individual utterances in Praat directly from the transcript page, but first, the LaBB-CAT/Praat integration has to be set up; this only has to be done once:\n\nOn the top-right of the page, above the playback controls, there‚Äôs a Praat icon ¬†- click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\n\n\n\n\n\n\n\nTip\n\n\n\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\n\n\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶\n\nClick on a line that has been aligned, and select the Open TextGrid option on the menu.\nPraat should open, and show you a spectrogram of the line‚Äôs audio, with a TextGrid below that includes the words and the segments.\nIf you click on a word, and hit the tabtab key, the word‚Äôs interval is played. Try out various words, and see what you think about how accurate the forced aligner has been.\n\nTry this out with different lines in the transcript. You will see that in some cases the alignment is pretty good, and in other cases, it‚Äôs not so good. In the not-so-good cases, see if you can figure out why the forced aligner got it wrong.\nYou may have noticed that, each time you open an utterance in Praat, a button appears in the transcript to the left of the line, labelled Import Changes. This button allows you to save any adjustments you might want to make to the alignments back into the LaBB-CAT database.\n\nIf you feel confident using Praat, open an utterance TextGrid, adjust the alignments of the words an phones so that they‚Äôre more accurate, and then press the Import Changes button in the transcript.\n\n\n\n\n\n\n\nWarning\n\n\n\nThese changes are flagged as manual edits, so if forced-alignment is run again, they will not be over-written with new bad alignments. Therefore it‚Äôs important that the changes you make are actually improvements, because automated forced alignment will never change them again.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThere are some rules about what you can change when correcting word/segment alignments:\n\nYou‚Äôre not allowed to add or delete words (if this is necessary, it should be done by correcting the transcript instead).\nAll the segments must be within the bounds of their own word.\nThe start of the first phone should line up with the start of the word, and the end of the last phone should line up with the end of the word.\nYou should not change the alignment of the utterance itself (which would only be possible if you select the Open Text Grid incl.¬†¬± 1 utterance in Praat option).",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/5-bas-webmaus.html#segment-layer-searches",
    "href": "worksheets/express-tutorial/5-bas-webmaus.html#segment-layer-searches",
    "title": "Forced Alignment",
    "section": "",
    "text": "Now that WebMAUS has created individually aligned phones in the corpus, those speech sounds can be searched and their labels and alignment information exported.\nLet‚Äôs say you‚Äôre particularly interested in the NEAR /…™…ô/ and SQUARE /…õ…ô/ monophthongs. You can now identify and extract instances of those phonemes, using their CELEX DISC labels 7 and 8.\n\nSelect the search option on the menu.\nTick the segment layer.\n\nThe segments layer contains annotations at the sub-word level - i.e.¬†there are potentially multiple annotations per word, each annotation representing a single phone of the word. On the search page you will see that, as with other layers, there is a box on the segments layer for a regular expression.\nAs with other patterns in the search matrix, the pattern that you enter in the box is matched against individual annotations. So if you enter 7 (i.e.¬†CELEX DISC for /…™…ô/) in the in the box, it will match each ‚ÄòNEAR‚Äô vowel segment in each word in the database.\n\n\n\n\n\n\nImportant\n\n\n\nIf you enter a pattern that would match more than a single character on this layer (i.e.¬†more than a single phoneme) then no search results will be returned, because each annotation on this layer is only a single character long (remember the DISC encoding uses one character per phoneme).\nFor example, if you enter n7 for your search, intending to match all instances of the word ‚Äúnear‚Äù, then no results will be returned, because no single segment will ever match that pattern.\nYou can match multiple segments, by adding another segment box using the  button in it, and entering for example n in the first box and 7 in the second box.\n\n\n\nWe want to search for all instances of the ‚ÄòNEAR‚Äô and ‚ÄòSQUARE‚Äô vowels, so enter [78] in the segment pattern box.\nPress Search\nAfter a short delay, you should see a list of words that have either /…™…ô/ or /…õ…ô/.\n\nYou can export all these vowel tokens to a CSV file for analysis or further processing\n\nPress the CSV Export button.\nSave and open the resulting file.\n\nYou will see that the file includes the following columns:\n\nTarget segment ‚Äì the label of the phone that matched the search pattern,\nTarget segment start ‚Äì the start time of the phone and\nTarget segment end ‚Äì the end time of the phone, as determined by WebMAUS.\n\nThis data can be used directly to calculate vowel duration, and in combination with Praat to make acoustic measurements.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/5-bas-webmaus.html#acoustic-measurement",
    "href": "worksheets/express-tutorial/5-bas-webmaus.html#acoustic-measurement",
    "title": "Forced Alignment",
    "section": "",
    "text": "The CSV file includes the columns ‚ÄúTarget segments start‚Äù and ‚ÄúTarget segments end‚Äù; these columns have the start and end time of the matching segment tokens. Given this information, LaBB-CAT can extract acoustic measurements on the speech sounds using Praat.\n\nIn LaBB-CAT, select the extract menu option.\nClick the process with praat option.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you have no process with praat option, and you have LaBB-CAT installed locally on your own computer (as opposed to it running on a server you access over the internet):\n\nFind out where Praat is installed on your own computer.\nOn a Windows computer this might be somewhere like C:\\Program Files\\Praat\nOn a Mac this will probably be /Applications\nSelect the system attributes option on the LaBB-CAT menu.\nIn the Praat Path box, enter the location you found above.\nPress the Save button at the bottom right of the page.\n\nThen go back the the upload page, and you should find that the process with praat option has appeared.\n\n\n\nPress Browse or Choose File and select the CSV results that you saved above.\nYou will see a form to fill in, and the first couple of settings (Transcript Name column and Participant column should be already filled in).\nFor the Start Time column, ensure that the Target segment start option is selected.\nFor the End Time column, ensure the Target segment end option is selected.\n\nThese two settings define the start/end times of the phone. For some measurements you might extract from Praat, processing signal that includes surrounding context is usually a good idea. You‚Äôll see there‚Äôs a setting for that (which you can leave at the default of 0.025s), and you will see options for various measurements.\nThe default options are for F1 and F2 only, but if you feel like getting other measurements, feel free to tick those options too. You can expand each section with the ‚ñ∫ button to reveal more settings, which allow you to specify more detail about how Praat should do its computations. Again, feel free to look at those and try different settings.\n\nPress Process.\nYou will see a progress bar while LaBB-CAT generates Praat scripts and runs them.\nOnce Praat has finished processing the intervals, you will get a CSV file (you might have to click the CSV file with measurements link) - save and open it.\n\nYou will see that it‚Äôs a copy of the CSV file you uploaded, with some extra columns added on the right.\nDepending on your settings, this will include at least one column per measurement you selected (the formant columns also include a column containing the time at which the measurements were taken), and a final column called Error which is hopefully blank, but which might contain errors reported back by Praat (e.g.¬†if it couldn‚Äôt find the audio file or ran into any other problem during processing).\n\nIn this exercise, you have seen how WebMAUS can be used to compute word and phone alignments automatically from your data. Perfect automatic labels and alignments are not guaranteed, but LaBB-CAT has a mechanism for manually correcting poor alignments.\nOnce forced alignment has been done, individual speech sounds can be identified by searching, extracted, and measured using Praat.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#labb-cat-needs",
    "href": "worksheets/express-tutorial/presentation.html#labb-cat-needs",
    "title": "LaBB-CAT",
    "section": "LaBB-CAT needs:",
    "text": "LaBB-CAT needs:\nTranscripts\n\nwhat: Orthographic transcripts (audio/video is optional)\nwhen: ‚Ä¶divided into time-stamped utterances (‚â§ 15 words)\nwho: ‚Ä¶with some way to identify the speaker\n\n\nTextual data is supported\n\nTranscript = text\nUtterances = lines\nSpeaker = author",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n\n\n\n\nOne tier per speaker",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats-1",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats-1",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n\n\n\n\nOne tier per layer",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats-2",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats-2",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n Transcriber",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats-3",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats-3",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n Transcriber\n ELAN",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats-4",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats-4",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n Transcriber\n ELAN\n Plain Text",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats-5",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats-5",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n Transcriber\n ELAN\n Plain Text\n CHAT (partial support)",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats-6",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats-6",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n Transcriber\n ELAN\n Plain Text\n CHAT (partial support)\n SALT (partial support)",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats-7",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats-7",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n Transcriber\n ELAN\n Plain Text\n CHAT (partial support)\n SALT (partial support)\n TEI (partial support)",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#transcript-formats-8",
    "href": "worksheets/express-tutorial/presentation.html#transcript-formats-8",
    "title": "LaBB-CAT",
    "section": "Transcript Formats",
    "text": "Transcript Formats\n\n Praat TextGrid\n Transcriber\n ELAN\n Plain Text\n CHAT (partial support)\n SALT (partial support)\n TEI (partial support)\n VTT Subtitles",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#elicitation-tasks",
    "href": "worksheets/express-tutorial/presentation.html#elicitation-tasks",
    "title": "LaBB-CAT",
    "section": "Elicitation Tasks",
    "text": "Elicitation Tasks\n\nDefine a speech elicitation task",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#elicitation-tasks-1",
    "href": "worksheets/express-tutorial/presentation.html#elicitation-tasks-1",
    "title": "LaBB-CAT",
    "section": "Elicitation Tasks",
    "text": "Elicitation Tasks\n\nRecording via the web browser",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#meta-data",
    "href": "worksheets/express-tutorial/presentation.html#meta-data",
    "title": "LaBB-CAT",
    "section": "Meta-data",
    "text": "Meta-data\nBoth Transcripts and Participants can have defined ‚Äòattributes‚Äô\n\n\n\nTextual types:\n\nString - e.g.¬†ethnicity\nText - e.g.¬†notes\nEmail - e.g.¬†contact address\nURL - e.g.¬†source document\nRead Only - e.g.¬†transcript version\n\nNumeric types:\n\nInteger - e.g.¬†age in years\nNumber - e.g.¬†syllables per minute\nStyles: Slider - e.g.¬†rating\n\n\n\n\nTemporal types:\n\nDate - e.g.¬†date of birth\nTime - e.g.¬†interview duration\nDate/Time - e.g.¬†recording date/time\n\nFixed class types:\n\nBoolean e.g.¬†checked\nSelect e.g.¬†language\nStyles:\n\nMultiple - e.g.¬†permissions\nOther - e.g.¬†gender",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#clientserver",
    "href": "worksheets/express-tutorial/presentation.html#clientserver",
    "title": "LaBB-CAT",
    "section": "Client/Server",
    "text": "Client/Server\n\n\n\n\n\nBrowser on Clients\n\n\n\n\n\n\n\n\nWeb Server",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#standalone",
    "href": "worksheets/express-tutorial/presentation.html#standalone",
    "title": "LaBB-CAT",
    "section": "Standalone",
    "text": "Standalone\n\nBrowser and Web Server on the same computer",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#layer-managers",
    "href": "worksheets/express-tutorial/presentation.html#layer-managers",
    "title": "LaBB-CAT",
    "section": "Layer Managers",
    "text": "Layer Managers\nAutomated Annotation\n\nPorter Stemmer ‚Äì English stem\nLexicon layer managers: CELEX, CMU Dictionary, Unisyn, Flat file dictionary\nPattern Matcher and Character Mapper ‚Äì regular-expression-based processing\nFrequency ‚Äì word counts in different scopes\nLIWC ‚Äì percentages of words in different categories\nStatistics ‚Äì aggregation od groups of tokens\nContext ‚Äì previous mention, previous pause\nPartition ‚Äì partitions of n tokens\nJavascript and Python managers ‚Äì arbitrary scripting\nStanford POS Tagger ‚Äì part-of-speech\nStanford Parser ‚Äì syntactic parsing\nForced alignment ‚Ä¶",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#forced-alignment",
    "href": "worksheets/express-tutorial/presentation.html#forced-alignment",
    "title": "LaBB-CAT",
    "section": "Forced Alignment",
    "text": "Forced Alignment\n\n\nAutomatically locate start/end times of speech sounds",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#htk-penn-aligner",
    "href": "worksheets/express-tutorial/presentation.html#htk-penn-aligner",
    "title": "LaBB-CAT",
    "section": "HTK / Penn Aligner",
    "text": "HTK / Penn Aligner\n\nHTK software, Penn pretrained models",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#montreal-forced-aligner",
    "href": "worksheets/express-tutorial/presentation.html#montreal-forced-aligner",
    "title": "LaBB-CAT",
    "section": "Montreal Forced Aligner",
    "text": "Montreal Forced Aligner\n\nMFA software, Dictionaries and pretrained models downloaded from GitHub",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#webmaus",
    "href": "worksheets/express-tutorial/presentation.html#webmaus",
    "title": "LaBB-CAT",
    "section": "WebMAUS",
    "text": "WebMAUS\n\nTranscripts and recordings sent over the internet",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#labb-cat",
    "href": "worksheets/express-tutorial/presentation.html#labb-cat",
    "title": "LaBB-CAT",
    "section": "LaBB-CAT",
    "text": "LaBB-CAT\n\nOpen Source\nCross Platform\nFree to install\nhttps://sourceforge.net/projects/labbcat\n\nrobert.fromont@canterbury.ac.nz\nhttps://labbcat.canterbury.ac.nz",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/presentation.html#worksheets",
    "href": "worksheets/express-tutorial/presentation.html#worksheets",
    "title": "LaBB-CAT",
    "section": "Worksheets‚Ä¶",
    "text": "Worksheets‚Ä¶\n\n\n\nCreate a corpus from ELAN transcripts",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "LaBB-CAT"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/multilingual-corpora.html",
    "href": "howto/phonemic-tagging/multilingual-corpora.html",
    "title": "Phonemic Tagging: Multilingual Corpora",
    "section": "",
    "text": "Phonemic Tagging: Multilingual Corpora\nIf the speech corpus includes data in more than one language, it is possible to ensure that the utterances are phonemically tagged in a way that‚Äôs sensitive to the language of the specific utterance.\nThe layer manager modules that phonemically transcribe the data can be configured to annotate only words that are in the language targeted for that specific module, using the language code (e.g.¬†‚Äúmi‚Äù for Te Reo MƒÅori, ‚Äúen‚Äù for English, ‚Äúen-NZ‚Äù for New Zealand English, etc.).\nEach annotation layer is usually managed by a single layer manager, but it‚Äôs possible to have extra ‚ÄòAuxiliary Layer Managers‚Äô configured for each layer. So you can have a single phonemes layer that contains all phonemic transcriptions, regardless of the language of the data; e.g.¬†you might have the layer with\n\nthe CELEX English layer manager as the primary layer manager, targeting only English utterances, plus\nthe CELEX German layer manager as an auxiliary, targeting only German utterances, and\nthe Character Mapper layer manager as an auxiliary, configured to target only utterances in Te Reo MƒÅori with orthography-to-phonology mappings.\n\nIn order to set this up:\n\nIn LaBB-CAT, select the word layers option on the menu.\nAdd a phonemes layer that‚Äôs managed by the CELEX English layer manager.\nSet the layer configuration as required, ensuring that in its configuration, the Language setting targets only English words:\n\nSelect the word layers option on the menu again.\nOn the phonemes layer, press the ‚ÄòOther configurations‚Äô icon: \nFill in the description box as German pronunciation\nFor the layer manager select the CELEX German option.\nPress the New button.\nPress Configure\nConfigure the layer as required.\nEnsure the Language setting is that to de.* to annotate only words that are in German:\n\nSelect the word layers option on the menu again.\nOn the phonemes layer, press the ‚ÄòOther configurations‚Äô icon: \nFill in the blank description box as Te Reo MƒÅori pronunciation\nFor its layer manager select the Character Mapper option.\nPress the New button.\nPress Configure\nConfigure the layer as required.\nEnsure the Language setting is that to mi to annotate only words that are in MƒÅori:\n\n\n\n\n\nThe ‚Äòphonemes‚Äô layer‚Äôs two auxiliary configurations\n\n\nWhen the layer is generated, first the main configuration will generate annotations (i.e.¬†CELEX English phonology), and then the auxiliary configurations will be run, in alphabetical order. As long as each has a different language targeted, they will each annotate different word tokens.\nLaBB-CAT has three mechanisms for determining the language of each word token in the corpus:\n\nIf the word is enclosed in an annotation on the language phrase layer, then the annotation‚Äôs label determines the language of that token. The language phrase layer is a time-span layer that allows spans of words to be marked as being in a specific language.\n\n\n\n\n\n\n\nTip\n\n\n\nHow these manual annotations are added depends on the transcription tool; e.g.¬†\n\nTranscriber has a mechanism specifically for this, and for ELAN transcripts, and\nLaBB-CAT supports a language-tagging transcription convention which can achieve the same thing.\n\n\n\n\nOtherwise, the transcript‚Äôs language transcript attribute is used to determine the language.\nIf the language transcript attribute is unset, then the language of the corpus the transcript is in is used to determine the language.\n\nUsing these mechanisms, it‚Äôs possible to ensure that each token is labelled with the correct phonemic transcription, even if the corpus contains multiple languages, and even if there are multiple languages within the same transcript.\n\n\n\nA transcript in Te Reo MƒÅori, with English words annotated on the language phrase layer\n\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Multilingual Corpora"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/unisyn.html",
    "href": "howto/phonemic-tagging/unisyn.html",
    "title": "Phonemic Tagging with the Unisyn lexicon",
    "section": "",
    "text": "LaBB-CAT includes the Unisyn layer manager, which is designed for ingesting Unisyn accent-specific lexicons. Unisyn must be downloaded separately, and the included scripts executed to produce a lexicon for the desired variety. The resulting file can be added to LaBB-CAT, and then the layer manager can be configured to use it for tagging word tokens with their phonemic transcriptions.\nUnisyn is a ‚Äòmaster lexicon‚Äô of English, which contains:\n\northography\npart-of-speech\npronunciation, in an ‚Äòaccent neutral‚Äô form\n‚Äòenriched orthography‚Äô showing morphological information\nfrequency, as derived from various sources, including the British National Corpus, Time articles, Gutenberg, etc.\n\nThe pronunciations in the lexicon can be converted into an accent-specific form using perl scripts that are included with the lexicon.\n\n\nUnisyn is available under a non-commercial license, and must be acquired seperately from this layer manager. To acquire Unisyn, you must first register on the the Unisyn website and accept the terms of their license. The Unisyn website is here:\nhttp://www.cstr.ed.ac.uk/projects/unisyn/\n(This layer manager has been tested with version 1.3 of Unisyn)\n\n\n\nFirst, the Unisyn layer manager module must be installed:\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link near the bottom.\nFind ‚ÄúUnisyn‚Äù in the list, and press its Install button, then Install again.\n\nOnce the layer manager is installed, you‚Äôll see a page of information explaining more details about the layer manager. Once you‚Äôve read this information, you can close the browser tab to return to LaBB-CAT.\n\n\n\nOnce you‚Äôve got Unisyn, you can use it to produce accent-specific lexicons, and provide these lexicons to the layer manager, which then uses them to annotate words in LaBB-CAT.\nFor example, if you want to annotate your transcripts with ‚ÄòGeneral American English‚Äô pronunciations:\n\nGenerate the General American English (gam) lexicon by running the following Unisyn commands:\n\nget-exceptions.pl -a gam -f unilex &gt; gam.1\npost-lex-rules.pl -a gam -f gam.1 &gt; gam.2\nmap-unique.pl -a gam -f gam.2 &gt; gam.unisyn. This gives you the file gam.unisyn, which is the lexicon file you need for the next step.\n\nUpload the accent-specific lexicon into LaBB-CAT:\n\nSelect layer managers on the menu.\nFind the Unisyn layer manager in the list, and click the Extensions button (the second-to-last button on the right).\nPress Choose File and select the gam.unisyn file you generated above.\nPress Upload Lexicon.\nYou will see a progress bar while the file is uploaded and the data is processed.\n\nCreate the layer for your pronunciation annotations: To create a new layer with CMUdict annotations:\n\nSelect the word layers option on the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID: enter a name - e.g.¬†phonemes\nType: select Phonological\nManager: select Unisyn\nAlignment: select None (as these are simply tags on the orthographic words)\nGenerate: select Always\nDescription: something like\nAll possible pronnunciations according to Unisyn‚Äôs General American accent-specific lexicon\n\nPress the New button to create the layer. You will see the layer configuration page. Check the online help for explanations of all options, but at least:\nEnsure the Source Layer is orthography\nSelect the desired Lexicon from the list (these relate to the file or files you generated and uploaded above)\nTick the Strip syllabification/stress if you will use this layer for forced alignment with HTK. \nPress Save\nPress Regenerate. You will see a progress bar while the layer manager annotates all the transcripts that have already been uploaded.\n\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, the Unisyn annotations will automatically be generated for it.\n\n\n\nLaBB-CAT‚Äôs processing of phonological layers assumes that the annotations use the DISC phoneme set designed for the CELEX phonemic transcriptions. This set is used because each phoneme is expressed by precisely one ASCII character, including phonemes usually expressed using a digraph - e.g.¬†affricates like /t É/ (which is /J/ in DISC) and diphthongs like /a…™/ (which is /2/ in DISC)\nUnisyn transcriptions use a set of phones that is greater that the set of phones available in DISC, and the transcriptions are designed to be broadly phonetic, not phonemic.\nThis means that using the DISC representation of the transcripts is imperfect, as there is a certain amount of loss of information when mapping Unisyn phones to DISC phonemes. The default mapping that is used is shown below.\n\n\n\nUnisyn\n\nDISC\nIPA\nLexical set e.g.\n\n\n\n\nah\n‚Üí\n#\n‚±≠:\nBATH\n\n\naa\n‚Üí\nQ\n…í\nPALM ‚Üí LOT\n\n\nar\n‚Üí\nQ\n…í\nstart ‚Üí PALM ‚Üí LOT\n\n\noa\n‚Üí\n{\n√¶\nBANANA ‚Üí TRAP\n\n\nao\n‚Üí\n#\n…ë:\nMAZDA ‚Üí BATH\n\n\ne\n‚Üí\nE\nŒµ\nDRESS\n\n\ner\n‚Üí\nE\nŒµ\nr-coloured DRESS in scots en\n\n\na\n‚Üí\n{\n√¶\nTRAP\n\n\neh\n‚Üí\n{\n√¶\nann use TRAP\n\n\nou\n‚Üí\n5\n…ô ä\nGOAT - but a monophthong for in some varieties\n\n\noul\n‚Üí\n5\n…ô ä\ngoal - post vocalic GOAT\n\n\nouw\n‚Üí\n5\n…ô ä\nKNOW ‚Üí GOAT (except for Abergave)\n\n\no\n‚Üí\nQ\n…í\nLOT\n\n\noou\n‚Üí\nQ\n…í\nadios ‚Üí LOT\n\n\nau\n‚Üí\nQ\n…í\nCLOTH ‚Üí LOT (but a diphthong in some en-US)\n\n\noo\n‚Üí\n$\n…î:\nTHOUGHT (but a diphthong in some varieties)\n\n\nor\n‚Üí\n$\n…î:\nr-coloured THOUGHT\n\n\nii\n‚Üí\ni\ni:\nFLEECE\n\n\niy\n‚Üí\ni\ni:\nHAPPY - I for some varieties\n\n\nie\n‚Üí\ni\ni:\nHARRIET - Leeds only\n\n\nii;\n‚Üí\ni\ni:\nAGREED ‚Üí FLEECE\n\n\nir\n‚Üí\ni\ni:\nNEARING - r-coloured NEAR ‚Üí FLEECE\n\n\nir;\n‚Üí\ni\ni:\nnear - scots-long NEAR ‚Üí FLEECE\n\n\ni\n‚Üí\nI\n…™\nKIT\n\n\n@\n‚Üí\n@\n…ô\nschwa\n\n\n@r\n‚Üí\n@\n…ô\nr-coloured schwa\n\n\nuh\n‚Üí\nV\n å\nSTRUT\n\n\nu\n‚Üí\nU\n ä\nFOOT\n\n\nuu\n‚Üí\nu\nu:\nGOOSE\n\n\niu\n‚Üí\nu\nu:\nBLEW ‚Üí GOOSE\n\n\nuu;\n‚Üí\nu\nu:\nbrewed ‚Üí GOOSE\n\n\nuw\n‚Üí\nu\nu:\nlouise ‚Üí GOOSE\n\n\nuul\n‚Üí\nu\nu:\ngoul - post-vocalic GOOSE\n\n\nei\n‚Üí\n1\ne…™\nFACE\n\n\nee\n‚Üí\n1\ne…™\nWASTE ‚Üí FACE (except for abercrave)\n\n\nai\n‚Üí\n2\na…™\nPRICE\n\n\nae\n‚Üí\n2\na…™\nTIED ‚Üí PRICE (except Edi and Aberdeen)\n\n\nae\n‚Üí\n2\na…™\nTIED ‚Üí PRICE (except Edi and Aberdeen)\n\n\naer\n‚Üí\n2\na…™\nFIRE - r-coloured PRICE\n\n\naai\n‚Üí\n2\na…™\nTIME ‚Üí PRICE (except S. Carolina)\n\n\noir\n‚Üí\n2\na…™\nCOIR - r-coloured PRICE\n\n\n@@r\n‚Üí\n3\n…ú:\nNURSE\n\n\noi\n‚Üí\n4\n…î…™\nCHOICE\n\n\now\n‚Üí\n6\na ä\nMOUTH\n\n\nowr\n‚Üí\n6\na ä\nHOUR - r-coloured MOUTH\n\n\noow\n‚Üí\n6\na ä\nHOUR ‚Üí MOUTH (exception S. Carolina)\n\n\ni@\n‚Üí\n7\n…™…ô\nNEAR\n\n\niir\n‚Üí\n7\n…™…ô\nbeard ‚Üí NEAR (except en-AU)\n\n\neir\n‚Üí\n8\nŒµ…ô\nSQUARING (actually a monophthong in many varieties)\n\n\nur\n‚Üí\n9\n ä…ô\nJURY\n\n\nur;\n‚Üí\n9\n ä…ô\nCURE - scots-long JURY\n\n\niur\n‚Üí\n9\n ä…ô\ncurious - JURY exception in Cardiff & Abercrave\n\n\np\n‚Üí\np\np\n\n\n\nt\n‚Üí\nt\nt\n\n\n\n?\n‚Üí\n?\n î\n(glottal stop)\n\n\nt^\n‚Üí\nL\n…æ\nbutter/merry flap\n\n\nk\n‚Üí\nk\nk\n\n\n\nx\n‚Üí\nx\nx\nloch\n\n\nb\n‚Üí\nb\nb\n\n\n\nd\n‚Üí\nd\nd\n\n\n\ng\n‚Üí\ng\ng\n\n\n\nch\n‚Üí\nJ\n ß\n\n\n\njh\n‚Üí\n_\n §\n\n\n\ns\n‚Üí\ns\ns\n\n\n\nz\n‚Üí\nz\nz\n\n\n\nsh\n‚Üí\nS\n É\n\n\n\nzh\n‚Üí\nZ\n í\n\n\n\nf\n‚Üí\nf\nf\n\n\n\nv\n‚Üí\nv\nv\n\n\n\nth\n‚Üí\nT\nŒ∏\n\n\n\ndh\n‚Üí\nD\n√∞\n\n\n\nh\n‚Üí\nm\nm\n\n\n\nm\n‚Üí\nm\nm\n\n\n\nm!\n‚Üí\nF\nmÃ©\nchasm\n\n\nn\n‚Üí\nn\nn\n\n\n\nn!\n‚Üí\nH\nnÃ©\nmission\n\n\nng\n‚Üí\nN\n≈ã\n\n\n\nl\n‚Üí\nl\nl\n\n\n\nll\n‚Üí\nl\nl\nllandudno (for Cardiff and Abercrave, this is different)\n\n\nlw\n‚Üí\nl\nl\nfeel - dark l\n\n\nr\n‚Üí\nr\nr\n\n\n\ny\n‚Üí\nj\nj\n\n\n\nw\n‚Üí\nw\nw\nwhich\n\n\nhw\n‚Üí\nw\nw\nwhich\n\n\n\n\n\nIf you would like to adjust this mapping, so that Unisyn symbols correspond to different DISC symbols, you can do so by visitin the Unisyn Layer Manager‚Äôs Extensions page, and following the dictionary‚Äôs ‚ÄòPhoneme Map‚Äô link, as shown in Figure¬†1\n\n\n\n\n\n\nFigure¬†1: Lexicon listing, where mappings can be speccified, and lexicons uploaded, or deleted\n\n\n\nThis page allows you to change how Unisyn symbols correspond to DISC symbols, as seen in Figure¬†2. You can change symbols/text in the text boxes, and then save your changes with the save button that appears at the bottom of the list.\n\n\n\n\n\n\nFigure¬†2: Phoneme Map page allowing correspondences to be edited\n\n\n\n\n\n\n\nIf having the original transcriptions precisely as defined in the Unisyn lexicon is very important, you can instead create a layer that uses the original transcription as contained in the file you uploaded. This has the advantage that the transcriptions are not filtered through the above mapping, and the disadvantage that LaBB-CAT won‚Äôt be able to display the transcriptions using IPA symbols, nor help you when creating search patterns for the layer.\nIf you decide to do this, Unisyn offers you two possible representations:\n\nUnisyn transcriptions - e.g.¬†{ p r @ . n ~ uh n s $}.&gt; ii . * ei . sh n! &gt; - these are already present in the file that you generated if you followed the instructions above (i.e.¬†gam.unisyn)\nSAM-PA transcriptions - e.g.¬†pr\\@%nVns$i\"e$Sn=$@5 - these can be obtained by running an extra Unisyn command, and uploading the resulting gam.sampa file:\noutput-sam.pl -a gam -f gam.unisyn &gt; gam.sampa\n\n(Unisyn has a third script called output-ipa.pl which produces transcriptions for displaying in HTML - e.g.¬†p…π…ôÀån åns.iÀàe. Én Ã© - which are not suitable for search, analysis, or forced-alignment)\nIn order to prevent the DISC mapping from applying on your layer:\n\nWhen creating the layer, set the layer type to Text rather than Phonological.\nWhen configuring the layer, set the field to Phonemes (original file) rather than Phonemes (DISC).",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Unisyn"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/unisyn.html#getting-unisyn",
    "href": "howto/phonemic-tagging/unisyn.html#getting-unisyn",
    "title": "Phonemic Tagging with the Unisyn lexicon",
    "section": "",
    "text": "Unisyn is available under a non-commercial license, and must be acquired seperately from this layer manager. To acquire Unisyn, you must first register on the the Unisyn website and accept the terms of their license. The Unisyn website is here:\nhttp://www.cstr.ed.ac.uk/projects/unisyn/\n(This layer manager has been tested with version 1.3 of Unisyn)",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Unisyn"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/unisyn.html#install-the-layer-manager",
    "href": "howto/phonemic-tagging/unisyn.html#install-the-layer-manager",
    "title": "Phonemic Tagging with the Unisyn lexicon",
    "section": "",
    "text": "First, the Unisyn layer manager module must be installed:\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link near the bottom.\nFind ‚ÄúUnisyn‚Äù in the list, and press its Install button, then Install again.\n\nOnce the layer manager is installed, you‚Äôll see a page of information explaining more details about the layer manager. Once you‚Äôve read this information, you can close the browser tab to return to LaBB-CAT.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Unisyn"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/unisyn.html#using-unisyn-with-this-layer-manager",
    "href": "howto/phonemic-tagging/unisyn.html#using-unisyn-with-this-layer-manager",
    "title": "Phonemic Tagging with the Unisyn lexicon",
    "section": "",
    "text": "Once you‚Äôve got Unisyn, you can use it to produce accent-specific lexicons, and provide these lexicons to the layer manager, which then uses them to annotate words in LaBB-CAT.\nFor example, if you want to annotate your transcripts with ‚ÄòGeneral American English‚Äô pronunciations:\n\nGenerate the General American English (gam) lexicon by running the following Unisyn commands:\n\nget-exceptions.pl -a gam -f unilex &gt; gam.1\npost-lex-rules.pl -a gam -f gam.1 &gt; gam.2\nmap-unique.pl -a gam -f gam.2 &gt; gam.unisyn. This gives you the file gam.unisyn, which is the lexicon file you need for the next step.\n\nUpload the accent-specific lexicon into LaBB-CAT:\n\nSelect layer managers on the menu.\nFind the Unisyn layer manager in the list, and click the Extensions button (the second-to-last button on the right).\nPress Choose File and select the gam.unisyn file you generated above.\nPress Upload Lexicon.\nYou will see a progress bar while the file is uploaded and the data is processed.\n\nCreate the layer for your pronunciation annotations: To create a new layer with CMUdict annotations:\n\nSelect the word layers option on the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID: enter a name - e.g.¬†phonemes\nType: select Phonological\nManager: select Unisyn\nAlignment: select None (as these are simply tags on the orthographic words)\nGenerate: select Always\nDescription: something like\nAll possible pronnunciations according to Unisyn‚Äôs General American accent-specific lexicon\n\nPress the New button to create the layer. You will see the layer configuration page. Check the online help for explanations of all options, but at least:\nEnsure the Source Layer is orthography\nSelect the desired Lexicon from the list (these relate to the file or files you generated and uploaded above)\nTick the Strip syllabification/stress if you will use this layer for forced alignment with HTK. \nPress Save\nPress Regenerate. You will see a progress bar while the layer manager annotates all the transcripts that have already been uploaded.\n\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, the Unisyn annotations will automatically be generated for it.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Unisyn"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/unisyn.html#mapping-unisyn-pronunciations-to-the-disc-phoneme-set",
    "href": "howto/phonemic-tagging/unisyn.html#mapping-unisyn-pronunciations-to-the-disc-phoneme-set",
    "title": "Phonemic Tagging with the Unisyn lexicon",
    "section": "",
    "text": "LaBB-CAT‚Äôs processing of phonological layers assumes that the annotations use the DISC phoneme set designed for the CELEX phonemic transcriptions. This set is used because each phoneme is expressed by precisely one ASCII character, including phonemes usually expressed using a digraph - e.g.¬†affricates like /t É/ (which is /J/ in DISC) and diphthongs like /a…™/ (which is /2/ in DISC)\nUnisyn transcriptions use a set of phones that is greater that the set of phones available in DISC, and the transcriptions are designed to be broadly phonetic, not phonemic.\nThis means that using the DISC representation of the transcripts is imperfect, as there is a certain amount of loss of information when mapping Unisyn phones to DISC phonemes. The default mapping that is used is shown below.\n\n\n\nUnisyn\n\nDISC\nIPA\nLexical set e.g.\n\n\n\n\nah\n‚Üí\n#\n‚±≠:\nBATH\n\n\naa\n‚Üí\nQ\n…í\nPALM ‚Üí LOT\n\n\nar\n‚Üí\nQ\n…í\nstart ‚Üí PALM ‚Üí LOT\n\n\noa\n‚Üí\n{\n√¶\nBANANA ‚Üí TRAP\n\n\nao\n‚Üí\n#\n…ë:\nMAZDA ‚Üí BATH\n\n\ne\n‚Üí\nE\nŒµ\nDRESS\n\n\ner\n‚Üí\nE\nŒµ\nr-coloured DRESS in scots en\n\n\na\n‚Üí\n{\n√¶\nTRAP\n\n\neh\n‚Üí\n{\n√¶\nann use TRAP\n\n\nou\n‚Üí\n5\n…ô ä\nGOAT - but a monophthong for in some varieties\n\n\noul\n‚Üí\n5\n…ô ä\ngoal - post vocalic GOAT\n\n\nouw\n‚Üí\n5\n…ô ä\nKNOW ‚Üí GOAT (except for Abergave)\n\n\no\n‚Üí\nQ\n…í\nLOT\n\n\noou\n‚Üí\nQ\n…í\nadios ‚Üí LOT\n\n\nau\n‚Üí\nQ\n…í\nCLOTH ‚Üí LOT (but a diphthong in some en-US)\n\n\noo\n‚Üí\n$\n…î:\nTHOUGHT (but a diphthong in some varieties)\n\n\nor\n‚Üí\n$\n…î:\nr-coloured THOUGHT\n\n\nii\n‚Üí\ni\ni:\nFLEECE\n\n\niy\n‚Üí\ni\ni:\nHAPPY - I for some varieties\n\n\nie\n‚Üí\ni\ni:\nHARRIET - Leeds only\n\n\nii;\n‚Üí\ni\ni:\nAGREED ‚Üí FLEECE\n\n\nir\n‚Üí\ni\ni:\nNEARING - r-coloured NEAR ‚Üí FLEECE\n\n\nir;\n‚Üí\ni\ni:\nnear - scots-long NEAR ‚Üí FLEECE\n\n\ni\n‚Üí\nI\n…™\nKIT\n\n\n@\n‚Üí\n@\n…ô\nschwa\n\n\n@r\n‚Üí\n@\n…ô\nr-coloured schwa\n\n\nuh\n‚Üí\nV\n å\nSTRUT\n\n\nu\n‚Üí\nU\n ä\nFOOT\n\n\nuu\n‚Üí\nu\nu:\nGOOSE\n\n\niu\n‚Üí\nu\nu:\nBLEW ‚Üí GOOSE\n\n\nuu;\n‚Üí\nu\nu:\nbrewed ‚Üí GOOSE\n\n\nuw\n‚Üí\nu\nu:\nlouise ‚Üí GOOSE\n\n\nuul\n‚Üí\nu\nu:\ngoul - post-vocalic GOOSE\n\n\nei\n‚Üí\n1\ne…™\nFACE\n\n\nee\n‚Üí\n1\ne…™\nWASTE ‚Üí FACE (except for abercrave)\n\n\nai\n‚Üí\n2\na…™\nPRICE\n\n\nae\n‚Üí\n2\na…™\nTIED ‚Üí PRICE (except Edi and Aberdeen)\n\n\nae\n‚Üí\n2\na…™\nTIED ‚Üí PRICE (except Edi and Aberdeen)\n\n\naer\n‚Üí\n2\na…™\nFIRE - r-coloured PRICE\n\n\naai\n‚Üí\n2\na…™\nTIME ‚Üí PRICE (except S. Carolina)\n\n\noir\n‚Üí\n2\na…™\nCOIR - r-coloured PRICE\n\n\n@@r\n‚Üí\n3\n…ú:\nNURSE\n\n\noi\n‚Üí\n4\n…î…™\nCHOICE\n\n\now\n‚Üí\n6\na ä\nMOUTH\n\n\nowr\n‚Üí\n6\na ä\nHOUR - r-coloured MOUTH\n\n\noow\n‚Üí\n6\na ä\nHOUR ‚Üí MOUTH (exception S. Carolina)\n\n\ni@\n‚Üí\n7\n…™…ô\nNEAR\n\n\niir\n‚Üí\n7\n…™…ô\nbeard ‚Üí NEAR (except en-AU)\n\n\neir\n‚Üí\n8\nŒµ…ô\nSQUARING (actually a monophthong in many varieties)\n\n\nur\n‚Üí\n9\n ä…ô\nJURY\n\n\nur;\n‚Üí\n9\n ä…ô\nCURE - scots-long JURY\n\n\niur\n‚Üí\n9\n ä…ô\ncurious - JURY exception in Cardiff & Abercrave\n\n\np\n‚Üí\np\np\n\n\n\nt\n‚Üí\nt\nt\n\n\n\n?\n‚Üí\n?\n î\n(glottal stop)\n\n\nt^\n‚Üí\nL\n…æ\nbutter/merry flap\n\n\nk\n‚Üí\nk\nk\n\n\n\nx\n‚Üí\nx\nx\nloch\n\n\nb\n‚Üí\nb\nb\n\n\n\nd\n‚Üí\nd\nd\n\n\n\ng\n‚Üí\ng\ng\n\n\n\nch\n‚Üí\nJ\n ß\n\n\n\njh\n‚Üí\n_\n §\n\n\n\ns\n‚Üí\ns\ns\n\n\n\nz\n‚Üí\nz\nz\n\n\n\nsh\n‚Üí\nS\n É\n\n\n\nzh\n‚Üí\nZ\n í\n\n\n\nf\n‚Üí\nf\nf\n\n\n\nv\n‚Üí\nv\nv\n\n\n\nth\n‚Üí\nT\nŒ∏\n\n\n\ndh\n‚Üí\nD\n√∞\n\n\n\nh\n‚Üí\nm\nm\n\n\n\nm\n‚Üí\nm\nm\n\n\n\nm!\n‚Üí\nF\nmÃ©\nchasm\n\n\nn\n‚Üí\nn\nn\n\n\n\nn!\n‚Üí\nH\nnÃ©\nmission\n\n\nng\n‚Üí\nN\n≈ã\n\n\n\nl\n‚Üí\nl\nl\n\n\n\nll\n‚Üí\nl\nl\nllandudno (for Cardiff and Abercrave, this is different)\n\n\nlw\n‚Üí\nl\nl\nfeel - dark l\n\n\nr\n‚Üí\nr\nr\n\n\n\ny\n‚Üí\nj\nj\n\n\n\nw\n‚Üí\nw\nw\nwhich\n\n\nhw\n‚Üí\nw\nw\nwhich\n\n\n\n\n\nIf you would like to adjust this mapping, so that Unisyn symbols correspond to different DISC symbols, you can do so by visitin the Unisyn Layer Manager‚Äôs Extensions page, and following the dictionary‚Äôs ‚ÄòPhoneme Map‚Äô link, as shown in Figure¬†1\n\n\n\n\n\n\nFigure¬†1: Lexicon listing, where mappings can be speccified, and lexicons uploaded, or deleted\n\n\n\nThis page allows you to change how Unisyn symbols correspond to DISC symbols, as seen in Figure¬†2. You can change symbols/text in the text boxes, and then save your changes with the save button that appears at the bottom of the list.\n\n\n\n\n\n\nFigure¬†2: Phoneme Map page allowing correspondences to be edited",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Unisyn"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/unisyn.html#other-possible-phoneme-encodings",
    "href": "howto/phonemic-tagging/unisyn.html#other-possible-phoneme-encodings",
    "title": "Phonemic Tagging with the Unisyn lexicon",
    "section": "",
    "text": "If having the original transcriptions precisely as defined in the Unisyn lexicon is very important, you can instead create a layer that uses the original transcription as contained in the file you uploaded. This has the advantage that the transcriptions are not filtered through the above mapping, and the disadvantage that LaBB-CAT won‚Äôt be able to display the transcriptions using IPA symbols, nor help you when creating search patterns for the layer.\nIf you decide to do this, Unisyn offers you two possible representations:\n\nUnisyn transcriptions - e.g.¬†{ p r @ . n ~ uh n s $}.&gt; ii . * ei . sh n! &gt; - these are already present in the file that you generated if you followed the instructions above (i.e.¬†gam.unisyn)\nSAM-PA transcriptions - e.g.¬†pr\\@%nVns$i\"e$Sn=$@5 - these can be obtained by running an extra Unisyn command, and uploading the resulting gam.sampa file:\noutput-sam.pl -a gam -f gam.unisyn &gt; gam.sampa\n\n(Unisyn has a third script called output-ipa.pl which produces transcriptions for displaying in HTML - e.g.¬†p…π…ôÀån åns.iÀàe. Én Ã© - which are not suitable for search, analysis, or forced-alignment)\nIn order to prevent the DISC mapping from applying on your layer:\n\nWhen creating the layer, set the layer type to Text rather than Phonological.\nWhen configuring the layer, set the field to Phonemes (original file) rather than Phonemes (DISC).",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Unisyn"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/character-mapper.html",
    "href": "howto/phonemic-tagging/character-mapper.html",
    "title": "Phonemic Tagging using the Character Mapper",
    "section": "",
    "text": "The orthography of some languages is closely related to its phonology.\nFor example, in the case of Te Reo MƒÅori, it‚Äôs possible to devise a relatively simple mapping from spelling to phonemes; most letters can represent themselves, with some letter clusters mapping to specific phonemes (e.g.¬†‚Äúng‚Äù ‚Üí /N/, ‚Äúwh‚Äù ‚Üí /f/, etc.).\nLaBB-CAT‚Äôs Character Mapper layer manager can be used to define the details of such a mapping, in order to generate the phonemic transcription annotation layer.\n\n\nThe Character Mapper maps characters strings in the source layer to new characters strings to generate in the target layer. e.g.¬†for mapping spelling to phonemic transcription.\nTo create a new layer with annotations from your dictionary:\n\nSelect the word layers option from the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID - enter a one- or two-word description - e.g.¬†phonemes\nType - select Phonological\nManager - select Character Mapper\nAlignment - select None (as these are simply tags on the orthographic words)\nGenerate - select Always\n\nPress the New button to create the layer\nYou will see the layer configuration page. Check the online help for explanations of all options.\n\nSource Layer - the layer from which annotations will have their characters matched.\nLanguage - a regular expression identifying the ISO 639 code of the language that this configuration should annotate, e.g.¬†en-NZ for New Zealand English, de.* for any variety of German, or blank for any language at all.\nMappings - a list of mappings from source characters to destination characters. If a character (or sequence of characters) in the left column is found in the source layer, then the corresponding character(s) in the right column is saved in the destination layer. Mapping rows are processed in order, and once a match is found, the rest of the rows are ignored for that character.\nRows can be added using the ‚Äúadd‚Äù button on the right, or removed by selecting a mapping (by clicking in the source or destination box) and using the ‚Äúremove‚Äù button.\nThe order of mappings can be changed by selecting a mapping and using the ‚Äúup‚Äù button to move it up, or the ‚Äúdown‚Äù button to move it down.\nFor characters in the source layer that don‚Äôt match any character in the left column, you can either Copy them into the destination layer, or Ignore them (so they are not copied).\n\n\nPress Save\nPress Regenerate.\nYou will see a progress bar while the layer manager annotates all the transcripts that have already been uploaded.\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, annotations will automatically be generated by using the mapping rules you specified.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Simple Mapping"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/character-mapper.html#creating-a-phonemes-layer",
    "href": "howto/phonemic-tagging/character-mapper.html#creating-a-phonemes-layer",
    "title": "Phonemic Tagging using the Character Mapper",
    "section": "",
    "text": "The Character Mapper maps characters strings in the source layer to new characters strings to generate in the target layer. e.g.¬†for mapping spelling to phonemic transcription.\nTo create a new layer with annotations from your dictionary:\n\nSelect the word layers option from the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID - enter a one- or two-word description - e.g.¬†phonemes\nType - select Phonological\nManager - select Character Mapper\nAlignment - select None (as these are simply tags on the orthographic words)\nGenerate - select Always\n\nPress the New button to create the layer\nYou will see the layer configuration page. Check the online help for explanations of all options.\n\nSource Layer - the layer from which annotations will have their characters matched.\nLanguage - a regular expression identifying the ISO 639 code of the language that this configuration should annotate, e.g.¬†en-NZ for New Zealand English, de.* for any variety of German, or blank for any language at all.\nMappings - a list of mappings from source characters to destination characters. If a character (or sequence of characters) in the left column is found in the source layer, then the corresponding character(s) in the right column is saved in the destination layer. Mapping rows are processed in order, and once a match is found, the rest of the rows are ignored for that character.\nRows can be added using the ‚Äúadd‚Äù button on the right, or removed by selecting a mapping (by clicking in the source or destination box) and using the ‚Äúremove‚Äù button.\nThe order of mappings can be changed by selecting a mapping and using the ‚Äúup‚Äù button to move it up, or the ‚Äúdown‚Äù button to move it down.\nFor characters in the source layer that don‚Äôt match any character in the left column, you can either Copy them into the destination layer, or Ignore them (so they are not copied).\n\n\nPress Save\nPress Regenerate.\nYou will see a progress bar while the layer manager annotates all the transcripts that have already been uploaded.\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, annotations will automatically be generated by using the mapping rules you specified.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Simple Mapping"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/celex.html",
    "href": "howto/phonemic-tagging/celex.html",
    "title": "Phonemic Tagging with CELEX",
    "section": "",
    "text": "If you have access to the CELEX lexical database, you can integrate LaBB-CAT with it, allowing you to annotate words in your transcripts with data from CELEX - that can include:\n\nstandard phonemic transcriptions - e.g.¬†‚Äúdifference‚Äù ‚Üí ‚Äúd…™fr…ôns‚Äù or ‚Äúd…™f…ôr…ôns‚Äù\nmorphological information - e.g.¬†‚Äúdifference‚Äù ‚Üí ‚Äúdifferent+ence‚Äù\npossible syntactic category - e.g.¬†‚Äúdifference‚Äù ‚Üí ‚ÄúN‚Äù\nfrequency data\nlemma\nsyllable count\n\nIf you want to do force-aligment (to determine the start and end times of each phone within each word), you will need to start with standard phonemic transcriptions, which CELEX can provide.\nCELEX is essentially a lexical database, available in English, German, and Dutch. You can purchase the database from the LDC, who provide a number of text files for each language. Once you‚Äôve got these data files, you need to install LaBB-CAT‚Äôs CELEX layer manager, which loads the data from the text files into the LaBB-CAT database, and provides mechanisms for generating annotation layers from it.\nThe basic steps are:\n\nBuy CELEX from the LDC.\nSave the data files on the same computer than LaBB-CAT is installed on. If you have zip files, these must be unzipped.\nInstall the CELEX English layer manager (or the German one if your data is in German), providing the location of the files you saved in the previous step\nCreate a new word layer, managed by the CELEX English (or German) layer manager, to generate the annotations you want.\n\n\n\nThe CELEX lexical databases are available from the Linguistic Data Consortium (LDC), and are available for English, German, and Dutch. Currently integration with only the English and German databases is supported by LaBB-CAT.\nYou can buy the databases online from the LDC catalogue.\n\n\n\nFor each language, the database you receive from the LDC consists of a collection of plain text files, arranged in a set of folders. For the language you are going to install, these files, in their original folders, must be saved on to the same computer that the LaBB-CAT server is running on.\nFor example, if you‚Äôre going to install the English CELEX data, then you need to end up with a folder on your LaBB-CAT server called ENGLISH, which contains the folders called:\n\nECT\nEFL\nEFS\nEFW\nEML\nEMW\nEOL\nEOW\nEPL\nEPW\nESL\n\nEach of these subfolders will contain a file named after the subdirectory (e.g.¬†in the ECT folder there‚Äôs a file called ECT.CD) and a file called README.\nIt doesn‚Äôt matter where the top level ENGLISH folder is saved, except that:\n\nit must be accessible to the LaBB-CAT application (so don‚Äôt save it in a private or read-protected location)\nyou have to know the path to the folder - e.g.¬†if you‚Äôre using a Windows computer, and you save the ENGLISH folder on the C: drive inside a folder called Temp, then the path would be C:\\Temp\\ENGLISH\n\n\n\n\nThe CELEX English (or CELEX German or CELEX Dutch) layer manager is a LaBB-CAT module that handles the integration with the CELEX database. It does two tasks:\n\nWhen you install the layer manager, it reads all of the data from the CELEX files, and loads it into a relational database that is part of LaBB-CAT (So once you‚Äôve installed the layer manager successfully, you can delete the original CELEX files if you want to, as LaBB-CAT doesn‚Äôt need them any more).\nAfter installation, the layer manager handles looking up relevant data from its database, and using it to generate annotations for words.\n\nTo install the layer manager:\n\nIn LaBB-CAT, select on the layer managers link on the menu.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for CELEX English (or CELEX Dutch or CELEX German, depending on your needs) and press its Install button.\nYou will see a form that asks for some information. Mostly the values are already filled in, and you can leave the default values as they are. The one important field you must specify is the ENGLISH data folder (or GERMAN data folder). You must fill in the path to the folder here. For example if you‚Äôre using a Windows computer, and you saved the ENGLISH folder on the C: drive inside a folder called Temp, then the path you enter here should be C:\\Temp\\ENGLISH\nClick Install Layer Manager.\nDuring the installation, you will see a progress bar, and information about the files currently being loaded from the CELEX folders. This may take a few minutes. Once it‚Äôs finished, the CELEX Layer Manager help page will appear, telling you what to do next (or you can navigate back to this page, and follow the instructions below).\n\n\n\n\nThe CELEX layer manager can be configured to annotate word tokens in your transcripts with data found in the CELEX database. As these annotations are about individual words, the layer manager can be used for ‚Äòword layers‚Äô (only).\nTo create a new layer with CELEX annotations:\n\nSelect on the word layers menu option.\nThe row of headers at the top of the list is also a form you can fill in to add a new layer.\nFill in the following details:\n\nLayer ID: Enter a descriptive label - e.g.¬†phonemes\nType: Phonological\nManager: CELEX English (or CELEX German or CELEX Dutch)\nAlignment: None (as these are simply tags on the orthographic words)\nGenerate: Always\nDescription:\nAll possible phonemic transcriptions of each word, according to the CELEX lexicon, encoded using DISC symbols*\n\nPress the New button to create the layer.\nYou will see a form that allows you to specify what the layer should generate.\n\nSelect the Phonology option on the left to generate phonemic transcriptions.\nTick the Pronounce Event Override option; this means that if a particular token is annotated on the pronounce layer, that annotation will take precedence over any pronunciation that might be found in CELEX.\n\nPress Save\nPress Renegerate\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, the CELEX annotations will automatically be generated for it.\n\n\n\nSometimes speakers start saying a word but don‚Äôt finish it. The CELEX layer manager includes some special handling for these case, so that it‚Äôs possible to tag them with a pronunciation even though the complete word is not uttered.\n\nFor a hesitation for which multiple syllables are uttered, these can be transcribed up to the point the speaker stops, and then a tilde ~ is used to indicate the word was cut off. Then the pronunciation of the word can be manually entered on the pronounce layer, and it will be copied to the CELEX layer as long as the Pronounce Event Override option is ticked.\ne.g.¬†if you are using ELAN or Praat for transcripts, you can provide pronounce tags in square brackets, directly after the word with no intervening whitespace, directly in the transcript:\nhesi~[hEz@].\nIf you are using Transcriber for transcripts, Transcriber has a mechanism for adding pronunciations to word tokens; just use that.\nFor very short hesitations, where only one or teo sounds are uttered, simply transcribing a couple of letters followed by a ~ is often sufficient; for such very short hesitations, the CELEX Layer Manager will provide a likely pronunciation. e.g.\nhe~",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CELEX"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/celex.html#getting-celex",
    "href": "howto/phonemic-tagging/celex.html#getting-celex",
    "title": "Phonemic Tagging with CELEX",
    "section": "",
    "text": "The CELEX lexical databases are available from the Linguistic Data Consortium (LDC), and are available for English, German, and Dutch. Currently integration with only the English and German databases is supported by LaBB-CAT.\nYou can buy the databases online from the LDC catalogue.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CELEX"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/celex.html#saving-the-data-files",
    "href": "howto/phonemic-tagging/celex.html#saving-the-data-files",
    "title": "Phonemic Tagging with CELEX",
    "section": "",
    "text": "For each language, the database you receive from the LDC consists of a collection of plain text files, arranged in a set of folders. For the language you are going to install, these files, in their original folders, must be saved on to the same computer that the LaBB-CAT server is running on.\nFor example, if you‚Äôre going to install the English CELEX data, then you need to end up with a folder on your LaBB-CAT server called ENGLISH, which contains the folders called:\n\nECT\nEFL\nEFS\nEFW\nEML\nEMW\nEOL\nEOW\nEPL\nEPW\nESL\n\nEach of these subfolders will contain a file named after the subdirectory (e.g.¬†in the ECT folder there‚Äôs a file called ECT.CD) and a file called README.\nIt doesn‚Äôt matter where the top level ENGLISH folder is saved, except that:\n\nit must be accessible to the LaBB-CAT application (so don‚Äôt save it in a private or read-protected location)\nyou have to know the path to the folder - e.g.¬†if you‚Äôre using a Windows computer, and you save the ENGLISH folder on the C: drive inside a folder called Temp, then the path would be C:\\Temp\\ENGLISH",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CELEX"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/celex.html#installing-the-layer-manager",
    "href": "howto/phonemic-tagging/celex.html#installing-the-layer-manager",
    "title": "Phonemic Tagging with CELEX",
    "section": "",
    "text": "The CELEX English (or CELEX German or CELEX Dutch) layer manager is a LaBB-CAT module that handles the integration with the CELEX database. It does two tasks:\n\nWhen you install the layer manager, it reads all of the data from the CELEX files, and loads it into a relational database that is part of LaBB-CAT (So once you‚Äôve installed the layer manager successfully, you can delete the original CELEX files if you want to, as LaBB-CAT doesn‚Äôt need them any more).\nAfter installation, the layer manager handles looking up relevant data from its database, and using it to generate annotations for words.\n\nTo install the layer manager:\n\nIn LaBB-CAT, select on the layer managers link on the menu.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for CELEX English (or CELEX Dutch or CELEX German, depending on your needs) and press its Install button.\nYou will see a form that asks for some information. Mostly the values are already filled in, and you can leave the default values as they are. The one important field you must specify is the ENGLISH data folder (or GERMAN data folder). You must fill in the path to the folder here. For example if you‚Äôre using a Windows computer, and you saved the ENGLISH folder on the C: drive inside a folder called Temp, then the path you enter here should be C:\\Temp\\ENGLISH\nClick Install Layer Manager.\nDuring the installation, you will see a progress bar, and information about the files currently being loaded from the CELEX folders. This may take a few minutes. Once it‚Äôs finished, the CELEX Layer Manager help page will appear, telling you what to do next (or you can navigate back to this page, and follow the instructions below).",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CELEX"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/celex.html#generating-annotations",
    "href": "howto/phonemic-tagging/celex.html#generating-annotations",
    "title": "Phonemic Tagging with CELEX",
    "section": "",
    "text": "The CELEX layer manager can be configured to annotate word tokens in your transcripts with data found in the CELEX database. As these annotations are about individual words, the layer manager can be used for ‚Äòword layers‚Äô (only).\nTo create a new layer with CELEX annotations:\n\nSelect on the word layers menu option.\nThe row of headers at the top of the list is also a form you can fill in to add a new layer.\nFill in the following details:\n\nLayer ID: Enter a descriptive label - e.g.¬†phonemes\nType: Phonological\nManager: CELEX English (or CELEX German or CELEX Dutch)\nAlignment: None (as these are simply tags on the orthographic words)\nGenerate: Always\nDescription:\nAll possible phonemic transcriptions of each word, according to the CELEX lexicon, encoded using DISC symbols*\n\nPress the New button to create the layer.\nYou will see a form that allows you to specify what the layer should generate.\n\nSelect the Phonology option on the left to generate phonemic transcriptions.\nTick the Pronounce Event Override option; this means that if a particular token is annotated on the pronounce layer, that annotation will take precedence over any pronunciation that might be found in CELEX.\n\nPress Save\nPress Renegerate\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, the CELEX annotations will automatically be generated for it.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CELEX"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/celex.html#incomplete-words-and-hesitations",
    "href": "howto/phonemic-tagging/celex.html#incomplete-words-and-hesitations",
    "title": "Phonemic Tagging with CELEX",
    "section": "",
    "text": "Sometimes speakers start saying a word but don‚Äôt finish it. The CELEX layer manager includes some special handling for these case, so that it‚Äôs possible to tag them with a pronunciation even though the complete word is not uttered.\n\nFor a hesitation for which multiple syllables are uttered, these can be transcribed up to the point the speaker stops, and then a tilde ~ is used to indicate the word was cut off. Then the pronunciation of the word can be manually entered on the pronounce layer, and it will be copied to the CELEX layer as long as the Pronounce Event Override option is ticked.\ne.g.¬†if you are using ELAN or Praat for transcripts, you can provide pronounce tags in square brackets, directly after the word with no intervening whitespace, directly in the transcript:\nhesi~[hEz@].\nIf you are using Transcriber for transcripts, Transcriber has a mechanism for adding pronunciations to word tokens; just use that.\nFor very short hesitations, where only one or teo sounds are uttered, simply transcribing a couple of letters followed by a ~ is often sufficient; for such very short hesitations, the CELEX Layer Manager will provide a likely pronunciation. e.g.\nhe~",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CELEX"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/g2p.html",
    "href": "howto/phonemic-tagging/g2p.html",
    "title": "Phonemic Tagging with the G2P BAS Web Service",
    "section": "",
    "text": "The Bavarian Archive for Speech Signals (BAS), has kindly published a set of speech processing web services including one for phonemic transcription called G2P. You can use this service yourself directly, using your web browser, but LaBB-CAT also has a module for using it automatically, called the BAS Services Manager.\n\n\n\n\n\n\nWarning\n\n\n\nIn order to function, your LaBB-CAT server must be able to connect to the internet.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nUsing G2P for phonological tagging requires LaBB-CAT to send your orthographic transcripts over the internet to a third party. Although point 3 of the BAS Web Services Terms of Service makes clear that uploaded data is deleted after 24 hours, using the service is only suitable in situations in which you have consent from participants to do so.\n\n\nYou can use G2P for phonological tagging if your speech is in any of the following languages:\n\nAlbanian\nAustralian Aboriginal Languages\nAfrikaans\nAlbanian\nBasque\nCatalan\nDutch\nEnglish\nEstonian\nFinnish\nFrench\nGeorgian\nGerman\nHungarian\nItalian\nJapanese\nKunwinjku\nLuxembourgish\nMaltese\nNorwegian\nPolish\nRomanian\nRussian\nSpanish\nSwedish\nYol≈ãu Matha\n\nLaBB-CAT must be able to identify which language each transcript is in, so you must ensure the language is set either\n\nin the transcript‚Äôs Language transcript attribute, or\non the corpora page (where you can define the language for all transcripts each corpus).\n\nThe available language options can be set in LaBB-CAT by going to the transcript attributes page and clicking the Options button of the ‚Äúlanguage‚Äù attribute. The value must be a two-letter ISO639-1 code optionally appended with a two-letter country code - e.g.¬†‚Äúen‚Äù or ‚Äúen-NZ‚Äù.\n\n\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for BAS Web Services Manager in the list, and press it‚Äôs Install button, and then Install again.\nFollow the ‚Äúterms of usage‚Äù link and read the terms.\nClose the terms page, returning to LaBB-CAT.\nSelect true for the ‚ÄúAccept Terms of Usage‚Äù option\nPress Configure.\nYou will see a page of information about the Layer Manager, including instructions on how to set up forced alignment.\n\n\n\n\n\nSelect the word layers option on the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID: enter something like phonemes\nType: select Phonological (Or Text if you don‚Äôt want to use ‚ÄúDISC‚Äù encoding; see below)\nAlignment: select None (as these are simply tags on the orthographic words)\nManager: select BAS Web Services Manager\nGenerate: select Always\nDescription: Phonemic transcription according to BAS Web Service‚Äôs G2P\n\nPress the New button to create the layer.\nYou will see a form that allows you to configure the layer; check the online help for that page to guide you.\nOptions include:\n\nG2P - ensure you select this option for phonemic transcription.\nPhoneme Encoding - the encoding of the phonemes, which includes all of the options supported by G2P, plus ‚ÄúDISC‚Äù which, if selected, invokes G2P with ‚Äúsampa‚Äù as the encoding option, and then converts the result to CELEX‚Äôs DISC encoding, which uses exactly one character per phoneme. The ‚ÄúDISC‚Äù option is recommended if the layer has its type set to ‚Äúphonological‚Äù.\nWord Stress - prefix stressed vowels with a stress marker\nSyllabification - include syllable boundary markers in the transcriptions.\n\n\nPress Set Parameters\nPress Regenerate\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, the G2P annotations will automatically be generated for it.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "BAS Web Services"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/g2p.html#install-the-layer-manager",
    "href": "howto/phonemic-tagging/g2p.html#install-the-layer-manager",
    "title": "Phonemic Tagging with the G2P BAS Web Service",
    "section": "",
    "text": "In LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for BAS Web Services Manager in the list, and press it‚Äôs Install button, and then Install again.\nFollow the ‚Äúterms of usage‚Äù link and read the terms.\nClose the terms page, returning to LaBB-CAT.\nSelect true for the ‚ÄúAccept Terms of Usage‚Äù option\nPress Configure.\nYou will see a page of information about the Layer Manager, including instructions on how to set up forced alignment.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "BAS Web Services"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/g2p.html#using-g2p-for-phonemic-transcription",
    "href": "howto/phonemic-tagging/g2p.html#using-g2p-for-phonemic-transcription",
    "title": "Phonemic Tagging with the G2P BAS Web Service",
    "section": "",
    "text": "Select the word layers option on the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID: enter something like phonemes\nType: select Phonological (Or Text if you don‚Äôt want to use ‚ÄúDISC‚Äù encoding; see below)\nAlignment: select None (as these are simply tags on the orthographic words)\nManager: select BAS Web Services Manager\nGenerate: select Always\nDescription: Phonemic transcription according to BAS Web Service‚Äôs G2P\n\nPress the New button to create the layer.\nYou will see a form that allows you to configure the layer; check the online help for that page to guide you.\nOptions include:\n\nG2P - ensure you select this option for phonemic transcription.\nPhoneme Encoding - the encoding of the phonemes, which includes all of the options supported by G2P, plus ‚ÄúDISC‚Äù which, if selected, invokes G2P with ‚Äúsampa‚Äù as the encoding option, and then converts the result to CELEX‚Äôs DISC encoding, which uses exactly one character per phoneme. The ‚ÄúDISC‚Äù option is recommended if the layer has its type set to ‚Äúphonological‚Äù.\nWord Stress - prefix stressed vowels with a stress marker\nSyllabification - include syllable boundary markers in the transcriptions.\n\n\nPress Set Parameters\nPress Regenerate\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, the G2P annotations will automatically be generated for it.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "BAS Web Services"
    ]
  },
  {
    "objectID": "howto/forced-alignment/htk-p2fa.html",
    "href": "howto/forced-alignment/htk-p2fa.html",
    "title": "HTK and P2FA",
    "section": "",
    "text": "You can use ‚ÄòHTK‚Äô and the ‚ÄòP2FA‚Äô pre-trained acoustic models to force align you speech data if it is US English, or sufficiently similar to US English for the phoneme set to produce good alignments.\nThe general process is illustrated in Figure¬†1.\n\n\n\n\n\n\nFigure¬†1: Pronunciations are looked up for transcripts, and then combined with recordings and the P2FA models to compute alignments, which are saved in LaBB-CAT\n\n\n\nThe Hidden Markhov Model Toolkit (HTK) is a speech recognition toolkit developed at Cambridge University. LaBB-CAT can use it for force-aligning words and segments. HTK is not free software in the ‚ÄúGNU‚Äù sense - i.e.¬†we can not distribute it with LaBB-CAT, instead you have to download it yourself from the Cambridge University website - however it is free in the ‚Äúno cost‚Äù sense, you just need to register on the HTK website, and you can then download and use HTK free of charge.\nThe Penn Phonetics Lab Forced Aligner (P2FA) is a is an automatic phonetic alignment toolkit based on HTK, and includes acoustic models that were pre-trained on US English. Jiahong Yuan has kindly granted permission for those models to be included in LaBB-CAT, so they can be used directly without needing to download the P2FA toolkit seperately.\n\n\nIn order to be able to force-align transcripts to the word and/or segment level, you first need the following:\n\nTranscripts that are aligned at the utterance level (i.e.¬†there‚Äôs a known time-point every 20 or so words), whch have been uploaded into LaBB-CAT\nA WAV file for each transcript, on the LaBB-CAT server\nA phonemic transcription word layer, that has at least one pronunciation for every word. This can be achieved for English data by using the CMU Dictionary Layer Manager (further information below). If there are some lines/utterances that contain words with missing pronunciations, those lines will be ignored by the HTK Layer Manager.\n\n\n\nLaBB-CAT can be integrated with the CMU Pronouncing Dictionary, which is a free pronouncing dictionary of English maintained by the Speech Group in the School of Computer Science at Carnegie Mellon University. The pronunciations are based on American English, so are suitable for American English recordings.\nIntegrating this lexicon with LaBB-CAT is achieved with the ‚ÄúCMU Dictionary Layer Manager‚Äù. As CMU has kindly granted permission to freely distribute the dictionary file, you don‚Äôt need to download the file from the CMU site; it‚Äôs included in the layer manager that you will install.\nTo install the CMU Pronouncing Dictionary and use it to tag words with their pronunciations, follow these instructions\n\n\n\n\nThe broad steps for getting forced-alignments from HTK are:\n\nInstall HTK on the same computer that LaBB-CAT is installed on\nInstall the HTK Layer Manager, which integrates LaBB-CAT with HTK\nCreate and configure a new HTK layer in LaBB-CAT\nPick a speaker/participant in your database\nFill in the missing pronunciations for that participant\nRun forced alignment\nRepeat steps 4-6 for all the participants in your database\n\n\n\nHTK is a 3rd-party tool that you must download and install from the Cambridge University website.\n\nRegister at http://htk.eng.cam.ac.uk/register.shtml\nDownload the version of HTK that is appropriate for the computer that LaBB-CAT is install on:\nFor Windows systems, there are pre-compiled .exe files that you can download. For Unix-like systems, you need to download the source code, which you will then install following the provided instructions (you may also need to install the xorg-dev package before it will successfully compile).\nUnzip (for Windows) or compile and install (for Unix-like systems) the downloaded files on the computer that LaBB-CAT is installed on.\n\n\n\n\nThe HTK Layer Manager is a LaBB-CAT module that integrates LaBB-CAT with HTK.\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for HTK in the list, and press it‚Äôs Install button.\nYou will see a form with boxes for filling in information.\n\nHTK Path must be set to the location where the HTK files are installed on your system. If this is already filled in, it‚Äôs probably correct. If it‚Äôs blank, you have to enter the full path for the HTK programs:\n\nOn Windows systems, this is where you unzipped the HTK .exe files - e.g.¬†something like C:\\Downloads\\HTK\nOn Unix-like systems, this is probably /usr/local/bin, but you can verify this by entering which HCopy at a command shell prompt.\n\nHTK Working Folder will already have a default value, which is probably best left as-is\n\nPress Install Layer Manager\n\n\n\n\nOnce you‚Äôve installed HTK and the HTK Layer Manager, you need to create a new layer for triggering and controlling forced alignment. This layer will itself contain a timestamp for each line/utterance it has force-aligned (and so it‚Äôs a ‚Äòphrase‚Äô layer), but during that process, the word and phone alignments will also be set on other layers.\n\nIn LaBB-CAT, select the phrase layers option\nAt the top of the page, there‚Äôs a blank form for creating a new layer; fill in the following details:\n\nLayer ID: HTK\nType: Text\nManager: HTK Manager\nAlignment: Time Intervals\nGenerate: Always\n\nPress New.\nYou will see the layer configuration page.\nCheck the online help if you want information about all the options, however, most likely the default options are approriate, except:\n\nPronunciaton Layer: this is the layer that provides the phonemic transcriptions for all the words; ensure you select the phonemes layer you created above.\nNB If you have created this layer but it doesn‚Äôt appear here as an option, it‚Äôs probably because the ‚Äòlayer type‚Äô of your pronunciation layer is not set to ‚ÄòPhonological‚Äô, which will need to be changed in order for it to appear as an option here.\nNB In the list of options there‚Äôs also a layer called ‚Äúpronounce‚Äù; this is a system layer for manually-added pronunciations, and you would only select that layer here if you have manually annotated pronunciations against every single word in your transcripts. You probably haven‚Äôt done that, so you don‚Äôt want to select the ‚Äúpronounce‚Äù layer here.\nUse P2FA models: ensure you tick this option.\n\nPress Save.\nIf you are confident all your transcripts include all pronunciations for all words, you can press Regenerate to force-align your whole corpus now. However, most likely you‚Äôll need to proceed per-speaker, described below, in order to fill in missing pronunciations.\n\n\n\n\nTo start a forced-alignment process per-speaker, you need to first select a speaker who will be aligned. Then you will fill in any missing pronunciations. After that, HTK will automatically force-align their utterances.\n\nIn LaBB-CAT, select the participants optoin on the menu\nTick a speaker, and press the All Utterances button\nClick List\nOnce the paginated list of utterances appears, press the HTK button below.\nBasically you need to fill in the boxes with the pronunciations and click Save Pronunciations.\n\n\n\n\n\n\n\nNote\n\n\n\n\nYou don‚Äôt have to fill them all in at once, you can do a few, and click Save, which will save your work and list what‚Äôs left.\nYou don‚Äôt have to fill them all in, you can leave some empty and continue with the HTK forced-alignment by clicking Start (HTK will ignore any lines where the remaining unknown words appear, but the ones you filled in will be included).\nSome of the boxes will be initially filled in with a suggestion from the lexicon layer manager - these may or may not be correct, and aren‚Äôt saved until you save them.\nThe pronunciations have to be in the ‚ÄòDISC‚Äô format - i.e.¬†one character per phoneme, with no spaces. There‚Äôs a ‚Äòhelper‚Äô link on the right of each pronunciation box - if you click it, it expands into a list of clickable phonemes - just the ones that aren‚Äôt ordinary letters, and diphthongs etc.\nThe search button lets you look up the lexicon for similar words - this probably won‚Äôt help for place names, but for words like ‚Äútarseal‚Äù, you can click the lookup button, enter ‚Äútar seal‚Äù in the box as two separate words, and you‚Äôll get back the DISC pronunciation of each word, with clickable buttons to copy the given pronunciation into the box. This is useful for digits and numbers too, which may not be in the lexicon - so for ‚Äú1‚Äù, search for ‚Äúone‚Äù and copy the pronunciation.\nIf you click on the word itself, the transcript for the first instance of that word is opened, in case you want to listen to it, or in case it‚Äôs actually just a typo and you want to correct the transcript.\nIf you‚Äôre using CELEX, when you specify the pronunciations, it‚Äôs recommended to put syllable separators (-) and primary stress markers (‚Äô) too - e.g.¬†for ‚Äútarseal‚Äù you can put t#sil but it would actually be better to put t#-‚Äôsil. These markers are entered into the dictionary even though they‚Äôre stripped out for HTK, and they may come in handy later (e.g.¬†the syllable separators are used by the CELEX layer manager to count syllables).\n\n\n\nWhen you add pronunciations this way, they‚Äôre added to the dictionary and all the instances of those words in LaBB-CAT are updated with the pronunciations - not just the participant you‚Äôre looking at, but all participants in the database. So you only have to come up with a pronunciation for each word once.\n\nOnce you‚Äôve filled in all the missing pronunciations, forced alignment will start automatically. If you want to start forced alignment before you‚Äôve entered all pronunciations, click the Start button at the bottom of the page.\n\nYou should see a progress bar while the forced alignment is running. It will take a few minutes to complete.\n\nOnce HTK has produced the word and segment alignments, it:\n\nsets the start/end times of the words on the transcript layer accordingly,\nadds new phone annotations to the segments layer with the alignments of the phones, and\nsaves a timestamp in the htk layer.\n\nWhen the layer manager has finished, you‚Äôll see a message saying ‚ÄúComplete - words and phones from selected utterances are now aligned.‚Äù",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "HTK and P2FA"
    ]
  },
  {
    "objectID": "howto/forced-alignment/htk-p2fa.html#prerequisites",
    "href": "howto/forced-alignment/htk-p2fa.html#prerequisites",
    "title": "HTK and P2FA",
    "section": "",
    "text": "In order to be able to force-align transcripts to the word and/or segment level, you first need the following:\n\nTranscripts that are aligned at the utterance level (i.e.¬†there‚Äôs a known time-point every 20 or so words), whch have been uploaded into LaBB-CAT\nA WAV file for each transcript, on the LaBB-CAT server\nA phonemic transcription word layer, that has at least one pronunciation for every word. This can be achieved for English data by using the CMU Dictionary Layer Manager (further information below). If there are some lines/utterances that contain words with missing pronunciations, those lines will be ignored by the HTK Layer Manager.\n\n\n\nLaBB-CAT can be integrated with the CMU Pronouncing Dictionary, which is a free pronouncing dictionary of English maintained by the Speech Group in the School of Computer Science at Carnegie Mellon University. The pronunciations are based on American English, so are suitable for American English recordings.\nIntegrating this lexicon with LaBB-CAT is achieved with the ‚ÄúCMU Dictionary Layer Manager‚Äù. As CMU has kindly granted permission to freely distribute the dictionary file, you don‚Äôt need to download the file from the CMU site; it‚Äôs included in the layer manager that you will install.\nTo install the CMU Pronouncing Dictionary and use it to tag words with their pronunciations, follow these instructions",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "HTK and P2FA"
    ]
  },
  {
    "objectID": "howto/forced-alignment/htk-p2fa.html#procedure-for-htk-forced-alignment",
    "href": "howto/forced-alignment/htk-p2fa.html#procedure-for-htk-forced-alignment",
    "title": "HTK and P2FA",
    "section": "",
    "text": "The broad steps for getting forced-alignments from HTK are:\n\nInstall HTK on the same computer that LaBB-CAT is installed on\nInstall the HTK Layer Manager, which integrates LaBB-CAT with HTK\nCreate and configure a new HTK layer in LaBB-CAT\nPick a speaker/participant in your database\nFill in the missing pronunciations for that participant\nRun forced alignment\nRepeat steps 4-6 for all the participants in your database\n\n\n\nHTK is a 3rd-party tool that you must download and install from the Cambridge University website.\n\nRegister at http://htk.eng.cam.ac.uk/register.shtml\nDownload the version of HTK that is appropriate for the computer that LaBB-CAT is install on:\nFor Windows systems, there are pre-compiled .exe files that you can download. For Unix-like systems, you need to download the source code, which you will then install following the provided instructions (you may also need to install the xorg-dev package before it will successfully compile).\nUnzip (for Windows) or compile and install (for Unix-like systems) the downloaded files on the computer that LaBB-CAT is installed on.\n\n\n\n\nThe HTK Layer Manager is a LaBB-CAT module that integrates LaBB-CAT with HTK.\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for HTK in the list, and press it‚Äôs Install button.\nYou will see a form with boxes for filling in information.\n\nHTK Path must be set to the location where the HTK files are installed on your system. If this is already filled in, it‚Äôs probably correct. If it‚Äôs blank, you have to enter the full path for the HTK programs:\n\nOn Windows systems, this is where you unzipped the HTK .exe files - e.g.¬†something like C:\\Downloads\\HTK\nOn Unix-like systems, this is probably /usr/local/bin, but you can verify this by entering which HCopy at a command shell prompt.\n\nHTK Working Folder will already have a default value, which is probably best left as-is\n\nPress Install Layer Manager\n\n\n\n\nOnce you‚Äôve installed HTK and the HTK Layer Manager, you need to create a new layer for triggering and controlling forced alignment. This layer will itself contain a timestamp for each line/utterance it has force-aligned (and so it‚Äôs a ‚Äòphrase‚Äô layer), but during that process, the word and phone alignments will also be set on other layers.\n\nIn LaBB-CAT, select the phrase layers option\nAt the top of the page, there‚Äôs a blank form for creating a new layer; fill in the following details:\n\nLayer ID: HTK\nType: Text\nManager: HTK Manager\nAlignment: Time Intervals\nGenerate: Always\n\nPress New.\nYou will see the layer configuration page.\nCheck the online help if you want information about all the options, however, most likely the default options are approriate, except:\n\nPronunciaton Layer: this is the layer that provides the phonemic transcriptions for all the words; ensure you select the phonemes layer you created above.\nNB If you have created this layer but it doesn‚Äôt appear here as an option, it‚Äôs probably because the ‚Äòlayer type‚Äô of your pronunciation layer is not set to ‚ÄòPhonological‚Äô, which will need to be changed in order for it to appear as an option here.\nNB In the list of options there‚Äôs also a layer called ‚Äúpronounce‚Äù; this is a system layer for manually-added pronunciations, and you would only select that layer here if you have manually annotated pronunciations against every single word in your transcripts. You probably haven‚Äôt done that, so you don‚Äôt want to select the ‚Äúpronounce‚Äù layer here.\nUse P2FA models: ensure you tick this option.\n\nPress Save.\nIf you are confident all your transcripts include all pronunciations for all words, you can press Regenerate to force-align your whole corpus now. However, most likely you‚Äôll need to proceed per-speaker, described below, in order to fill in missing pronunciations.\n\n\n\n\nTo start a forced-alignment process per-speaker, you need to first select a speaker who will be aligned. Then you will fill in any missing pronunciations. After that, HTK will automatically force-align their utterances.\n\nIn LaBB-CAT, select the participants optoin on the menu\nTick a speaker, and press the All Utterances button\nClick List\nOnce the paginated list of utterances appears, press the HTK button below.\nBasically you need to fill in the boxes with the pronunciations and click Save Pronunciations.\n\n\n\n\n\n\n\nNote\n\n\n\n\nYou don‚Äôt have to fill them all in at once, you can do a few, and click Save, which will save your work and list what‚Äôs left.\nYou don‚Äôt have to fill them all in, you can leave some empty and continue with the HTK forced-alignment by clicking Start (HTK will ignore any lines where the remaining unknown words appear, but the ones you filled in will be included).\nSome of the boxes will be initially filled in with a suggestion from the lexicon layer manager - these may or may not be correct, and aren‚Äôt saved until you save them.\nThe pronunciations have to be in the ‚ÄòDISC‚Äô format - i.e.¬†one character per phoneme, with no spaces. There‚Äôs a ‚Äòhelper‚Äô link on the right of each pronunciation box - if you click it, it expands into a list of clickable phonemes - just the ones that aren‚Äôt ordinary letters, and diphthongs etc.\nThe search button lets you look up the lexicon for similar words - this probably won‚Äôt help for place names, but for words like ‚Äútarseal‚Äù, you can click the lookup button, enter ‚Äútar seal‚Äù in the box as two separate words, and you‚Äôll get back the DISC pronunciation of each word, with clickable buttons to copy the given pronunciation into the box. This is useful for digits and numbers too, which may not be in the lexicon - so for ‚Äú1‚Äù, search for ‚Äúone‚Äù and copy the pronunciation.\nIf you click on the word itself, the transcript for the first instance of that word is opened, in case you want to listen to it, or in case it‚Äôs actually just a typo and you want to correct the transcript.\nIf you‚Äôre using CELEX, when you specify the pronunciations, it‚Äôs recommended to put syllable separators (-) and primary stress markers (‚Äô) too - e.g.¬†for ‚Äútarseal‚Äù you can put t#sil but it would actually be better to put t#-‚Äôsil. These markers are entered into the dictionary even though they‚Äôre stripped out for HTK, and they may come in handy later (e.g.¬†the syllable separators are used by the CELEX layer manager to count syllables).\n\n\n\nWhen you add pronunciations this way, they‚Äôre added to the dictionary and all the instances of those words in LaBB-CAT are updated with the pronunciations - not just the participant you‚Äôre looking at, but all participants in the database. So you only have to come up with a pronunciation for each word once.\n\nOnce you‚Äôve filled in all the missing pronunciations, forced alignment will start automatically. If you want to start forced alignment before you‚Äôve entered all pronunciations, click the Start button at the bottom of the page.\n\nYou should see a progress bar while the forced alignment is running. It will take a few minutes to complete.\n\nOnce HTK has produced the word and segment alignments, it:\n\nsets the start/end times of the words on the transcript layer accordingly,\nadds new phone annotations to the segments layer with the alignments of the phones, and\nsaves a timestamp in the htk layer.\n\nWhen the layer manager has finished, you‚Äôll see a message saying ‚ÄúComplete - words and phones from selected utterances are now aligned.‚Äù",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "HTK and P2FA"
    ]
  },
  {
    "objectID": "howto/forced-alignment/correction-praat.html",
    "href": "howto/forced-alignment/correction-praat.html",
    "title": "Checking/Correcting Alignments: Praat",
    "section": "",
    "text": "Checking/Correcting Alignments: Praat\nAfter force-aligning transcripts, the alignments can be checked and corrected directly from LaBB-CAT, using the Praat integration with the transcript page.\n\n\n\nRound-trip of alignnments, coming from LaBB-CAT to Praat, with manual corrections imported back into LaBB-CAT\n\n\nTo check the alignments:\n\nIn LaBB-CAT, open a transcript page.\nTick both the forced-aligner‚Äôs layer (e.g.¬†HTK) and the segments layer.\n\nYou will see which lines have been force-aligned, as they have an HTK timestamp, and have the segment layer filled in. If it has missed some lines, this is most likely because there is an unknown word, another speaker speaking at the same time, or possible HTK simply failed to align the line (there are various reasons this happens, including not enough data for training, noisy recordings, inaccurate transcription, etc.).\nThe interactive transcript page doesn‚Äôt show you the alignments of the words or phones, but you can see those using Praat. You can open individual utterances in Praat directly from the transcript page, but first, the LaBB-CAT/Praat integration has to be set up; this only has to be done once:\n\nOn the top-right of the page, above the playback controls, there‚Äôs a Praat icon - click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed on your computer, and double-click the Praat.exe file (on some systems the file may simply be called Praat).\nThe Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\n\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶\n\nClick on a line that has been aligned, and select the Open Text Grid in Praat option on the menu.\nPraat should open, and show you a spectrogram of the line‚Äôs audio, with a TextGrid below that includes the words and the segments.\nIf you click on a word, and hit the key, the word‚Äôs interval is played. Try out various words, and see what you think about how accurate the forced aligner has been with its alignment.\nTry this out with different lines in the transcript.\n\nYou will see that in some cases the alignment is pretty good, and in other cases, it‚Äôs not so good.\n\nAdjust the alignments of the words and phones so that they‚Äôre more accurate, and then click the Import Changes button in the transcript page (in LaBB-CAT).\n\nThese changes are flagged as manual edits, so if forced-alignment is run again, they will not be over-written with new bad alignments. Therefore it‚Äôs important that the changes you make are actually improvements, because the forced aligner will never change them again.\nThere are some rules about what you can change:\n\nYou‚Äôre not allowed to add or delete words (if this is necessary, it should be done by correcting the transcript instead).\nAll the phones must be within the bounds of their own word.\nThe start of the first phone should line up with the start of the word, and the end of the last phone should line up with the end of the word.\nYou should not change the alignment of the utterance itself (which would only be possible if you select the Open Text Grid incl.¬†¬± 1 utterance in Praat option).\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "Checking/Correcting Alignments: Praat"
    ]
  },
  {
    "objectID": "howto/forced-alignment/fragment-htk-installation.html",
    "href": "howto/forced-alignment/fragment-htk-installation.html",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "HTK is a 3rd-party tool that you must download and install from the Cambridge University website.\n\nRegister at http://htk.eng.cam.ac.uk/register.shtml\nDownload the version of HTK that is appropriate for the computer that LaBB-CAT is install on:\nFor Windows systems, there are pre-compiled .exe files that you can download. For Unix-like systems, you need to download the source code, which you will then install following the provided instructions (you may also need to install the xorg-dev package before it will successfully compile).\nUnzip (for Windows) or compile and install (for Unix-like systems) the downloaded files on the computer that LaBB-CAT is installed on.\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB"
  },
  {
    "objectID": "howto/forced-alignment/fragment-htk-annotator-installation.html",
    "href": "howto/forced-alignment/fragment-htk-annotator-installation.html",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "The HTK Layer Manager is a LaBB-CAT module that integrates LaBB-CAT with HTK.\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for HTK in the list, and press it‚Äôs Install button.\nYou will see a form with boxes for filling in information.\n\nHTK Path must be set to the location where the HTK files are installed on your system. If this is already filled in, it‚Äôs probably correct. If it‚Äôs blank, you have to enter the full path for the HTK programs:\n\nOn Windows systems, this is where you unzipped the HTK .exe files - e.g.¬†something like C:\\Downloads\\HTK\nOn Unix-like systems, this is probably /usr/local/bin, but you can verify this by entering which HCopy at a command shell prompt.\n\nHTK Working Folder will already have a default value, which is probably best left as-is\n\nPress Install Layer Manager\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB"
  },
  {
    "objectID": "howto/forced-alignment/fragment-mfa-installation.html",
    "href": "howto/forced-alignment/fragment-mfa-installation.html",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "MFA is not included as part of LaBB-CAT, and so it must be installed on the server you have installed LaBB-CAT on before you can integrate LaBB-CAT with it.\nIf MFA has not been installed already, please follow the following steps, depending on the operatings system of your LaBB-CAT server:\n\n\n\n\n\n\nNoteLinux\n\n\n\n\n\nTo install the Montreal Forced Aligner on Linux systems for all users, so that your web server can access it if required:\n\nDownload Miniconda:\nwget https://repo.anaconda.com/miniconda/Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nStart the installer:\nsudo bash Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nWhen asked the location to install Miniconda, use:\n/opt/conda\nWhen asked whether the installer should initialize Miniconda, this is unnecessary so you can respond no\nChange ownership of the conda files):\nsudo chown -R $USERNAME:$USERNAME /opt/conda\nMake conda accessible to all users (so you web server can access MFA):\nchmod -R go-w /opt/conda\nchmod -R go+rX /opt/conda\nInstall the Montreal Forced Aligner\n/opt/conda/bin/conda create -n aligner -c conda-forge montreal-forced-aligner=3.2.1\n\nIf you see errors when trying to use MFA, you may find that one of the following resolves the issue:\n/opt/conda/envs/aligner/bin/pip install joblib==1.3.2\nand/or\n/opt/conda/envs/aligner/bin/pip uninstall setuptools\n/opt/conda/envs/aligner/bin/pip install setuptools==66.1.1\n\n\n\n\n\n\n\n\n\n\nNoteWindows\n\n\n\n\n\nTo install the Montreal Forced Aligner on Windows systems for all users, so that your web server can access it if required:\n\nDownload the Miniconda installer:¬†¬†¬†\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\nStart the installer by double-clicking it.\nWhen asked, select the ‚ÄúInstall for all users‚Äù option. This will install conda somewhere like\nC:\\ProgramData\\Miniconda3\nWhen asked, tick the add to PATH option.\nInstall the Montreal Forced Aligner by specifying a path to the environment\nconda create -c conda-forge -p C:\\ProgramData\\Miniconda3\\envs\\aligner montreal-forced-aligner=3.2.1\n\n\n\n\n\n\n\n\n\n\nWarningWindows Troubleshooting\n\n\n\n\n\nThe 3rd party MFA software requires:\n\nthe possibility of running command-line programs during installation and forced alignement\nthe possibility that these programs can download data from the internet\n\nOn Windows, this can sometimes be complicated by the fact that Apache Tomcat and LaBB-CAT are installed as a ‚ÄòWindows Service‚Äô. Windows Services usually run using the permissions of a special anonymous login account called ‚ÄòLocal System‚Äô, which in some environments has restricted permissions to access different resources.\nIf you install the MFA Manager LaBB-CAT integration module, but you find it returns errors when trying to interact with MFA, the problem may be that the Windows Service:\n\ndoes not have permission to access the folder where MFA is installed, or\nis not allowed to execute other programs, or\ncannot access the internet.\n\nSometimes problems can be resolved by:\n\nrunning the Apache Tomcat Windows Service as a different user other than ‚ÄòLocal System‚Äô. (or if it was running as some other used, try setting it back to ‚ÄòLocal System‚Äô), or\nadjusting the permissions of the Windows Service users, or\nadjusting the permissions of the folders where MFA is installed\nconfiguring the service to use the local Internet Proxy settings to enable connecting to the internet.\n\nPSexec is a tool that can be used to diagnose and solve problems on Windows.\n\nPSexec\n\nDownload PStool.zip from Microsoft:\nhttp://technet.microsoft.com/en-us/sysinternals/bb897553.aspx\nUnzip it\nPut PSexec.exe into C:\\Windows\\System32\nOpen cmd using ‚ÄúRun as Administrator‚Äù\nRun the command:\nPsexec.exe -i -s cmd.exe\nThis opens a new command prompt for local system account\nIn the new command prompt window, check you have the correct account type with the command:\nwhomai\n\nThen you can use the command prompt to run MFA commands to diagnose errors - e.g.:\n\nconda activate montreal-forced-aligner - activates the MFA environment\nmfa version - ensures MFA is installed and accessible, and confirms the version\nmfa model download dictionary - ensures MFA can connect to the internet to get models etc.; this command should return a long list of language dictionaries, and not report errors.\n\n\n\nProxy Settings\nTo update proxy server settings:\n\ntype inetcpl.cpl\ngoto Connections tab\nclick on the LAN Settings button\nFill in the Proxy section with the correct details\n\n\n\n\n\n\n\n\n\n\n\nNoteDocker Container\n\n\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, it can download and install Miniconda and MFA itself, as part of the process of installing the MFA Manager LaBB-CAT module.\nThere is no need for a separate installation of the MFA software.\n\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB"
  },
  {
    "objectID": "howto/forced-alignment/compare.html",
    "href": "howto/forced-alignment/compare.html",
    "title": "Comparing Forced Alignment Methods",
    "section": "",
    "text": "There are several tools and methods for force-aligning speech recordings, and each works well or badly depending on different factors. It can be difficult to know which method to use.\nYou can compare different forced alignment methods with your own data by configuring LaBB-CAT to allow multiple simultaneous alignments which can then be compared, in order to decide which method to use.\nTo do this, the broad process is:\n\nset up multiple forced alignment configurations, configured to output their word and phone alignments to separate layers (i.e.¬†not the normal word and segment layers), and then\nRun each forced alignment configuration on some subset of the data, so that the separate word and phone alignment layers are populated with aligned intervals.\nFinally, you can compare the configurations, either by:\n\nselecting individual utterances, extracting all the alignments to a TextGrid with the audio, and doing an auditory/visual evaluation of each set of alignments, or\nmanually aligning a selection of utterances, and automatically comparing each set of automatic alignments with the corresponding manual alignments.\n\n\nOnce you have decided on a winner, you then delete the losing configurations, and reconfigure the winning one to output its alignments to LaBB-CAT‚Äôs word and segment layers, and run forced alignment again, on all the data.\n\n\nNormally, LaBB-CAT only allows one set of word/phone alignments at a time, and these are stored in the word and segment layers. In order to compare alignments, you need to be able to have multiple word/phone alignments in LaBB-CAT at the same time, so you can compare them side-by-side in order to choose the best one.\nIn order to set this up, you need to set up the forced aligment configurations to output their alignments to different layers, instead of the word and segment layers which are the default. The steps to achieve this are as follows:\n\nDecide which forced alignment configurations you want to compare. They may all involve the same layer manager module (e.g.¬†if you want to compare HTK‚Äôs train/align procedure with its built-in P2FA pretrained acoustic models), or they may involve different layer manager modules (e.g.¬†if you want to compare MFA‚Äôs pretrained models with the WebMAUS ones).\n(In these instructions, we show a comparison of HTK‚Äôs P2FA models with MFA‚Äôs pretrained US English models.)\nEnsure that the layer manager modules you need are installed in LaBB-CAT - i.e.¬†install the HTK and the HTK Manager, or MFA and the MFA Manage, etc.\nIn LaBB-CAT, select the phrase layers menu option.\nYou will see a list of phrase layers, which may include language and entity.\nThe column headings at the top are also a form to fill in in order to add a new phrase layer. Fill it in with the following details:\n\nLayer ID: a descriptive name of the configuration, e.g.¬†WebMAUS or HTK-P2FA\nType: Text (this layer will end up containing the word tokens)\nAlignment: Intervals (i.e.¬†annotations with a start time and an end time)\nManager: select the layer manager for this forced alignment configuration, e.g.¬†HTK Manager\nGenerate: Never (we will be running forced alignment manually on a selection of recordings, and we don‚Äôt want these forced alignments being automatically triggered when new transcripts are uploaded)\nProject: this can be left as-is, unless you have already created a ‚Äòproject‚Äô to categorise these layers under.\nDescription: A descriptive note something like ‚ÄúWord alignments produced by HTK using the Penn Forced Aligner pretrained acoustic models (P2FA)‚Äù \n\nPress the New button.\nThe layer‚Äôs configuration form will appear.\nFill in the configuration form as required for this configuration, e.g.¬†if it‚Äôs HTK with P2FA models, tick the Use P2FA models checkbox, etc.\n\nThe configuration form will also allow you to configure which layer the word alignments and phone alignments are saved to, with a setting like Word Alignment Layer set to word by default, and Phone Alignment Layer set to segment by default.\nChange the Word Alignment Layer to be the layer itself (i.e.¬†if the layer you just added is called ‚ÄúHTK-P2FA‚Äù, select the HTK-P2FA option in the dropdown list next to Word Alignment Layer).\nChange the Phone Alignment Layer by selecting the [add new layer] option.\nYou will be asked what you want the new layer to be called.\n\nYou can leave this as the default value, which will be something like ‚ÄúHTK-P2FAPhone‚Äù, and press OK\nThere may also be an Utterance Tag Layer setting, which by default has the layer itself selected. We‚Äôre already using the layer itself for the word alignments, and don‚Äôt want it to also contain a time-stamp for when the alignment was done, so we are going to un-set this setting.\nSet Utterance Tag Layer to [none].\n\nPress the Set Parameters button to save the configuration.\nRepeat steps 3-11 for each configuration you want to compare.\nFor this example, we have added an MFA Manager layer‚Ä¶ . ‚Ä¶using the english_us_arpa dictionary/models.\n\nSelect the phrase layers option from the menu.\nYou will see that, in addition to the layers you added for the word alignments, the corresponding phone alignment layers have also been automatically created.\n\n\nNow you have multiple forced alignment methods set up, and none of them is configured to output their alignments on the word and segment layers. Instead, each method outputs its alignments to different ‚Äòphrase‚Äô layers.\nThe configurations are set, but there are no alignments to compare yet.\n\n\n\nOnce you have set up all the configurations you need, you can run each forced alignment configuration on a subset of utterances. In order to compare side by side, you should force-align the same utterance for all configurations.\n\nDecide what subset of utterances to align.\n\nIf you are comparing configurations that all use pre-trained acoustic models, the subset can be as small as a handful of utterances from different speakers, or even single utterance, as the amount of data included in the forced alignment run won‚Äôt effect the quality of the alignments.\nIf you are comparing configurations that first train acoustic models and then force-align utterances based on those models (i.e.¬†the ‚Äòtrain/align‚Äô method), you will need to have a larger subset, which might be all the utterances of one or more speakers, or even the whole corpus. How big the subset needs to be depends on the configuration (e.g.¬†for train/align with HTK, you‚Äôll need at least 5 minutes of speech, and for traing/align with MFA, you may need as much as 3-5 hours of speech)\n\nIn LaBB-CAT, collect together your subset of utterances on a ‚Äòmatches‚Äô page.\ne.g.¬†if it is to be all the utterances of a selected speaker or speakers:\n\ngo to participants page,\nfind the desired participants,\ntick them\n\npress the All Utterances button, and\npress List.\n\nAlternatively, if you run a search using specific participant and transcript criteria, you will also be shown a ‚Äòmatches‚Äô page that lists matching utterances, and allows you to export data and perform a number of other operations on the utterances.\nHowever you determine your subset of utterances, you need to end up at a ‚Äòmatches‚Äô page like this:\n\nAll utterances will be ticked by default, but you can manually select utterances from the list by un-ticking Select all results and then ticking individual utterances to align.\nAt the bottom, there will be a button for each of the forced alignment configuration layers you added earlier.\n\nPress the first button.\nThis will start the forced alignment process for that configuration, including only the selected utterances. This may involve filling in missing pronunciations, and then you will see a progress bar while the utterances are being aligned.\n\nOnce the forced alignment for this configuration is complete, repeat steps 2 and 3 above for each of the other forced alignment configurations.\n\nOnce you‚Äôve completed the last forced alignment, you will have multiple sets of alignments simultaneously saved in different layers in LaBB-CAT, ready for comparison.\n\n\n\nThe easiest way to directly compare the different sets of alignments is by extracting utterances to TextGrids, and opening them with corresponding audio in Praat. This can be done directly from the transcript page, using LaBB-CAT‚Äôs Praat Integration.\n\nIn LaBB-CAT, select the transcripts option on the menu.\nFind one of the transcripts that includes utterances in the subset you force-aligned above, and click its name to open the transcript page.\nAt the top of the transcript there is a list of layers, which should now include options for the forced alignment layers you added earlier, and their corresponding phone alignment layers.\n\nTick all of the forced-alignment layers.\n\nThis will cause the aligned annotations for these layers to be displayed on the transcript page, for the utterances that have been forced-aligned.\n\nThe transcript page is not intended to accurately represent time alignment at this granularity, so the display will look cramped and confusing. The word and phone annotations on each layer will probably not line up with the corresponding transcript words below.\nClick any word in the utterance (i.e.¬†from the olive-coloured words), and select Open TextGrid in Praat from the resulting menu.\n\nThis will open Praat and show the utterance TextGrid with the corresponding audio. The TextGrid will include:\n\na tier named after each forced-alignment configuration layer, containing the word alignments from that configuration\na tier named after each configuration‚Äôs Phone Alignment Layer, containing the phone alignments from that configuration\na word tier at the bottom, containing the main word alignments - most likely these will be evenly spaced out during the duration of the turn, and will not line up with the words in the audio; this is because the main word tokens haven‚Äôt been aligned yet, and won‚Äôt be until you select the winning configuration and change it to output it‚Äôs word alignments to the word layer (and phone alignments to the segment layer)\n\n\n\n\nMultiple sets of alignments shown in Praat\n\n\nIn Praat, you can compare the phone/word alignments of each configuration, by selecting intervals, examining how they line up with the spectrogram above, and playing the corresponding audio to get an impression of how well aligned the segment is with the audio.\nThis type of evaluation is impressionistic, but after comparing a number of utterances across a number of speakers this way, it may become clear which configuration has more accurate alignments.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "Comparing Forced Alignment Methods"
    ]
  },
  {
    "objectID": "howto/forced-alignment/compare.html#setting-up-multiple-forced-alignment-configurations",
    "href": "howto/forced-alignment/compare.html#setting-up-multiple-forced-alignment-configurations",
    "title": "Comparing Forced Alignment Methods",
    "section": "",
    "text": "Normally, LaBB-CAT only allows one set of word/phone alignments at a time, and these are stored in the word and segment layers. In order to compare alignments, you need to be able to have multiple word/phone alignments in LaBB-CAT at the same time, so you can compare them side-by-side in order to choose the best one.\nIn order to set this up, you need to set up the forced aligment configurations to output their alignments to different layers, instead of the word and segment layers which are the default. The steps to achieve this are as follows:\n\nDecide which forced alignment configurations you want to compare. They may all involve the same layer manager module (e.g.¬†if you want to compare HTK‚Äôs train/align procedure with its built-in P2FA pretrained acoustic models), or they may involve different layer manager modules (e.g.¬†if you want to compare MFA‚Äôs pretrained models with the WebMAUS ones).\n(In these instructions, we show a comparison of HTK‚Äôs P2FA models with MFA‚Äôs pretrained US English models.)\nEnsure that the layer manager modules you need are installed in LaBB-CAT - i.e.¬†install the HTK and the HTK Manager, or MFA and the MFA Manage, etc.\nIn LaBB-CAT, select the phrase layers menu option.\nYou will see a list of phrase layers, which may include language and entity.\nThe column headings at the top are also a form to fill in in order to add a new phrase layer. Fill it in with the following details:\n\nLayer ID: a descriptive name of the configuration, e.g.¬†WebMAUS or HTK-P2FA\nType: Text (this layer will end up containing the word tokens)\nAlignment: Intervals (i.e.¬†annotations with a start time and an end time)\nManager: select the layer manager for this forced alignment configuration, e.g.¬†HTK Manager\nGenerate: Never (we will be running forced alignment manually on a selection of recordings, and we don‚Äôt want these forced alignments being automatically triggered when new transcripts are uploaded)\nProject: this can be left as-is, unless you have already created a ‚Äòproject‚Äô to categorise these layers under.\nDescription: A descriptive note something like ‚ÄúWord alignments produced by HTK using the Penn Forced Aligner pretrained acoustic models (P2FA)‚Äù \n\nPress the New button.\nThe layer‚Äôs configuration form will appear.\nFill in the configuration form as required for this configuration, e.g.¬†if it‚Äôs HTK with P2FA models, tick the Use P2FA models checkbox, etc.\n\nThe configuration form will also allow you to configure which layer the word alignments and phone alignments are saved to, with a setting like Word Alignment Layer set to word by default, and Phone Alignment Layer set to segment by default.\nChange the Word Alignment Layer to be the layer itself (i.e.¬†if the layer you just added is called ‚ÄúHTK-P2FA‚Äù, select the HTK-P2FA option in the dropdown list next to Word Alignment Layer).\nChange the Phone Alignment Layer by selecting the [add new layer] option.\nYou will be asked what you want the new layer to be called.\n\nYou can leave this as the default value, which will be something like ‚ÄúHTK-P2FAPhone‚Äù, and press OK\nThere may also be an Utterance Tag Layer setting, which by default has the layer itself selected. We‚Äôre already using the layer itself for the word alignments, and don‚Äôt want it to also contain a time-stamp for when the alignment was done, so we are going to un-set this setting.\nSet Utterance Tag Layer to [none].\n\nPress the Set Parameters button to save the configuration.\nRepeat steps 3-11 for each configuration you want to compare.\nFor this example, we have added an MFA Manager layer‚Ä¶ . ‚Ä¶using the english_us_arpa dictionary/models.\n\nSelect the phrase layers option from the menu.\nYou will see that, in addition to the layers you added for the word alignments, the corresponding phone alignment layers have also been automatically created.\n\n\nNow you have multiple forced alignment methods set up, and none of them is configured to output their alignments on the word and segment layers. Instead, each method outputs its alignments to different ‚Äòphrase‚Äô layers.\nThe configurations are set, but there are no alignments to compare yet.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "Comparing Forced Alignment Methods"
    ]
  },
  {
    "objectID": "howto/forced-alignment/compare.html#running-multiple-independent-forced-alignments",
    "href": "howto/forced-alignment/compare.html#running-multiple-independent-forced-alignments",
    "title": "Comparing Forced Alignment Methods",
    "section": "",
    "text": "Once you have set up all the configurations you need, you can run each forced alignment configuration on a subset of utterances. In order to compare side by side, you should force-align the same utterance for all configurations.\n\nDecide what subset of utterances to align.\n\nIf you are comparing configurations that all use pre-trained acoustic models, the subset can be as small as a handful of utterances from different speakers, or even single utterance, as the amount of data included in the forced alignment run won‚Äôt effect the quality of the alignments.\nIf you are comparing configurations that first train acoustic models and then force-align utterances based on those models (i.e.¬†the ‚Äòtrain/align‚Äô method), you will need to have a larger subset, which might be all the utterances of one or more speakers, or even the whole corpus. How big the subset needs to be depends on the configuration (e.g.¬†for train/align with HTK, you‚Äôll need at least 5 minutes of speech, and for traing/align with MFA, you may need as much as 3-5 hours of speech)\n\nIn LaBB-CAT, collect together your subset of utterances on a ‚Äòmatches‚Äô page.\ne.g.¬†if it is to be all the utterances of a selected speaker or speakers:\n\ngo to participants page,\nfind the desired participants,\ntick them\n\npress the All Utterances button, and\npress List.\n\nAlternatively, if you run a search using specific participant and transcript criteria, you will also be shown a ‚Äòmatches‚Äô page that lists matching utterances, and allows you to export data and perform a number of other operations on the utterances.\nHowever you determine your subset of utterances, you need to end up at a ‚Äòmatches‚Äô page like this:\n\nAll utterances will be ticked by default, but you can manually select utterances from the list by un-ticking Select all results and then ticking individual utterances to align.\nAt the bottom, there will be a button for each of the forced alignment configuration layers you added earlier.\n\nPress the first button.\nThis will start the forced alignment process for that configuration, including only the selected utterances. This may involve filling in missing pronunciations, and then you will see a progress bar while the utterances are being aligned.\n\nOnce the forced alignment for this configuration is complete, repeat steps 2 and 3 above for each of the other forced alignment configurations.\n\nOnce you‚Äôve completed the last forced alignment, you will have multiple sets of alignments simultaneously saved in different layers in LaBB-CAT, ready for comparison.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "Comparing Forced Alignment Methods"
    ]
  },
  {
    "objectID": "howto/forced-alignment/compare.html#auditoryvisual-comparison-of-the-alignments",
    "href": "howto/forced-alignment/compare.html#auditoryvisual-comparison-of-the-alignments",
    "title": "Comparing Forced Alignment Methods",
    "section": "",
    "text": "The easiest way to directly compare the different sets of alignments is by extracting utterances to TextGrids, and opening them with corresponding audio in Praat. This can be done directly from the transcript page, using LaBB-CAT‚Äôs Praat Integration.\n\nIn LaBB-CAT, select the transcripts option on the menu.\nFind one of the transcripts that includes utterances in the subset you force-aligned above, and click its name to open the transcript page.\nAt the top of the transcript there is a list of layers, which should now include options for the forced alignment layers you added earlier, and their corresponding phone alignment layers.\n\nTick all of the forced-alignment layers.\n\nThis will cause the aligned annotations for these layers to be displayed on the transcript page, for the utterances that have been forced-aligned.\n\nThe transcript page is not intended to accurately represent time alignment at this granularity, so the display will look cramped and confusing. The word and phone annotations on each layer will probably not line up with the corresponding transcript words below.\nClick any word in the utterance (i.e.¬†from the olive-coloured words), and select Open TextGrid in Praat from the resulting menu.\n\nThis will open Praat and show the utterance TextGrid with the corresponding audio. The TextGrid will include:\n\na tier named after each forced-alignment configuration layer, containing the word alignments from that configuration\na tier named after each configuration‚Äôs Phone Alignment Layer, containing the phone alignments from that configuration\na word tier at the bottom, containing the main word alignments - most likely these will be evenly spaced out during the duration of the turn, and will not line up with the words in the audio; this is because the main word tokens haven‚Äôt been aligned yet, and won‚Äôt be until you select the winning configuration and change it to output it‚Äôs word alignments to the word layer (and phone alignments to the segment layer)\n\n\n\n\nMultiple sets of alignments shown in Praat\n\n\nIn Praat, you can compare the phone/word alignments of each configuration, by selecting intervals, examining how they line up with the spectrogram above, and playing the corresponding audio to get an impression of how well aligned the segment is with the audio.\nThis type of evaluation is impressionistic, but after comparing a number of utterances across a number of speakers this way, it may become clear which configuration has more accurate alignments.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "Comparing Forced Alignment Methods"
    ]
  },
  {
    "objectID": "howto/forced-alignment/fragment-mfa-annotator-installation.html",
    "href": "howto/forced-alignment/fragment-mfa-annotator-installation.html",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "Once MFA has been installed, you have to install the MFA Manager, which is the LaBB-CAT module that provides MFA with all the data it needs, and then saves to alignments MFA produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link.\nFind MFA Manager in the list, and press its Install button and then press Install again.\nAs long as MFA has been installed for all users, you should see a box that‚Äôs already filled in with the location that MFA was installed to.\nClick Configure to continue the layer manager installation.\nYou will see a window open with some information about integrating with MFA, including the information you‚Äôve already read above.\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB"
  },
  {
    "objectID": "howto/media-annotation/mediapipe.html",
    "href": "howto/media-annotation/mediapipe.html",
    "title": "MediaPipe",
    "section": "",
    "text": "MediaPipe is a suite of tools produced by Google which includes a system for detecting faces in video media, and producing landmark coordinates and scores for facial features.\nLaBB-CAT includes a module that integrates with MediaPipe call the MediaPipe Annotator.\nThe annotator can produce four outputs, each of which is optional:\n\nan alternative webm version of the video, visually annotated with facial features,\nindividual video frame images, annotated with facial features,\n\na JSON file for each video frame representing the blendshape landmark coordinates of each facial feature, and\ninstantaneous numeric score annotations for each facial feature.\n\n\n\n\nVisually annotated facial features produces by MediaPipe\n\n\n\n\nCurrently the module has only been tested on Unix-like systems (i.e.¬†Ubuntu Linux, and the LaBB-CAT Docker image)\nThe following must already be installed on the same machine that LaBB-CAT runs on:\n\nPython 3\nSupport for Python virtual environments (venv)\n\n\n\n\n\n\n\nNotevenv on Ubuntu\n\n\n\n\n\nSupport for Python ‚Äòvenv‚Äô can be installed on Ubuntu-like systems with the command:\napt install python3.10-venv\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDuring installation, the annotator needs to be able to connect to the internet so that required Python packages and model files can be installed.\n(Once installed, the annotator should function without an internet connection.)\n\n\n\nIn LaBB-CAT, select the layer managers option on the menu.\nClick the link at the bottom of the page:\nList of layer managers that are not yet installed\nFind MediaPipeAnnotator in the list, and press its Install button.\nPress Install.\nLaBB-CAT will check for the required prerequisites, and download/install the MediaPipe software and models. You will see a progress bar and status messages during this process.\nOnce everything is installed, you will see an information page titled ‚ÄúMediaPipeAnnotator‚Äù open in a new browser tab.\nClose the browser tab that just opened.\n\nMediaPipe and LaBB-CAT‚Äôs integration module are now installed.\n\n\n\n\n\nFor each video, the annotator can produce a sound-less webm video of the original video input, annotated with the detected facial features.\nIf you want this video, LaBB-CAT needs a distinct place to store it - i.e.¬†a new ‚Äòmedia track‚Äô that differentiates the annotated video from the origina video, for each transcript.\n\n\n\n\n\n\nNote\n\n\n\nIf you don‚Äôt want an annotated video file, you can skip these steps.\n\n\n\nSelect the media tracks option on the right of LaBB-CAT‚Äôs menu at the top of the page.\n\nYou will see a list of Media Tracks that most likely has only one item called ‚ÄúMedia‚Äù.\nEach media track is distinguished by a unique ‚Äòsuffix‚Äô - i.e.¬†a string of characters that is appeneded to the end of the file name to distinguish it from the main media file. For example, for the video file called AP513_Steve.mp4 we will configure the annotator to produce an annotated video called something like AP513_Steve-facial-features.webm.\nThe ‚Äòsuffix‚Äô in this example would be the -facial-features part of the name.\n\nThe row of headings at the top of the Media Tracks are a form you can fill in to create a new track.\nFill in the following details:\n\nSuffix: -facial-features\nDescription: ‚ÄúVideo annotated with facial features, with no audio track.‚Äù\n\nPress the New button to the right.\nThe new track will be added to the list.\n\n\n\n\nBy default, the annotator produces a large number of annotations on a large number of annotation layers:\n\na layer for the blendshapes file,\na layer for the annotated frame images file,\na layer for each facial featre that is tracked (there are 52 of these)\n\nFor organizational purposes, it‚Äôs a good idea to create a ‚Äòproject‚Äô for the MediaPipe data, so that layers can easily be all hidden or shown as required.\n\nSelect the projects option on the menu at the top.\nFill in the following details on the form at the top of the page:\n\nName: mediapipe\nDescription: ‚ÄúLayers of facial-feature annotations produced by MediaPipe.‚Äù\n\nPress the New button on the right to add the project.\n\n\n\n\nThe instantaneous frame annotations that are produced by the annotator relate only to the video media, and are not assigned to a participant in the transcript. As they don‚Äôt relate directly to word annotations or speaker turns, they go on a ‚Äòspan layer‚Äô.\n\nSelect the span layers option on the menu.\nOn the header row form, fill out the following details:\n\nLayer ID: blendshape\nType: Text\nAlignment: Instants (there will be a blendshape annotation for each video frame in which a face is detected)\nManager: MediaPipe Manager\nGenerate: Always\nProject: mediapipe\nDescription: ‚ÄúBlendshape coordinates for each frame‚Äù\n\nPress the New button on the right to add the layer.\n\nYou will see the annotators configuration page. The top section of the page relates to saving the blendshapes, annotated video and frame images, and what to include in the visual annotations.\n\nIf you want a video visually annotated with tracked facial features, and you have created the corresponding media track, set the Annotated Video Track setting to the track you created before.\nIf you want individual frame images visually annotated with facial features, for the Annotated Images Layer, select the [add new layer] option, specify a name for that layer (or use the default layer name) and press OK\nThere are three options for what aspects of the facial features you would like visually represented, tick the options you prefer.\n\n\n\n\n\n\nVisual annotation of feature tesselation only\n\n\n\n\n\n\nVisual annotation of contours only\n\n\n\n\nThe annotator runs facial feature detection on each frame in the video, and creates annotations only for frames in which detection was successful. The annotator can store the number of frames with faces in a transcript attribute. This can be useful for identifying videos for which few frames had faces found, in order to better calibrate the recognition tresholds.\n\nIf you want a count of frames with detected faces, for the Annotated Frame Count setting, select the [add new layer] option, and press OK.\n\nThe middle section, labelled ‚ÄúFace Blendshapes‚Äù, allows you to select which facial featured you‚Äôd like numerical annotations for, for each video frame. There are 52 facial features tracked, and a numeric rating is assigned to each one, for each frame in which a face is detected. By default, a layer is create for each feature.\n\nFor any features that you do not want the rating stored for each frame, select [none] in the dropdown list of options.\n\nThe bottom section allows you to calibrate thresholds for face/feature detection when processing video frames. These can probably be left with their default values, but if you find that no frames (or only a few) are annotated, you might try a lower value e.g.¬†for the min_face_detection_confidence theshold.\n\nOnce you have the configuration options you want, press Set Parameters at the bottom.\n\nNow the MediaPipe annotations are configured, you can either generate annotations for you entire corpus, by pressing the Regenerate button, or you can target specific transcripts by:\n\nlocating them on the transcripts page,\nticking their checkboxes,\npressing the Generate button at the top,\nselecting the blendshape layer you just created, and\npressing Generate to run MediaPipe on only the ticked recordings.\n\nThe amount of time it takes to generate annotations can be quite long, and depends on how long the videos are, how many there are, and how much computing power your LaBB-CAT server has.\n\n\n\n\n\n\nTip\n\n\n\nWhile generating annotations, the mediapipe may show warnings like the following:\n\n‚Ä¶OpenCV: FFMPEG: tag 0x30387076/‚Äòvp80‚Äô is not supported with codec id 139 and format ‚Äòwebm / WebM‚Äô WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1748469849.962542 71 task_runner.cc:85] GPU suport is not available‚Ä¶\n\nDo not be alarmed by these apparent problems, faces will be annotated anyway.\nIf you find that no faces are found in your videos, the most likely solution is to set min_face_detection_confidence to a lower value.\n\n\n\n\n\n\nDifferent types of annotations are accessible in different ways.\n\n\nYou can get a list of annotated frame counts from the transcripts page:\n\nSelect the transcripts option on the menu at the top.\nPress the Export Attributes button.\nA dropdown list of transcript attributes will appear.\nEnsure that the transcript and mediapipeFrameCount options are ticked.\nPress the Export Attributes button.\n\nYou will receive a CSV file, with a column containing the transcript/recording name, and a column with the number of video frames in which a face was detected.\n\n\n\nIf an Annotated Video Track has been specified, an alternative version of the video is created, with no audio, and with the detected facial features painted on to the video frames.\nYou can view this video directly in the transcript page, by ticking the -facial-features track on the top-right of the page.\n\n\n\nVideo track annotated with tesselation, contours, and irises\n\n\nYou can also download the video file by using the webm link to the right of the track‚Äôs name.\n\n\n\nIf you specified an Annotated Images Layer, then the visually annotated frame images are created on that layer.\nThe images can be seen directly in the transcript page:\n\nOpen the transcript page of a recording that has been annotated.\nSelect the Layers tab to list selectable layers.\nTick the mediapipe project on the left, to list all of the MediaPipe layers.\nTick the mediapipeFrame layer (or whate layer name you specified on the configuration page)\nYou will see a number of annotations appear on the page, labelled with a ‚Äòcamera‚Äô icon.\nHover your mouse over one of the camera icons to see the annotated image.\n\n\n\n\nA single frame (annotated with iris positions only)\n\n\nYou can open the image full size in your browser, save it, etc. by clicking on the image.\nAlthough only one link per word is visualized on the transcript, there is on image for every video frame in which a face was located. They can all be accessed using LaBB-CAT API, for example using the getFragmentAnnotationData function of the nzilbb.labbcat R package, or the nzilbb-labbcat Python package.\n\n\n\nFor each frame containing a face, the blendshape layer has JSON-encoded data that include the facial feature coordinates and the blendshape feature scores.\nThese are accessible on the transcript page in a similar way to the frame images; if you select the blendshape layer icons will appear in the transcript text which, if clicked, will download a JSON file containing mediapipe‚Äôs recognition result.\n\n\n\nJSON-encoded recognition result data\n\n\nAs with annotated images, these can all be accessed using the getFragmentAnnotationData function of the nzilbb.labbcat R package, or the nzilbb-labbcat Python package.\n\n\n\nIn addition to raw JSON-encoded data, numeric feature scores for each facial feature are available as instantaneous numeric annotations on layers named after the feature they score.\nAlthough these can be visualized on the transcript page, they are perhaps more usefully extracted using the getFragmentAnnotations or getFragments functions of the nzilbb.labbcat R package to extract score values between targeted start/end times, for targeted facial features.\nFor example the following R code will extract a CSV file with selected feature scores during given time intervals:\ncsvFragments &lt;- nzilbb.labbcat::getFragments(\n  url, matches$Transcript, matches$startTime, matches$endTime, \n  layer.ids = c(\"jawOpen\", \"eyeBlinkLeft\", \"eyeBlinkRight\"), \n  mime.type = \"text/csv\")",
    "crumbs": [
      "How-to",
      "Annotating Media",
      "MediaPipe"
    ]
  },
  {
    "objectID": "howto/media-annotation/mediapipe.html#prerequisites",
    "href": "howto/media-annotation/mediapipe.html#prerequisites",
    "title": "MediaPipe",
    "section": "",
    "text": "Currently the module has only been tested on Unix-like systems (i.e.¬†Ubuntu Linux, and the LaBB-CAT Docker image)\nThe following must already be installed on the same machine that LaBB-CAT runs on:\n\nPython 3\nSupport for Python virtual environments (venv)\n\n\n\n\n\n\n\nNotevenv on Ubuntu\n\n\n\n\n\nSupport for Python ‚Äòvenv‚Äô can be installed on Ubuntu-like systems with the command:\napt install python3.10-venv",
    "crumbs": [
      "How-to",
      "Annotating Media",
      "MediaPipe"
    ]
  },
  {
    "objectID": "howto/media-annotation/mediapipe.html#installation",
    "href": "howto/media-annotation/mediapipe.html#installation",
    "title": "MediaPipe",
    "section": "",
    "text": "Important\n\n\n\nDuring installation, the annotator needs to be able to connect to the internet so that required Python packages and model files can be installed.\n(Once installed, the annotator should function without an internet connection.)\n\n\n\nIn LaBB-CAT, select the layer managers option on the menu.\nClick the link at the bottom of the page:\nList of layer managers that are not yet installed\nFind MediaPipeAnnotator in the list, and press its Install button.\nPress Install.\nLaBB-CAT will check for the required prerequisites, and download/install the MediaPipe software and models. You will see a progress bar and status messages during this process.\nOnce everything is installed, you will see an information page titled ‚ÄúMediaPipeAnnotator‚Äù open in a new browser tab.\nClose the browser tab that just opened.\n\nMediaPipe and LaBB-CAT‚Äôs integration module are now installed.",
    "crumbs": [
      "How-to",
      "Annotating Media",
      "MediaPipe"
    ]
  },
  {
    "objectID": "howto/media-annotation/mediapipe.html#configuration",
    "href": "howto/media-annotation/mediapipe.html#configuration",
    "title": "MediaPipe",
    "section": "",
    "text": "For each video, the annotator can produce a sound-less webm video of the original video input, annotated with the detected facial features.\nIf you want this video, LaBB-CAT needs a distinct place to store it - i.e.¬†a new ‚Äòmedia track‚Äô that differentiates the annotated video from the origina video, for each transcript.\n\n\n\n\n\n\nNote\n\n\n\nIf you don‚Äôt want an annotated video file, you can skip these steps.\n\n\n\nSelect the media tracks option on the right of LaBB-CAT‚Äôs menu at the top of the page.\n\nYou will see a list of Media Tracks that most likely has only one item called ‚ÄúMedia‚Äù.\nEach media track is distinguished by a unique ‚Äòsuffix‚Äô - i.e.¬†a string of characters that is appeneded to the end of the file name to distinguish it from the main media file. For example, for the video file called AP513_Steve.mp4 we will configure the annotator to produce an annotated video called something like AP513_Steve-facial-features.webm.\nThe ‚Äòsuffix‚Äô in this example would be the -facial-features part of the name.\n\nThe row of headings at the top of the Media Tracks are a form you can fill in to create a new track.\nFill in the following details:\n\nSuffix: -facial-features\nDescription: ‚ÄúVideo annotated with facial features, with no audio track.‚Äù\n\nPress the New button to the right.\nThe new track will be added to the list.\n\n\n\n\nBy default, the annotator produces a large number of annotations on a large number of annotation layers:\n\na layer for the blendshapes file,\na layer for the annotated frame images file,\na layer for each facial featre that is tracked (there are 52 of these)\n\nFor organizational purposes, it‚Äôs a good idea to create a ‚Äòproject‚Äô for the MediaPipe data, so that layers can easily be all hidden or shown as required.\n\nSelect the projects option on the menu at the top.\nFill in the following details on the form at the top of the page:\n\nName: mediapipe\nDescription: ‚ÄúLayers of facial-feature annotations produced by MediaPipe.‚Äù\n\nPress the New button on the right to add the project.\n\n\n\n\nThe instantaneous frame annotations that are produced by the annotator relate only to the video media, and are not assigned to a participant in the transcript. As they don‚Äôt relate directly to word annotations or speaker turns, they go on a ‚Äòspan layer‚Äô.\n\nSelect the span layers option on the menu.\nOn the header row form, fill out the following details:\n\nLayer ID: blendshape\nType: Text\nAlignment: Instants (there will be a blendshape annotation for each video frame in which a face is detected)\nManager: MediaPipe Manager\nGenerate: Always\nProject: mediapipe\nDescription: ‚ÄúBlendshape coordinates for each frame‚Äù\n\nPress the New button on the right to add the layer.\n\nYou will see the annotators configuration page. The top section of the page relates to saving the blendshapes, annotated video and frame images, and what to include in the visual annotations.\n\nIf you want a video visually annotated with tracked facial features, and you have created the corresponding media track, set the Annotated Video Track setting to the track you created before.\nIf you want individual frame images visually annotated with facial features, for the Annotated Images Layer, select the [add new layer] option, specify a name for that layer (or use the default layer name) and press OK\nThere are three options for what aspects of the facial features you would like visually represented, tick the options you prefer.\n\n\n\n\n\n\nVisual annotation of feature tesselation only\n\n\n\n\n\n\nVisual annotation of contours only\n\n\n\n\nThe annotator runs facial feature detection on each frame in the video, and creates annotations only for frames in which detection was successful. The annotator can store the number of frames with faces in a transcript attribute. This can be useful for identifying videos for which few frames had faces found, in order to better calibrate the recognition tresholds.\n\nIf you want a count of frames with detected faces, for the Annotated Frame Count setting, select the [add new layer] option, and press OK.\n\nThe middle section, labelled ‚ÄúFace Blendshapes‚Äù, allows you to select which facial featured you‚Äôd like numerical annotations for, for each video frame. There are 52 facial features tracked, and a numeric rating is assigned to each one, for each frame in which a face is detected. By default, a layer is create for each feature.\n\nFor any features that you do not want the rating stored for each frame, select [none] in the dropdown list of options.\n\nThe bottom section allows you to calibrate thresholds for face/feature detection when processing video frames. These can probably be left with their default values, but if you find that no frames (or only a few) are annotated, you might try a lower value e.g.¬†for the min_face_detection_confidence theshold.\n\nOnce you have the configuration options you want, press Set Parameters at the bottom.\n\nNow the MediaPipe annotations are configured, you can either generate annotations for you entire corpus, by pressing the Regenerate button, or you can target specific transcripts by:\n\nlocating them on the transcripts page,\nticking their checkboxes,\npressing the Generate button at the top,\nselecting the blendshape layer you just created, and\npressing Generate to run MediaPipe on only the ticked recordings.\n\nThe amount of time it takes to generate annotations can be quite long, and depends on how long the videos are, how many there are, and how much computing power your LaBB-CAT server has.\n\n\n\n\n\n\nTip\n\n\n\nWhile generating annotations, the mediapipe may show warnings like the following:\n\n‚Ä¶OpenCV: FFMPEG: tag 0x30387076/‚Äòvp80‚Äô is not supported with codec id 139 and format ‚Äòwebm / WebM‚Äô WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1748469849.962542 71 task_runner.cc:85] GPU suport is not available‚Ä¶\n\nDo not be alarmed by these apparent problems, faces will be annotated anyway.\nIf you find that no faces are found in your videos, the most likely solution is to set min_face_detection_confidence to a lower value.",
    "crumbs": [
      "How-to",
      "Annotating Media",
      "MediaPipe"
    ]
  },
  {
    "objectID": "howto/media-annotation/mediapipe.html#accessing-annotations",
    "href": "howto/media-annotation/mediapipe.html#accessing-annotations",
    "title": "MediaPipe",
    "section": "",
    "text": "Different types of annotations are accessible in different ways.\n\n\nYou can get a list of annotated frame counts from the transcripts page:\n\nSelect the transcripts option on the menu at the top.\nPress the Export Attributes button.\nA dropdown list of transcript attributes will appear.\nEnsure that the transcript and mediapipeFrameCount options are ticked.\nPress the Export Attributes button.\n\nYou will receive a CSV file, with a column containing the transcript/recording name, and a column with the number of video frames in which a face was detected.\n\n\n\nIf an Annotated Video Track has been specified, an alternative version of the video is created, with no audio, and with the detected facial features painted on to the video frames.\nYou can view this video directly in the transcript page, by ticking the -facial-features track on the top-right of the page.\n\n\n\nVideo track annotated with tesselation, contours, and irises\n\n\nYou can also download the video file by using the webm link to the right of the track‚Äôs name.\n\n\n\nIf you specified an Annotated Images Layer, then the visually annotated frame images are created on that layer.\nThe images can be seen directly in the transcript page:\n\nOpen the transcript page of a recording that has been annotated.\nSelect the Layers tab to list selectable layers.\nTick the mediapipe project on the left, to list all of the MediaPipe layers.\nTick the mediapipeFrame layer (or whate layer name you specified on the configuration page)\nYou will see a number of annotations appear on the page, labelled with a ‚Äòcamera‚Äô icon.\nHover your mouse over one of the camera icons to see the annotated image.\n\n\n\n\nA single frame (annotated with iris positions only)\n\n\nYou can open the image full size in your browser, save it, etc. by clicking on the image.\nAlthough only one link per word is visualized on the transcript, there is on image for every video frame in which a face was located. They can all be accessed using LaBB-CAT API, for example using the getFragmentAnnotationData function of the nzilbb.labbcat R package, or the nzilbb-labbcat Python package.\n\n\n\nFor each frame containing a face, the blendshape layer has JSON-encoded data that include the facial feature coordinates and the blendshape feature scores.\nThese are accessible on the transcript page in a similar way to the frame images; if you select the blendshape layer icons will appear in the transcript text which, if clicked, will download a JSON file containing mediapipe‚Äôs recognition result.\n\n\n\nJSON-encoded recognition result data\n\n\nAs with annotated images, these can all be accessed using the getFragmentAnnotationData function of the nzilbb.labbcat R package, or the nzilbb-labbcat Python package.\n\n\n\nIn addition to raw JSON-encoded data, numeric feature scores for each facial feature are available as instantaneous numeric annotations on layers named after the feature they score.\nAlthough these can be visualized on the transcript page, they are perhaps more usefully extracted using the getFragmentAnnotations or getFragments functions of the nzilbb.labbcat R package to extract score values between targeted start/end times, for targeted facial features.\nFor example the following R code will extract a CSV file with selected feature scores during given time intervals:\ncsvFragments &lt;- nzilbb.labbcat::getFragments(\n  url, matches$Transcript, matches$startTime, matches$endTime, \n  layer.ids = c(\"jawOpen\", \"eyeBlinkLeft\", \"eyeBlinkRight\"), \n  mime.type = \"text/csv\")",
    "crumbs": [
      "How-to",
      "Annotating Media",
      "MediaPipe"
    ]
  },
  {
    "objectID": "howto/install/rhel.html",
    "href": "howto/install/rhel.html",
    "title": "Installing LaBB-CAT on Red Hat Linux",
    "section": "",
    "text": "Broad steps are:\n\nInstall Apache Tomcat 9\nInstall MariaDB\nInstall third-party tools (Praat, ffmpeg, HTK if required)\nInstall LaBB-CAT webapp\n\nAdditional steps might include\n\nSetting up password protection\nIntegrating Apache web server with Tomcat\n\n\n\nInstall Tomcat 9, later versions are currently not tested.\n\nInstall JDK with the following command:\nsudo dnf install wget java-11-openjdk-devel\nDownload and unpack the Tomcat software with the following commands:\ncd /usr/local\nsudo wget https://downloads.apache.org/tomcat/tomcat-9/v9.0.95/bin//apache-tomcat-9.0.95.tar.gz\nsudo tar -xvf apache-tomcat-9.0.95.tar.gz\nsudo mv apache-tomcat-9.0.95 tomcat9\nCreate a user for the Tomcat service with the following commands:\nsudo useradd -r tomcat\nsudo chown -R tomcat:tomcat /usr/local/tomcat9\nCreate a service file /etc/systemd/system/tomcat.service with your favourite text editor, e.g.\nsudo vim /etc/systemd/system/tomcat.service\nThe content should be:\n\n[Unit]  \nDescription=Apache Tomcat Server  \nAfter=syslog.target network.target  \n[Service]  \nType=forking  \nUser=tomcat  \nGroup=tomcat  \nEnvironment=CATALINA_PID=/usr/local/tomcat9/temp/tomcat.pid  \nEnvironment=CATALINA_HOME=/usr/local/tomcat9  \nEnvironment=CATALINA_BASE=/usr/local/tomcat9  \nExecStart=/usr/local/tomcat9/bin/catalina.sh start  \nExecStop=/usr/local/tomcat9/bin/catalina.sh stop  \nRestartSec=10  \nRestart=always  \n[Install]  \nWantedBy=multi-user.target\n\nRemove example webapps that are installed by default: sudo rm -r /usr/local/tomcat9/webapps/docs sudo rm -r /usr/local/tomcat9/webapps/host-manager sudo rm -r /usr/local/tomcat9/webapps/examples\nEnable/start the Tomcat service with the following commands: sudo systemctl daemon-reload sudo systemctl enable tomcat.service sudo systemctl start tomcat.service\nEnsure Tomcat can receive requests from external clients: sudo firewall-cmd --zone=public --permanent --add-port=8080/tcp sudo firewall-cmd --reload\n\nAt this point, Tomcat should be working. You can check this by opening your browser and browsing to your server‚Äôs host name, on port 8080, something like:\nhttp://example.com:8080/\n(Substitute example.com with the host name of your server.).\nThis should display the Apache Tomcat default page (and not en error).\n\nEnsure Tomcat‚Äôs catalina.out log file is rotated by creating a logrotate configuration file called /etc/logrotate.d/tomcat with your favourite text editor, e.g.\nsudo vim /etc/logrotate.d/tomcat\nAdd the following content to the file, and save it:\n\n/usr/local/tomcat9/logs/catalina.out {\n    copytruncate\n    daily\n    rotate 7\n    compress\n    missingok\n    size 5M\n}\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThese steps for installation of the MariaDB on relation database management software assume that you want to run MariaDB on the same server as Tomcat.\nYou can run Tomcat and MariaDB on different servers, just take the following steps on the other server, and make sure communication between the Tomcat and MariaDB servers is enabled.\nIf you do this, then you will also have to execute the following commands on the MariaDB server:\n\nsudo firewall-cmd --zone=public --add-port=3306/tcp --permanent\nsudo firewall-cmd --reload\n\n\n\n\nInstall MariaDB with the following command:\nsudo yum install mariadb\nEnable and system its service with the following commands:\nsudo systemctl enable mariadb\nsudo systemctl start mariadb\nsudo systemctl stop mariadb\n\n\n\n\nLaBB-CAT integrates with various tird party software tools, which you can install now. These steps are optional.\n\n\nIf you want to user LaBB-CAT‚Äôs batch Praat processing functionality, you must install Praat on the server, with the following commands:\n\nsudo wget https://www.fon.hum.uva.nl/praat/praat6420_linux-intel64-barren.tar.gz\nsudo tar zxvf praat6420_linux-intel64-barren.tar.gz\nsudo cp praat_barren /usr/bin/praat\n\n\n\n\nIf you want LaBB-CAT to be able to automatically convert media between formats (e.g.¬†automatically extract a .wav audio file from uploaded videos) you must install Praat on the server, with the following commands:\n\nsudo dnf install epel-release\nsudo dnf install https://download.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm\nsudo dnf install https://dl.fedoraproject.org/pub/epel/epel-next-release-latest-9.noarch.rpm\nsudo dnf install --nogpgcheck https://mirrors.rpmfusion.org/free/el/rpmfusion-free-release-$(rpm -E %rhel).noarch.rpm\nsudo dnf install https://mirrors.rpmfusion.org/nonfree/el/rpmfusion-nonfree-release-$(rpm -E %rhel).noarch.rpm\nsudo dnf install https://mirror.stream.centos.org/9-stream/CRB/x86_64/os/Packages/ladspa-1.13-28.el9.x86_64.rpm\nsudo dnf install ffmpeg ffmpeg-devel\n\n\n\n\nIf you want to user HTK for forced alginment, you must install HTK on the server, using the following steps.\n\nEnsure you have registered a username and password on http://htk.eng.cam.ac.uk/register.shtml\nInstall prerequisites for coompiling HTK from source: sudo  yum -y install glibc-devel.i686 libX11-devel.i686 glibc-devel.i686 libstdc++-devel.i686\nDownload and unpack the source code: cd /tmp\nIn the following command, replace my-username with the username you registered on the HTK site: wget --user=my-username --ask-password http://htk.eng.cam.ac.uk/ftp/software/HTK-3.4.1.tar.gz\nEnter your HTK password when asked.\ntar -zxf HTK-3.4.1.tar.gz\nPrepare for compilation: cd htk\n./configure\nOpen the HLMTools/Makefile file with your favourite text editor, e.g. vim HLMTools/Makefile ‚Ä¶and replace spaces on line 77 with a tab character. Then save the file.\nCompile and install the software with the following commands: make all sudo make install\n\n\n\n\n\nOnce Tomcat and MariaDB are installed, the LaBB-CAT web application can be installed, using the following steps:\n\nDownload the most recent labbcat-server_yyyymmdd.zip file from SourceForge:\nhttps://sourceforge.net/projects/labbcat/files/install/\nUnzip the resulting file, will with contain LaBB-CAT‚Äôs Web Application Archive, called labbcat.war\nCopy labbcat.war into Tomcat‚Äôs webapps directory with a command like:\nsudo cp labbcat.war /usr/local/tomcat9/webapps/\n\nTomcat will automatically unpack the file into a subirectory with the same name as the .war file. You can check this is successful with the following command:\nsudo ls /usr/local/tomcat9/webapps/labbcat/\n‚Ä¶which should show a list of files, rather than returning an error.\n\nIn your web browser, open the labbcat webapp page, with a URL like:\nhttp://example.com:8080/labbcat/\n(Substitute example.com with the host name of your server.)\n\nYou should see a page with the title: web application self-installation and a form asking for information for database information.\n\nNext to the title LaBB-CAT Database Exists there is an expandable section labelled:\nA MySQL database and MySQL user can be pre-created\nClick this section to expand it, revealing SQL statements for pre-creating the database.\n\nThere are four SQL commands that look something like this:\nCREATE DATABASE IF NOT EXISTS labbcat CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\nCREATE USER 'labbcat'@'%' IDENTIFIED BY ...;\nGRANT ALL PRIVILEGES ON labbcat.* TO 'labbcat'@'%';\nGRANT PROCESS ON *.* TO 'labbcat'@'%';\n\nBack in you command shell on the server on which MariaDB is installed, start the mysql command line interface with the following command:\nsudo mysql\nThis will display a command prompt something like: MariaDB [(none)]&gt;\nCopy and paste the four SQL commands from your browser into the MariaDB command prompt, and hit returnreturn to execute all of them.\nExit from the MariaDDB command prompt with the following command:\nexit\nBack in your browser, on the web application self-installation page, tick the box labelled:\nThe above database already exists, so don‚Äôt create it.\nPress the install button.\n\nYou should see a page listing steps that are being taken during the webapp installation, with\nInstallation is complete.\n‚Ä¶printed at the bottom.\nAfter a short delay, the page will reload, and the LaBB-CAT home page will be displayed.\nLaBB-CAT is now installed on your server, and can be accessed with the URL shown in your browser.\n\n\n\n\n\nWhen first installed, LaBB-CAT can be accessed by anyone who has a browser connection to the server. You probably want to password-protect LaBB-CAT to restrict access.\nFollow these optional steps to enable password protection:\n\nEnsure that Tomcat itself can connect to the MariaDB database to authenticate users, using the following commands:\nsudo cp /usr/local/tomcat9/webapps/labbcat/WEB-INF/lib/mysql-connector-java-latest.jar /usr/local/tomcat9/lib/\nsudo chown tomcat:tomcat /usr/local/tomcat9/lib/mysql-connector-java-latest.jar\nOpen LaBB-CAT‚Äôs WEB-INF/web.xml file with your favourite text editor, e.g.\nsudo vim /usr/local/tomcat9/webapps/labbcat/WEB-INF/web.xml\nDelete the lines that contain the phrase USER-SECURITY - there should be two lines, one that opens an XML comment, and one that closes it.\nSave the web.xml file.\nRestart Tomcat to ensure the changes take effect, using the followiing command:\nsudo systemctl restart tomcat.service\nIn your web browser, open LaBB-CAT‚Äôs home-page (or reload the page if it‚Äôs already displayed).\nYou should be asked for a username and password.\n(If you see an error, close your browser completely down and start it up again)\nEnter the username labbcat and the password labbcat.\nYou should see a page asking you to change your password.\nSet your labbcat user‚Äôs password to something memorable, and the LaBB-CAT home page will be displayed.\n\nLaBB-CAT is now password protected.\nYou can add new users using the users link at the top of the page:\n\nFill in the User ID box at the top of the page.\nPress the New button on the right.\nSet an initial password for the new user by entering it twice.\nPress the Save button that appears after you‚Äôve entered the same new password twice.\n\nThe new user will have read-only access to LaBB-CAT. If you want them to have more privileges, you need to tick corresponding Roles checkboxes for their user:\n\nedit: the user can upload transcripts, media, and transcript/participant meta-data.\nadmin: the user can do anything at all, and\nexport: the user can export a copy of the whole LaBB-CAT instance.\n\n\n\n\nYour server may already have Apache web server installed, e.g.¬†for serving requests on the normal HTTP port and/or supporting encrypted HTTPS connections.\nTomcat can be integrated with Apache, so that HTTP/HTTPS requests received by Apache are handled by Tomcat.\nSteps to integrate Apache Web Server with Tomcat are are:\n\nInstall package dependencies:\nsudo dnf install httpd-devel apr apr-devel apr-util apr-util-devel gcc gcc-c++ make autoconf libtool httpd-devel.x86_64\nDownload and install Jk:\n\nsudo mkdir -p /opt/mod_jk/\ncd /opt/mod_jk/\nsudo wget https://downloads.apache.org/tomcat/tomcat-connectors/jk/tomcat-connectors-1.2.50-src.tar.gz\nsudo tar -xvzf tomcat-connectors-1.2.50-src.tar.gz\ncd tomcat-connectors-1.2.50-src/native\nsudo ./configure --with-apxs=/usr/bin/apxs\nsudo make\nsudo libtool --finish /usr/lib64/httpd/modules\nsudo cp ./apache-2.0/mod_jk.so /etc/httpd/modules/mod_jk.so\n\nConfigure Tomcat to accept connections from Apache:\n\nOpen /etc/tomcat/server.xml with your favourite text editor, e.g.\nsudo vim /etc/tomcat/server.xml\nChange the Engine tag to be:\n&lt;Engine name=\"Catalina\" defaultHost=\"localhost\" jvmRoute=\"jvm1\"&gt;\nComment out the connector for port 8080:\n&lt;!-- &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\" /&gt;  --&gt;\nComment in the connector for 8009, and set the attributes as follows:\n&lt;Connector protocol=\"AJP/1.3\"\n           address=\"127.0.0.1\"\n           port=\"8009\"\n           maxParameterCount=\"-1\"\n           redirectPort=\"8443\"\n           secretRequired=\"false\"/&gt;\nSave the file.\n\nCreate the Jk module configuration file /etc/httpd/conf.d/mod_jk.conf with the following content:\nLoadModule jk_module \"/etc/httpd/modules/mod_jk.so\"\nJkWorkersFile /etc/httpd/conf/workers.properties\nJkShmFile     /var/run/httpd/mod_jk.shm\nJkLogFile     /var/log/httpd/mod_jk.log\nJkLogLevel    info\nJkLogStampFormat \"[%a %b %d %H:%M:%S %Y] \"\n#JkRequestLogFormat \"%w %V %T\"\n#JkEnvVar SSL_CLIENT_V_START worker1\nCreate /var/run/mod_jk:\n\nsudo mkdir -p /var/run/mod_jk\nsudo chown apache:apache /var/run/mod_jk\n\nCreate the /etc/httpd/conf/workers.properties file with the following content:\nworkers.apache_log=/var/log/httpd\nworker.list=app1Worker\nworker.stat1.type=status\nworker.app1Worker.type=ajp13\nworker.app1Worker.host=127.0.0.1\nworker.app1Worker.port=8009\nCreate the /etc/httpd/conf.d/tomcat.conf file with the following content (substituting example.com with your server‚Äôs host name):\n&lt;VirtualHost *:80&gt;\n  ServerName example.com\n  ServerAdmin webmaster@example.com\n  LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b \\\"%{Referer}i\\\" \\\"%{User-agent}i\\\"\" combined\n  CustomLog /var/log/httpd/tomcat.log combined\n  ErrorLog /var/log/httpd/tomcat.log\n  &lt;IfModule mod_jk.c&gt;\n     JkMount /* app1Worker\n     # so that certbot works:\n     JkUnMount /.well-known/*  app1Worker\n  &lt;/IfModule&gt;\n&lt;/VirtualHost&gt;\nRestart Tomcat and Apache Web Server:\n\nsudo service tomcat restart\nsudo service httpd restart\n\nIf you are using SElinux, you may see an error when restarting httpd. If so, execute the following commands:\n\nsudo ausearch -c 'httpd' --raw | audit2allow -M my-httpd\nsudo semodule -i my-httpd.pp\nsudo service httpd restart\n\n\nNow ordinary browser connections like http://example.com/labbcat should show the LaBB-CAT home page, and if you have HTTPS configured with an SSL certificat, encrypted connections like https://example.com/labbcat should work.",
    "crumbs": [
      "How-to",
      "Installation",
      "Red Hat Linux"
    ]
  },
  {
    "objectID": "howto/install/rhel.html#tomcat",
    "href": "howto/install/rhel.html#tomcat",
    "title": "Installing LaBB-CAT on Red Hat Linux",
    "section": "",
    "text": "Install Tomcat 9, later versions are currently not tested.\n\nInstall JDK with the following command:\nsudo dnf install wget java-11-openjdk-devel\nDownload and unpack the Tomcat software with the following commands:\ncd /usr/local\nsudo wget https://downloads.apache.org/tomcat/tomcat-9/v9.0.95/bin//apache-tomcat-9.0.95.tar.gz\nsudo tar -xvf apache-tomcat-9.0.95.tar.gz\nsudo mv apache-tomcat-9.0.95 tomcat9\nCreate a user for the Tomcat service with the following commands:\nsudo useradd -r tomcat\nsudo chown -R tomcat:tomcat /usr/local/tomcat9\nCreate a service file /etc/systemd/system/tomcat.service with your favourite text editor, e.g.\nsudo vim /etc/systemd/system/tomcat.service\nThe content should be:\n\n[Unit]  \nDescription=Apache Tomcat Server  \nAfter=syslog.target network.target  \n[Service]  \nType=forking  \nUser=tomcat  \nGroup=tomcat  \nEnvironment=CATALINA_PID=/usr/local/tomcat9/temp/tomcat.pid  \nEnvironment=CATALINA_HOME=/usr/local/tomcat9  \nEnvironment=CATALINA_BASE=/usr/local/tomcat9  \nExecStart=/usr/local/tomcat9/bin/catalina.sh start  \nExecStop=/usr/local/tomcat9/bin/catalina.sh stop  \nRestartSec=10  \nRestart=always  \n[Install]  \nWantedBy=multi-user.target\n\nRemove example webapps that are installed by default: sudo rm -r /usr/local/tomcat9/webapps/docs sudo rm -r /usr/local/tomcat9/webapps/host-manager sudo rm -r /usr/local/tomcat9/webapps/examples\nEnable/start the Tomcat service with the following commands: sudo systemctl daemon-reload sudo systemctl enable tomcat.service sudo systemctl start tomcat.service\nEnsure Tomcat can receive requests from external clients: sudo firewall-cmd --zone=public --permanent --add-port=8080/tcp sudo firewall-cmd --reload\n\nAt this point, Tomcat should be working. You can check this by opening your browser and browsing to your server‚Äôs host name, on port 8080, something like:\nhttp://example.com:8080/\n(Substitute example.com with the host name of your server.).\nThis should display the Apache Tomcat default page (and not en error).\n\nEnsure Tomcat‚Äôs catalina.out log file is rotated by creating a logrotate configuration file called /etc/logrotate.d/tomcat with your favourite text editor, e.g.\nsudo vim /etc/logrotate.d/tomcat\nAdd the following content to the file, and save it:\n\n/usr/local/tomcat9/logs/catalina.out {\n    copytruncate\n    daily\n    rotate 7\n    compress\n    missingok\n    size 5M\n}",
    "crumbs": [
      "How-to",
      "Installation",
      "Red Hat Linux"
    ]
  },
  {
    "objectID": "howto/install/rhel.html#mariadb",
    "href": "howto/install/rhel.html#mariadb",
    "title": "Installing LaBB-CAT on Red Hat Linux",
    "section": "",
    "text": "Tip\n\n\n\nThese steps for installation of the MariaDB on relation database management software assume that you want to run MariaDB on the same server as Tomcat.\nYou can run Tomcat and MariaDB on different servers, just take the following steps on the other server, and make sure communication between the Tomcat and MariaDB servers is enabled.\nIf you do this, then you will also have to execute the following commands on the MariaDB server:\n\nsudo firewall-cmd --zone=public --add-port=3306/tcp --permanent\nsudo firewall-cmd --reload\n\n\n\n\nInstall MariaDB with the following command:\nsudo yum install mariadb\nEnable and system its service with the following commands:\nsudo systemctl enable mariadb\nsudo systemctl start mariadb\nsudo systemctl stop mariadb",
    "crumbs": [
      "How-to",
      "Installation",
      "Red Hat Linux"
    ]
  },
  {
    "objectID": "howto/install/rhel.html#third-party-tools",
    "href": "howto/install/rhel.html#third-party-tools",
    "title": "Installing LaBB-CAT on Red Hat Linux",
    "section": "",
    "text": "LaBB-CAT integrates with various tird party software tools, which you can install now. These steps are optional.\n\n\nIf you want to user LaBB-CAT‚Äôs batch Praat processing functionality, you must install Praat on the server, with the following commands:\n\nsudo wget https://www.fon.hum.uva.nl/praat/praat6420_linux-intel64-barren.tar.gz\nsudo tar zxvf praat6420_linux-intel64-barren.tar.gz\nsudo cp praat_barren /usr/bin/praat\n\n\n\n\nIf you want LaBB-CAT to be able to automatically convert media between formats (e.g.¬†automatically extract a .wav audio file from uploaded videos) you must install Praat on the server, with the following commands:\n\nsudo dnf install epel-release\nsudo dnf install https://download.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm\nsudo dnf install https://dl.fedoraproject.org/pub/epel/epel-next-release-latest-9.noarch.rpm\nsudo dnf install --nogpgcheck https://mirrors.rpmfusion.org/free/el/rpmfusion-free-release-$(rpm -E %rhel).noarch.rpm\nsudo dnf install https://mirrors.rpmfusion.org/nonfree/el/rpmfusion-nonfree-release-$(rpm -E %rhel).noarch.rpm\nsudo dnf install https://mirror.stream.centos.org/9-stream/CRB/x86_64/os/Packages/ladspa-1.13-28.el9.x86_64.rpm\nsudo dnf install ffmpeg ffmpeg-devel\n\n\n\n\nIf you want to user HTK for forced alginment, you must install HTK on the server, using the following steps.\n\nEnsure you have registered a username and password on http://htk.eng.cam.ac.uk/register.shtml\nInstall prerequisites for coompiling HTK from source: sudo  yum -y install glibc-devel.i686 libX11-devel.i686 glibc-devel.i686 libstdc++-devel.i686\nDownload and unpack the source code: cd /tmp\nIn the following command, replace my-username with the username you registered on the HTK site: wget --user=my-username --ask-password http://htk.eng.cam.ac.uk/ftp/software/HTK-3.4.1.tar.gz\nEnter your HTK password when asked.\ntar -zxf HTK-3.4.1.tar.gz\nPrepare for compilation: cd htk\n./configure\nOpen the HLMTools/Makefile file with your favourite text editor, e.g. vim HLMTools/Makefile ‚Ä¶and replace spaces on line 77 with a tab character. Then save the file.\nCompile and install the software with the following commands: make all sudo make install",
    "crumbs": [
      "How-to",
      "Installation",
      "Red Hat Linux"
    ]
  },
  {
    "objectID": "howto/install/rhel.html#labb-cat-webapp",
    "href": "howto/install/rhel.html#labb-cat-webapp",
    "title": "Installing LaBB-CAT on Red Hat Linux",
    "section": "",
    "text": "Once Tomcat and MariaDB are installed, the LaBB-CAT web application can be installed, using the following steps:\n\nDownload the most recent labbcat-server_yyyymmdd.zip file from SourceForge:\nhttps://sourceforge.net/projects/labbcat/files/install/\nUnzip the resulting file, will with contain LaBB-CAT‚Äôs Web Application Archive, called labbcat.war\nCopy labbcat.war into Tomcat‚Äôs webapps directory with a command like:\nsudo cp labbcat.war /usr/local/tomcat9/webapps/\n\nTomcat will automatically unpack the file into a subirectory with the same name as the .war file. You can check this is successful with the following command:\nsudo ls /usr/local/tomcat9/webapps/labbcat/\n‚Ä¶which should show a list of files, rather than returning an error.\n\nIn your web browser, open the labbcat webapp page, with a URL like:\nhttp://example.com:8080/labbcat/\n(Substitute example.com with the host name of your server.)\n\nYou should see a page with the title: web application self-installation and a form asking for information for database information.\n\nNext to the title LaBB-CAT Database Exists there is an expandable section labelled:\nA MySQL database and MySQL user can be pre-created\nClick this section to expand it, revealing SQL statements for pre-creating the database.\n\nThere are four SQL commands that look something like this:\nCREATE DATABASE IF NOT EXISTS labbcat CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\nCREATE USER 'labbcat'@'%' IDENTIFIED BY ...;\nGRANT ALL PRIVILEGES ON labbcat.* TO 'labbcat'@'%';\nGRANT PROCESS ON *.* TO 'labbcat'@'%';\n\nBack in you command shell on the server on which MariaDB is installed, start the mysql command line interface with the following command:\nsudo mysql\nThis will display a command prompt something like: MariaDB [(none)]&gt;\nCopy and paste the four SQL commands from your browser into the MariaDB command prompt, and hit returnreturn to execute all of them.\nExit from the MariaDDB command prompt with the following command:\nexit\nBack in your browser, on the web application self-installation page, tick the box labelled:\nThe above database already exists, so don‚Äôt create it.\nPress the install button.\n\nYou should see a page listing steps that are being taken during the webapp installation, with\nInstallation is complete.\n‚Ä¶printed at the bottom.\nAfter a short delay, the page will reload, and the LaBB-CAT home page will be displayed.\nLaBB-CAT is now installed on your server, and can be accessed with the URL shown in your browser.",
    "crumbs": [
      "How-to",
      "Installation",
      "Red Hat Linux"
    ]
  },
  {
    "objectID": "howto/install/rhel.html#additional-steps",
    "href": "howto/install/rhel.html#additional-steps",
    "title": "Installing LaBB-CAT on Red Hat Linux",
    "section": "",
    "text": "When first installed, LaBB-CAT can be accessed by anyone who has a browser connection to the server. You probably want to password-protect LaBB-CAT to restrict access.\nFollow these optional steps to enable password protection:\n\nEnsure that Tomcat itself can connect to the MariaDB database to authenticate users, using the following commands:\nsudo cp /usr/local/tomcat9/webapps/labbcat/WEB-INF/lib/mysql-connector-java-latest.jar /usr/local/tomcat9/lib/\nsudo chown tomcat:tomcat /usr/local/tomcat9/lib/mysql-connector-java-latest.jar\nOpen LaBB-CAT‚Äôs WEB-INF/web.xml file with your favourite text editor, e.g.\nsudo vim /usr/local/tomcat9/webapps/labbcat/WEB-INF/web.xml\nDelete the lines that contain the phrase USER-SECURITY - there should be two lines, one that opens an XML comment, and one that closes it.\nSave the web.xml file.\nRestart Tomcat to ensure the changes take effect, using the followiing command:\nsudo systemctl restart tomcat.service\nIn your web browser, open LaBB-CAT‚Äôs home-page (or reload the page if it‚Äôs already displayed).\nYou should be asked for a username and password.\n(If you see an error, close your browser completely down and start it up again)\nEnter the username labbcat and the password labbcat.\nYou should see a page asking you to change your password.\nSet your labbcat user‚Äôs password to something memorable, and the LaBB-CAT home page will be displayed.\n\nLaBB-CAT is now password protected.\nYou can add new users using the users link at the top of the page:\n\nFill in the User ID box at the top of the page.\nPress the New button on the right.\nSet an initial password for the new user by entering it twice.\nPress the Save button that appears after you‚Äôve entered the same new password twice.\n\nThe new user will have read-only access to LaBB-CAT. If you want them to have more privileges, you need to tick corresponding Roles checkboxes for their user:\n\nedit: the user can upload transcripts, media, and transcript/participant meta-data.\nadmin: the user can do anything at all, and\nexport: the user can export a copy of the whole LaBB-CAT instance.\n\n\n\n\nYour server may already have Apache web server installed, e.g.¬†for serving requests on the normal HTTP port and/or supporting encrypted HTTPS connections.\nTomcat can be integrated with Apache, so that HTTP/HTTPS requests received by Apache are handled by Tomcat.\nSteps to integrate Apache Web Server with Tomcat are are:\n\nInstall package dependencies:\nsudo dnf install httpd-devel apr apr-devel apr-util apr-util-devel gcc gcc-c++ make autoconf libtool httpd-devel.x86_64\nDownload and install Jk:\n\nsudo mkdir -p /opt/mod_jk/\ncd /opt/mod_jk/\nsudo wget https://downloads.apache.org/tomcat/tomcat-connectors/jk/tomcat-connectors-1.2.50-src.tar.gz\nsudo tar -xvzf tomcat-connectors-1.2.50-src.tar.gz\ncd tomcat-connectors-1.2.50-src/native\nsudo ./configure --with-apxs=/usr/bin/apxs\nsudo make\nsudo libtool --finish /usr/lib64/httpd/modules\nsudo cp ./apache-2.0/mod_jk.so /etc/httpd/modules/mod_jk.so\n\nConfigure Tomcat to accept connections from Apache:\n\nOpen /etc/tomcat/server.xml with your favourite text editor, e.g.\nsudo vim /etc/tomcat/server.xml\nChange the Engine tag to be:\n&lt;Engine name=\"Catalina\" defaultHost=\"localhost\" jvmRoute=\"jvm1\"&gt;\nComment out the connector for port 8080:\n&lt;!-- &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\" /&gt;  --&gt;\nComment in the connector for 8009, and set the attributes as follows:\n&lt;Connector protocol=\"AJP/1.3\"\n           address=\"127.0.0.1\"\n           port=\"8009\"\n           maxParameterCount=\"-1\"\n           redirectPort=\"8443\"\n           secretRequired=\"false\"/&gt;\nSave the file.\n\nCreate the Jk module configuration file /etc/httpd/conf.d/mod_jk.conf with the following content:\nLoadModule jk_module \"/etc/httpd/modules/mod_jk.so\"\nJkWorkersFile /etc/httpd/conf/workers.properties\nJkShmFile     /var/run/httpd/mod_jk.shm\nJkLogFile     /var/log/httpd/mod_jk.log\nJkLogLevel    info\nJkLogStampFormat \"[%a %b %d %H:%M:%S %Y] \"\n#JkRequestLogFormat \"%w %V %T\"\n#JkEnvVar SSL_CLIENT_V_START worker1\nCreate /var/run/mod_jk:\n\nsudo mkdir -p /var/run/mod_jk\nsudo chown apache:apache /var/run/mod_jk\n\nCreate the /etc/httpd/conf/workers.properties file with the following content:\nworkers.apache_log=/var/log/httpd\nworker.list=app1Worker\nworker.stat1.type=status\nworker.app1Worker.type=ajp13\nworker.app1Worker.host=127.0.0.1\nworker.app1Worker.port=8009\nCreate the /etc/httpd/conf.d/tomcat.conf file with the following content (substituting example.com with your server‚Äôs host name):\n&lt;VirtualHost *:80&gt;\n  ServerName example.com\n  ServerAdmin webmaster@example.com\n  LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b \\\"%{Referer}i\\\" \\\"%{User-agent}i\\\"\" combined\n  CustomLog /var/log/httpd/tomcat.log combined\n  ErrorLog /var/log/httpd/tomcat.log\n  &lt;IfModule mod_jk.c&gt;\n     JkMount /* app1Worker\n     # so that certbot works:\n     JkUnMount /.well-known/*  app1Worker\n  &lt;/IfModule&gt;\n&lt;/VirtualHost&gt;\nRestart Tomcat and Apache Web Server:\n\nsudo service tomcat restart\nsudo service httpd restart\n\nIf you are using SElinux, you may see an error when restarting httpd. If so, execute the following commands:\n\nsudo ausearch -c 'httpd' --raw | audit2allow -M my-httpd\nsudo semodule -i my-httpd.pp\nsudo service httpd restart\n\n\nNow ordinary browser connections like http://example.com/labbcat should show the LaBB-CAT home page, and if you have HTTPS configured with an SSL certificat, encrypted connections like https://example.com/labbcat should work.",
    "crumbs": [
      "How-to",
      "Installation",
      "Red Hat Linux"
    ]
  },
  {
    "objectID": "howto/install/standalone-mac.html",
    "href": "howto/install/standalone-mac.html",
    "title": "Installing LaBB-CAT on Mac OS X systems",
    "section": "",
    "text": "Important\n\n\n\nLaBB-CAT can only be installed on newer M-series Macs.\nThese instructions will not work for older Intel-based Macs. Sorry!\n\n\nOn OS X, there are two prerequisites that must be installed before you can install LaBB-CAT:\n\nHomebrew\nJava\n\nYou may already have one or other of these installed; if so, you can skip the corresponding section below.\n\n\nHomebrew is a ‚Äòpackage manager‚Äô for Mac computers, which allows you to install other programes, including Java.\n\nOpen the following page in your web browser:\nhttps://github.com/Homebrew/brew/releases/latest\nScroll down to the Assets section.\n\nClick the file called Homebrew-n.n.n.pkg (where n.n.n is the version number) to download the file.\nOnce the file has been downloaded, double-click on it to run the installer.\n\nClick Continue, Continue, Agree and Install to complete the installation.\n\n\n\n\n\nOpen Launchpad and type Terminal.\nDouble click Terminal to open a command shell.\nType in the following command:\nbrew install openjdk\nPress the returnreturn key on your keyboard to enter the command.\nSome text will appear in the Terminal window while Homebrew downloads everything it needs to install Java\nOnce it‚Äôs finished, you‚Äôll see the % shell prompt again.\n\n\n\n\n\n\n\nFigure¬†1: brew install openjdk\n\n\n\n\n\n\nOnce Homebew and Java are installed, you can install LaBB-CAT:\n\nOpen the following page in your web browser:\nhttps://sourceforge.net/projects/labbcat/files/install/\nThis page has all versions of the LaBB-CAT installer, both for personal computer installations\nand also for web-server installations. The the files are listed most recent first.\nDownload the first file named install-labbcat_yyyymmdd.jar (where yyyymmdd are numbers).\nDouble-click on the file you just downloaded to open it.\nMost likely you will see a message that the files was ‚ÄúNot Opened‚Äù as show in Figure¬†2.\n\n\n\n\n\n\n\nFigure¬†2: install-labbcat‚Ä¶jar Not Opened\n\n\n\n\nGo to the Apple menu and select System Settings.\nSelect the section labelled Privacy and Security.\nScroll to the bottom and under the Security heading you will see a message saying that install-labbcat_yyyymmdd.jar ‚Äúwas blocked to protect your Mac.‚Äù as shown in Figure¬†3\n\n\n\n\n\n\n\nFigure¬†3: Privacy and Security: Open Anyway\n\n\n\n\nPress Open Anyway.\nYou will see another warning message as shown in Figure¬†4\n\n\n\n\n\n\n\nFigure¬†4: Open Anyway (again)\n\n\n\n\nPress Open Anyway.\nYou may see a request for Java to access your Downloads folder like in Figure¬†5.\n\n\n\n\n\n\n\nFigure¬†5: Allow Java access to Downloads\n\n\n\n\nIf so, press Allow.\n\nYou should see the LaBB-CAT installer program (Figure¬†6).\n\n\n\n\n\n\nFigure¬†6: LaBB-CAT Installer\n\n\n\n\nPress Start.\n\nYou should see a progress bar while components are installed and files are copied.\nOnce the installation is finished, the progress bar will be all blue, and there will be a button labelled Finished (Figure¬†7).\n\n\n\n\n\n\nFigure¬†7: Installer finished\n\n\n\n\nPress Finished.\n\nYour default web browser will open on your LaBB-CAT home page, as show in Figure¬†8.\n\n\n\n\n\n\nFigure¬†8: LaBB-CAT is successfully installed and running\n\n\n\n\nIf you a shown the LaBB-CAT Licence page, scroll to the bottom and press I Agree.\n\nAs seen in Figure¬†9, in your Applications folder, you will see that there is a LaBB-CAT entry that can be used to access LaBB-CAT from now on.\n\n\n\n\n\n\nFigure¬†9: Use Applications/LaBB-CAT to open LaBB-CAT\n\n\n\n\n\n\nIn future you may want to uninstall LaBB-CAT, in which case you can use the same installer you used to install it.\nIf you run install-labbcat_yyyymmdd.jar and LaBB-CAT is already installed, after pressing Start it will offer further options.\n\n\n\nRunning install-labbcat_yyyymmdd.jar when LaBB-CAT is already installed\n\n\nThe options are:\n\nUpgrade ‚Äì Install this version of LaBB-CAT, keeping all your corpus data intact.\nReplace ‚Äì Install LaBB-CAT afresh, deleting all your existing corpus data and leaving you with an empty LaBB-CAT installation.\nUninstall ‚Äì Remove LaBB-CAT from your personal computer.\nCancel ‚Äì Close the installer without taking any action.",
    "crumbs": [
      "How-to",
      "Installation",
      "Mac"
    ]
  },
  {
    "objectID": "howto/install/standalone-mac.html#uninstalling-labb-cat",
    "href": "howto/install/standalone-mac.html#uninstalling-labb-cat",
    "title": "Installing LaBB-CAT on Mac OS X systems",
    "section": "",
    "text": "In future you may want to uninstall LaBB-CAT, in which case you can use the same installer you used to install it.\nIf you run install-labbcat_yyyymmdd.jar and LaBB-CAT is already installed, after pressing Start it will offer further options.\n\n\n\nRunning install-labbcat_yyyymmdd.jar when LaBB-CAT is already installed\n\n\nThe options are:\n\nUpgrade ‚Äì Install this version of LaBB-CAT, keeping all your corpus data intact.\nReplace ‚Äì Install LaBB-CAT afresh, deleting all your existing corpus data and leaving you with an empty LaBB-CAT installation.\nUninstall ‚Äì Remove LaBB-CAT from your personal computer.\nCancel ‚Äì Close the installer without taking any action.",
    "crumbs": [
      "How-to",
      "Installation",
      "Mac"
    ]
  },
  {
    "objectID": "howto/install/index.html",
    "href": "howto/install/index.html",
    "title": "How to Install LaBB-CAT",
    "section": "",
    "text": "These pages include instructions on how to install LaBB-CAT on various operating systems:\n\nRed Hat Linux\nMac\nWindows\n\n\n\nWhen you are browsing a LaBB-CAT corpus (either installed on your own computer or on a server), the transcript page can integrate directly with Praat so that you can open utterance in Praat directly from your browser.\n\nInstalling Praat Browser Integration"
  },
  {
    "objectID": "howto/install/index.html#praat-browser-integration",
    "href": "howto/install/index.html#praat-browser-integration",
    "title": "How to Install LaBB-CAT",
    "section": "",
    "text": "When you are browsing a LaBB-CAT corpus (either installed on your own computer or on a server), the transcript page can integrate directly with Praat so that you can open utterance in Praat directly from your browser.\n\nInstalling Praat Browser Integration"
  },
  {
    "objectID": "howto/corpus-management/change-corpus.html",
    "href": "howto/corpus-management/change-corpus.html",
    "title": "Changing Corpus",
    "section": "",
    "text": "The ‚Äòcorpus‚Äô and the ‚Äòepisode‚Äô of a transcript belongs to is specified when it is uploaded; every transcript belongs to an ‚Äòepisode‚Äô (which groups together transcripts from the same recording session), and each episode belongs to a ‚Äòcorpus‚Äô\nWhat if you choose the wrong corpus, or change your mind about episode name later? You can use the episode organiser option on the menu to make such changes after uploading transcripts.\nThe organiser appears as a list of collapsable ‚Äòfolders‚Äô that represent existing corpora, containing episodes:\n\n\n\nTo move an episode from one corpus to another, simply drag the episode with your mouse and drop it on to the desired corpus (if you want a new corpus, you must add it first using the corpora option on the menu).\n\n\n\nTo rename an episode, right-click on the episode and select the Rename option.",
    "crumbs": [
      "How-to",
      "Corpus Management",
      "Changing Corpus"
    ]
  },
  {
    "objectID": "howto/corpus-management/change-corpus.html#changing-corpus-1",
    "href": "howto/corpus-management/change-corpus.html#changing-corpus-1",
    "title": "Changing Corpus",
    "section": "",
    "text": "To move an episode from one corpus to another, simply drag the episode with your mouse and drop it on to the desired corpus (if you want a new corpus, you must add it first using the corpora option on the menu).",
    "crumbs": [
      "How-to",
      "Corpus Management",
      "Changing Corpus"
    ]
  },
  {
    "objectID": "howto/corpus-management/change-corpus.html#renaming-an-episode",
    "href": "howto/corpus-management/change-corpus.html#renaming-an-episode",
    "title": "Changing Corpus",
    "section": "",
    "text": "To rename an episode, right-click on the episode and select the Rename option.",
    "crumbs": [
      "How-to",
      "Corpus Management",
      "Changing Corpus"
    ]
  },
  {
    "objectID": "howto/corpus-management/participant-deduplication.html",
    "href": "howto/corpus-management/participant-deduplication.html",
    "title": "Participant Deduplication",
    "section": "",
    "text": "Participant Deduplication\nDuring transcript upload, LaBB-CAT looks up the participants named in the transcript, and if it doesn‚Äôt find a matching participant record, it creates a new one.\nBut sometimes, names of participants are not totally identical across all of their transcripts, leading to multiple records for the same person.\nYou can merge participant records together to fix this problem:\n\nIn LaBB-CAT, select the participants option on the menu\nIn the box under Participant, type part of the participant name that will match all the records you want to merge, and hit EnterEnter:\n\nTick the records you want to merge together.\nPress Merge Participants. \nMerging cannot be undone, so double-check that the records are the correct ones, and untick any you don‚Äôt want to be merged together.\nChange the name to the final name/ID for the participant.\nIf there are participant attributes with conflicting values, the conflicts are also listed; choose the correct final value for each conflict.\nPress Merge\nYou will see a message:\n‚ÄúThis will merge all selected participants into a single new record. Existing attribute values will be assigned to the new participant. Transcripts for these participants will be assigned to the new participant. Automatic layer annotations will be lost and must be regenerated.\nThis can not be undone. Are you sure?‚Äù\nPress OK\nThe new record is created, and the number of corpora, transcripts, turns, and lines affected is shown\nIf you would like to double-check, or tweak, the new participant record, press the Edit ‚Ä¶ link.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Corpus Management",
      "Participant Deduplication"
    ]
  },
  {
    "objectID": "howto/pos-tagging/stanford-pos-tagger.html",
    "href": "howto/pos-tagging/stanford-pos-tagger.html",
    "title": "Stanford POS Tagger",
    "section": "",
    "text": "Depending on the language of your transcripts, you may be able to tag each word with its part of speech (Noun, Verb, Adjective, etc.) using the Stanford POS Tagger.\nThe Stanford POS Tagger has models for:\n\nArabic\nChinese\nEnglish\nFrench\nGerman\nSpanish\n\nThe steps for POS tagging your corpus are:\n\nInstall the Layer Manager\nConfigure a POS layer\n\n\n\n\nIn LaBB-CAT, select the layer managers option on the menu at the top.\nAt the bottom, follow the link labelled: List of layer managers that are not yet installed.\nFind the StanfordPosTagger layer manager in the list, and press its Install button, then Install again.\nYou will see a configuration page with some information about the tagger.\nPress Configure.\nYou will see a progress bar while the layer manager downloads the Stanford POS Tagger files.\n\nOnce it‚Äôs finished, you‚Äôll see a further information page.\n\n\n\nNow the layer manager is installed, we need to create a layer that is configured to use it to tag words with their part of speech‚Ä¶\n\nSelect word layers on the menu at the top.\nYou will see a list of word tag layers that have already been configured. The column headings at the top are also a form for creating a new layer, so we‚Äôll fill in that form now.\nFill in the following details on the form at the top:\n\nLayer ID: pos\nType: Text\nAlignment: Intervals\nNB it‚Äôs important that this is not set to None because a single word can have multiple POS tags, one after another, which are strung between the start and the end of the word token.\nManager: Stanford POS Tagger\nGenerate: Always\nProject: This can be left as the default value, unless you want to add the layer to a category of your choice.\n\nPress New\nYou will see the layer configuration form. Mostly you can leave the default values as they are.\nSet the Model to use setting to something that makes sense for your transcripts, which depends on their language. This is a setting you may experiment with to get the best results. For English recordings, you may find the english-bidirectional-distsim.tagger is slower but produces better results.\nPress Set Parameters.\nNow press Regenerate to run the POS tagger on your whole corpus.\nYou will see a progress bar while the transcripts are being tagged.\nOnce it‚Äôs complete, select the transcripts option on the menu, and click the first transcript in the list.\nTick the new pos layer to display the tags.\nYou will see that each word has one or more tags above it - these identify the parts of speech or syntactic categories of the words.\n\n\nThe tags can be searched, extracted, summarised, etc. just like any other annotations.\n\n\n\nOne possible aggregated analysis might be to compute the distributions of POS tags for each speaker.\nIn order to do that, you would set up the tagger as above to output the POS tags, and then set up a Frequency Layer Manager layer with the POS tags as input. In order to do that:\n\nIn LaBB-CAT, select the word layers menu option.\nAdd a new word layer with the following characteristics:\n\nLayer ID: posFrequency\nType: Number\nAlignment: None\nManager: Frequency Layer Manager\nGenerate: Always\n\nPress New.\nYou will see the Frequency Layer Manager configuration form.\nConfigure the layer as follows:\n\nSummary: Raw Count\nLayer to Summarize: pos (i.e.¬†the POS layer we created earlier)\nScope of Summary: Speaker\nThe rest of the settings can be left with their defaults, except:\nAnnotate Tokens: unticked - we only want the summary information.\n\nPress Save.\nPress Regenerate to analyse your corpus.\nYou‚Äôll see a progress bar while each POS label is counted for each participant.\nOnce the layer manager is finished, select layer managers on the menu.\nFind the Frequency Layer Manager in the list, and press its Extensions button.\nThis will show a page that lets you select from ‚Äòdictionaries‚Äô that are named after layers managed by the Frequency Layer Manager.\nSelect posFrequency and press Select\nA form is displayed that allows you to perform various operations on the frequency lists you have generated. Most likely, you just want to export a list of frequencies for a speaker:\nUnder Scope, select a speaker.\nOr if you want to include all speakers, select the [all scopes] option at the bottom of the dropdown box options.\nPress the Export button at the bottom.\nThis will give you a CSV file. If you open this in Excel (or any other data analysis tool), you‚Äôll see that it contains three columns:\n\nScope - the speaker name\nType - the POS label\nFrequency - the number of times that speaker uttered a word with that POS label\n\n\n\nIf you prefer to have POS counts by transcript instead of by speaker, you can select Transcript as the scope at step 4 above. If you want both of these, create two word layers, one for summarising by participant, and the other by transcript.",
    "crumbs": [
      "How-to",
      "Stanford POS Tagger"
    ]
  },
  {
    "objectID": "howto/pos-tagging/stanford-pos-tagger.html#install-the-layer-manager",
    "href": "howto/pos-tagging/stanford-pos-tagger.html#install-the-layer-manager",
    "title": "Stanford POS Tagger",
    "section": "",
    "text": "In LaBB-CAT, select the layer managers option on the menu at the top.\nAt the bottom, follow the link labelled: List of layer managers that are not yet installed.\nFind the StanfordPosTagger layer manager in the list, and press its Install button, then Install again.\nYou will see a configuration page with some information about the tagger.\nPress Configure.\nYou will see a progress bar while the layer manager downloads the Stanford POS Tagger files.\n\nOnce it‚Äôs finished, you‚Äôll see a further information page.",
    "crumbs": [
      "How-to",
      "Stanford POS Tagger"
    ]
  },
  {
    "objectID": "howto/pos-tagging/stanford-pos-tagger.html#create-a-pos-layer",
    "href": "howto/pos-tagging/stanford-pos-tagger.html#create-a-pos-layer",
    "title": "Stanford POS Tagger",
    "section": "",
    "text": "Now the layer manager is installed, we need to create a layer that is configured to use it to tag words with their part of speech‚Ä¶\n\nSelect word layers on the menu at the top.\nYou will see a list of word tag layers that have already been configured. The column headings at the top are also a form for creating a new layer, so we‚Äôll fill in that form now.\nFill in the following details on the form at the top:\n\nLayer ID: pos\nType: Text\nAlignment: Intervals\nNB it‚Äôs important that this is not set to None because a single word can have multiple POS tags, one after another, which are strung between the start and the end of the word token.\nManager: Stanford POS Tagger\nGenerate: Always\nProject: This can be left as the default value, unless you want to add the layer to a category of your choice.\n\nPress New\nYou will see the layer configuration form. Mostly you can leave the default values as they are.\nSet the Model to use setting to something that makes sense for your transcripts, which depends on their language. This is a setting you may experiment with to get the best results. For English recordings, you may find the english-bidirectional-distsim.tagger is slower but produces better results.\nPress Set Parameters.\nNow press Regenerate to run the POS tagger on your whole corpus.\nYou will see a progress bar while the transcripts are being tagged.\nOnce it‚Äôs complete, select the transcripts option on the menu, and click the first transcript in the list.\nTick the new pos layer to display the tags.\nYou will see that each word has one or more tags above it - these identify the parts of speech or syntactic categories of the words.\n\n\nThe tags can be searched, extracted, summarised, etc. just like any other annotations.",
    "crumbs": [
      "How-to",
      "Stanford POS Tagger"
    ]
  },
  {
    "objectID": "howto/pos-tagging/stanford-pos-tagger.html#summarising-pos-tags",
    "href": "howto/pos-tagging/stanford-pos-tagger.html#summarising-pos-tags",
    "title": "Stanford POS Tagger",
    "section": "",
    "text": "One possible aggregated analysis might be to compute the distributions of POS tags for each speaker.\nIn order to do that, you would set up the tagger as above to output the POS tags, and then set up a Frequency Layer Manager layer with the POS tags as input. In order to do that:\n\nIn LaBB-CAT, select the word layers menu option.\nAdd a new word layer with the following characteristics:\n\nLayer ID: posFrequency\nType: Number\nAlignment: None\nManager: Frequency Layer Manager\nGenerate: Always\n\nPress New.\nYou will see the Frequency Layer Manager configuration form.\nConfigure the layer as follows:\n\nSummary: Raw Count\nLayer to Summarize: pos (i.e.¬†the POS layer we created earlier)\nScope of Summary: Speaker\nThe rest of the settings can be left with their defaults, except:\nAnnotate Tokens: unticked - we only want the summary information.\n\nPress Save.\nPress Regenerate to analyse your corpus.\nYou‚Äôll see a progress bar while each POS label is counted for each participant.\nOnce the layer manager is finished, select layer managers on the menu.\nFind the Frequency Layer Manager in the list, and press its Extensions button.\nThis will show a page that lets you select from ‚Äòdictionaries‚Äô that are named after layers managed by the Frequency Layer Manager.\nSelect posFrequency and press Select\nA form is displayed that allows you to perform various operations on the frequency lists you have generated. Most likely, you just want to export a list of frequencies for a speaker:\nUnder Scope, select a speaker.\nOr if you want to include all speakers, select the [all scopes] option at the bottom of the dropdown box options.\nPress the Export button at the bottom.\nThis will give you a CSV file. If you open this in Excel (or any other data analysis tool), you‚Äôll see that it contains three columns:\n\nScope - the speaker name\nType - the POS label\nFrequency - the number of times that speaker uttered a word with that POS label\n\n\n\nIf you prefer to have POS counts by transcript instead of by speaker, you can select Transcript as the scope at step 4 above. If you want both of these, create two word layers, one for summarising by participant, and the other by transcript.",
    "crumbs": [
      "How-to",
      "Stanford POS Tagger"
    ]
  },
  {
    "objectID": "howto/aligned-data/articulation-rate.html",
    "href": "howto/aligned-data/articulation-rate.html",
    "title": "Speech Rate and Articulation Rate",
    "section": "",
    "text": "Speech rate is usually measured in syllables per minute or syllables per second. LaBB-CAT can calculate this if it has the following information:\n\nstart and end times of utterances, from which the each utterance duration can be calculated (usually, transcripts you upload to LaBB-CAT include this information), and\nthe number of syllables in each word token, which can be obtained either\n\nby using the CELEX layer manager to tag each with with its syllable count, or\nif the data has been force-aligned, using a lexicon with syllabification information, the syllables themselves can be reconstructed.\n\n\nIf the speech has not been force-aligned, LaBB-CAT only knows, for each utterance, how many syllables were uttered between the start and end times of the utterance; any inter-word pauses during the utterance are counted as speech. Usually, this level of granularity is referred to as the Speech Rate.\nIf the speech has been force-aligned, LaBB-CAT can use the start and end times of the individual word tokens, and so can exclude inter-word pauses from its rate calculation. This higher level of granularity is usually referred to as the Articulation Rate.\nThe rate annotations can cover a number of different scopes with different granularities, e.g.\n\nthe local rate for each utterance,\nthe local rate for each speaker turn (which may include many utterances),\nthe global rate for the entire recording, or\nthe global rate for the speaker, across all the recordings they appear in.\n\nOnce the rate annotations are generated, they can be searched or extracted, in the same way other annotations can.\n\n\n\nCreate a word layer that tags each token with the number of syllables in the word. For example, if you‚Äôve got English data, and have the CELEX Layer Manager installed, you can achieve this by creating a new word layer with the following characteristics:\n\nLayer ID: syllableCount\nType: Number\nAlignment: None\nManager: CELEX English\n‚Ä¶configured with the Syllable count option ticked\nIMPORTANT: Ensure tick the First match only option for this layer, as some words have more than one possible syllable count, and we don‚Äôt want any words counted more than once.\n. If you do not use the CELEX Layer Manager, you may find the layer manager you use for phonemic transcriptions also has a similar syllable count option.\n\nOnce the layer has finished generating, have a look at a transcript or two to check the results. Each word should be tagged with a number corresponding to the number of syllables:\n\nClick the phrase layers menu option.\nAdd a new phrase layer for speech rate. Key points are:\n\nThe layer manager to use is the Statistics Layer Manager\nThe layer to summarize should be the syllableCount layer\nThe statistic to compute is Label-Sum Rate (per minute), because we want LaBB-CAT to take the sum of all the labels, and then compute the rate from the start/end time.\n\nYou can select difference scopes for the computation. The illustration above computes a local rate for each speaker turn, and a global rate for each participant.\n\nHave a look in a transcript or two, and a participant or two, to see what the annotations you just generated look like.\n\n\n\n\nIf forced alignment has already be done, the steps to compute speech rate are:\n\nCreate a word layer that reconstructs the syllables, using these steps.\nOnce the layer has finished generating, have a look at a transcript or two to check the results. Each word should be tagged with a phonemic transcription, separated into syllables:\n\nSelect the phrase layers menu option.\nAdd a new phrase layer for speech rate. Key points are:\n\nThe layer manager to use is the Statistics Layer Manager\nThe layer to summarize should be the syllable layer\nThe statistic to compute is Token Rate (per minute), because we want LaBB-CAT to take the count the number of syllables, and then compute the rate from the start/end time of each word.\n. You can select difference scopes for the computation. The illustration above computes a local rate for each utterance, and a global rate for each participant.\n\nHave a look in a transcript or two, and a participant or two, to see what the annotations you just generated look like.",
    "crumbs": [
      "How-to",
      "Aligned Data",
      "Speech Rate and Articulation Rate"
    ]
  },
  {
    "objectID": "howto/aligned-data/articulation-rate.html#computing-speecharticulation-rate",
    "href": "howto/aligned-data/articulation-rate.html#computing-speecharticulation-rate",
    "title": "Speech Rate and Articulation Rate",
    "section": "",
    "text": "Create a word layer that tags each token with the number of syllables in the word. For example, if you‚Äôve got English data, and have the CELEX Layer Manager installed, you can achieve this by creating a new word layer with the following characteristics:\n\nLayer ID: syllableCount\nType: Number\nAlignment: None\nManager: CELEX English\n‚Ä¶configured with the Syllable count option ticked\nIMPORTANT: Ensure tick the First match only option for this layer, as some words have more than one possible syllable count, and we don‚Äôt want any words counted more than once.\n. If you do not use the CELEX Layer Manager, you may find the layer manager you use for phonemic transcriptions also has a similar syllable count option.\n\nOnce the layer has finished generating, have a look at a transcript or two to check the results. Each word should be tagged with a number corresponding to the number of syllables:\n\nClick the phrase layers menu option.\nAdd a new phrase layer for speech rate. Key points are:\n\nThe layer manager to use is the Statistics Layer Manager\nThe layer to summarize should be the syllableCount layer\nThe statistic to compute is Label-Sum Rate (per minute), because we want LaBB-CAT to take the sum of all the labels, and then compute the rate from the start/end time.\n\nYou can select difference scopes for the computation. The illustration above computes a local rate for each speaker turn, and a global rate for each participant.\n\nHave a look in a transcript or two, and a participant or two, to see what the annotations you just generated look like.",
    "crumbs": [
      "How-to",
      "Aligned Data",
      "Speech Rate and Articulation Rate"
    ]
  },
  {
    "objectID": "howto/aligned-data/articulation-rate.html#aligned-words",
    "href": "howto/aligned-data/articulation-rate.html#aligned-words",
    "title": "Speech Rate and Articulation Rate",
    "section": "",
    "text": "If forced alignment has already be done, the steps to compute speech rate are:\n\nCreate a word layer that reconstructs the syllables, using these steps.\nOnce the layer has finished generating, have a look at a transcript or two to check the results. Each word should be tagged with a phonemic transcription, separated into syllables:\n\nSelect the phrase layers menu option.\nAdd a new phrase layer for speech rate. Key points are:\n\nThe layer manager to use is the Statistics Layer Manager\nThe layer to summarize should be the syllable layer\nThe statistic to compute is Token Rate (per minute), because we want LaBB-CAT to take the count the number of syllables, and then compute the rate from the start/end time of each word.\n. You can select difference scopes for the computation. The illustration above computes a local rate for each utterance, and a global rate for each participant.\n\nHave a look in a transcript or two, and a participant or two, to see what the annotations you just generated look like.",
    "crumbs": [
      "How-to",
      "Aligned Data",
      "Speech Rate and Articulation Rate"
    ]
  },
  {
    "objectID": "howto/aligned-data/syllables.html",
    "href": "howto/aligned-data/syllables.html",
    "title": "Syllables and Stress",
    "section": "",
    "text": "This page describes how to generate stress-marked syllable annotations after forced alignment, which can be achieved if your original poronunciation dictionary includes syllable/stress marking (e.g.¬†CELEX and Unisyn do, but the CMU Pronouncing Dictionary doesn‚Äôt).\nWhat LaBB-CAT does is:\n\nTake the phonemic transcription of each word from the segment layer (e.g.¬†the one chosen by HTK during forced alignment), which has no syllable or stress marks.\nLook it up in CELEX.\nIf it‚Äôs found, it takes the syllable/stress-marked version of the phonemic transcription\nIt splits the transcription into syllables, and creates an annotation for each syllable that spans the corresponding phones on the segment layer.\n\nOnce you have such annotations, it‚Äôs much easier to identify, for example, specific vowels but in stressed syllables only.\n\n\n\nA layer that tags each word token with its phonemic transcription according to CELEX or a Unisyn lexicon.\nForce-alignment using the above phonemic transcription layer, so you have a segments layer filled in with aligned phones.\n\nNB: If phone alignments are produced by a different dictionary, then the resulting phonemic transcriptions will not match the dictionary and so syllables cannot be reconstructed. e.g.¬†if you use the MFA built-in English dictionary, with MFA‚Äôs pretrained acoustic models, reconstructing syllables from CELEX transcriptions will fail. \n\n\n\n\nIn LaBB-CAT, click the word layers menu option\nAt the top of the list of word layers, fill in the blank header form in order to add a new layer. Important points are:\n\nType = Phonological\nAlignment = Intervals\nManager = CELEX English\n\n\nPress New. You will bee taken to the layer configuration page.\nOn the left, select the Syllables from Phonology option.\nThis will automatically set Source Layer to segments and Delimiters to - (hyphen)\n\nPress Save\nPres Regenerate\nYou will see a progress bar as LaBB-CAT processes all the transcripts in the database. This processing is done in the background, you don‚Äôt need to wait until it‚Äôs finished before visiting other pages.\n\nOnce the layer annotations are generated, each word that has been previously force-aligned will now have one or more syllable annotations, marking out the phones that belong to each syllable.\nThe label of each syllable annotation is the stress-marked phonemic transcription of the syllable, so for syllables with primary stress, the first character in the label is ‚Äô (an apostrophe), and those with secondary stress have ‚Äù (double-quote) as the first character.\n\n\n\nStress-marked syllables as seen in Praat\n\n\nNow, if you want to, for example, identify all kit vowels in syllables with primary stress only, you can do a search:\n\nfor segments labelled as the kit vowel\nwhose syllable starts with the primary stress mark '\n\n\n\n\nSearch matrix for KIT segments whose syllable starts with the primary stress marker",
    "crumbs": [
      "How-to",
      "Aligned Data",
      "Syllables and Stress"
    ]
  },
  {
    "objectID": "howto/aligned-data/syllables.html#prerequisites",
    "href": "howto/aligned-data/syllables.html#prerequisites",
    "title": "Syllables and Stress",
    "section": "",
    "text": "A layer that tags each word token with its phonemic transcription according to CELEX or a Unisyn lexicon.\nForce-alignment using the above phonemic transcription layer, so you have a segments layer filled in with aligned phones.\n\nNB: If phone alignments are produced by a different dictionary, then the resulting phonemic transcriptions will not match the dictionary and so syllables cannot be reconstructed. e.g.¬†if you use the MFA built-in English dictionary, with MFA‚Äôs pretrained acoustic models, reconstructing syllables from CELEX transcriptions will fail.",
    "crumbs": [
      "How-to",
      "Aligned Data",
      "Syllables and Stress"
    ]
  },
  {
    "objectID": "howto/aligned-data/syllables.html#steps",
    "href": "howto/aligned-data/syllables.html#steps",
    "title": "Syllables and Stress",
    "section": "",
    "text": "In LaBB-CAT, click the word layers menu option\nAt the top of the list of word layers, fill in the blank header form in order to add a new layer. Important points are:\n\nType = Phonological\nAlignment = Intervals\nManager = CELEX English\n\n\nPress New. You will bee taken to the layer configuration page.\nOn the left, select the Syllables from Phonology option.\nThis will automatically set Source Layer to segments and Delimiters to - (hyphen)\n\nPress Save\nPres Regenerate\nYou will see a progress bar as LaBB-CAT processes all the transcripts in the database. This processing is done in the background, you don‚Äôt need to wait until it‚Äôs finished before visiting other pages.\n\nOnce the layer annotations are generated, each word that has been previously force-aligned will now have one or more syllable annotations, marking out the phones that belong to each syllable.\nThe label of each syllable annotation is the stress-marked phonemic transcription of the syllable, so for syllables with primary stress, the first character in the label is ‚Äô (an apostrophe), and those with secondary stress have ‚Äù (double-quote) as the first character.\n\n\n\nStress-marked syllables as seen in Praat\n\n\nNow, if you want to, for example, identify all kit vowels in syllables with primary stress only, you can do a search:\n\nfor segments labelled as the kit vowel\nwhose syllable starts with the primary stress mark '\n\n\n\n\nSearch matrix for KIT segments whose syllable starts with the primary stress marker",
    "crumbs": [
      "How-to",
      "Aligned Data",
      "Syllables and Stress"
    ]
  },
  {
    "objectID": "howto/transcription/tei.html",
    "href": "howto/transcription/tei.html",
    "title": "TEI Texts",
    "section": "",
    "text": "TEI Texts\n\nThe Text Encoding Initiative (TEI - http://www.tei-c.org) is a consortium that develops guidelines for representation of texts in digital form, mainly for libraries, humanities research, social sciences, and linguistics. They have developed an XML format, which you can use to produce texts that can be uploaded into LaBB-CAT. At present, only texts that are not synchronised with audio or video are supported. However, the TEI P5 guidelines do specify methods for linking text to media, and support for this will be added to LaBB-CAT in the future.\n\nTags in the text\nThe P5 guidelines for TEI specify a dazzling array of tags for capturing all kinds of information about texts, only a subset of which will work well with LaBB-CAT. There is explicit support for the following TEI tags:\n\n&lt;p&gt;, &lt;div&gt;, and &lt;ab&gt; are interpreted as starting a new line\n&lt;w&gt; tags (for marking up words) are used for word tokenization if they are present (if they are absent, LaBB-CAT‚Äôs standard whitespace-based tokenization is used). Attributes of the &lt;w&gt; tag like lemma or type can be mapped to word layers for capturing such tagging in the text.\nthe &lt;choice&gt;&lt;orig&gt;‚Ä¶&lt;/orig&gt;&lt;reg&gt;‚Ä¶&lt;/reg&gt;&lt;/choice&gt; construction for marking regularization of text is recognized, and the contents of the &lt;reg&gt;‚Ä¶&lt;/reg&gt; tag can be extracted to the lexical layer (for single-word regularization) or a selected ‚Äòphrase‚Äô layer (if multi-word regularization is used).\n&lt;foreign&gt; is recognised as marking sections of the transcript as being in another language, and so its contents are annotated on the language layer, using value of the the xml:lang attribute as the annotation label.\n&lt;note&gt; is recognised as a commentary marker, and so its contents are put on to the comment layer instead of being inserted into the transcript text.\n&lt;unclear&gt; tags can create annotations on a selected layer, and the reason and cert attributes recognised and used in the resulting annotation label if present.\n\nOther tags are by default mapped on to the entities LaBB-CAT layer (in which case their tag name, and its type attribute if present, will be used for the entity label).\nAlternatively, if there is a LaBB-CAT layer that is named after the TEI tag name, then tags will be mapped to that layer by default during upload. For example, to have all &lt;sic&gt; tags extracted to their own layer (instead of the entities layer) by default, create a new ‚Äòphrase‚Äô layer called sic.\n\n\nThe TEI header and Meta-data\nLaBB-CAT recognises and imports certain constructions in the &lt;teiHeader&gt; section of a TEI file:\n\nin the &lt;fileDesc&gt; subsection:\n\nthe text in &lt;titleStmt&gt;&lt;title&gt;‚Ä¶ is taken to be the value of the title transcript attribute\nthe text in &lt;titleStmt&gt;&lt;respStmt&gt;&lt;name&gt;‚Ä¶ is taken to be the value of the scribe transcript attribute (i.e.¬†the name of the transcriber)\nthe text in &lt;publicationStmt&gt;&lt;distributor&gt;‚Ä¶ is taken to be the value of the distributor transcript attribute\nthe text in &lt;publicationStmt&gt;&lt;publisher&gt;‚Ä¶ is taken to be the value of the publisher transcript attribute\nthe text in &lt;publicationStmt&gt;&lt;availability&gt;&lt;p&gt;‚Ä¶ is taken to be the value of the availability transcript attribute\nthe text in &lt;publicationStmt&gt;&lt;date&gt;‚Ä¶ is taken to be the value of the airDate transcript attribute\nthe text in &lt;publicationStmt&gt;&lt;distributor&gt;‚Ä¶ is taken to be the value of the distributor transcript attribute\nthe text in &lt;sourceDesc&gt;&lt;bibleStruct&gt;&lt;monogr&gt;&lt;author&gt;‚Ä¶ is taken to be the name of the author of the text (who is created as the sole ‚Äòparticipant‚Äô of the transcript)\n\nin the &lt;profileDesc&gt; subsection:\n\nthe text in &lt;creation&gt;&lt;date&gt;‚Ä¶ is taken to be the value of the creationDate transcript attribute\nthe value of the &lt;langUsage&gt;&lt;language ident=\"‚Ä¶\"&gt; attribute is taken to be the value of the creationDate transcript attribute\nthe &lt;particDesc&gt;&lt;person&gt; tags are taken to be participants, whose &lt;idno&gt; tag specifies the participant‚Äôs identifier, and whose other tags specify the participant‚Äôs attributes named after the tag name (or optionally are added as transcript attributes). The content of the &lt;person&gt; tag‚Äôs &lt;age&gt; tag is converted to a single number (in years) if the text is formatted as y;m.d or as y years m months d days\n\nin the &lt;revisionDesc&gt; subsection:\n\nthe text in &lt;change&gt;&lt;date&gt;‚Ä¶ is taken to be the value of the versionDate transcript attribute\nthe text in &lt;change&gt;&lt;respStmt&gt;&lt;name&gt;‚Ä¶ is taken to be the value of the scribe transcript attribute\n\n\nArbitrary transcript/document attributes are implemented by including a &lt;notesStmt&gt; within the &lt;fileDesc&gt; header, containing one &lt;note&gt; tag per attribute, and using the type attribute as the attribute key and the tag content as the value - e.g.\n&lt;notesStmt&gt;\n &lt;note type=\"subreddit\"&gt;StrangerThings&lt;/note&gt;\n &lt;note type=\"parent_id\"&gt;t1_dd5f8en&lt;/note&gt;\n&lt;/notesStmt&gt;\nParticipant/speaker attributes can be included in the &lt;person&gt; tag, as per the TEI specification.\nArbitrary participant/speaker attributes (i.e.¬†custom attributes or others not foreseen by the TEI specification) can be processed by including one &lt;note&gt; tag per attribute within each participant‚Äôs &lt;person&gt; tag, and using the type attribute as the attribute key and the tag content as the value - e.g.\n&lt;person&gt;\n &lt;idno&gt;ABCD&lt;/idno&gt;\n &lt;age&gt;46&lt;/age&gt;\n &lt;education&gt;Secondary&lt;/education&gt;\n &lt;note type=\"first language\"&gt;English&lt;/note&gt;\n &lt;note type=\"origin\"&gt;Liverpool&lt;/note&gt;\n&lt;/person&gt;\nSpecial support for regularization is used; for a construction like this:\n&lt;choice&gt;&lt;orig&gt;color&lt;/orig&gt;&lt;reg&gt;colour&lt;/reg&gt;&lt;/choice&gt;\nThis deserializer supports part of the schema for Representation of Computer-mediated Communication proposed by Michael Bei√üwenger, Maria Ermakova, Alexander Geyken, Lothar Lemnitzer, and Angelika Storrer (2012), with the exception of the following:\n\nWhen &lt;posting&gt; tags are sychronised to a &lt;when&gt; tag inside a &lt;timeline&gt;, the time synchronisation is ignored.\nThe &lt;addressingTerm&gt;, &lt;addressMarker&gt; and &lt;addressee&gt; tags supported, and mapped to ‚Äúentities‚Äù layer by default, but the who attribute of &lt;addressee&gt; is ignored.\nThe type attribute of the &lt;div&gt; tag is ignored.\nThe revisedWhen, revisedBy, and indentLevel attributes of the &lt;posting&gt; tag are ignored\nThe &lt;interactionTerm&gt; tag is ignored.\nThe &lt;interactionTemplate&gt;, &lt;interactionWord&gt;, and &lt;emoticon&gt; tags are not explicitly supported.\nThe &lt;autoSignature&gt; and &lt;signatureContent&gt; tags are not explicitly supported.\n\n\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Transcription",
      "TEI Texts"
    ]
  },
  {
    "objectID": "howto/transcription/elan-language.html",
    "href": "howto/transcription/elan-language.html",
    "title": "Specifying Language in ELAN transcripts",
    "section": "",
    "text": "For multilingual corpora, it‚Äôs important that each transcript specifies the language of the speech that has been transcribed.\nIn ELAN, each tier can have a language specified by setting the Content Language attributed of the tier. This is set using a dropdown box, which unfortunately is often populated with a single item: English (eng).\nIf the speech is in a language other than English, you will first have to add the desired language to the list of options.\n\n\n\nClick the Edit menu and select the Edit List of Languages‚Ä¶ option.\n\nClick the lower dropdown box (directly above the buttons) and select the language you want.\n\nClick Add.\nThe selected language should appear in the upper dropdown box.\n\nClick Close\n\n\n\n\nYour transcript tiers now need to have this language selected.\n\nIn the transcript, right-click the name of a transcript tier on the left and select the Change Attributes Of‚Ä¶ option.\n\nChange the Content Language option by selecting the language from the dropdown list.\n\nClick Change.\nThe tier attributes window will close.\nRepeat the previous three steps for each transcript tier.\n\n\n\n\nSometime the speaker may include words or phrases in a different language from the rest of the transcript. It may be important to tag these words with the language they‚Äôre in (e.g.¬†to ensure that after upload to LaBB-CAT, the pronunciation is correctly inferred).\nLaBB-CAT recognises a transcription convention for tagging ‚Äòcode-switches‚Äô (CS) into another language. Immediately following the word (i.e.¬†with no intevening space) in square brackes the code ‚ÄúCS:‚Äù is added with the ISO 639 3-letter code for the language. e.g.\n\n‚Ä¶me mud√© de Christchurch[CS:eng] en 2004‚Ä¶\n\nFor longer phrases, the code-switch tag can be placed immediately before the first word and immediately after the last word (again with no intervening space between the word and the tag), to mark those and all intervening words as being in a different language. e.g.\n\n‚Ä¶it has a certain [CS:fre]je ne sais quoi[CS:fre] I think‚Ä¶",
    "crumbs": [
      "How-to",
      "Transcription",
      "Specifying Language in ELAN transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/elan-language.html#adding-a-new-language-option",
    "href": "howto/transcription/elan-language.html#adding-a-new-language-option",
    "title": "Specifying Language in ELAN transcripts",
    "section": "",
    "text": "Click the Edit menu and select the Edit List of Languages‚Ä¶ option.\n\nClick the lower dropdown box (directly above the buttons) and select the language you want.\n\nClick Add.\nThe selected language should appear in the upper dropdown box.\n\nClick Close",
    "crumbs": [
      "How-to",
      "Transcription",
      "Specifying Language in ELAN transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/elan-language.html#defining-the-language-for-the-transcript",
    "href": "howto/transcription/elan-language.html#defining-the-language-for-the-transcript",
    "title": "Specifying Language in ELAN transcripts",
    "section": "",
    "text": "Your transcript tiers now need to have this language selected.\n\nIn the transcript, right-click the name of a transcript tier on the left and select the Change Attributes Of‚Ä¶ option.\n\nChange the Content Language option by selecting the language from the dropdown list.\n\nClick Change.\nThe tier attributes window will close.\nRepeat the previous three steps for each transcript tier.",
    "crumbs": [
      "How-to",
      "Transcription",
      "Specifying Language in ELAN transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/elan-language.html#speech-in-a-different-language",
    "href": "howto/transcription/elan-language.html#speech-in-a-different-language",
    "title": "Specifying Language in ELAN transcripts",
    "section": "",
    "text": "Sometime the speaker may include words or phrases in a different language from the rest of the transcript. It may be important to tag these words with the language they‚Äôre in (e.g.¬†to ensure that after upload to LaBB-CAT, the pronunciation is correctly inferred).\nLaBB-CAT recognises a transcription convention for tagging ‚Äòcode-switches‚Äô (CS) into another language. Immediately following the word (i.e.¬†with no intevening space) in square brackes the code ‚ÄúCS:‚Äù is added with the ISO 639 3-letter code for the language. e.g.\n\n‚Ä¶me mud√© de Christchurch[CS:eng] en 2004‚Ä¶\n\nFor longer phrases, the code-switch tag can be placed immediately before the first word and immediately after the last word (again with no intervening space between the word and the tag), to mark those and all intervening words as being in a different language. e.g.\n\n‚Ä¶it has a certain [CS:fre]je ne sais quoi[CS:fre] I think‚Ä¶",
    "crumbs": [
      "How-to",
      "Transcription",
      "Specifying Language in ELAN transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/elan.html",
    "href": "howto/transcription/elan.html",
    "title": "Transcribing with ELAN",
    "section": "",
    "text": "ELAN (EUDICO Linguistic Annotator - http://www.lat-mpi.eu/tools/elan/) is a tier-based media annotation tool developed by the Max Planck Institute for Psycholinguistics, which can be used both for orthographic transcription, and also extensive annotation on different tiers. It can be used to annotate multiple video files, and/or an audio file.\nLaBB-CAT supports using ELAN files for uploading, as long as the ELAN file contains one tier per speaker that includes orthographic transcription of their speech, like this:\n\n\n\nELAN file with orthographic transcription, one tier per speaker\n\n\nLaBB-CAT needs a mechanism for uniquely identifying the speaker of each utterance. In ELAN, the best way to achieve that is to ensure that the Participant attribute of each tier is set with the name (or ID) of the speaker:\n\n\n\nThe Participant tier attribute is set as the speaker ID\n\n\nIf the transcript is part of multilingual corpus, you should also set the Content Language attribute of each tier. For more information, see Specifying Language in ELAN transcripts.\n\n\nTo upload ELAN files, click the upload menu option, and then the upload transcripts option.\nPress Choose File on the left and select the transcript .eaf file. On the right the text ‚ÄúELAN EAF Transcript‚Äù should appear. Press the Choose File to the right of this to select the media file(s) that correspond to the transcript. Press Upload.\nNext you will be asked to specify which ELAN tiers (listed on the left) correspond to which LaBB-CAT layers (listed on the right). Tiers that contain orthographic transcript text (as illustrated above) should be mapped to LaBB-CAT‚Äôs ‚Äúutterance‚Äù layer. You may also have other annotations in the transcript (e.g.¬†a tier for noise annotations). These can be mapped to LaBB-CAT layers if a corresponding layer has already been set up in LaBB-CAT. Generally speaking, for these you‚Äôll want to create a ‚Äúspan‚Äù layer for time intervals, and it‚Äôs best to create a LaBB-CAT layer with the ‚Äúname‚Äù set to the same name as the tier, so that it‚Äôs selected by default. LaBB-CAT already has a ‚Äúnoise‚Äù layer and a ‚Äúcomment‚Äù layer, so these don‚Äôt need to be set up in advance.\n\n\n\nELAN tiers listed on the left are mapped to LaBB-CAT layers on the right\n\n\nIn the illustration, the ‚ÄúInterverwee‚Äù and ‚ÄúInterviewer‚Äù ELAN tiers are mapped to the ‚Äúutterances‚Äù LaBB-CAT phrase layer, and the ‚ÄúNoise‚Äù ELAN tier is mapped to the ‚Äúnoise‚Äù LaBB-CAT span layer.\nWhen you click Set Mappings, the transcript will be imported into LaBB-CAT using the specified tier/layer correspondences.\n\n\n\nELAN has no direct mechanism for marking non-speech annotations in their position within the transcript text. However, LaBB-CAT supports the use of textual conventions in various ways to make certain annotations:\n\nTo tag a word with its pronunciation, enter the pronunciation (with no spaces) in square brackets, directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶this was at Wingatui[wIN@tui]‚Ä¶\nTo tag a word with its full orthography (if the transcript doesn‚Äôt include it), enter the orthography (with no spaces) in round parentheses, directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶I can't remem~(remember)‚Ä¶\nTo tag a word as being in a different language, enter the code CS: (for ‚Äòcode switch‚Äô) followed by the the ISO 639 3-letter code for the language, in square brackets (with no spaces), directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶me mud√© de New[CS:eng] Zealand[CS:eng] en dos mil cu√°tro‚Ä¶\nFor longer phrases, the code-switch tag can be placed immediately before the first word and immediately after the last word (again with no intervening space between the word and the tag), to mark those and all intervening words as being in a different language. e.g.:\n‚Ä¶has a certain [CS:fre]je ne sais quoi[CS:fre] I think‚Ä¶\nTo insert a noise annotation within the text, enclose it in square brackets (surrounded by spaces so it‚Äôs not taken as a pronunciation annotation), e.g.:\n‚Ä¶sometimes me [laughs] not always but sometimes‚Ä¶\nTo insert a comment annotation within the text, enclose it in curly braces (surrounded by spaces), e.g.:\n‚Ä¶beautifully warm {softly} but its‚Ä¶\n\nDuring upload, these annotations will be extracted from the transcript text and inserted into corresponding LaBB-CAT layers.",
    "crumbs": [
      "How-to",
      "Transcription",
      "Transcribing with ELAN"
    ]
  },
  {
    "objectID": "howto/transcription/elan.html#uploading-elan-files",
    "href": "howto/transcription/elan.html#uploading-elan-files",
    "title": "Transcribing with ELAN",
    "section": "",
    "text": "To upload ELAN files, click the upload menu option, and then the upload transcripts option.\nPress Choose File on the left and select the transcript .eaf file. On the right the text ‚ÄúELAN EAF Transcript‚Äù should appear. Press the Choose File to the right of this to select the media file(s) that correspond to the transcript. Press Upload.\nNext you will be asked to specify which ELAN tiers (listed on the left) correspond to which LaBB-CAT layers (listed on the right). Tiers that contain orthographic transcript text (as illustrated above) should be mapped to LaBB-CAT‚Äôs ‚Äúutterance‚Äù layer. You may also have other annotations in the transcript (e.g.¬†a tier for noise annotations). These can be mapped to LaBB-CAT layers if a corresponding layer has already been set up in LaBB-CAT. Generally speaking, for these you‚Äôll want to create a ‚Äúspan‚Äù layer for time intervals, and it‚Äôs best to create a LaBB-CAT layer with the ‚Äúname‚Äù set to the same name as the tier, so that it‚Äôs selected by default. LaBB-CAT already has a ‚Äúnoise‚Äù layer and a ‚Äúcomment‚Äù layer, so these don‚Äôt need to be set up in advance.\n\n\n\nELAN tiers listed on the left are mapped to LaBB-CAT layers on the right\n\n\nIn the illustration, the ‚ÄúInterverwee‚Äù and ‚ÄúInterviewer‚Äù ELAN tiers are mapped to the ‚Äúutterances‚Äù LaBB-CAT phrase layer, and the ‚ÄúNoise‚Äù ELAN tier is mapped to the ‚Äúnoise‚Äù LaBB-CAT span layer.\nWhen you click Set Mappings, the transcript will be imported into LaBB-CAT using the specified tier/layer correspondences.",
    "crumbs": [
      "How-to",
      "Transcription",
      "Transcribing with ELAN"
    ]
  },
  {
    "objectID": "howto/transcription/elan.html#conventions-for-non-speech-annotations-within-the-transcript",
    "href": "howto/transcription/elan.html#conventions-for-non-speech-annotations-within-the-transcript",
    "title": "Transcribing with ELAN",
    "section": "",
    "text": "ELAN has no direct mechanism for marking non-speech annotations in their position within the transcript text. However, LaBB-CAT supports the use of textual conventions in various ways to make certain annotations:\n\nTo tag a word with its pronunciation, enter the pronunciation (with no spaces) in square brackets, directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶this was at Wingatui[wIN@tui]‚Ä¶\nTo tag a word with its full orthography (if the transcript doesn‚Äôt include it), enter the orthography (with no spaces) in round parentheses, directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶I can't remem~(remember)‚Ä¶\nTo tag a word as being in a different language, enter the code CS: (for ‚Äòcode switch‚Äô) followed by the the ISO 639 3-letter code for the language, in square brackets (with no spaces), directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶me mud√© de New[CS:eng] Zealand[CS:eng] en dos mil cu√°tro‚Ä¶\nFor longer phrases, the code-switch tag can be placed immediately before the first word and immediately after the last word (again with no intervening space between the word and the tag), to mark those and all intervening words as being in a different language. e.g.:\n‚Ä¶has a certain [CS:fre]je ne sais quoi[CS:fre] I think‚Ä¶\nTo insert a noise annotation within the text, enclose it in square brackets (surrounded by spaces so it‚Äôs not taken as a pronunciation annotation), e.g.:\n‚Ä¶sometimes me [laughs] not always but sometimes‚Ä¶\nTo insert a comment annotation within the text, enclose it in curly braces (surrounded by spaces), e.g.:\n‚Ä¶beautifully warm {softly} but its‚Ä¶\n\nDuring upload, these annotations will be extracted from the transcript text and inserted into corresponding LaBB-CAT layers.",
    "crumbs": [
      "How-to",
      "Transcription",
      "Transcribing with ELAN"
    ]
  },
  {
    "objectID": "howto/workflow/index.html",
    "href": "howto/workflow/index.html",
    "title": "Workflows",
    "section": "",
    "text": "Workflows\nThese are workflows for commonly repeated tasks.\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "LaBB-CAT Documentation\nThis is the documentation for the LaBB-CAT corpus management system.\nLaBB-CAT is a browser-based linguistics research tool that stores audio or video recordings, text transcripts, and other annotations.\nAnnotations of various types can be automatically generated or manually added.\nThe transcripts and annotations can be searched for particular text or regular expressions. The search results, or entire transcripts, can be viewed or saved in a variety of formats, and the related parts of the recordings can be played or opened in acoustic analysis software, all directly through the web-browser.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "LaBB-CAT Documentation"
    ]
  },
  {
    "objectID": "howto/cite.html",
    "href": "howto/cite.html",
    "title": "How-to cite LaBB-CAT",
    "section": "",
    "text": "To cite LaBB-CAT, you may use:\nFromont, Robert & Jennifer Hay (2012) LaBB-CAT: an Annotation Store, Proceedings of Australasian Language Technology Association Workshop, pp.¬†113-117, Australasian Language Technology Association, Dunedin.\n@InProceedings{FromontHay2012,\n  author = {Robert Fromont and Jennifer Hay},\n  title = {{LaBB-CAT: an Annotation Store}},\n  booktitle = {{Proceedings of Australasian Language Technology Association Workshop}},\n  year = {2012},\n  pages = {113--117},\n  month = {November},\n  organization = {Australasian Language Technology Association},\n}\nOr to cite specific versions, see below.\n\n\nRobert Fromont, Lynn Clark, Joshua Wilson Black, & Margaret Blackwood (2023) Maximizing accuracy of forced alignment for spontaneous child speech, Language Development Research, Volume 3, Issue 1, 2023, DOI: 10.34842/SHRR-SV10\n@article{FromontEtAl2023,\n    author = {Robert Fromont and Lynn Clark and Joshua Wilson Black and Margaret Blackwood},\n    title = {Maximizing accuracy of forced alignment for spontaneous child speech},\n    volume = {3},\n    year = {2023},\n    url = {http://ldr.lps.library.cmu.edu/article/id/672/},\n    issue = {1},\n    doi = {10.34842/shrr-sv10},\n    month = {9},\n    pages = {182-210},\n    issn = {2771-7976},\n    publisher ={Carnegie Mellon University Library Publishing Service},\n    journal = {Language Development Research}\n}\nKsenia Gnevsheva, Simon Gonzalez & Robert Fromont (2020), Australian English Bilingual Corpus: Automatic forced-alignment accuracy in Russian and English, Australian Journal of Linguistics, DOI: 10.1080/07268602.2020.1737507\n@article{GnevshevaEtAl2020,\n  author = {Ksenia Gnevsheva and Simon Gonzalez and Robert Fromont},\n  title = {{Australian English Bilingual Corpus: Automatic forced-alignment accuracy in Russian and English}},\n  journal = {Australian Journal of Linguistics},\n  pages = {1-12},\n  year  = {2020},\n  publisher = {Routledge},\n  doi = {10.1080/07268602.2020.1737507},\n  URL = {https://doi.org/10.1080/07268602.2020.1737507}\n}\n\nFromont, Robert (2019), Forced Alignment of Different Language Varieties using LaBB-CAT, in proceedings of the International Congress of Phonetic Sciences 2019 (ICPhS2019), Melbourne.\n@inproceedings{Fromont2019,\n  title={{Forced Alignment of Different Language Varieties using LaBB-CAT}},\n  author={Fromont, Robert},\n  booktitle={International Congress of Phonetic Sciences 2019 (ICPhS2019)},\n  year={2019}\n}\n\nFromont, Robert (2017), Toward a format-neutral annotation store, Computer Speech & Language Vol. 45, pp.¬†348-374, Academic Press, DOI: 10.1016/j.csl.2017.01.004\n@article{Fromont2017,\n  title={Toward a format-neutral annotation store},\n  author={Fromont, Robert},\n  journal={Computer Speech \\& Language},\n  volume={45},\n  pages={348--374},\n  year={2017},\n  publisher={Academic Press},\n  doi = {10.1016/j.csl.2017.01.004},\n  URL = {https://doi.org/10.1016/j.csl.2017.01.004}\n}\n\nFromont, Robert & Kevin Watson (2016), Factors influencing automatic segmental alignment of sociophonetic corpora, Corpora Vol. 11 (3), pp.¬†401-431, Edinburgh University Press 22 George Square, Edinburgh EH8 9LF UK DOI: [10.3366/cor.2016.0101]\n@Article{FromontWatson2016,\n  author = {Robert Fromont and Kevin Watson},\n  title = {Factors influencing automatic segmental alignment of sociophonetic corpora},\n  journal = {Corpora},\n  year = {2016},\n  volume = {11},\n  number = {3},\n  pages = {401--431},\n  publisher={Edinburgh University Press 22 George Square, Edinburgh EH8 9LF UK,\n  doi = {10.3366/cor.2016.0101},\n  URL = {https://doi.org/10.3366/cor.2016.0101}\n}\n\nFromont, Robert & Jennifer Hay (2012) LaBB-CAT: an Annotation Store, Proceedings of Australasian Language Technology Association Workshop, pp.¬†113-117, Australasian Language Technology Association, Dunedin.\n@InProceedings{FromontHay2012,\n  author = {Robert Fromont and Jennifer Hay},\n  title = {{LaBB-CAT: an Annotation Store}},\n  booktitle = {{Proceedings of Australasian Language Technology Association Workshop}},\n  year = {2012},\n  pages = {113--117},\n  month = {November},\n  organization = {Australasian Language Technology Association},\n}\n\nFromont, Robert & Jennifer Hay (2008), ONZE Miner: the development of a browser-based research tool, Corpora Vol. 3 (2), pp.¬†173-193, Edinburgh University Press 22 George Square, Edinburgh EH8 9LF UK\n@Article{FromontHay2008,\n  author = {Robert Fromont and Jennifer Hay},\n  title = {{ONZE Miner}: the development of a browser-based research tool},\n  journal = {Corpora},\n  year = {2008},\n  volume = {3},\n  number = {2},\n  pages = {173--193},\n  publisher={Edinburgh University Press 22 George Square, Edinburgh EH8 9LF UK\n}\n\n\n\nVersion 20250819\n@Misc{labbcat20250819,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20250819.zip}}\n  year = {2024}\n}\nVersion 20250430\n@Misc{labbcat20250430,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20250430.zip}}\n  year = {2025}\n}\nVersion 20241111\n@Misc{labbcat20241111,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20241111.zip}}\n  year = {2024}\n}\nVersion 20241018\n@Misc{labbcat20241018,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20241018.zip}}\n  year = {2024}\n}\nVersion 20240702\n@Misc{labbcat20240702,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20240702.zip}}\n  year = {2024}\n}\nVersion 20240306\n@Misc{labbcat20240306,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20240306.zip}}\n  year = {2024}\n}\nVersion 20230719\n@Misc{labbcat20230719,\nauthor = {Robert Fromont},\ntitle = {LaBB-CAT: linguistic annotation system [Computer program]},\nhowpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat_20230719.zip}}\nyear = {2023}\n}\nVersion 20230202\n@Misc{labbcat20230202,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20230202.zip}}\n  year = {2023}\n}\nVersion 20230119\n@Misc{labbcat20230119,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20230119.zip}}\n  year = {2023}\n}\nVersion 20230118\n@Misc{labbcat20230118,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20230118.zip}}\n  year = {2023}\n}\nVersion 20221013\n@Misc{labbcat20221013,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20221013.zip}}\n  year = {2022}\n}\nVersion 20220413\n@Misc{labbcat20220413,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20220413.zip}}\n  year = {2022}\n}\nVersion 20220120\n@Misc{labbcat20220120,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20220120.zip}}\n  year = {2022}\n}\nVersion 20220112\n@Misc{labbcat20220112,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20220112.zip}}\n  year = {2022}\n}\nVersion 20210528\n@Misc{labbcat20210528,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20210528.zip}}\n  year = {2021}\n}\nVersion 20210216\n@Misc{labbcat20210216,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20210216.zip}}\n  year = {2021}\n}\nVersion 20200901\n@Misc{labbcat20200901,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20200901.zip}}\n  year = {2020}\n}\nVersion 20200615\n@Misc{labbcat20200615,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20200615.zip}}\n  year = {2020}\n}\nVersion 20200110\n@Misc{labbcat20200110,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20200110.zip}},\n  year = {2020}\n}\nVersion 20191031\n@Misc{labbcat20191031,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20191031.zip}},\n  year = {2019}\n}\nVersion 20190724\n@Misc{labbcat20190724,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20190724.zip}},\n  year = {2019}\n}\nVersion {20190425}(https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20190425.zip)\n@Misc{labbcat20190425,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20190425.zip}},\n  year = {2019}\n}\nVersion {20181221}(https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20181221.zip)\n@Misc{labbcat20181221,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20181221.zip}},\n  year = {2018}\n}\nVersion 20180626\n@Misc{labbcat20180626,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20180626.zip}},\n  year = {2018}\n}\nVersion 20171221\n@Misc{labbcat20171221,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20171221.zip}},\n  year = {2017}\n}\nVersion 20170614\n@Misc{labbcat20170614,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20170614.zip}},\n  year = {2017}\n}\nVersion 20161003\n@Misc{labbcat20161003,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20161003.zip}},\n  year = {2016}\n}\nVersion 20160707\n@Misc{labbcat20160707,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20160707.zip}},\n  year = {2016}\n}",
    "crumbs": [
      "How-to",
      "Cite"
    ]
  },
  {
    "objectID": "howto/cite.html#publications",
    "href": "howto/cite.html#publications",
    "title": "How-to cite LaBB-CAT",
    "section": "",
    "text": "Robert Fromont, Lynn Clark, Joshua Wilson Black, & Margaret Blackwood (2023) Maximizing accuracy of forced alignment for spontaneous child speech, Language Development Research, Volume 3, Issue 1, 2023, DOI: 10.34842/SHRR-SV10\n@article{FromontEtAl2023,\n    author = {Robert Fromont and Lynn Clark and Joshua Wilson Black and Margaret Blackwood},\n    title = {Maximizing accuracy of forced alignment for spontaneous child speech},\n    volume = {3},\n    year = {2023},\n    url = {http://ldr.lps.library.cmu.edu/article/id/672/},\n    issue = {1},\n    doi = {10.34842/shrr-sv10},\n    month = {9},\n    pages = {182-210},\n    issn = {2771-7976},\n    publisher ={Carnegie Mellon University Library Publishing Service},\n    journal = {Language Development Research}\n}\nKsenia Gnevsheva, Simon Gonzalez & Robert Fromont (2020), Australian English Bilingual Corpus: Automatic forced-alignment accuracy in Russian and English, Australian Journal of Linguistics, DOI: 10.1080/07268602.2020.1737507\n@article{GnevshevaEtAl2020,\n  author = {Ksenia Gnevsheva and Simon Gonzalez and Robert Fromont},\n  title = {{Australian English Bilingual Corpus: Automatic forced-alignment accuracy in Russian and English}},\n  journal = {Australian Journal of Linguistics},\n  pages = {1-12},\n  year  = {2020},\n  publisher = {Routledge},\n  doi = {10.1080/07268602.2020.1737507},\n  URL = {https://doi.org/10.1080/07268602.2020.1737507}\n}\n\nFromont, Robert (2019), Forced Alignment of Different Language Varieties using LaBB-CAT, in proceedings of the International Congress of Phonetic Sciences 2019 (ICPhS2019), Melbourne.\n@inproceedings{Fromont2019,\n  title={{Forced Alignment of Different Language Varieties using LaBB-CAT}},\n  author={Fromont, Robert},\n  booktitle={International Congress of Phonetic Sciences 2019 (ICPhS2019)},\n  year={2019}\n}\n\nFromont, Robert (2017), Toward a format-neutral annotation store, Computer Speech & Language Vol. 45, pp.¬†348-374, Academic Press, DOI: 10.1016/j.csl.2017.01.004\n@article{Fromont2017,\n  title={Toward a format-neutral annotation store},\n  author={Fromont, Robert},\n  journal={Computer Speech \\& Language},\n  volume={45},\n  pages={348--374},\n  year={2017},\n  publisher={Academic Press},\n  doi = {10.1016/j.csl.2017.01.004},\n  URL = {https://doi.org/10.1016/j.csl.2017.01.004}\n}\n\nFromont, Robert & Kevin Watson (2016), Factors influencing automatic segmental alignment of sociophonetic corpora, Corpora Vol. 11 (3), pp.¬†401-431, Edinburgh University Press 22 George Square, Edinburgh EH8 9LF UK DOI: [10.3366/cor.2016.0101]\n@Article{FromontWatson2016,\n  author = {Robert Fromont and Kevin Watson},\n  title = {Factors influencing automatic segmental alignment of sociophonetic corpora},\n  journal = {Corpora},\n  year = {2016},\n  volume = {11},\n  number = {3},\n  pages = {401--431},\n  publisher={Edinburgh University Press 22 George Square, Edinburgh EH8 9LF UK,\n  doi = {10.3366/cor.2016.0101},\n  URL = {https://doi.org/10.3366/cor.2016.0101}\n}\n\nFromont, Robert & Jennifer Hay (2012) LaBB-CAT: an Annotation Store, Proceedings of Australasian Language Technology Association Workshop, pp.¬†113-117, Australasian Language Technology Association, Dunedin.\n@InProceedings{FromontHay2012,\n  author = {Robert Fromont and Jennifer Hay},\n  title = {{LaBB-CAT: an Annotation Store}},\n  booktitle = {{Proceedings of Australasian Language Technology Association Workshop}},\n  year = {2012},\n  pages = {113--117},\n  month = {November},\n  organization = {Australasian Language Technology Association},\n}\n\nFromont, Robert & Jennifer Hay (2008), ONZE Miner: the development of a browser-based research tool, Corpora Vol. 3 (2), pp.¬†173-193, Edinburgh University Press 22 George Square, Edinburgh EH8 9LF UK\n@Article{FromontHay2008,\n  author = {Robert Fromont and Jennifer Hay},\n  title = {{ONZE Miner}: the development of a browser-based research tool},\n  journal = {Corpora},\n  year = {2008},\n  volume = {3},\n  number = {2},\n  pages = {173--193},\n  publisher={Edinburgh University Press 22 George Square, Edinburgh EH8 9LF UK\n}",
    "crumbs": [
      "How-to",
      "Cite"
    ]
  },
  {
    "objectID": "howto/cite.html#versions",
    "href": "howto/cite.html#versions",
    "title": "How-to cite LaBB-CAT",
    "section": "",
    "text": "Version 20250819\n@Misc{labbcat20250819,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20250819.zip}}\n  year = {2024}\n}\nVersion 20250430\n@Misc{labbcat20250430,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20250430.zip}}\n  year = {2025}\n}\nVersion 20241111\n@Misc{labbcat20241111,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20241111.zip}}\n  year = {2024}\n}\nVersion 20241018\n@Misc{labbcat20241018,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20241018.zip}}\n  year = {2024}\n}\nVersion 20240702\n@Misc{labbcat20240702,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20240702.zip}}\n  year = {2024}\n}\nVersion 20240306\n@Misc{labbcat20240306,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20240306.zip}}\n  year = {2024}\n}\nVersion 20230719\n@Misc{labbcat20230719,\nauthor = {Robert Fromont},\ntitle = {LaBB-CAT: linguistic annotation system [Computer program]},\nhowpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat_20230719.zip}}\nyear = {2023}\n}\nVersion 20230202\n@Misc{labbcat20230202,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20230202.zip}}\n  year = {2023}\n}\nVersion 20230119\n@Misc{labbcat20230119,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20230119.zip}}\n  year = {2023}\n}\nVersion 20230118\n@Misc{labbcat20230118,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20230118.zip}}\n  year = {2023}\n}\nVersion 20221013\n@Misc{labbcat20221013,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20221013.zip}}\n  year = {2022}\n}\nVersion 20220413\n@Misc{labbcat20220413,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20220413.zip}}\n  year = {2022}\n}\nVersion 20220120\n@Misc{labbcat20220120,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20220120.zip}}\n  year = {2022}\n}\nVersion 20220112\n@Misc{labbcat20220112,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20220112.zip}}\n  year = {2022}\n}\nVersion 20210528\n@Misc{labbcat20210528,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20210528.zip}}\n  year = {2021}\n}\nVersion 20210216\n@Misc{labbcat20210216,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20210216.zip}}\n  year = {2021}\n}\nVersion 20200901\n@Misc{labbcat20200901,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20200901.zip}}\n  year = {2020}\n}\nVersion 20200615\n@Misc{labbcat20200615,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20200615.zip}}\n  year = {2020}\n}\nVersion 20200110\n@Misc{labbcat20200110,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20200110.zip}},\n  year = {2020}\n}\nVersion 20191031\n@Misc{labbcat20191031,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20191031.zip}},\n  year = {2019}\n}\nVersion 20190724\n@Misc{labbcat20190724,\n  author = {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20190724.zip}},\n  year = {2019}\n}\nVersion {20190425}(https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20190425.zip)\n@Misc{labbcat20190425,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20190425.zip}},\n  year = {2019}\n}\nVersion {20181221}(https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20181221.zip)\n@Misc{labbcat20181221,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20181221.zip}},\n  year = {2018}\n}\nVersion 20180626\n@Misc{labbcat20180626,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20180626.zip}},\n  year = {2018}\n}\nVersion 20171221\n@Misc{labbcat20171221,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20171221.zip}},\n  year = {2017}\n}\nVersion 20170614\n@Misc{labbcat20170614,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20170614.zip}},\n  year = {2017}\n}\nVersion 20161003\n@Misc{labbcat20161003,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20161003.zip}},\n  year = {2016}\n}\nVersion 20160707\n@Misc{labbcat20160707,\n  author =   {Robert Fromont},\n  title = {LaBB-CAT: linguistic annotation system [Computer program]},\n  howpublished = {{https://sourceforge.net/projects/labbcat/files/install/labbcat-server_20160707.zip}},\n  year = {2016}\n}",
    "crumbs": [
      "How-to",
      "Cite"
    ]
  },
  {
    "objectID": "howto/workflow/upload-align-htk.html",
    "href": "howto/workflow/upload-align-htk.html",
    "title": "Upload and Force-align Transcripts",
    "section": "",
    "text": "This workflow details the steps required to upload new transcripts and then run forced alignment on them.\n\n\n\n\n\n\nNoteAssumptions\n\n\n\n\n\nThese instructions assume that\n\nyou‚Äôve got a LaBB-CAT server set up\nit‚Äôs already configured for CELEX-based pronunciations to be tagged on the phonemes layer\nit‚Äôs already configured for forced alignment with HTK\nthe HTK configuration is designed for the per-speaker train/align procedure\n\n\n\n\nThere are two sub-tasks:\n\nupload the transcripts for a given speaker, and then\nrun forced alignment for all of that speaker‚Äôs utterances.\n\nThese two broad steps will be repeated for each speaker.\n\n\nAs forced alignment is done on a per-speaker database, it‚Äôs best to upload all the transcripts that a speaker appears in before running forced alignment.\n\nChoose a speaker/participant to upload.\nIdentify all the transcripts/recordings that they appear in. This may be only one transcript, which is fine. But if they‚Äôre in more than one recording, they should all be uploaded before forced alignment, to maximise the amount of speech available for training acoustic models for alignment.\nIn LaBB-CAT, select the upload option in the menu.\nSelect the first option, upload transcripts.\nPress the left-hand Choose File button and select the first transcript file (it may be a .eaf ELAN file, or a Praat .TextGrid file, etc.).\n\nWhen you select a file, a new row of Choose File buttons will appear below the first. This is for adding more transcripts in the ‚Äòepisode‚Äô. An ‚Äòepisode‚Äô is a set of transcripts that belong together because they were recorded during the same session. Unless your recordings for a speaker wer all recorded on the same day, each recording session has only one recording.\n\nNext to Media on the first row, press Choose File\nSelect the .wav file that corresponds to the transcript.\nEnsure the Corpus option is correct for the transcript you‚Äôre uploading.\nEnsure the Type option is correct (e.g.¬†interview for an interview, word-list for a word list reading, etc.)\nLeave the other options as-is, and press Upload\n\n\n\n\nSelect the transcript on the left and the media on the right\n\n\nELAN/Praat transcripts have a number of Tiers defined in them, e.g.:\n\none for the participant's utterances,\nanother for an ‚Äòinterviewer‚Äô if there is one,\none for noise annotations,\none for transcriber comments, and\none for topic annotations.\n\nEach tier must be mapped to a LaBB-CAT annotation layer.\nNow that you‚Äôve uploaded the file, LaBB-CAT has analysed the structure of the transcript file and pre-selected some default options for layer mappings. These defaults are correct under most circumstances, but it‚Äôs a good idea to double-check that\n\ntiers that contain transcripts of speech are mapped to utterance and\ntiers that contain other information aren‚Äôt mapped to utterance.\n\n\n\n\nCheck mappings of tiers to layers\n\n\n\nClick Next to continue.\nThis will display a page listing all the speakers in the transcript, so you can select which one is the ‚Äòmain participant‚Äô, which is the speaker selected by default for searches and other processing.\nEnsure that the target speaker is ticked, and others like the interviewer are not ticked, and click Set Main Participants.\nThis will display a page with the name of transcript you uploaded, with an edit meta-data link, and a progress bar (which may have already finished). The progress bar indicates progress with processing of automatically generated annotations.\nEnsure the progress bar finishes, and there are no errors.\n\nIf there are more transcripts to upload for this speaker, you can repeat from step 5. above, using the form below the heading ‚Äòselect transcripts to upload‚Äô.\n\nClick the name of the (last) transcript you uploaded.\nThis opens LaBB-CAT‚Äôs interactive transcript page.\nDouble check that the transcript text appears correct and that the media playback control appears on the top right.\nClick on an utterance and select the Play option from the resulting menu.\nEnsure that the audio corresponding to the given utterance is played.\nAt the top of the page, tick the phonemes layer, to show the pronunciation annotations on the words.\nYou should see that most, if not all, words in the transcript have a pronunciation above them.\n\n\n\n\nA transcript showing the phonemes layer\n\n\nFor HTK to force-align an utterance, it must know the pronunciation of every word in the utterance. It uses the phonemes layer to determine what the pronunciations are, and these are usually tagged by looking up a lexicon like CELEX.\nIf you see gaps in the phonemes layer on the transcript, these are words for which there is no known pronunciation. These missing entries should be filled in in order to ensure HTK force-aligns all utterances; there are instructions for this below.\nAt this point, the transcripts have been uploaded and are ready for forced alignment.\n\n\n\n\nTo start a forced-alignment process per-speaker, you need to first select the speaker to be aligned. Then you will fill in any pronunciations that are missing from the dictionary. After that, HTK will automatically force-align their utterances, producing start/end times for each speech sound.\n\nIn LaBB-CAT, select the participants option on the menu\nFind and tick the speaker.\nPress the All Utterances button\nPress List\nOnce the paginated list of utterances appears, press the Htk button below.\n\nLaBB-CAT will first determine which words have missing pronunciations; you will see a progress bar, and then a list will appear of words that need their pronunciations adding to the dictionary. The list of missing words may grow as more utterances are analysed.\n\n\n\nMissing pronuciations that need filling in\n\n\nThe list has the following columns:\n\nThe word that is missing\nA dictionary lookup button\nA box for entering the pronunciation that you want to add to the dictionary\nA phoneme selector button\n\nEach of these is explained below:\n\n\n\nIf you click the word, it will open, in a separate tab, the first transcript in which the word appears, so you can see the context, play the audio, etc.\nThis is for cases where it‚Äôs not clear from the spelling what the pronunciation should be, and cases where you need to change the transcript, instead of adding an entry to the dictionary.\nFor example:\n\nIf the word is a spelling mistake, you need to correct it in the transcript:\n\nclick the word to open the transcript where it appears,\nclick the word in the transcript and select Edit Transcript (under ‚ÄòUtterance‚Äô) from the resulting menu,\nfix the spelling error:\n\n\npress Update and then Close.\n\nIn some cases, it‚Äôs an interrupted word, or some other one-off case that shouldn‚Äôt be added to the global dictionary, because it won‚Äôt come up over and again in other transcripts.\nThese cases need to have a pronounce tag added to the word token directly in the transcript:\n\nclick the word to open the transcript where it appears,\nclick the word in the transcript and select Edit Transcript (under ‚ÄòUtterance‚Äô) from the resulting menu,\n\nimmediately after the hesitated word, with no intervening space, add a DISC pronunciation enclosed in square brackets ‚Äì this is a pronounce tag:\n\npress Update and then Close.\n\n\n\n\n\nThis allows you to lookup the dictionary for similar words, in order to quickly get a pronunciation that you can adapt. Clicking the button allows you to lookup one or more words in the dictionary:\n\n\n\nLook up the dictionary for one or more words\n\n\nThe pronunciations for the words you enter are displayed on buttons:\n\n\n\nExisting pronunciations of other words\n\n\nPressing a button adds that pronunciation to the box above, so you can base the new pronunciation on existing ones, correcting them before adding them to the global dictionary.\nThe dictionary lookup can be useful for compound words like tarseal, numbers like 3 (you can look up ‚Äúthree‚Äù), and words that are pronounced similarly.\n\n\n\nAdding to the dictionary means that the pronunciation you add becomes available to all other transcripts, as well as the one(s) you‚Äôre force-aligning now.\nThe pronunciations must ben entered using CELEX‚Äôs ‚ÄòDISC‚Äô symbols (i.e.¬†one character per phoneme, with no spaces), see below.\n\n\n\nThis button helps with using the correct symbols.\n\n\nClicking on an IPA symbol adds the corresponding DISC symbol to the pronunciation box.\nSome of the pronunciations may already be filled in. In these cases, LaBB-CAT is suggesting a pronunciation, based on how the word relates to other words it already has a pronunciation for. The suggestion may be wrong, and you should check/correct these before saving them.\n\n\n\n\n\n\nImportant\n\n\n\nThe pronunciations you add to the dictionary should include:\n\n- : the syllable separator (hyphen)\n' : the primary lexical stress marker (apostrophe), and\n\" : the secondary stress marker (double-quote) if any.\n\nIf you use the dictionary lookup button, these are included in the pronunciations that are returned.\n\n\nBasically you need to fill in the boxes with the pronunciations and click Save. You don‚Äôt have to fill them all in before clicking Save, you can save several pronunciations, which will disappear from the list, leaving the ones you haven‚Äôt filled in yet.\n\n\n\n\n\n\nNote\n\n\n\nYou don‚Äôt have to fill in all pronunciations, you can leave some empty and continue with the HTK forced-alignment by clicking Start\nHowever, HTK will ignore any lines where the remaining unknown words appear, so not all utterances will be aligned in the end.\n\n\n\nOnce you‚Äôve filled in all the missing pronunciations, forced alignment will start automatically. If you want to start forced alignment before you‚Äôve entered all pronunciations, click the Start button at the bottom of the page.\n\nYou should see a progress bar while the forced alignment is running. It will take a few minutes to complete.\n\nOnce HTK has produced the word and segment alignments, it:\n\nsets the start/end times of the words on the transcript layer accordingly,\nadds new phone annotations to the segment layer with the alignments of the phones, and\nsaves a timestamp in the htk layer.\n\nWhen the layer manager has finished, you‚Äôll see a message saying ‚ÄúComplete - words and phones from selected utterances are now aligned.‚Äù\nTo double-check aligned segment annotations were created:\n\nSelect the transcripts option from the menu.\nFind one of the transcripts the speaker appears in, and click its name to open it.\nTick the htk layer and the segment layer\nCheck that each of the speaker‚Äôs utterances has a time-stamp annotation above, and phone annotations below for each word.\n\n\n\n\nAligned utterances are tagged with a timestamp above, and include segment annotations below\n\n\nExceptions might include:\n\nutterances with words that still have missing pronunciations, and\nsimultaneous speech (i.e.¬†there‚Äôs another participant speaking at the same time) ‚Äì these are deliberately ignored as automatic aligments are usually of poor quality.\n\n\n\n\n\n\nThese are the symbols that should be used for all pronunciations:\n\n\n\nIPA\nDISC\n¬†\n¬†\nIPA\nDISC\n¬†\n\n\np\np\npat\n¬†\n…™\nI\nKIT\n\n\nb\nb\nbad\n¬†\nŒµ\nE\nDRESS\n\n\nt\nt\ntack\n¬†\n√¶\n{\nTRAP\n\n\nd\nd\ndad\n¬†\n å\nV\nSTRUT\n\n\nk\nk\ncad\n¬†\n…í\nQ\nLOT\n\n\ng\ng\ngame\n¬†\n ä\nU\nFOOT\n\n\n≈ã\nN\nbang\n¬†\n…ô\n@\nanother\n\n\nm\nm\nmat\n¬†\ni:\ni\nFLEECE\n\n\nn\nn\nnat\n¬†\nŒ±:¬†\n#\nSTART\n\n\nl\nl\nlad\n¬†\n…î:\n$\nTHOUGHT\n\n\nr\nr\nrat\n¬†\nu:\nu\nGOOSE\n\n\nf\nf\nfat\n¬†\n…ú:\n3\nNURSE\n\n\nv\nv\nvat\n¬†\ne…™\n1\nFACE\n\n\nŒ∏\nT\nthin\n¬†\nŒ±…™\n2\nPRICE\n\n\n√∞\nD\nthen\n¬†\n…î…™\n4\nCHOICE\n\n\ns\ns\nsap\n¬†\n…ô ä\n5\nGOAT\n\n\nz\nz\nzap\n¬†\nŒ± ä\n6\nMOUTH\n\n\n‚à´\nS\nsheep\n¬†\n…™…ô\n7\nNEAR\n\n\n í\nZ\nmeasure\n¬†\nŒµ…ô\n8\nSQUARE\n\n\nj\nj\nyank\n¬†\n ä…ô\n9\nCURE\n\n\nx\nx\nloch\n¬†\n√¶\nc\ntimbre\n\n\nh\nh\nhad\n¬†\n…ëÃÉÀê\nq\nd√©tente\n\n\nw\nw\nwet\n¬†\n√¶ÃÉÀê\n0\nlingerie\n\n\n ß\nJ\ncheap\n¬†\n…íÃÉÀê\n~\nbouillon\n\n\n §\n_\njeep\n¬†\n¬†\n¬†\n¬†\n\n\n≈ãÃ©\nC\nbacon\n¬†\n¬†\n¬†\n¬†\n\n\nmÃ©\nF\nidealism\n¬†\n¬†\n¬†-\nsyllable separator\n\n\nnÃ©\nH\nburden\n¬†\n¬†\n¬†'\nprimary stress\n\n\nlÃ©\nP\ndangle\n¬†\n¬†\n¬†\"\nsecondary stress"
  },
  {
    "objectID": "howto/workflow/upload-align-htk.html#upload-transcripts",
    "href": "howto/workflow/upload-align-htk.html#upload-transcripts",
    "title": "Upload and Force-align Transcripts",
    "section": "",
    "text": "As forced alignment is done on a per-speaker database, it‚Äôs best to upload all the transcripts that a speaker appears in before running forced alignment.\n\nChoose a speaker/participant to upload.\nIdentify all the transcripts/recordings that they appear in. This may be only one transcript, which is fine. But if they‚Äôre in more than one recording, they should all be uploaded before forced alignment, to maximise the amount of speech available for training acoustic models for alignment.\nIn LaBB-CAT, select the upload option in the menu.\nSelect the first option, upload transcripts.\nPress the left-hand Choose File button and select the first transcript file (it may be a .eaf ELAN file, or a Praat .TextGrid file, etc.).\n\nWhen you select a file, a new row of Choose File buttons will appear below the first. This is for adding more transcripts in the ‚Äòepisode‚Äô. An ‚Äòepisode‚Äô is a set of transcripts that belong together because they were recorded during the same session. Unless your recordings for a speaker wer all recorded on the same day, each recording session has only one recording.\n\nNext to Media on the first row, press Choose File\nSelect the .wav file that corresponds to the transcript.\nEnsure the Corpus option is correct for the transcript you‚Äôre uploading.\nEnsure the Type option is correct (e.g.¬†interview for an interview, word-list for a word list reading, etc.)\nLeave the other options as-is, and press Upload\n\n\n\n\nSelect the transcript on the left and the media on the right\n\n\nELAN/Praat transcripts have a number of Tiers defined in them, e.g.:\n\none for the participant's utterances,\nanother for an ‚Äòinterviewer‚Äô if there is one,\none for noise annotations,\none for transcriber comments, and\none for topic annotations.\n\nEach tier must be mapped to a LaBB-CAT annotation layer.\nNow that you‚Äôve uploaded the file, LaBB-CAT has analysed the structure of the transcript file and pre-selected some default options for layer mappings. These defaults are correct under most circumstances, but it‚Äôs a good idea to double-check that\n\ntiers that contain transcripts of speech are mapped to utterance and\ntiers that contain other information aren‚Äôt mapped to utterance.\n\n\n\n\nCheck mappings of tiers to layers\n\n\n\nClick Next to continue.\nThis will display a page listing all the speakers in the transcript, so you can select which one is the ‚Äòmain participant‚Äô, which is the speaker selected by default for searches and other processing.\nEnsure that the target speaker is ticked, and others like the interviewer are not ticked, and click Set Main Participants.\nThis will display a page with the name of transcript you uploaded, with an edit meta-data link, and a progress bar (which may have already finished). The progress bar indicates progress with processing of automatically generated annotations.\nEnsure the progress bar finishes, and there are no errors.\n\nIf there are more transcripts to upload for this speaker, you can repeat from step 5. above, using the form below the heading ‚Äòselect transcripts to upload‚Äô.\n\nClick the name of the (last) transcript you uploaded.\nThis opens LaBB-CAT‚Äôs interactive transcript page.\nDouble check that the transcript text appears correct and that the media playback control appears on the top right.\nClick on an utterance and select the Play option from the resulting menu.\nEnsure that the audio corresponding to the given utterance is played.\nAt the top of the page, tick the phonemes layer, to show the pronunciation annotations on the words.\nYou should see that most, if not all, words in the transcript have a pronunciation above them.\n\n\n\n\nA transcript showing the phonemes layer\n\n\nFor HTK to force-align an utterance, it must know the pronunciation of every word in the utterance. It uses the phonemes layer to determine what the pronunciations are, and these are usually tagged by looking up a lexicon like CELEX.\nIf you see gaps in the phonemes layer on the transcript, these are words for which there is no known pronunciation. These missing entries should be filled in in order to ensure HTK force-aligns all utterances; there are instructions for this below.\nAt this point, the transcripts have been uploaded and are ready for forced alignment."
  },
  {
    "objectID": "howto/workflow/upload-align-htk.html#forced-alignment",
    "href": "howto/workflow/upload-align-htk.html#forced-alignment",
    "title": "Upload and Force-align Transcripts",
    "section": "",
    "text": "To start a forced-alignment process per-speaker, you need to first select the speaker to be aligned. Then you will fill in any pronunciations that are missing from the dictionary. After that, HTK will automatically force-align their utterances, producing start/end times for each speech sound.\n\nIn LaBB-CAT, select the participants option on the menu\nFind and tick the speaker.\nPress the All Utterances button\nPress List\nOnce the paginated list of utterances appears, press the Htk button below.\n\nLaBB-CAT will first determine which words have missing pronunciations; you will see a progress bar, and then a list will appear of words that need their pronunciations adding to the dictionary. The list of missing words may grow as more utterances are analysed.\n\n\n\nMissing pronuciations that need filling in\n\n\nThe list has the following columns:\n\nThe word that is missing\nA dictionary lookup button\nA box for entering the pronunciation that you want to add to the dictionary\nA phoneme selector button\n\nEach of these is explained below:\n\n\n\nIf you click the word, it will open, in a separate tab, the first transcript in which the word appears, so you can see the context, play the audio, etc.\nThis is for cases where it‚Äôs not clear from the spelling what the pronunciation should be, and cases where you need to change the transcript, instead of adding an entry to the dictionary.\nFor example:\n\nIf the word is a spelling mistake, you need to correct it in the transcript:\n\nclick the word to open the transcript where it appears,\nclick the word in the transcript and select Edit Transcript (under ‚ÄòUtterance‚Äô) from the resulting menu,\nfix the spelling error:\n\n\npress Update and then Close.\n\nIn some cases, it‚Äôs an interrupted word, or some other one-off case that shouldn‚Äôt be added to the global dictionary, because it won‚Äôt come up over and again in other transcripts.\nThese cases need to have a pronounce tag added to the word token directly in the transcript:\n\nclick the word to open the transcript where it appears,\nclick the word in the transcript and select Edit Transcript (under ‚ÄòUtterance‚Äô) from the resulting menu,\n\nimmediately after the hesitated word, with no intervening space, add a DISC pronunciation enclosed in square brackets ‚Äì this is a pronounce tag:\n\npress Update and then Close.\n\n\n\n\n\nThis allows you to lookup the dictionary for similar words, in order to quickly get a pronunciation that you can adapt. Clicking the button allows you to lookup one or more words in the dictionary:\n\n\n\nLook up the dictionary for one or more words\n\n\nThe pronunciations for the words you enter are displayed on buttons:\n\n\n\nExisting pronunciations of other words\n\n\nPressing a button adds that pronunciation to the box above, so you can base the new pronunciation on existing ones, correcting them before adding them to the global dictionary.\nThe dictionary lookup can be useful for compound words like tarseal, numbers like 3 (you can look up ‚Äúthree‚Äù), and words that are pronounced similarly.\n\n\n\nAdding to the dictionary means that the pronunciation you add becomes available to all other transcripts, as well as the one(s) you‚Äôre force-aligning now.\nThe pronunciations must ben entered using CELEX‚Äôs ‚ÄòDISC‚Äô symbols (i.e.¬†one character per phoneme, with no spaces), see below.\n\n\n\nThis button helps with using the correct symbols.\n\n\nClicking on an IPA symbol adds the corresponding DISC symbol to the pronunciation box.\nSome of the pronunciations may already be filled in. In these cases, LaBB-CAT is suggesting a pronunciation, based on how the word relates to other words it already has a pronunciation for. The suggestion may be wrong, and you should check/correct these before saving them.\n\n\n\n\n\n\nImportant\n\n\n\nThe pronunciations you add to the dictionary should include:\n\n- : the syllable separator (hyphen)\n' : the primary lexical stress marker (apostrophe), and\n\" : the secondary stress marker (double-quote) if any.\n\nIf you use the dictionary lookup button, these are included in the pronunciations that are returned.\n\n\nBasically you need to fill in the boxes with the pronunciations and click Save. You don‚Äôt have to fill them all in before clicking Save, you can save several pronunciations, which will disappear from the list, leaving the ones you haven‚Äôt filled in yet.\n\n\n\n\n\n\nNote\n\n\n\nYou don‚Äôt have to fill in all pronunciations, you can leave some empty and continue with the HTK forced-alignment by clicking Start\nHowever, HTK will ignore any lines where the remaining unknown words appear, so not all utterances will be aligned in the end.\n\n\n\nOnce you‚Äôve filled in all the missing pronunciations, forced alignment will start automatically. If you want to start forced alignment before you‚Äôve entered all pronunciations, click the Start button at the bottom of the page.\n\nYou should see a progress bar while the forced alignment is running. It will take a few minutes to complete.\n\nOnce HTK has produced the word and segment alignments, it:\n\nsets the start/end times of the words on the transcript layer accordingly,\nadds new phone annotations to the segment layer with the alignments of the phones, and\nsaves a timestamp in the htk layer.\n\nWhen the layer manager has finished, you‚Äôll see a message saying ‚ÄúComplete - words and phones from selected utterances are now aligned.‚Äù\nTo double-check aligned segment annotations were created:\n\nSelect the transcripts option from the menu.\nFind one of the transcripts the speaker appears in, and click its name to open it.\nTick the htk layer and the segment layer\nCheck that each of the speaker‚Äôs utterances has a time-stamp annotation above, and phone annotations below for each word.\n\n\n\n\nAligned utterances are tagged with a timestamp above, and include segment annotations below\n\n\nExceptions might include:\n\nutterances with words that still have missing pronunciations, and\nsimultaneous speech (i.e.¬†there‚Äôs another participant speaking at the same time) ‚Äì these are deliberately ignored as automatic aligments are usually of poor quality."
  },
  {
    "objectID": "howto/workflow/upload-align-htk.html#DISC",
    "href": "howto/workflow/upload-align-htk.html#DISC",
    "title": "Upload and Force-align Transcripts",
    "section": "",
    "text": "These are the symbols that should be used for all pronunciations:\n\n\n\nIPA\nDISC\n¬†\n¬†\nIPA\nDISC\n¬†\n\n\np\np\npat\n¬†\n…™\nI\nKIT\n\n\nb\nb\nbad\n¬†\nŒµ\nE\nDRESS\n\n\nt\nt\ntack\n¬†\n√¶\n{\nTRAP\n\n\nd\nd\ndad\n¬†\n å\nV\nSTRUT\n\n\nk\nk\ncad\n¬†\n…í\nQ\nLOT\n\n\ng\ng\ngame\n¬†\n ä\nU\nFOOT\n\n\n≈ã\nN\nbang\n¬†\n…ô\n@\nanother\n\n\nm\nm\nmat\n¬†\ni:\ni\nFLEECE\n\n\nn\nn\nnat\n¬†\nŒ±:¬†\n#\nSTART\n\n\nl\nl\nlad\n¬†\n…î:\n$\nTHOUGHT\n\n\nr\nr\nrat\n¬†\nu:\nu\nGOOSE\n\n\nf\nf\nfat\n¬†\n…ú:\n3\nNURSE\n\n\nv\nv\nvat\n¬†\ne…™\n1\nFACE\n\n\nŒ∏\nT\nthin\n¬†\nŒ±…™\n2\nPRICE\n\n\n√∞\nD\nthen\n¬†\n…î…™\n4\nCHOICE\n\n\ns\ns\nsap\n¬†\n…ô ä\n5\nGOAT\n\n\nz\nz\nzap\n¬†\nŒ± ä\n6\nMOUTH\n\n\n‚à´\nS\nsheep\n¬†\n…™…ô\n7\nNEAR\n\n\n í\nZ\nmeasure\n¬†\nŒµ…ô\n8\nSQUARE\n\n\nj\nj\nyank\n¬†\n ä…ô\n9\nCURE\n\n\nx\nx\nloch\n¬†\n√¶\nc\ntimbre\n\n\nh\nh\nhad\n¬†\n…ëÃÉÀê\nq\nd√©tente\n\n\nw\nw\nwet\n¬†\n√¶ÃÉÀê\n0\nlingerie\n\n\n ß\nJ\ncheap\n¬†\n…íÃÉÀê\n~\nbouillon\n\n\n §\n_\njeep\n¬†\n¬†\n¬†\n¬†\n\n\n≈ãÃ©\nC\nbacon\n¬†\n¬†\n¬†\n¬†\n\n\nmÃ©\nF\nidealism\n¬†\n¬†\n¬†-\nsyllable separator\n\n\nnÃ©\nH\nburden\n¬†\n¬†\n¬†'\nprimary stress\n\n\nlÃ©\nP\ndangle\n¬†\n¬†\n¬†\"\nsecondary stress"
  },
  {
    "objectID": "howto/transcription/index.html",
    "href": "howto/transcription/index.html",
    "title": "Transcription Guidelines",
    "section": "",
    "text": "There are various tools available for transcribing recordings, and LaBB-CAT supports the transcription file formats used by the most commonly used tools. Each of these tools has its own capabilities for specifying speakers and meta data, and adding annotations.\nBeyond the specific tool and file format used for transcription, there are some general principles that can facilitate subsequent processing of speech data in LaBB-CAT.\n\n\nMany automatic annotation tasks involve looking up standard dictionaries, and words that are not found are not annotated, so it‚Äôs important to use standard spelling where possible.\n\nUse conventional spelling, and if you are unsure of how to spell something, look it up in a dictionary, or on a map.\nWrite all numbers out in full, with spaces instead of hyphens - e.g.\n\n\\(\\times\\) ‚Äú1984‚Äù\n\\(\\times\\) ‚Äúnineteen-eighty-four‚Äù\n\\(\\checkmark\\) ‚Äúnineteen eighty four‚Äù\n\nWhen abbreviations are used, use capital letters with spaces in between each letter if each letter is said separately, otherwise use capitals with no spaces - e.g.\n\n\\(\\times\\) ‚ÄúNSA‚Äù\n\\(\\times\\) ‚ÄúN A S A‚Äù\n\\(\\checkmark\\) ‚ÄúN S A‚Äù\n\\(\\checkmark\\) ‚ÄúNASA‚Äù\n\nAll words should be spelt out in full, like ‚Äúand‚Äù and ‚Äúsuppose‚Äù. Final gs and ds should not be dropped from words even if that‚Äôs what the speaker says - e.g.\n\n\\(\\times\\) ‚Äúskippin‚Äô an‚Äô jumpin‚Äô an ol‚Äô rope‚Äù\n\\(\\checkmark\\) ‚Äúskipping and jumping an old rope‚Äù\n\nA single word should always be spelt as an entire word, even if there is a pause between syllables.\nDon‚Äôt tidy up the speech. Leave in the repetitions, fillers and errors.\n\nThere may be a limited set of shortened words and contractions defined, which is fine as long as they‚Äôre consistently used - e.g.¬†if you use ‚Äúcos‚Äù as a shortened version of ‚Äúbecause‚Äù, always spell it ‚Äúcos‚Äù, and never ‚Äúcause‚Äù, nor ‚Äú‚Äôcause‚Äù, nor ‚Äúcoz‚Äù. For example:\n\n\n\ngonna\nsorta\ncos\nkinda\ngotta\ndunno\nwanna\n\n\n\nyip\nyeah\nokay\nuh huh\ngee\njeez\n\n\n\n\n\n\n\n\n\nNoteFillers in SALT Transcripts\n\n\n\n\n\nSALT transcription guidelines include their own set of standardised spellings for interjections and fillers. If you‚Äôre working with SALT transcripts, you should use these instead:\n\n\n\nhey\nhmm\nhuh\nmhm\nnope\noops\noopsy\n\n\n\nok\npsst\nssh\nuhhuh (indicating ‚Äúyes‚Äù)\nuhuh (indicating ‚Äúno‚Äù)\nyeah\nyep\n\n\n\n\n\n\n\n\n\nIt‚Äôs important to be consistent with the spelling of filled pauses:\n\nah\ner\num\nmmm\n\nThe spelling of the last of these, with three m‚Äôs, is recommended because if it‚Äôs spelled with one m - ‚Äúm‚Äù - this can match the name of the letter ‚ÄúM‚Äù in the dictionary, so the pronunciation can be tagged as /Œµm/, and if it‚Äôs spelled with two m‚Äôs - ‚Äúmm‚Äù - this sometimes matches an alternative spelling of the word ‚Äúmillimeter‚Äù, so the pronunciation can be tagged /'m…™-l…™-\"mi-t…ô/.\nUnfilled pauses can be transcribed with a hyphen surrounded by whitespace; some modules use such pause information to help with automatic annotation (e.g.¬†force-alginment with HTK benefits with pause annotations like this) - e.g.\n\n\\(\\times\\) ‚Äústop-before you begin‚Äù\n\\(\\checkmark\\) ‚Äústop - before you begin‚Äù\n\nIncomplete words should marked with a tilde ~ (not a hyphen which may be interpreted as a pause) at the end of the word e.g.:\n\n\\(\\times\\) ‚Äúhesi-‚Äù\n\\(\\checkmark\\) ‚Äúhesi~‚Äù\n\nFor very short hesitations - ‚Äúb~ bu~ but‚Äù - some pronunciation module can infer a pronunciation for such words, without the need for a manual pronunciation tag.\n\n\n\nSome transcription tools allow tagging individual words with extra information, but others do not. For these, the only way to, for example, tag a word with its pronunciation, is to use transcription conventions.\nLaBB-CAT optionally supports the following transcription conventions, if you are using ELAN transcripts, Praat TextGrids, or plain text files for transcripts:\n\nThe pronunciation of an invented word or a hesitation can be marked by using square brackets immediately after the word (i.e.¬†with no space between the word and the annotation) - e.g.\n‚Äústut~[stVt]‚Äù\nThe full form standard form of a hesitation (or other word with non-standard spelling) can be marked by using parentheses immediately after the word (i.e.¬†with no space between the word and the annotation) - e.g.\n‚Äústut~[stVt](stutter)‚Äù\nNoises can be annotated using square brackets surrounded by white space, e.g.\n‚Äúnow [tongue click] where were we‚Äù\nComments can be added by using curly braces surrounded by white space, e.g.\n‚ÄúIt hit me about here {points to temple}‚Äù\n\n\n\n\nSome processes, like forced alignment, involve processing individual utterances in the recording, which correspond to lines of text in many transcription systems. Very long or very short utterances can be difficult to process.\nIdeally, each line in a transcript should be 5 to 15 words long, and line breaks should be made where there are pauses in speech.\nSome annotation tools allow for marking periods of simultaneous speech - i.e.¬†periods during which there‚Äôs more than one person speaking. These periods should be aligned as accurately as possible, because some automatic processing (e.g.¬†forced alignment) ignore simultaneous speech; short simultaneous-speech utterances ensure that as little speech as possible is ignored.",
    "crumbs": [
      "How-to",
      "Transcription"
    ]
  },
  {
    "objectID": "howto/transcription/index.html#spelling",
    "href": "howto/transcription/index.html#spelling",
    "title": "Transcription Guidelines",
    "section": "",
    "text": "Many automatic annotation tasks involve looking up standard dictionaries, and words that are not found are not annotated, so it‚Äôs important to use standard spelling where possible.\n\nUse conventional spelling, and if you are unsure of how to spell something, look it up in a dictionary, or on a map.\nWrite all numbers out in full, with spaces instead of hyphens - e.g.\n\n\\(\\times\\) ‚Äú1984‚Äù\n\\(\\times\\) ‚Äúnineteen-eighty-four‚Äù\n\\(\\checkmark\\) ‚Äúnineteen eighty four‚Äù\n\nWhen abbreviations are used, use capital letters with spaces in between each letter if each letter is said separately, otherwise use capitals with no spaces - e.g.\n\n\\(\\times\\) ‚ÄúNSA‚Äù\n\\(\\times\\) ‚ÄúN A S A‚Äù\n\\(\\checkmark\\) ‚ÄúN S A‚Äù\n\\(\\checkmark\\) ‚ÄúNASA‚Äù\n\nAll words should be spelt out in full, like ‚Äúand‚Äù and ‚Äúsuppose‚Äù. Final gs and ds should not be dropped from words even if that‚Äôs what the speaker says - e.g.\n\n\\(\\times\\) ‚Äúskippin‚Äô an‚Äô jumpin‚Äô an ol‚Äô rope‚Äù\n\\(\\checkmark\\) ‚Äúskipping and jumping an old rope‚Äù\n\nA single word should always be spelt as an entire word, even if there is a pause between syllables.\nDon‚Äôt tidy up the speech. Leave in the repetitions, fillers and errors.\n\nThere may be a limited set of shortened words and contractions defined, which is fine as long as they‚Äôre consistently used - e.g.¬†if you use ‚Äúcos‚Äù as a shortened version of ‚Äúbecause‚Äù, always spell it ‚Äúcos‚Äù, and never ‚Äúcause‚Äù, nor ‚Äú‚Äôcause‚Äù, nor ‚Äúcoz‚Äù. For example:\n\n\n\ngonna\nsorta\ncos\nkinda\ngotta\ndunno\nwanna\n\n\n\nyip\nyeah\nokay\nuh huh\ngee\njeez\n\n\n\n\n\n\n\n\n\nNoteFillers in SALT Transcripts\n\n\n\n\n\nSALT transcription guidelines include their own set of standardised spellings for interjections and fillers. If you‚Äôre working with SALT transcripts, you should use these instead:\n\n\n\nhey\nhmm\nhuh\nmhm\nnope\noops\noopsy\n\n\n\nok\npsst\nssh\nuhhuh (indicating ‚Äúyes‚Äù)\nuhuh (indicating ‚Äúno‚Äù)\nyeah\nyep",
    "crumbs": [
      "How-to",
      "Transcription"
    ]
  },
  {
    "objectID": "howto/transcription/index.html#disfluencies",
    "href": "howto/transcription/index.html#disfluencies",
    "title": "Transcription Guidelines",
    "section": "",
    "text": "It‚Äôs important to be consistent with the spelling of filled pauses:\n\nah\ner\num\nmmm\n\nThe spelling of the last of these, with three m‚Äôs, is recommended because if it‚Äôs spelled with one m - ‚Äúm‚Äù - this can match the name of the letter ‚ÄúM‚Äù in the dictionary, so the pronunciation can be tagged as /Œµm/, and if it‚Äôs spelled with two m‚Äôs - ‚Äúmm‚Äù - this sometimes matches an alternative spelling of the word ‚Äúmillimeter‚Äù, so the pronunciation can be tagged /'m…™-l…™-\"mi-t…ô/.\nUnfilled pauses can be transcribed with a hyphen surrounded by whitespace; some modules use such pause information to help with automatic annotation (e.g.¬†force-alginment with HTK benefits with pause annotations like this) - e.g.\n\n\\(\\times\\) ‚Äústop-before you begin‚Äù\n\\(\\checkmark\\) ‚Äústop - before you begin‚Äù\n\nIncomplete words should marked with a tilde ~ (not a hyphen which may be interpreted as a pause) at the end of the word e.g.:\n\n\\(\\times\\) ‚Äúhesi-‚Äù\n\\(\\checkmark\\) ‚Äúhesi~‚Äù\n\nFor very short hesitations - ‚Äúb~ bu~ but‚Äù - some pronunciation module can infer a pronunciation for such words, without the need for a manual pronunciation tag.",
    "crumbs": [
      "How-to",
      "Transcription"
    ]
  },
  {
    "objectID": "howto/transcription/index.html#word-tags-and-other-in-situ-annotations",
    "href": "howto/transcription/index.html#word-tags-and-other-in-situ-annotations",
    "title": "Transcription Guidelines",
    "section": "",
    "text": "Some transcription tools allow tagging individual words with extra information, but others do not. For these, the only way to, for example, tag a word with its pronunciation, is to use transcription conventions.\nLaBB-CAT optionally supports the following transcription conventions, if you are using ELAN transcripts, Praat TextGrids, or plain text files for transcripts:\n\nThe pronunciation of an invented word or a hesitation can be marked by using square brackets immediately after the word (i.e.¬†with no space between the word and the annotation) - e.g.\n‚Äústut~[stVt]‚Äù\nThe full form standard form of a hesitation (or other word with non-standard spelling) can be marked by using parentheses immediately after the word (i.e.¬†with no space between the word and the annotation) - e.g.\n‚Äústut~[stVt](stutter)‚Äù\nNoises can be annotated using square brackets surrounded by white space, e.g.\n‚Äúnow [tongue click] where were we‚Äù\nComments can be added by using curly braces surrounded by white space, e.g.\n‚ÄúIt hit me about here {points to temple}‚Äù",
    "crumbs": [
      "How-to",
      "Transcription"
    ]
  },
  {
    "objectID": "howto/transcription/index.html#utteranceslines",
    "href": "howto/transcription/index.html#utteranceslines",
    "title": "Transcription Guidelines",
    "section": "",
    "text": "Some processes, like forced alignment, involve processing individual utterances in the recording, which correspond to lines of text in many transcription systems. Very long or very short utterances can be difficult to process.\nIdeally, each line in a transcript should be 5 to 15 words long, and line breaks should be made where there are pauses in speech.\nSome annotation tools allow for marking periods of simultaneous speech - i.e.¬†periods during which there‚Äôs more than one person speaking. These periods should be aligned as accurately as possible, because some automatic processing (e.g.¬†forced alignment) ignore simultaneous speech; short simultaneous-speech utterances ensure that as little speech as possible is ignored.",
    "crumbs": [
      "How-to",
      "Transcription"
    ]
  },
  {
    "objectID": "howto/transcription/salt.html",
    "href": "howto/transcription/salt.html",
    "title": "SALT Transcripts",
    "section": "",
    "text": "‚ÄúSystematic Analysis of Language Transcripts‚Äù software (SALT) is a system designed, at the University of Wisconsin-Madison primarily by Jon F. Miller, for speech/language therapists to help them perform Language Sample Analysis (LSA).\nSALT transcripts are essentially plain-text documents that use predefined transcription conventions that cover specification meta-data, as well as textual annotations, as seen in Figure¬†1.\n\n\n\n\n\n\nFigure¬†1: Example of SALT transcript, including a meta-data header, Child/Examiner speaker turns, and morpheme/error annotations. (Times are typically in whole seconds, but it‚Äôs recommended to have more granular synchronization, as seen in Figure¬†4)\n\n\n\nLaBB-CAT recognises and imports SALT transcripts (files ending in .slt). The transcript conventions cover a closed set of meta-data and annotation types, and many of the defined annotations can be imported into LaBB-CAT, as long as attributes and layers are pre-defined in LaBB-CAT in order to receive the annotations. If layers are not specifed in LaBB-CAT, transcripts can still be imported, but annotation data is necessarily lost during import.\nLinks between SALT annotations and LaBB-CAT layers must be explicitly configured in LaBB-CAT i.e.\n\nYou must create appropriate word/phrase layers and participant/transcript attributes to hold the SALT annotations you want to parse out of the transcripts.\nThen you must select the converters menu option, and press the configuration button for the SALT transcript converter and specify/save the settings, as shown in Figure¬†2. (There will be two SALT options in the list, one for importing SALT transcripts, and one for exporting them, but they both use the same settings, so pressing the configuration button for either will have the same effect.)\n\n\n\n\n\n\n\nFigure¬†2: Example of a SALT converter configuration in LaBB-CAT\n\n\n\n\n\nThe following SALT headers can be imported as participant or transcript attributes into LaBB-CAT:\n\nParticipantId\nLanguage\nGender\nDob - date of birth\nDoe - date of sample\nEthnicity\nContext - sampling context\nSubgroup - Subgroup/story\nCollect - collection point number\nLocation - place of sample\n\nThe assumed format for date values (Dob/Doe) ‚Äì i.e.¬†whether month or day comes first, and whether the year has two or four digits ‚Äì is specified by the SALT converter‚Äôs Date format setting. However, dates are stored by LaBB-CAT in ISO format - i.e.¬†yyyy-MM-dd\n\n\n\nThe following annotations on words can be extracted into word layers if desired (when setting up each word layer to receive the tags, ensure with ‚ÄòAlignment‚Äô set to None):\n\nRoot - word stems marked with |, e.g.¬†wented|went\nBound Morpheme - affixes marked with / e.g.¬†ring/ing, wante/*ed\nPartial Word - cutoffs suffixed with * e.g.¬†ever* everybody\n\n\n\n\nThe following annotations, which can span multiple words, or do not apply directly to words, can be extracted into phrase layers if desired:\n\nC-Unit - i.e.¬†divisions into utterance based on where full-stops/periods and other specific punctuation appear in the transcript\nParenthetical - enclosed in (( and ))\ne.g.¬†the boy ((I can/'t remember his name)) left\nProper Name - multi-word names delimited by _\ne.g.¬†Mr_Jones\n‚Äì these are split into individual tokens where the _ delimiters occur, which are tagged on the phrase layer specified by the Proper Name Layer setting, if specified.\nRepetition - repetitions delimited by _\ne.g.¬†heaps_and_heaps|heaps\n‚Äì similarly these are tokenised on _ and the multiple tokens are tagged on the selected phrase layer.\nError - tags in square brackets, where the tag starts E\ne.g.¬†he[EP:she] wented|went[EO:went]\n‚Äì these can encompass multiple words, e.g utterance errors [EU]\nCode - tags in square brackets, where the tag doesn‚Äôt start with E\ne.g.¬†it's your turn to tell the story X[REDACTED]\nSound effect - prefixed by %\ne.g.¬†%yip_yip went Schnitzel_von_Crumm\nPause - prefixed by :\ne.g.¬†um :02 because\nMaze - false starts, repetitions, etc. enclosed in ( and )\ne.g.¬†(That and) and his mum\nOmission - missing words prefixed by *\ne.g call/ing *on the phone\nComment - enclosed in { and }\ne.g.¬†{pretends to eat}\nThere is a system span layer that can be used to extract comments.\nbackground noises, etc. - comments that start with a single word followed by a colon can be extracted into their own span layer e.g.¬†comments like {NOISE:phone ringing} can be mapped at upload time to LaBB-CAT‚Äôs noise layer.\n\n\n\n\nEach SALT transcript starts by declaring the IDs of the speakers, the first speaker being the ‚Äòtarget speaker‚Äô. This translates to LaBB-CAT‚Äôs concept of a ‚Äòmain participant‚Äô, and there is a setting called Target Participant Layer making this link explicit.\nAs previously mentioned, the expected format of dates is specified by the Date format setting. Options are:\n\nM/d/yyyy - month first, four digit year\nd/M/yyyy - day first, four digit year\nM/d/yy - month first, two digit year\nd/M/yy - daye first, two digit year\n\nAlso, all of the above annotation parsing can be disabled by un-ticking the Parse Inline Conventions check box. If this is done, then no annotation parsing is done by LaBB-CAT, and all words, codes, pauses, etc. will appear as-is in the word layer, no annotations or tags will be added, and the text on the word layer will not be normalized.\n\n\n\nUnless parsing of inline conventions is disabled, the word token spellings are normalized during input, so that the resulting word orthographies are the normal spellings that might be found in dictionaries, recognised by syntactic parsers, etc.\nThis is to ensure that SALT transcripts can be automatically annotated in LaBB-CAT in the same way that other formats can be.\nFor example, an utterance in a SALT transcript might look like this:\nBut he[EP:she] was ring/ing on the phone.\nIn LaBB-CAT, after upload, this utterance will look like this:\nBut he was ringing on the phone.\ni.e.¬†the slashes marking morphem boundaries, and any comments, codes, and any other annotations are stripped out, and where possible the spelling are normalised (e.g.¬†smile/ing will become smiling).\nIf layers have been configured to receive the annotations, then no information is lost; it‚Äôs parsed out into separate layers in LaBB-CAT, as seen in Figure¬†3.\n\n\n\n\n\n\nFigure¬†3: Error and bound morpheme tags have been extracted out on to corresponding annotation layers in LaBB-CAT\n\n\n\n\n\n\nIt is imperative that each utterance is bounded by a synchronization time mark - i.e.¬†a line starting with : which specifies the time the utterance occured in the recording.\nLaBB-CAT needs utterance start/end times in order to synchronized playback, and also perform automatic annotations that relate the transcript to the audio, like forced alignment.\nThe SALT transcript conventions generally include examples of time synchronization to the nearest second. However, this is often not accurate enough for some LaBB-CAT processing, and specifying times accurate to the millisecond are recommended, as shown in Figure¬†4.\n\n\n\n\n\n\nFigure¬†4: Utterance synchronization to the milliscond is recommended",
    "crumbs": [
      "How-to",
      "Transcription",
      "SALT Transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/salt.html#meta-data-header",
    "href": "howto/transcription/salt.html#meta-data-header",
    "title": "SALT Transcripts",
    "section": "",
    "text": "The following SALT headers can be imported as participant or transcript attributes into LaBB-CAT:\n\nParticipantId\nLanguage\nGender\nDob - date of birth\nDoe - date of sample\nEthnicity\nContext - sampling context\nSubgroup - Subgroup/story\nCollect - collection point number\nLocation - place of sample\n\nThe assumed format for date values (Dob/Doe) ‚Äì i.e.¬†whether month or day comes first, and whether the year has two or four digits ‚Äì is specified by the SALT converter‚Äôs Date format setting. However, dates are stored by LaBB-CAT in ISO format - i.e.¬†yyyy-MM-dd",
    "crumbs": [
      "How-to",
      "Transcription",
      "SALT Transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/salt.html#word-tag-annotations",
    "href": "howto/transcription/salt.html#word-tag-annotations",
    "title": "SALT Transcripts",
    "section": "",
    "text": "The following annotations on words can be extracted into word layers if desired (when setting up each word layer to receive the tags, ensure with ‚ÄòAlignment‚Äô set to None):\n\nRoot - word stems marked with |, e.g.¬†wented|went\nBound Morpheme - affixes marked with / e.g.¬†ring/ing, wante/*ed\nPartial Word - cutoffs suffixed with * e.g.¬†ever* everybody",
    "crumbs": [
      "How-to",
      "Transcription",
      "SALT Transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/salt.html#other-in-situ-annotations",
    "href": "howto/transcription/salt.html#other-in-situ-annotations",
    "title": "SALT Transcripts",
    "section": "",
    "text": "The following annotations, which can span multiple words, or do not apply directly to words, can be extracted into phrase layers if desired:\n\nC-Unit - i.e.¬†divisions into utterance based on where full-stops/periods and other specific punctuation appear in the transcript\nParenthetical - enclosed in (( and ))\ne.g.¬†the boy ((I can/'t remember his name)) left\nProper Name - multi-word names delimited by _\ne.g.¬†Mr_Jones\n‚Äì these are split into individual tokens where the _ delimiters occur, which are tagged on the phrase layer specified by the Proper Name Layer setting, if specified.\nRepetition - repetitions delimited by _\ne.g.¬†heaps_and_heaps|heaps\n‚Äì similarly these are tokenised on _ and the multiple tokens are tagged on the selected phrase layer.\nError - tags in square brackets, where the tag starts E\ne.g.¬†he[EP:she] wented|went[EO:went]\n‚Äì these can encompass multiple words, e.g utterance errors [EU]\nCode - tags in square brackets, where the tag doesn‚Äôt start with E\ne.g.¬†it's your turn to tell the story X[REDACTED]\nSound effect - prefixed by %\ne.g.¬†%yip_yip went Schnitzel_von_Crumm\nPause - prefixed by :\ne.g.¬†um :02 because\nMaze - false starts, repetitions, etc. enclosed in ( and )\ne.g.¬†(That and) and his mum\nOmission - missing words prefixed by *\ne.g call/ing *on the phone\nComment - enclosed in { and }\ne.g.¬†{pretends to eat}\nThere is a system span layer that can be used to extract comments.\nbackground noises, etc. - comments that start with a single word followed by a colon can be extracted into their own span layer e.g.¬†comments like {NOISE:phone ringing} can be mapped at upload time to LaBB-CAT‚Äôs noise layer.",
    "crumbs": [
      "How-to",
      "Transcription",
      "SALT Transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/salt.html#other-settings",
    "href": "howto/transcription/salt.html#other-settings",
    "title": "SALT Transcripts",
    "section": "",
    "text": "Each SALT transcript starts by declaring the IDs of the speakers, the first speaker being the ‚Äòtarget speaker‚Äô. This translates to LaBB-CAT‚Äôs concept of a ‚Äòmain participant‚Äô, and there is a setting called Target Participant Layer making this link explicit.\nAs previously mentioned, the expected format of dates is specified by the Date format setting. Options are:\n\nM/d/yyyy - month first, four digit year\nd/M/yyyy - day first, four digit year\nM/d/yy - month first, two digit year\nd/M/yy - daye first, two digit year\n\nAlso, all of the above annotation parsing can be disabled by un-ticking the Parse Inline Conventions check box. If this is done, then no annotation parsing is done by LaBB-CAT, and all words, codes, pauses, etc. will appear as-is in the word layer, no annotations or tags will be added, and the text on the word layer will not be normalized.",
    "crumbs": [
      "How-to",
      "Transcription",
      "SALT Transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/salt.html#orthography-normalization",
    "href": "howto/transcription/salt.html#orthography-normalization",
    "title": "SALT Transcripts",
    "section": "",
    "text": "Unless parsing of inline conventions is disabled, the word token spellings are normalized during input, so that the resulting word orthographies are the normal spellings that might be found in dictionaries, recognised by syntactic parsers, etc.\nThis is to ensure that SALT transcripts can be automatically annotated in LaBB-CAT in the same way that other formats can be.\nFor example, an utterance in a SALT transcript might look like this:\nBut he[EP:she] was ring/ing on the phone.\nIn LaBB-CAT, after upload, this utterance will look like this:\nBut he was ringing on the phone.\ni.e.¬†the slashes marking morphem boundaries, and any comments, codes, and any other annotations are stripped out, and where possible the spelling are normalised (e.g.¬†smile/ing will become smiling).\nIf layers have been configured to receive the annotations, then no information is lost; it‚Äôs parsed out into separate layers in LaBB-CAT, as seen in Figure¬†3.\n\n\n\n\n\n\nFigure¬†3: Error and bound morpheme tags have been extracted out on to corresponding annotation layers in LaBB-CAT",
    "crumbs": [
      "How-to",
      "Transcription",
      "SALT Transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/salt.html#synchronization",
    "href": "howto/transcription/salt.html#synchronization",
    "title": "SALT Transcripts",
    "section": "",
    "text": "It is imperative that each utterance is bounded by a synchronization time mark - i.e.¬†a line starting with : which specifies the time the utterance occured in the recording.\nLaBB-CAT needs utterance start/end times in order to synchronized playback, and also perform automatic annotations that relate the transcript to the audio, like forced alignment.\nThe SALT transcript conventions generally include examples of time synchronization to the nearest second. However, this is often not accurate enough for some LaBB-CAT processing, and specifying times accurate to the millisecond are recommended, as shown in Figure¬†4.\n\n\n\n\n\n\nFigure¬†4: Utterance synchronization to the milliscond is recommended",
    "crumbs": [
      "How-to",
      "Transcription",
      "SALT Transcripts"
    ]
  },
  {
    "objectID": "howto/transcription/praat.html",
    "href": "howto/transcription/praat.html",
    "title": "Transcribing with Praat",
    "section": "",
    "text": "If you already have Praat TextGrids that are transcripts of recordings, you may be able to upload them directly into LaBB-CAT, instead of converting them to Transcriber files.\n\n\nThere are several conditions that your TextGrids must meet in order to use them as source transcripts for Praat:\n\nThey must be transcripts - i.e.¬†each must contain at least one tier that contains intervals containing the words uttered by the speaker(s) in ordinary orthographic spelling.\nIn particular, if the TextGrid contains only sparse, isolated intervals that code individual words or phonemes, but no transcription of whole utterances, then it cannot be used as a transcript for uploading directly into LaBB-CAT (but once you have a full transcript for the recording, you may be able to upload the coded annotations in your original TextGrid)\nThe speaker of each utterance must be systematically identifiable - possible ways of doing this are illustrated below.\nIn addition to utterance interval tiers, the TextGrid may contain other tiers that have intervals marking noises, comments, and other annotations. If you want to import these into LaBB-CAT, then you must first ensure that, for each such non-transcription tier, there is a layer in LaBB-CAT already created, ready to receive the annotations. It‚Äôs best to make sure that the TextGrid tier name and the LaBB-CAT layer‚Äôs ‚Äòname‚Äô are the same.\n(there are already LaBB-CAT layers for ‚Äònoise‚Äô and ‚Äòcomment‚Äô, so you don‚Äôt need to create those)\n\n\n\n\nAs mentioned above, the speaker of each utterance in the TextGrid must be systematically identifiable. There are two possible structures for your TextGrid to facilitate this:\n\nOne tier per speaker, tier name = speaker name\nTurns tier and utterances tier, turns tier containing speaker names\n\n\n\nYou may have one tier for each speaker. In this case, each interval marks the start/end times of each utterance (equivalent to each line in Transcriber transcripts), and the name of the tier is the name of the speaker, as shown in Figure¬†1.\nWith this structure, you can annotate simultaneous speech.\n\n\n\n\n\n\nFigure¬†1: Each tier corresponds to the transcript of one speaker\n\n\n\n\n\n\nAlternatively, your TextGrid may have two tiers, one called turns and the other called utterances. The turns tier marks the start/end times of speaker turns, and contains the names of the speakers speaking, and the utterances tier contains the actual words spoken by the speaker speaking at that time, as shown in Figure¬†2.\nYou can have multiple utterances per turn, but you must ensure that the first utterance starts at the same time as the start of its turn, and that the last utterance ends at the same time as the end of its turn.\nWith this structure, you cannot annotate simultaneous speech.\n\n\n\n\n\n\nFigure¬†2: The turns tier labels the current speaker, and the utterances tier contains utterance transcription\n\n\n\n\n\n\n\nWhen uploading transcripts that are TextGrid, use exactly the same upload page as for all other formats - i.e.¬†select upload on the menu, and then select upload transcripts.\n(Make sure you don‚Äôt select the upload textgrid annotations option on the upload page - this is for uploading annotations into transcripts that already exist in the LaBB-CAT database)\nIf your TextGrids contain tiers that are annotations rather than utterances or turns, and you want to import those annotations, then you must first ensure that matching layers exist in LaBB-CAT. Most likely you will want to create span layers, so select that option on the menu, and when you create new layers, set the alignment of the layer to ‚ÄòTime Stamps‚Äô for point tiers, and ‚ÄòTime Intervals‚Äô for interval tiers.\nOnce you‚Äôre sure all the layers you need exist, the steps are:\n\nSelect upload on the LaBB-CAT menu.\nSelect upload transcripts.\nPress Choose File on the left and select the transcript .TextGrid file.\nOn the right the text ‚ÄúPraat TextGrid‚Äù should appear.\nPress the Choose File to the right of this to select the media file(s) that correspond to the transcript.\nPress Upload.\nNow you must specify how LaBB-CAT should interpret the tiers. On the left are listed the tiers in the TextGrid, and for each you can specify a LaBB-CAT layer for it.\n\nFor tiers that contain transcriptions, select the utterances option, and if you‚Äôre using the ‚Äúturns tier and utterances tier‚Äù structure described above, ensure that the turns tier has the turns layer selected.\nFor tiers that contain annotations for noises or other events, select the appropriate layer.\nFor tiers that you don‚Äôt want to import, select *[none]\n\n\n\n\n\n\n\n\nFigure¬†3: Mapping TextGrid tiers to LaBB-CAT layers\n\n\n\nIn Figure¬†3, the crosscheck tier is not being imported, the annotations on the noise tier will be inserted into the noise layer in LaBB-CAT, and the interviewer and Agnes Shacklock tiers contain the transcriptions of the speech of those two speakers, so they are mapped to the utterances layer in LaBB-CAT.\n\nClick Set Mappings, and the data from the TextGrids will be imported into LaBB-CAT.\n\n\n\n\nPraat has no direct mechanism for marking non-speech annotations in their position within the transcript text. However, LaBB-CAT supports the use of textual conventions in various ways to make certain annotations:\n\nTo tag a word with its pronunciation, enter the pronunciation (with no spaces) in square brackets, directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶this was at Wingatui[wIN@tui]‚Ä¶\nTo tag a word with its full orthography (if the transcript doesn‚Äôt include it), enter the orthography (with no spaces) in round parentheses, directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶I can't remem~(remember)‚Ä¶\nTo insert a noise annotation within the text, enclose it in square brackets (surrounded by spaces so it‚Äôs not taken as a pronunciation annotation), e.g.:\n‚Ä¶sometimes me [laughs] not always but sometimes‚Ä¶\nTo insert a comment annotation within the text, enclose it in curly braces (surrounded by spaces), e.g.:\n‚Ä¶beautifully warm {softly} but its‚Ä¶\n\nDuring upload, these annotations will be extracted from the transcript text and inserted into corresponding LaBB-CAT layers.",
    "crumbs": [
      "How-to",
      "Transcription",
      "Transcribing with Praat"
    ]
  },
  {
    "objectID": "howto/transcription/praat.html#prerequisites",
    "href": "howto/transcription/praat.html#prerequisites",
    "title": "Transcribing with Praat",
    "section": "",
    "text": "There are several conditions that your TextGrids must meet in order to use them as source transcripts for Praat:\n\nThey must be transcripts - i.e.¬†each must contain at least one tier that contains intervals containing the words uttered by the speaker(s) in ordinary orthographic spelling.\nIn particular, if the TextGrid contains only sparse, isolated intervals that code individual words or phonemes, but no transcription of whole utterances, then it cannot be used as a transcript for uploading directly into LaBB-CAT (but once you have a full transcript for the recording, you may be able to upload the coded annotations in your original TextGrid)\nThe speaker of each utterance must be systematically identifiable - possible ways of doing this are illustrated below.\nIn addition to utterance interval tiers, the TextGrid may contain other tiers that have intervals marking noises, comments, and other annotations. If you want to import these into LaBB-CAT, then you must first ensure that, for each such non-transcription tier, there is a layer in LaBB-CAT already created, ready to receive the annotations. It‚Äôs best to make sure that the TextGrid tier name and the LaBB-CAT layer‚Äôs ‚Äòname‚Äô are the same.\n(there are already LaBB-CAT layers for ‚Äònoise‚Äô and ‚Äòcomment‚Äô, so you don‚Äôt need to create those)",
    "crumbs": [
      "How-to",
      "Transcription",
      "Transcribing with Praat"
    ]
  },
  {
    "objectID": "howto/transcription/praat.html#textgrid-transcript-structures",
    "href": "howto/transcription/praat.html#textgrid-transcript-structures",
    "title": "Transcribing with Praat",
    "section": "",
    "text": "As mentioned above, the speaker of each utterance in the TextGrid must be systematically identifiable. There are two possible structures for your TextGrid to facilitate this:\n\nOne tier per speaker, tier name = speaker name\nTurns tier and utterances tier, turns tier containing speaker names\n\n\n\nYou may have one tier for each speaker. In this case, each interval marks the start/end times of each utterance (equivalent to each line in Transcriber transcripts), and the name of the tier is the name of the speaker, as shown in Figure¬†1.\nWith this structure, you can annotate simultaneous speech.\n\n\n\n\n\n\nFigure¬†1: Each tier corresponds to the transcript of one speaker\n\n\n\n\n\n\nAlternatively, your TextGrid may have two tiers, one called turns and the other called utterances. The turns tier marks the start/end times of speaker turns, and contains the names of the speakers speaking, and the utterances tier contains the actual words spoken by the speaker speaking at that time, as shown in Figure¬†2.\nYou can have multiple utterances per turn, but you must ensure that the first utterance starts at the same time as the start of its turn, and that the last utterance ends at the same time as the end of its turn.\nWith this structure, you cannot annotate simultaneous speech.\n\n\n\n\n\n\nFigure¬†2: The turns tier labels the current speaker, and the utterances tier contains utterance transcription",
    "crumbs": [
      "How-to",
      "Transcription",
      "Transcribing with Praat"
    ]
  },
  {
    "objectID": "howto/transcription/praat.html#uploading-textgrid-transcripts",
    "href": "howto/transcription/praat.html#uploading-textgrid-transcripts",
    "title": "Transcribing with Praat",
    "section": "",
    "text": "When uploading transcripts that are TextGrid, use exactly the same upload page as for all other formats - i.e.¬†select upload on the menu, and then select upload transcripts.\n(Make sure you don‚Äôt select the upload textgrid annotations option on the upload page - this is for uploading annotations into transcripts that already exist in the LaBB-CAT database)\nIf your TextGrids contain tiers that are annotations rather than utterances or turns, and you want to import those annotations, then you must first ensure that matching layers exist in LaBB-CAT. Most likely you will want to create span layers, so select that option on the menu, and when you create new layers, set the alignment of the layer to ‚ÄòTime Stamps‚Äô for point tiers, and ‚ÄòTime Intervals‚Äô for interval tiers.\nOnce you‚Äôre sure all the layers you need exist, the steps are:\n\nSelect upload on the LaBB-CAT menu.\nSelect upload transcripts.\nPress Choose File on the left and select the transcript .TextGrid file.\nOn the right the text ‚ÄúPraat TextGrid‚Äù should appear.\nPress the Choose File to the right of this to select the media file(s) that correspond to the transcript.\nPress Upload.\nNow you must specify how LaBB-CAT should interpret the tiers. On the left are listed the tiers in the TextGrid, and for each you can specify a LaBB-CAT layer for it.\n\nFor tiers that contain transcriptions, select the utterances option, and if you‚Äôre using the ‚Äúturns tier and utterances tier‚Äù structure described above, ensure that the turns tier has the turns layer selected.\nFor tiers that contain annotations for noises or other events, select the appropriate layer.\nFor tiers that you don‚Äôt want to import, select *[none]\n\n\n\n\n\n\n\n\nFigure¬†3: Mapping TextGrid tiers to LaBB-CAT layers\n\n\n\nIn Figure¬†3, the crosscheck tier is not being imported, the annotations on the noise tier will be inserted into the noise layer in LaBB-CAT, and the interviewer and Agnes Shacklock tiers contain the transcriptions of the speech of those two speakers, so they are mapped to the utterances layer in LaBB-CAT.\n\nClick Set Mappings, and the data from the TextGrids will be imported into LaBB-CAT.",
    "crumbs": [
      "How-to",
      "Transcription",
      "Transcribing with Praat"
    ]
  },
  {
    "objectID": "howto/transcription/praat.html#conventions-for-non-speech-annotations",
    "href": "howto/transcription/praat.html#conventions-for-non-speech-annotations",
    "title": "Transcribing with Praat",
    "section": "",
    "text": "Praat has no direct mechanism for marking non-speech annotations in their position within the transcript text. However, LaBB-CAT supports the use of textual conventions in various ways to make certain annotations:\n\nTo tag a word with its pronunciation, enter the pronunciation (with no spaces) in square brackets, directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶this was at Wingatui[wIN@tui]‚Ä¶\nTo tag a word with its full orthography (if the transcript doesn‚Äôt include it), enter the orthography (with no spaces) in round parentheses, directly following the word (i.e.¬†with no intervening space), e.g.:\n‚Ä¶I can't remem~(remember)‚Ä¶\nTo insert a noise annotation within the text, enclose it in square brackets (surrounded by spaces so it‚Äôs not taken as a pronunciation annotation), e.g.:\n‚Ä¶sometimes me [laughs] not always but sometimes‚Ä¶\nTo insert a comment annotation within the text, enclose it in curly braces (surrounded by spaces), e.g.:\n‚Ä¶beautifully warm {softly} but its‚Ä¶\n\nDuring upload, these annotations will be extracted from the transcript text and inserted into corresponding LaBB-CAT layers.",
    "crumbs": [
      "How-to",
      "Transcription",
      "Transcribing with Praat"
    ]
  },
  {
    "objectID": "howto/aligned-data/index.html",
    "href": "howto/aligned-data/index.html",
    "title": "Aligned Data",
    "section": "",
    "text": "Aligned Data\nCommon tasks that can be done once phones are aligned:\n\nReconstruct syllables and stress\nSpeech rate and articulation rate\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Aligned Data"
    ]
  },
  {
    "objectID": "howto/pos-tagging/index.html",
    "href": "howto/pos-tagging/index.html",
    "title": "Part of Speech Tagging",
    "section": "",
    "text": "Part of Speech Tagging\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB"
  },
  {
    "objectID": "howto/index.html",
    "href": "howto/index.html",
    "title": "How-to",
    "section": "",
    "text": "How-to\nThese pages describe how to achieve various common tasks in LaBB-CAT, including:\n\nInstallation\nTranscription\nPhonemic Tagging\nForced Alignment\n\n‚Ä¶and other options you can see in the menu on the left.\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to"
    ]
  },
  {
    "objectID": "howto/corpus-management/index.html",
    "href": "howto/corpus-management/index.html",
    "title": "Corpus Management",
    "section": "",
    "text": "Corpus Management\n‚Üô Please select a Corpus Management option from the menu on the left.\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Corpus Management"
    ]
  },
  {
    "objectID": "howto/word-frequency/index.html",
    "href": "howto/word-frequency/index.html",
    "title": "Word Frequency",
    "section": "",
    "text": "LaBB-CAT can generate frequency data about your corpus; i.e.¬†count the number of tokens of each word (type) that appears in you transcripts. LaBB-CAT can both\n\nGenerate a list of word types with the token count of each type, and\nTag each token in the corpus with its frequency (token count)\n\nTo do this:\n\nSelect the word layers menu option.\nYou will see a list of word layers.\nThe row of headers at the top of the list is also a form you can fill in to add a new layer.\nFill in the following details:\n\nLayer ID: frequency\nType: Number\nAlignment: None\nManager: Frequency Layer Manager\nGenerate: Always\nDescription: Count of tokens of the same type across all corpora.\n\nPress the New button to add the layer.\nYou will see the layer configuration form. Fill it in with the following details:\n\nSummary: Raw Count\nLayer to summarize: orthography\nScope of Summary: Database\nMain participants only: ticked\nParticipants: unticked\nFilter Layer: unticked\nWord pairs: unticked\nWordPause Markers: (Leave this box empty)\nTranscript types: If you have a word-list or reading trascript type, un-tick it to ensure that your readings don‚Äôt make certain words over-represented in the frequency counts.\nAnnotate tokens: ticked\nIf you want more information about what these options mean, check the online help page by clicking the question-mark icon at the top right of the page. This will provide information about how to break down counts by corpus, by speaker, etc.\n\nPress Save\nPress Regenerate\nYou will see a progress bar moving across the page while the counts are being generated. When it is finished, you will see a message saying Layer complete.\n\nNow each word in each transcript is annotated with the count of the number of instances of that word with the corpus of the transcript. To see what that looks like:\n\nSelect the transcripts menu option.\nClick the name of the first transcript in the list.\nTick the frequency layer.\n\nWhen the transcript reloads, you will see that above each word is a number. That number is the number of times that word appears in the transcript‚Äôs corpus. e.g.¬†if the word ‚Äúand‚Äù has 1743 above it, that means that the word ‚Äúand‚Äù appears in the corpus 1743 times.\n\n\n\nLines of text from transcript, where each word has a number above it representing its frequency\n\n\nThe new word tags are searchable and exportable into CSV results files, just like any other annotations; If you do any search, the CSV Export options dropdown now contains a frequency checkbox that allows you to include the word frequency of the matches as a column in the CSV file.\nIf you have already exported the CSV results previously, and want to insert frequencies into the existing CSV file, you can do this by using the uploads ‚Üí insert data option.\nThe Frequency Layer Manager also keeps a word-list with token counts for each corpus:\n\nSelect the layer managers menu option.\nOn the Frequency Layer Manager row, press the Extensions button.\n(If you have multiple Frequency Layer Manager layers, you will have to select the layer you‚Äôre after from the list, and then press Select. If you have only one Frequency Layer Manager layer, this step is not necessary.)\nPress Export\nSave and open the resulting CSV file.\n\nYou will see an alphabetical list of all the distinct word types in your corpus, and next to each, a count of the number of tokens of that type.\nThis page can also be used to search for target words and list their frequencies directly on the page.\n\n\n\nA search for the pattern\n\n\nThe steps above will give you basic word-form counts across all your data. The Frequency Layer Manager can be used to calculate other frequencies too:\n\nStem/lemma frequencies can be computed if you have tagged each word token with its stem (e.g.¬†using the Porter Stemmer Layer Manager or the CELEX Layer Manager); to do this, specify the stem or lemma layer generated by the other layer manager as the Layer to Summarize for the Frequency Layer Manager.\nIf you have several sub-corpora in your database, you can get frequencies by corpus, by selecting ‚ÄúCorpus‚Äù as the Scope of Summary.\nSimilarly you can get frequencies by speaker, to get information of each speaker‚Äôs vocabulary use, by selecting ‚ÄúSpeaker‚Äù as the Scope of Summary.\nYou can compare frequencies in your corpus against a reference corpus, in order to identify unusually frequent or infrequent words, by selecting Keyness as the Summary option, and then selecting a reference corpus.\nFor this option to work, you must have frequencies from a reference corpus loaded as a dictionary into LaBB-CAT; e.g.¬†if you have installed the CELEX Layer Manager, this includes word-form and lemma frequencies from reference corpora.\n\n\n\n\nKeyness ratings, compared to the Cobuild corpus, listing showing\n\n\n\n\nIf you want word tokens tagged with their individual frequencies, and also want a word-pair frequency list, simply tick the Word Pairs option when you create the word layer to get an extra word-pair list.\nThis does not tag word tokens with bigram frequencies, so you can‚Äôt see the word-pair frequencies in transcript, nor extract them as part of search results files. But it does keep a list of frequencies that can be downloaded separately.\nTo access the word pair frequency list:\n\nSelect the layer managers menu option.\nOn the Frequency Layer ManagerI row, press the Extensions button.\n(If you have multiple Frequency Layer Manager layers, you will have to select the layer you‚Äôre after from the list, and then click Select. If you have only one Frequency Layer Manager layer, this step is not necessary.)\nSelect the Token Pair Counts option:\n\nPress Export\nSave and open the resulting CSV file; you will see there are three columns:\n\nWord1 - the first word in the pair\nWord2 - the second word in the pair\n0 words between - the number of times Word1 is immediately followed by Word2\n\n\nNote that when configuring the layer, next to the Word Pairs checkbox, there‚Äôs a dropdown box with ‚Äòadjacent‚Äô selected by default. This option lets you get frequencies for word pairs that are further apart. e.g.¬†if you select the ‚Äòwithin 1 word‚Äô option, then in addition to the Word1, Word2, and 0 words between columns in the CSV file, you‚Äôll also get a 1 words between column, containing the number of times Word1 is followed by Word2 with one intervening word.\n\n\n\nIf you not only want bigram frequencies in a list, but you also want to token pairs themselves annotated with that bigram‚Äôs frequency, or you‚Äôre interested in frequencies of trigrams or larger word clusters, you can use the Frequency Layer Manager to tag multiple words with their n-gram frequencies.\nFor example, to tag bigrams with their frequencies:\n\nSelect the phrase layers option on the menu (because instead of tagging individual word tokens, we‚Äôre going to create annotations that cover multiple words within the same speaker turn).\nCreate a layer with the following characteristics\n\nLayer ID: bigram\nType: Number\nAlignment: Intervals\nManager: Frequency Layer Manager\nGenerate: Always\nDescription: Bigram frequencies\n\nOn the configuration page, use the following settings:\n\nSummary: Raw Count\nLayer to Summarize: orthography (unless you‚Äôre interested in combinations of stems/lemmas, in which case select your stem/lemma layer)\nScope of Summary: Database\nMain participants only: ticked (unless you want to include interviewer speech or other incidental speakers)\nParticipants: unticked\nFilter Layer: unticked\nN-gram: ticked, and leave the bigram option selected\nUnder Transcript Types you may want to un-tick ‚Äòword list‚Äô or ‚Äòreading‚Äô transcript types, if you have them, in order to only include spontaneous speech\nAnnotate Tokens: ticked\n\nPress Save\nPress Regenerate\n\nOnce the annotation layer has been generated, if you open a transcript and tick the bigram layer you just created, you‚Äôll see that each pair of words has been annotated with a number; the frequency of that bigram:\n\n\n\nBigram frequency annotation\n\n\nFor example, you can see that the bigram ‚Äúfirst one‚Äù appears 7 times in this corpus.\nYou can see that each word token is covered by two annotations; for when it‚Äôs the first word in the bigram, and for when it‚Äôs the second word in the bigram. For example, the token ‚Äúone‚Äù above is at the beginning of the ‚Äúone being‚Äù bigram (labelled ‚Äú1‚Äù), and at the end of the ‚Äúfirst one‚Äù bigram (labelled ‚Äú7‚Äù).\nWhen you extract bigram frequency annotations in search results, you can extract both of these frequencies; when you do a search, expand the CSV Export options to select layers, and tick the bigram layer, you will see a box with a number appear. Enter 2 in the box to extract two bigram annotations per match.\n\n\n\nExtract 2 bigram annotations per match\n\n\nThe resulting CSV file will have two columns for the bigram layer:\n\nTarget bigram 1 - the chronologically first bigram the target is part of (i.e.¬†where it is the second word).\nTarget bigram 2 - the chronologically second bigram the target is part of (i.e.¬†where it is the first word).\n\n(You will also have Target bigram 1 start, Target bigram 1 end, Target bigram 2 start, and Target bigram 2 end columns; these will contain the start and end times of the bigram annotations, but only if the words have been aligned.)",
    "crumbs": [
      "How-to",
      "Word Frequency"
    ]
  },
  {
    "objectID": "howto/word-frequency/index.html#word-pair-frequency-list",
    "href": "howto/word-frequency/index.html#word-pair-frequency-list",
    "title": "Word Frequency",
    "section": "",
    "text": "If you want word tokens tagged with their individual frequencies, and also want a word-pair frequency list, simply tick the Word Pairs option when you create the word layer to get an extra word-pair list.\nThis does not tag word tokens with bigram frequencies, so you can‚Äôt see the word-pair frequencies in transcript, nor extract them as part of search results files. But it does keep a list of frequencies that can be downloaded separately.\nTo access the word pair frequency list:\n\nSelect the layer managers menu option.\nOn the Frequency Layer ManagerI row, press the Extensions button.\n(If you have multiple Frequency Layer Manager layers, you will have to select the layer you‚Äôre after from the list, and then click Select. If you have only one Frequency Layer Manager layer, this step is not necessary.)\nSelect the Token Pair Counts option:\n\nPress Export\nSave and open the resulting CSV file; you will see there are three columns:\n\nWord1 - the first word in the pair\nWord2 - the second word in the pair\n0 words between - the number of times Word1 is immediately followed by Word2\n\n\nNote that when configuring the layer, next to the Word Pairs checkbox, there‚Äôs a dropdown box with ‚Äòadjacent‚Äô selected by default. This option lets you get frequencies for word pairs that are further apart. e.g.¬†if you select the ‚Äòwithin 1 word‚Äô option, then in addition to the Word1, Word2, and 0 words between columns in the CSV file, you‚Äôll also get a 1 words between column, containing the number of times Word1 is followed by Word2 with one intervening word.",
    "crumbs": [
      "How-to",
      "Word Frequency"
    ]
  },
  {
    "objectID": "howto/word-frequency/index.html#n-gram-annotations",
    "href": "howto/word-frequency/index.html#n-gram-annotations",
    "title": "Word Frequency",
    "section": "",
    "text": "If you not only want bigram frequencies in a list, but you also want to token pairs themselves annotated with that bigram‚Äôs frequency, or you‚Äôre interested in frequencies of trigrams or larger word clusters, you can use the Frequency Layer Manager to tag multiple words with their n-gram frequencies.\nFor example, to tag bigrams with their frequencies:\n\nSelect the phrase layers option on the menu (because instead of tagging individual word tokens, we‚Äôre going to create annotations that cover multiple words within the same speaker turn).\nCreate a layer with the following characteristics\n\nLayer ID: bigram\nType: Number\nAlignment: Intervals\nManager: Frequency Layer Manager\nGenerate: Always\nDescription: Bigram frequencies\n\nOn the configuration page, use the following settings:\n\nSummary: Raw Count\nLayer to Summarize: orthography (unless you‚Äôre interested in combinations of stems/lemmas, in which case select your stem/lemma layer)\nScope of Summary: Database\nMain participants only: ticked (unless you want to include interviewer speech or other incidental speakers)\nParticipants: unticked\nFilter Layer: unticked\nN-gram: ticked, and leave the bigram option selected\nUnder Transcript Types you may want to un-tick ‚Äòword list‚Äô or ‚Äòreading‚Äô transcript types, if you have them, in order to only include spontaneous speech\nAnnotate Tokens: ticked\n\nPress Save\nPress Regenerate\n\nOnce the annotation layer has been generated, if you open a transcript and tick the bigram layer you just created, you‚Äôll see that each pair of words has been annotated with a number; the frequency of that bigram:\n\n\n\nBigram frequency annotation\n\n\nFor example, you can see that the bigram ‚Äúfirst one‚Äù appears 7 times in this corpus.\nYou can see that each word token is covered by two annotations; for when it‚Äôs the first word in the bigram, and for when it‚Äôs the second word in the bigram. For example, the token ‚Äúone‚Äù above is at the beginning of the ‚Äúone being‚Äù bigram (labelled ‚Äú1‚Äù), and at the end of the ‚Äúfirst one‚Äù bigram (labelled ‚Äú7‚Äù).\nWhen you extract bigram frequency annotations in search results, you can extract both of these frequencies; when you do a search, expand the CSV Export options to select layers, and tick the bigram layer, you will see a box with a number appear. Enter 2 in the box to extract two bigram annotations per match.\n\n\n\nExtract 2 bigram annotations per match\n\n\nThe resulting CSV file will have two columns for the bigram layer:\n\nTarget bigram 1 - the chronologically first bigram the target is part of (i.e.¬†where it is the second word).\nTarget bigram 2 - the chronologically second bigram the target is part of (i.e.¬†where it is the first word).\n\n(You will also have Target bigram 1 start, Target bigram 1 end, Target bigram 2 start, and Target bigram 2 end columns; these will contain the start and end times of the bigram annotations, but only if the words have been aligned.)",
    "crumbs": [
      "How-to",
      "Word Frequency"
    ]
  },
  {
    "objectID": "howto/install/standalone-windows.html",
    "href": "howto/install/standalone-windows.html",
    "title": "Installing LaBB-CAT on Windows",
    "section": "",
    "text": "LaBB-CAT is a web-browser based application, and is primarily designed to run on a central web server accessible over the internet, so that multiple collaborators can easily work on the same corpus data from different locations.\nHowever, it is possible to have a ‚Äòprivate‚Äô installation of LaBB-CAT which runs directly on your personal computer. These instructions explain how to achieve that.\nOn Windows, before you can install LaBB-CAT, you first must have Java installed.\n\n\nUse the following steps to check whether you already have Java installed.\n\nPress the  Start menu button.\nType Control Panel\nSelect the Control Panel option that appears.\n\nType Java\n\nIf a Java icon appears as shown in Figure¬†1, then you already have Java, and can skip section 2.\n\n\n\n\n\n\nFigure¬†1: Java in the Control Panel\n\n\n\nIf there‚Äôs no Java icon in the Control Panel, follow the steps in the next section to install it.\n\n\n\n\nOpen the Java website in your browser:\nhttps://www.java.com/\nPress the Download Java button.\nPress the Download Java button on the next page and save the resulting installer file.\nClick the installer to run it.\n\n\n\n\n\n\n\nFigure¬†2: The Java installer\n\n\n\n\nPress Install.\n\n\n\n\n\n\n\nFigure¬†3: Java installation is complete\n\n\n\n\nPress Close.\n\n\n\n\nOnce Java is installed, you can install LaBB-CAT:\n\nOpen the following page in your web browser:\nhttps://sourceforge.net/projects/labbcat/files/install/\nThis page has all versions of the LaBB-CAT installer, both for personal computer installations\nand also for web-server installations. The the files are listed most recent first.\nDownload the first file named install-labbcat_yyyymmdd.jar (where yyyymmdd are numbers).\nDouble-click on the file you just downloaded to open it.\n\nYou should see the LaBB-CAT installer program (Figure¬†4).\n\n\n\n\n\n\nFigure¬†4: LaBB-CAT Installer\n\n\n\n\nPress Start.\n\nYou should see a progress bar while components are installed and files are copied.\nOnce the installation is finished, the progress bar will be all blue, and there will be a button labelled Finished (Figure¬†5).\n\n\n\n\n\n\nFigure¬†5: Installer finished\n\n\n\n\nPress Finished.\n\nThe LaBB-CAT Server application will appear, as shown in Figure¬†6.\n\n\n\n\n\n\nFigure¬†6: LaBB-CAT Server\n\n\n\nThen your default web browser will open on your LaBB-CAT home page, as shown in Figure¬†7.\n\n\n\n\n\n\nFigure¬†7: LaBB-CAT is successfully installed and running\n\n\n\n\nIf you are shown the LaBB-CAT Licence page, scroll to the bottom and press I Agree.\n\nAs seen in Figure¬†8, in your Start Menu, you will see that there is a LaBB-CAT app that can be used to start and access LaBB-CAT from now on.\n\n\n\n\n\n\nFigure¬†8: Use Start/LaBB-CAT to open LaBB-CAT\n\n\n\nThis starts the LaBB-CAT Server app (Figure¬†6), which must be running when you‚Äôre using LaBB-CAT. It can be closed once you‚Äôve finished working with LaBB-CAT.\n\n\n\nIn future you may want to uninstall LaBB-CAT, in which case you can use the same installer you used to install it.\nIf you run install-labbcat_yyyymmdd.jar and LaBB-CAT is already installed, after pressing Start it will offer further options.\n\n\n\nRunning install-labbcat_yyyymmdd.jar when LaBB-CAT is already installed\n\n\nThe options are:\n\nUpgrade ‚Äì Install this version of LaBB-CAT, keeping all your corpus data intact.\nReplace ‚Äì Install LaBB-CAT afresh, deleting all your existing corpus data and leaving you with an empty LaBB-CAT installation.\nUninstall ‚Äì Remove LaBB-CAT from your personal computer.\nCancel ‚Äì Close the installer without taking any action.",
    "crumbs": [
      "How-to",
      "Installation",
      "Windows"
    ]
  },
  {
    "objectID": "howto/install/standalone-windows.html#uninstalling-labb-cat",
    "href": "howto/install/standalone-windows.html#uninstalling-labb-cat",
    "title": "Installing LaBB-CAT on Windows",
    "section": "",
    "text": "In future you may want to uninstall LaBB-CAT, in which case you can use the same installer you used to install it.\nIf you run install-labbcat_yyyymmdd.jar and LaBB-CAT is already installed, after pressing Start it will offer further options.\n\n\n\nRunning install-labbcat_yyyymmdd.jar when LaBB-CAT is already installed\n\n\nThe options are:\n\nUpgrade ‚Äì Install this version of LaBB-CAT, keeping all your corpus data intact.\nReplace ‚Äì Install LaBB-CAT afresh, deleting all your existing corpus data and leaving you with an empty LaBB-CAT installation.\nUninstall ‚Äì Remove LaBB-CAT from your personal computer.\nCancel ‚Äì Close the installer without taking any action.",
    "crumbs": [
      "How-to",
      "Installation",
      "Windows"
    ]
  },
  {
    "objectID": "howto/install/praat/praat-browser.html",
    "href": "howto/install/praat/praat-browser.html",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "When you are browsing a LaBB-CAT corpus (either installed on your own computer or on a server), the transcript page can integrate directly with Praat so that you can open utterance in Praat directly from your browser.\n\n\n\n\n\n\nImportant\n\n\n\nLaBB-CAT‚Äôs browser integration with Praat currently does not work with Safari, so if you‚Äôre using a Mac, ensure you try the steps below in Google Chrome, Microsoft Edge, or Mozilla Firefox.\n\n\nIn order for this to work, you need some software installed on your local computer:\n\n\nIf you don‚Äôt already have Praat, or you have a version older than 6.2.05, download and install Praat from the Praat website:\nhttp://praat.org\n\n\n\nJava may already be installed on you system. The steps for discovering if Java is already installed, and how to install it if it‚Äôs not, depend on your operating system:\n\n\n\n\n\n\nNote Windows\n\n\n\n\n\nOn Windows, before you can install LaBB-CAT, you first must have Java installed.\n\n\nUse the following steps to check whether you already have Java installed.\n\nPress the  Start menu button.\nType Control Panel\nSelect the Control Panel option that appears.\n\nType Java\n\nIf a Java icon appears as shown in Figure¬†1, then you already have Java, and can skip section 2.\n\n\n\n\n\n\nFigure¬†1: Java in the Control Panel\n\n\n\nIf there‚Äôs no Java icon in the Control Panel, follow the steps in the next section to install it.\n\n\n\n\nOpen the Java website in your browser:\nhttps://www.java.com/\nPress the Download Java button.\nPress the Download Java button on the next page and save the resulting installer file.\nClick the installer to run it.\n\n\n\n\n\n\n\nFigure¬†2: The Java installer\n\n\n\n\nPress Install.\n\n\n\n\n\n\n\nFigure¬†3: Java installation is complete\n\n\n\n\nPress Close.\n\n\n\n\n\n\n\n\n\n\n\nNote Mac\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThese instructions are for newer M-series Macs, and will not work for older Intel-based Macs. Sorry!\n\n\nOn OS X, there are a various ways to install Java.\nYou can try the Java website in your browser:\nhttps://www.java.com/\nOr you can use the ‚ÄòHomebrew‚Äô package management system.\nYou may already have one or other of these installed; if so, you can skip the corresponding section below.\n\n\nHomebrew is a ‚Äòpackage manager‚Äô for Mac computers, which allows you to install other programes, including Java.\n\nOpen the following page in your web browser:\nhttps://github.com/Homebrew/brew/releases/latest\nScroll down to the Assets section.\n\nClick the file called Homebrew-n.n.n.pkg (where n.n.n is the version number) to download the file.\nOnce the file has been downloaded, double-click on it to run the installer.\n\nClick Continue, Continue, Agree and Install to complete the installation.\n\n\n\n\n\nOpen Launchpad and type Terminal.\nDouble click Terminal to open a command shell.\nType in the following command:\nbrew install openjdk\nPress the returnreturn key on your keyboard to enter the command.\nSome text will appear in the Terminal window while Homebrew downloads everything it needs to install Java\nOnce it‚Äôs finished, you‚Äôll see the % shell prompt again.\n\n\n\n\n\n\n\nFigure¬†4: brew install openjdk\n\n\n\n\n\n\n\n\n\n\n\nIn LaBB-CAT, open any transcript.\nOn the top-right of the transcript page, above the playback controls, there‚Äôs a Praat icon  - click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\n\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\n\n\n\n\nOnce you‚Äôve installed the browser extension, return to the transcript page.\nPress OK on the message that appears, to reload the page.\nClick on any line, and select the ‚ÄòOpen Text Grid in Praat‚Äô option on the menu.\n\nYou will see a page with three-step instructions for finishing the Praat integration.\nAssuming you already have Praat and Java installed, you just have to do the third step. i.e.¬†download and run a program called ‚Äúinstall-jsendpraat.jar‚Äù.\n\nClick the install-jsendpraat.jar link, save the resulting file.\nDouble-click the program you just saved.\nOn the window that appears, press the Install button.\n\n\n\n\n\n\n\nNoteMac Installation\n\n\n\n\n\nWhen you try to run install-jsendpraat.jar on a Mac, you may see the following message:\n\nIf so:\n\nPress Done.\nClick the Apple icon on the top left corner of the screen to open the menu.\nSelect System Settings‚Ä¶\nOn the left hand side, select the Privacy and Security option.\nScroll to the bottom of the page.\nUnder Security you should seem a message saying\n‚Äúinstall-sendpraat.jar‚Äù was blocked to protect your Mac\n\nPress Open Anyway\nYou will see a warning message:\n\nPress Open Anyway\nYou may see a further prompt to allow this:\n\n\nFinally you should see the installer open:\n\nThen you can press Install.\n\n\n\n\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\nClose the instructions page.\n\nIf in doubt, check the  online help on the transcript page; it has a section explaining how to set up Praat integration on various browsers and operating systems.\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶",
    "crumbs": [
      "How-to",
      "Installation",
      "Praat Browser Extension"
    ]
  },
  {
    "objectID": "howto/install/praat/praat-browser.html#installing-praat-browser-integration",
    "href": "howto/install/praat/praat-browser.html#installing-praat-browser-integration",
    "title": "LaBB-CAT Documentation",
    "section": "",
    "text": "When you are browsing a LaBB-CAT corpus (either installed on your own computer or on a server), the transcript page can integrate directly with Praat so that you can open utterance in Praat directly from your browser.\n\n\n\n\n\n\nImportant\n\n\n\nLaBB-CAT‚Äôs browser integration with Praat currently does not work with Safari, so if you‚Äôre using a Mac, ensure you try the steps below in Google Chrome, Microsoft Edge, or Mozilla Firefox.\n\n\nIn order for this to work, you need some software installed on your local computer:\n\n\nIf you don‚Äôt already have Praat, or you have a version older than 6.2.05, download and install Praat from the Praat website:\nhttp://praat.org\n\n\n\nJava may already be installed on you system. The steps for discovering if Java is already installed, and how to install it if it‚Äôs not, depend on your operating system:\n\n\n\n\n\n\nNote Windows\n\n\n\n\n\nOn Windows, before you can install LaBB-CAT, you first must have Java installed.\n\n\nUse the following steps to check whether you already have Java installed.\n\nPress the  Start menu button.\nType Control Panel\nSelect the Control Panel option that appears.\n\nType Java\n\nIf a Java icon appears as shown in Figure¬†1, then you already have Java, and can skip section 2.\n\n\n\n\n\n\nFigure¬†1: Java in the Control Panel\n\n\n\nIf there‚Äôs no Java icon in the Control Panel, follow the steps in the next section to install it.\n\n\n\n\nOpen the Java website in your browser:\nhttps://www.java.com/\nPress the Download Java button.\nPress the Download Java button on the next page and save the resulting installer file.\nClick the installer to run it.\n\n\n\n\n\n\n\nFigure¬†2: The Java installer\n\n\n\n\nPress Install.\n\n\n\n\n\n\n\nFigure¬†3: Java installation is complete\n\n\n\n\nPress Close.\n\n\n\n\n\n\n\n\n\n\n\nNote Mac\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThese instructions are for newer M-series Macs, and will not work for older Intel-based Macs. Sorry!\n\n\nOn OS X, there are a various ways to install Java.\nYou can try the Java website in your browser:\nhttps://www.java.com/\nOr you can use the ‚ÄòHomebrew‚Äô package management system.\nYou may already have one or other of these installed; if so, you can skip the corresponding section below.\n\n\nHomebrew is a ‚Äòpackage manager‚Äô for Mac computers, which allows you to install other programes, including Java.\n\nOpen the following page in your web browser:\nhttps://github.com/Homebrew/brew/releases/latest\nScroll down to the Assets section.\n\nClick the file called Homebrew-n.n.n.pkg (where n.n.n is the version number) to download the file.\nOnce the file has been downloaded, double-click on it to run the installer.\n\nClick Continue, Continue, Agree and Install to complete the installation.\n\n\n\n\n\nOpen Launchpad and type Terminal.\nDouble click Terminal to open a command shell.\nType in the following command:\nbrew install openjdk\nPress the returnreturn key on your keyboard to enter the command.\nSome text will appear in the Terminal window while Homebrew downloads everything it needs to install Java\nOnce it‚Äôs finished, you‚Äôll see the % shell prompt again.\n\n\n\n\n\n\n\nFigure¬†4: brew install openjdk\n\n\n\n\n\n\n\n\n\n\n\nIn LaBB-CAT, open any transcript.\nOn the top-right of the transcript page, above the playback controls, there‚Äôs a Praat icon  - click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\n\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\n\n\n\n\nOnce you‚Äôve installed the browser extension, return to the transcript page.\nPress OK on the message that appears, to reload the page.\nClick on any line, and select the ‚ÄòOpen Text Grid in Praat‚Äô option on the menu.\n\nYou will see a page with three-step instructions for finishing the Praat integration.\nAssuming you already have Praat and Java installed, you just have to do the third step. i.e.¬†download and run a program called ‚Äúinstall-jsendpraat.jar‚Äù.\n\nClick the install-jsendpraat.jar link, save the resulting file.\nDouble-click the program you just saved.\nOn the window that appears, press the Install button.\n\n\n\n\n\n\n\nNoteMac Installation\n\n\n\n\n\nWhen you try to run install-jsendpraat.jar on a Mac, you may see the following message:\n\nIf so:\n\nPress Done.\nClick the Apple icon on the top left corner of the screen to open the menu.\nSelect System Settings‚Ä¶\nOn the left hand side, select the Privacy and Security option.\nScroll to the bottom of the page.\nUnder Security you should seem a message saying\n‚Äúinstall-sendpraat.jar‚Äù was blocked to protect your Mac\n\nPress Open Anyway\nYou will see a warning message:\n\nPress Open Anyway\nYou may see a further prompt to allow this:\n\n\nFinally you should see the installer open:\n\nThen you can press Install.\n\n\n\n\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\nClose the instructions page.\n\nIf in doubt, check the  online help on the transcript page; it has a section explaining how to set up Praat integration on various browsers and operating systems.\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶",
    "crumbs": [
      "How-to",
      "Installation",
      "Praat Browser Extension"
    ]
  },
  {
    "objectID": "howto/media-annotation/index.html",
    "href": "howto/media-annotation/index.html",
    "title": "Annotating Media",
    "section": "",
    "text": "Annotating Media\nSome automatic annotation processes do not involve reference to the transcript text, but rather involve computations that come directly and solely from the media.\nLaBB-CAT includes annotation modules that integrate with some 3rd-party tools that produce such computations:\n\nReaper - for automated voicing and pitch measurement.\nMediaPipe - for detecting facial features in video recordings.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Annotating Media"
    ]
  },
  {
    "objectID": "howto/manual-annotation/doccano.html",
    "href": "howto/manual-annotation/doccano.html",
    "title": "Phrase Tagging with Doccano",
    "section": "",
    "text": "Doccano is an open-source data labeling tool intended for machine learning practitioners. It allows you to tag words and phrases in texts with a very easy-to-use drag and select user interface.\n\nYou can use Doccano to tag phrases and import your tags into phrase layers in LaBB-CAT. The broad steps of the process are:\n\nExport a selected set of transcripts from LaBB-CAT to the Doccano JSONL format\nImport the resulting file into Doccano\nTag the texts as desired\nExport the tagged texts from Doccano to a JSONL file\nImport the tagged JSONL file into LaBB-CAT\n\n\n\n\n\n\n\nNoteInstallation of the Doccano Formatter\n\n\n\n\n\nLaBB-CAT uses ‚Äòformatter‚Äô modules to import and export files in the formats of different annotation tools.\nIf you find that ‚ÄòDoccano JSONL Dataset‚Äô is not an option for exporting or importing Doccano files, it‚Äôs because the Doccano module is not installed on your LaBB-CAT instance.\nTo install the Doccano formatter:\n\nDownload the format conversion module here:\nhttps://github.com/nzilbb/ag/blob/main/bin/nzilbb.formatter.doccano.jar\nIn LaBB-CAT, select the converters menu option\nPress Choose File at the bottom, and select the nzilbb.formatter.doccano.jar file you downloaded in 1.\nPress Upload\nPress Install\n\nDoccano JSONL Dataset should now be an option for selection on the transcripts page.\n\n\n\n\n\n\nIn LaBB-CAT, open the transcripts page.\nUse the filters at the top to narrow the list down to the transcripts you want to export, and/or tick the target transcripts.\nClick Export Format.\nA list of layers will appear, with a list of formats below.\nIf you wish to include any existing phrase/span layers in Doccano, tick the corresponding layers in the list.\n\nNB: Annotations on the layers you select here will be displayed in Doccano but cannot be edited; any changes to these annotations will be ignored when re-importing the dataset into LaBB-CAT.\nBelow the list of layers, there‚Äôs a dropdown list of export formats.\nSelect Doccano JSONL Dataset.1\n\nClick Export Format\nSave the resulting ‚Ä¶jsonl file.\n\n\n\n\n\nIn Doccano, you will need to create a project to import your texts into. Click Projects on the top right.\nPress Create on the top left.\nSelect the Sequence Labelling option.\n Sequence Labelling option in Doccano is ticked\nEnter a name and description for your project.\nTick the Allow overlapping entity option.\n\nPress Create at the bottom.\nThis will create the project and take you to its Home page.\nPress Dataset on the left.\n\nMove the mouse over the Actions button at the top, and select the Import Dataset option.\n\nSelect JSONL as the File format.\nYou can leave the other options that appear with their default values.\nFind the ‚Ä¶jsonl file you exported from LaBB-CAT earlier, and drap/drop it on to the grey area labelled Drop files here‚Ä¶\n(Alternatively you can click on the Drop files here‚Ä¶ area, and find/select the ‚Ä¶jsonl file.)\n\nPress Import.\n\nOnce the import is complete, you will see a list of texts on the Dataset page. The Metadata column will be full of text and numbers - this is normal; LaBB-CAT includes information in the Metadata that it needs to import the text back into LaBB-CAT correctly.\n\n\n\nThe imported dataset includes metadata to aid re-import into LaBB-CAT\n\n\n\n\n\nBefore adding annotations to the texts, you need to create Labels in Doccano. These are the annotations you‚Äôll be able to add to words/phrases in the texts.\n\nIn Doccano, click Labels on the left-hand menu.\nIf you exported any additional phrase/span layers from LaBB-CAT, you will see labels for the resulting annotations already listed here.\n\nEach imported label is prefixed with the ID of the LaBB-CAT layer it came from, followed by a colon. This is the pattern you must follow with the labels you create.\nMove the mouse over the Actions button at the top and click the Create Label option.\n\nEnter the label. This should be using the format:\n{LaBB-CAT-Layer-ID}:{LaBB-CAT-Label}\ne.g if you intend for your new annotations to be added to a LaBB-CAT layer called ‚Äúnarrative-action‚Äù and one of the possible labels in LaBB-CAT will be ‚Äúcomplicating action‚Äù, then the Label you create in Doccano should be: narrative-action:complicating action\n\nPick a colour for the label if you wish.\nAssuming you want to add more than one label, click Save and add another.\nRepeat the above steps for each label you would like to annotate with.\nOnce you‚Äôve finished, click the Labels option on the left-hand menu.\nYou should see the label‚Äôs you‚Äôve added, listed after the imported ones.\n\n\n\n\nNow that you‚Äôve configured the labels you‚Äôre going to use, you can annotate the texts you imported:\nIn Doccano click Start Annotation at the top left.\n(Alternatively, you can click Dataset and then press the Annotate button on a text of your choice)\nYou will see one of the texts you imported.\n\n\n\nTranscript including annotations exported from LaBB-CAT\n\n\nThe participant ID of the speaker appears at the beginning of each speaker turn, and if you exported phrase/span annotations from LaBB-CAT, they will appear tagging the corresponding regions of the text.\nTo tag a phrase in the text, simply click and drag over the phrase to select it. A menu of tags will appear.\n\n\n\nClick/drag for label menu\n\n\nWhen you click the desired tag, it will be added to the text.\n\n\n\nNew tags appear in the text\n\n\n\n\n\nDoccano includes a mode for tagging in which you can pre-select the Label you want to use, and then the selected Label is automatically used whenever you click/drag a phrase. This mode may be quicker as it involves fewer clicks overall.\nTo use this method of tagging, scroll to the top of the text, and click the desired Label in the list on the top right.\n\n\n\nPre-select a label in the label Types list at the top right of the text\n\n\nNow, whenever you click/drag a phrase in the tex, it will immediately be tagged with the selected Label.\nChanges are automatically saved. Once you‚Äôve added all the tags you want in this text, you can move to the next by using the navigation buttons at the top right of the text.\n\n\n\nButtons for navigating to the first, previous, next, and last text\n\n\n\n\n\n\nOne you‚Äôve finished annotating all texts, you need to export them with the new tags so they can be imported into LaBB-CAT.\n\nIn Doccano, click the Dataset option on the left-hand menu.\nMove the mouse over Actions at the top and select Export Dataset.\n\nSelect JSONL as the File format\nPress Export.\nSave the resulting ‚Ä¶zip file.\nExtract the ‚Ä¶jsonl file that is contained in the ‚Ä¶zip file you just saved.\n\n\n\n\n\n\nWhen you import the ‚Ä¶jsonl file into LaBB-CAT, it will extract the new Labels you‚Äôve added, and assume that each Label is in the format:\n{LaBB-CAT-Layer-ID}:{LaBB-CAT-Label}\nEach label will be split on the colon, and the left part will be assumed to be a layer ID, and the right part will be assumed to be the label for annotations on that layer.\nIf you have added layer ID prefixes for layers that don‚Äôt exist yet in LaBB-CAT, you have to create the LaBB-CAT layers before importing the ‚Ä¶jsonl file, so that the new annotations have somewhere to go.\nIf the new annotations always tag phrases within the same speaker turn (i.e.¬†never cross turn boundaries), then you can add a phrase layer. Otherwise, you must add a span layer.\n\nIn LaBB-CAT, select phrase layers or span layers from the menu as appropriate.\nAt the top of the list of layers, fill in the details of the blank row for the layer to add:\n\nLayer ID: the Doccanno Label‚Äôs prefix (i.e.¬†the part before the colon)\nType: Text\nAlignment: Intervals\nManager: no manager should be selected\nGenerate: Never\nProject: select a project if desired, or none if not\nDescription: An informative description of the layer, perhaps including a lilst of all labels included.\n\nClick New to add the layer\n\nIf you have included Labels corresponding to multiple LaBB-CAT layers, ensure all the layers have been created in LaBB-CAT before continuing with the import.\n\n\n\n\nIn LaBB-CAT, select the upload menu option at the top and then the upload transcripts option.\nPress the first Choose File button on the left.\nSelect the ‚Ä¶json file you extracted from the ‚Ä¶zip file above.\nTick the Update Existing checkbox.\n\nPress Upload.\nYou will see a list of all the new Label prefixes, with a dropdown box for each for selecting the LaBB-CAT layer that the annotations should be imported into.\n\nEnsure all Label prefixes are matched to the correct LaBB-CAT layer\nPres Next\n\nYour new annotations will be merged into the existing transcript in LaBB-CAT.\nYou can double check this by opening on of the transcripts you tagged in LaBB-CAT and ticking the layer(s) of the new annotations. You annotations will appear, lined up with the phrases as you specified in Doccano.",
    "crumbs": [
      "How-to",
      "Phrase Tagging with Doccano"
    ]
  },
  {
    "objectID": "howto/manual-annotation/doccano.html#export-from-labb-cat",
    "href": "howto/manual-annotation/doccano.html#export-from-labb-cat",
    "title": "Phrase Tagging with Doccano",
    "section": "",
    "text": "In LaBB-CAT, open the transcripts page.\nUse the filters at the top to narrow the list down to the transcripts you want to export, and/or tick the target transcripts.\nClick Export Format.\nA list of layers will appear, with a list of formats below.\nIf you wish to include any existing phrase/span layers in Doccano, tick the corresponding layers in the list.\n\nNB: Annotations on the layers you select here will be displayed in Doccano but cannot be edited; any changes to these annotations will be ignored when re-importing the dataset into LaBB-CAT.\nBelow the list of layers, there‚Äôs a dropdown list of export formats.\nSelect Doccano JSONL Dataset.1\n\nClick Export Format\nSave the resulting ‚Ä¶jsonl file.",
    "crumbs": [
      "How-to",
      "Phrase Tagging with Doccano"
    ]
  },
  {
    "objectID": "howto/manual-annotation/doccano.html#import-into-doccano",
    "href": "howto/manual-annotation/doccano.html#import-into-doccano",
    "title": "Phrase Tagging with Doccano",
    "section": "",
    "text": "In Doccano, you will need to create a project to import your texts into. Click Projects on the top right.\nPress Create on the top left.\nSelect the Sequence Labelling option.\n Sequence Labelling option in Doccano is ticked\nEnter a name and description for your project.\nTick the Allow overlapping entity option.\n\nPress Create at the bottom.\nThis will create the project and take you to its Home page.\nPress Dataset on the left.\n\nMove the mouse over the Actions button at the top, and select the Import Dataset option.\n\nSelect JSONL as the File format.\nYou can leave the other options that appear with their default values.\nFind the ‚Ä¶jsonl file you exported from LaBB-CAT earlier, and drap/drop it on to the grey area labelled Drop files here‚Ä¶\n(Alternatively you can click on the Drop files here‚Ä¶ area, and find/select the ‚Ä¶jsonl file.)\n\nPress Import.\n\nOnce the import is complete, you will see a list of texts on the Dataset page. The Metadata column will be full of text and numbers - this is normal; LaBB-CAT includes information in the Metadata that it needs to import the text back into LaBB-CAT correctly.\n\n\n\nThe imported dataset includes metadata to aid re-import into LaBB-CAT",
    "crumbs": [
      "How-to",
      "Phrase Tagging with Doccano"
    ]
  },
  {
    "objectID": "howto/manual-annotation/doccano.html#tag-the-texts",
    "href": "howto/manual-annotation/doccano.html#tag-the-texts",
    "title": "Phrase Tagging with Doccano",
    "section": "",
    "text": "Before adding annotations to the texts, you need to create Labels in Doccano. These are the annotations you‚Äôll be able to add to words/phrases in the texts.\n\nIn Doccano, click Labels on the left-hand menu.\nIf you exported any additional phrase/span layers from LaBB-CAT, you will see labels for the resulting annotations already listed here.\n\nEach imported label is prefixed with the ID of the LaBB-CAT layer it came from, followed by a colon. This is the pattern you must follow with the labels you create.\nMove the mouse over the Actions button at the top and click the Create Label option.\n\nEnter the label. This should be using the format:\n{LaBB-CAT-Layer-ID}:{LaBB-CAT-Label}\ne.g if you intend for your new annotations to be added to a LaBB-CAT layer called ‚Äúnarrative-action‚Äù and one of the possible labels in LaBB-CAT will be ‚Äúcomplicating action‚Äù, then the Label you create in Doccano should be: narrative-action:complicating action\n\nPick a colour for the label if you wish.\nAssuming you want to add more than one label, click Save and add another.\nRepeat the above steps for each label you would like to annotate with.\nOnce you‚Äôve finished, click the Labels option on the left-hand menu.\nYou should see the label‚Äôs you‚Äôve added, listed after the imported ones.\n\n\n\n\nNow that you‚Äôve configured the labels you‚Äôre going to use, you can annotate the texts you imported:\nIn Doccano click Start Annotation at the top left.\n(Alternatively, you can click Dataset and then press the Annotate button on a text of your choice)\nYou will see one of the texts you imported.\n\n\n\nTranscript including annotations exported from LaBB-CAT\n\n\nThe participant ID of the speaker appears at the beginning of each speaker turn, and if you exported phrase/span annotations from LaBB-CAT, they will appear tagging the corresponding regions of the text.\nTo tag a phrase in the text, simply click and drag over the phrase to select it. A menu of tags will appear.\n\n\n\nClick/drag for label menu\n\n\nWhen you click the desired tag, it will be added to the text.\n\n\n\nNew tags appear in the text\n\n\n\n\n\nDoccano includes a mode for tagging in which you can pre-select the Label you want to use, and then the selected Label is automatically used whenever you click/drag a phrase. This mode may be quicker as it involves fewer clicks overall.\nTo use this method of tagging, scroll to the top of the text, and click the desired Label in the list on the top right.\n\n\n\nPre-select a label in the label Types list at the top right of the text\n\n\nNow, whenever you click/drag a phrase in the tex, it will immediately be tagged with the selected Label.\nChanges are automatically saved. Once you‚Äôve added all the tags you want in this text, you can move to the next by using the navigation buttons at the top right of the text.\n\n\n\nButtons for navigating to the first, previous, next, and last text",
    "crumbs": [
      "How-to",
      "Phrase Tagging with Doccano"
    ]
  },
  {
    "objectID": "howto/manual-annotation/doccano.html#export-from-doccano",
    "href": "howto/manual-annotation/doccano.html#export-from-doccano",
    "title": "Phrase Tagging with Doccano",
    "section": "",
    "text": "One you‚Äôve finished annotating all texts, you need to export them with the new tags so they can be imported into LaBB-CAT.\n\nIn Doccano, click the Dataset option on the left-hand menu.\nMove the mouse over Actions at the top and select Export Dataset.\n\nSelect JSONL as the File format\nPress Export.\nSave the resulting ‚Ä¶zip file.\nExtract the ‚Ä¶jsonl file that is contained in the ‚Ä¶zip file you just saved.",
    "crumbs": [
      "How-to",
      "Phrase Tagging with Doccano"
    ]
  },
  {
    "objectID": "howto/manual-annotation/doccano.html#import-into-labb-cat",
    "href": "howto/manual-annotation/doccano.html#import-into-labb-cat",
    "title": "Phrase Tagging with Doccano",
    "section": "",
    "text": "When you import the ‚Ä¶jsonl file into LaBB-CAT, it will extract the new Labels you‚Äôve added, and assume that each Label is in the format:\n{LaBB-CAT-Layer-ID}:{LaBB-CAT-Label}\nEach label will be split on the colon, and the left part will be assumed to be a layer ID, and the right part will be assumed to be the label for annotations on that layer.\nIf you have added layer ID prefixes for layers that don‚Äôt exist yet in LaBB-CAT, you have to create the LaBB-CAT layers before importing the ‚Ä¶jsonl file, so that the new annotations have somewhere to go.\nIf the new annotations always tag phrases within the same speaker turn (i.e.¬†never cross turn boundaries), then you can add a phrase layer. Otherwise, you must add a span layer.\n\nIn LaBB-CAT, select phrase layers or span layers from the menu as appropriate.\nAt the top of the list of layers, fill in the details of the blank row for the layer to add:\n\nLayer ID: the Doccanno Label‚Äôs prefix (i.e.¬†the part before the colon)\nType: Text\nAlignment: Intervals\nManager: no manager should be selected\nGenerate: Never\nProject: select a project if desired, or none if not\nDescription: An informative description of the layer, perhaps including a lilst of all labels included.\n\nClick New to add the layer\n\nIf you have included Labels corresponding to multiple LaBB-CAT layers, ensure all the layers have been created in LaBB-CAT before continuing with the import.\n\n\n\n\nIn LaBB-CAT, select the upload menu option at the top and then the upload transcripts option.\nPress the first Choose File button on the left.\nSelect the ‚Ä¶json file you extracted from the ‚Ä¶zip file above.\nTick the Update Existing checkbox.\n\nPress Upload.\nYou will see a list of all the new Label prefixes, with a dropdown box for each for selecting the LaBB-CAT layer that the annotations should be imported into.\n\nEnsure all Label prefixes are matched to the correct LaBB-CAT layer\nPres Next\n\nYour new annotations will be merged into the existing transcript in LaBB-CAT.\nYou can double check this by opening on of the transcripts you tagged in LaBB-CAT and ticking the layer(s) of the new annotations. You annotations will appear, lined up with the phrases as you specified in Doccano.",
    "crumbs": [
      "How-to",
      "Phrase Tagging with Doccano"
    ]
  },
  {
    "objectID": "howto/manual-annotation/doccano.html#footnotes",
    "href": "howto/manual-annotation/doccano.html#footnotes",
    "title": "Phrase Tagging with Doccano",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf Doccano JSONL Dataset is not an option, then you need to install the Doccano JSONL Dataset formatter - see instructions on Installation of the Doccano Formatter‚Ü©Ô∏é",
    "crumbs": [
      "How-to",
      "Phrase Tagging with Doccano"
    ]
  },
  {
    "objectID": "howto/forced-alignment/index.html",
    "href": "howto/forced-alignment/index.html",
    "title": "Forced Alignment",
    "section": "",
    "text": "Forced alignment is the automatic processing of recordings of utterance and their orthographic transcripts in order order to determing the start and end times of the individual words, and the phones within the words.\n\n\n\nForced Alignment\n\n\nThere are several ways that forced alignment can be achieved in LaBB-CAT:\n\nWebMAUS with BAS Web Services\nHTK using the Penn Aligner (P2FA) pre-trained acoustic models\nHTK by training your own acoustic models for alignment (‚Äòtrain-and-align‚Äô)\nMFA using pre-trained acoustic models\nMFA by trining your own acoustic models for alignment (‚Äòtrain-and-align‚Äô)\n\n\n\nThere are several tools and methods listed above for force-aligning your recordings, and each works well or badly depending on different factors. It can be difficult to know which method to use.\nYou can compare different forced alignment methods with your own data, in order to decide which method to use.\n\n\n\nBeing an unsupervised automatic process, the alignments are not always optimal. Various factors can degrade the quality of alignments:\n\nNot enough data (if you‚Äôre using the ‚Äòtrain-and-align‚Äô approach)\nPoor quality recording, background noises, etc.\nSimultaneous speech (ignored by default)\nInaccurate transcripts\nInaccurate utterance alignment\nLack of pause marking in the transcripts\nMismatched phonology between dictionary and speech. e.g.¬†using a rhotic dictionary to align non-rhotic speech\n\nBecause of this, you should manually inspect and possibly correct at least some of your data.\nSometimes the above factors can cause alignment failure for some utterances; i.e.¬†the utterance has no phone annotations created, the words are not aligned.\nYou can use LaBB-CAT‚Äôs search/export functionality to identify utterances that were not aligned.\n\n\n\nThere are two ways you can check/correct alignments:\n\nLaBB-CAT integrates with Praat\nLaBB-CAT integrates with the EMU-webApp\n\n\n\n\nOnce your data has been force-aligned, you will have start/end times for phones within words, which opens many possibilities for analysis and further annotation, for example.\n\nBatch processing of targeted tokens with Praat\nReconstruction of syllables",
    "crumbs": [
      "How-to",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "howto/forced-alignment/index.html#comparing-forced-alignment-methods",
    "href": "howto/forced-alignment/index.html#comparing-forced-alignment-methods",
    "title": "Forced Alignment",
    "section": "",
    "text": "There are several tools and methods listed above for force-aligning your recordings, and each works well or badly depending on different factors. It can be difficult to know which method to use.\nYou can compare different forced alignment methods with your own data, in order to decide which method to use.",
    "crumbs": [
      "How-to",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "howto/forced-alignment/index.html#alignment-accuracy",
    "href": "howto/forced-alignment/index.html#alignment-accuracy",
    "title": "Forced Alignment",
    "section": "",
    "text": "Being an unsupervised automatic process, the alignments are not always optimal. Various factors can degrade the quality of alignments:\n\nNot enough data (if you‚Äôre using the ‚Äòtrain-and-align‚Äô approach)\nPoor quality recording, background noises, etc.\nSimultaneous speech (ignored by default)\nInaccurate transcripts\nInaccurate utterance alignment\nLack of pause marking in the transcripts\nMismatched phonology between dictionary and speech. e.g.¬†using a rhotic dictionary to align non-rhotic speech\n\nBecause of this, you should manually inspect and possibly correct at least some of your data.\nSometimes the above factors can cause alignment failure for some utterances; i.e.¬†the utterance has no phone annotations created, the words are not aligned.\nYou can use LaBB-CAT‚Äôs search/export functionality to identify utterances that were not aligned.",
    "crumbs": [
      "How-to",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "howto/forced-alignment/index.html#checkingcorrecting-alignments",
    "href": "howto/forced-alignment/index.html#checkingcorrecting-alignments",
    "title": "Forced Alignment",
    "section": "",
    "text": "There are two ways you can check/correct alignments:\n\nLaBB-CAT integrates with Praat\nLaBB-CAT integrates with the EMU-webApp",
    "crumbs": [
      "How-to",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "howto/forced-alignment/index.html#after-alignment",
    "href": "howto/forced-alignment/index.html#after-alignment",
    "title": "Forced Alignment",
    "section": "",
    "text": "Once your data has been force-aligned, you will have start/end times for phones within words, which opens many possibilities for analysis and further annotation, for example.\n\nBatch processing of targeted tokens with Praat\nReconstruction of syllables",
    "crumbs": [
      "How-to",
      "Forced Alignment"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-train-align.html",
    "href": "howto/forced-alignment/mfa-train-align.html",
    "title": "MFA: Train-and-Align",
    "section": "",
    "text": "You can use ‚ÄòMFA‚Äô to train new speaker-specific acoustic models on your speech data, and then to force align the data on those models. You may decide to do this if:\n\nYou can‚Äôt share your data with third parties and so can‚Äôt use WebMAUS.\nMFA has no dictionaries and pre-trained acoustic models for the language of your data and so you can‚Äôt use MFA and Pretrained Acoustic Models.\nYou have 3-5 hours‚Äô speech.\n\nThe general process is illustrated in Figure¬†1.\n\n\n\n\n\n\nFigure¬†1: Pronunciations are generated from transcripts, and then combined with the recordings to train acoustic models, which are then used to compute phone-level alignements, which are saved to LaBB-CAT‚Äôs database\n\n\n\n\n\nIn order to be able to force-align transcripts to the word and/or segment level, you first need the following:\n\nTranscripts that are aligned at the utterance level (i.e.¬†there‚Äôs a known time-point every 20 or so words), whch have been uploaded into LaBB-CAT\nA WAV file for each transcript, on the LaBB-CAT server\nA phonemic transcription word layer, that has at least one pronunciation for every word. If there are some lines/utterances that contain words with missing pronunciations, those lines will be ignored by the HTK Layer Manager.\n\nDepending on your speech data, there are several ways to obtain phonemic transcriptions for words:\n\nLexical tagging\n\nCELEX - for British English, German, Dutch, using one of the CELEX layer managers.\nCMU Pronouncing Dictionary - for US English, using th CMU Pronouncing Dictionary layer manager.\nUnisyn - for various English varieties, using the Unisyn layer manager.\nDefine your own lexicon, and use the Flat File Dictionary layer manager to integrate it into LaBB-CAT.\n\nInferring pronunciation from orthography\n\nSpanish, using the Spanish Phonological Transcriber layer manager\nBas Web Service: G2P - for various languages.\nDefine your own simple mapping rules from orthography to phonology, using the Character Mapper layer manager.\n\n\nIf the speech corpus includes data in more than one language, it is possible to ensure that the utterances are phonemically tagged in a way that‚Äôs sensitive to the language of the specific utterance, using the language layers and attributes, and auxiliary layer managers.\nWhichever method you choose, you need a phonemes ‚Äòword layer‚Äô on which each word token is tagged with its pronunciation, before you can proceed with the forced-alignment steps below.\n\n\n\nThe broad steps for getting forced-alignments from MFA are:\n\nInstall MFA on the same computer that LaBB-CAT is installed on\nInstall the MFA Layer Manager, which integrates LaBB-CAT with MFA\nCreate and configure a new MFA layer in LaBB-CAT\nPick a speakers/participants in your database and identify their utterances\nFill in the missing pronunciations for those utterances\nRun forced alignment\nRepeat steps 4-6 for all the participants in your database\n\n\n\n\nMFA is not included as part of LaBB-CAT, and so it must be installed on the server you have installed LaBB-CAT on before you can integrate LaBB-CAT with it.\nIf MFA has not been installed already, please follow the following steps, depending on the operatings system of your LaBB-CAT server:\n\n\n\n\n\n\nNoteLinux\n\n\n\n\n\nTo install the Montreal Forced Aligner on Linux systems for all users, so that your web server can access it if required:\n\nDownload Miniconda:\nwget https://repo.anaconda.com/miniconda/Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nStart the installer:\nsudo bash Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nWhen asked the location to install Miniconda, use:\n/opt/conda\nWhen asked whether the installer should initialize Miniconda, this is unnecessary so you can respond no\nChange ownership of the conda files):\nsudo chown -R $USERNAME:$USERNAME /opt/conda\nMake conda accessible to all users (so you web server can access MFA):\nchmod -R go-w /opt/conda\nchmod -R go+rX /opt/conda\nInstall the Montreal Forced Aligner\n/opt/conda/bin/conda create -n aligner -c conda-forge montreal-forced-aligner=3.2.1\n\nIf you see errors when trying to use MFA, you may find that one of the following resolves the issue:\n/opt/conda/envs/aligner/bin/pip install joblib==1.3.2\nand/or\n/opt/conda/envs/aligner/bin/pip uninstall setuptools\n/opt/conda/envs/aligner/bin/pip install setuptools==66.1.1\n\n\n\n\n\n\n\n\n\n\nNoteWindows\n\n\n\n\n\nTo install the Montreal Forced Aligner on Windows systems for all users, so that your web server can access it if required:\n\nDownload the Miniconda installer:¬†¬†¬†\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\nStart the installer by double-clicking it.\nWhen asked, select the ‚ÄúInstall for all users‚Äù option. This will install conda somewhere like\nC:\\ProgramData\\Miniconda3\nWhen asked, tick the add to PATH option.\nInstall the Montreal Forced Aligner by specifying a path to the environment\nconda create -c conda-forge -p C:\\ProgramData\\Miniconda3\\envs\\aligner montreal-forced-aligner=3.2.1\n\n\n\n\n\n\n\n\n\n\nWarningWindows Troubleshooting\n\n\n\n\n\nThe 3rd party MFA software requires:\n\nthe possibility of running command-line programs during installation and forced alignement\nthe possibility that these programs can download data from the internet\n\nOn Windows, this can sometimes be complicated by the fact that Apache Tomcat and LaBB-CAT are installed as a ‚ÄòWindows Service‚Äô. Windows Services usually run using the permissions of a special anonymous login account called ‚ÄòLocal System‚Äô, which in some environments has restricted permissions to access different resources.\nIf you install the MFA Manager LaBB-CAT integration module, but you find it returns errors when trying to interact with MFA, the problem may be that the Windows Service:\n\ndoes not have permission to access the folder where MFA is installed, or\nis not allowed to execute other programs, or\ncannot access the internet.\n\nSometimes problems can be resolved by:\n\nrunning the Apache Tomcat Windows Service as a different user other than ‚ÄòLocal System‚Äô. (or if it was running as some other used, try setting it back to ‚ÄòLocal System‚Äô), or\nadjusting the permissions of the Windows Service users, or\nadjusting the permissions of the folders where MFA is installed\nconfiguring the service to use the local Internet Proxy settings to enable connecting to the internet.\n\nPSexec is a tool that can be used to diagnose and solve problems on Windows.\n\n\n\nDownload PStool.zip from Microsoft:\nhttp://technet.microsoft.com/en-us/sysinternals/bb897553.aspx\nUnzip it\nPut PSexec.exe into C:\\Windows\\System32\nOpen cmd using ‚ÄúRun as Administrator‚Äù\nRun the command:\nPsexec.exe -i -s cmd.exe\nThis opens a new command prompt for local system account\nIn the new command prompt window, check you have the correct account type with the command:\nwhomai\n\nThen you can use the command prompt to run MFA commands to diagnose errors - e.g.:\n\nconda activate montreal-forced-aligner - activates the MFA environment\nmfa version - ensures MFA is installed and accessible, and confirms the version\nmfa model download dictionary - ensures MFA can connect to the internet to get models etc.; this command should return a long list of language dictionaries, and not report errors.\n\n\n\n\nTo update proxy server settings:\n\ntype inetcpl.cpl\ngoto Connections tab\nclick on the LAN Settings button\nFill in the Proxy section with the correct details\n\n\n\n\n\n\n\n\n\n\n\nNoteDocker Container\n\n\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, it can download and install Miniconda and MFA itself, as part of the process of installing the MFA Manager LaBB-CAT module.\nThere is no need for a separate installation of the MFA software.\n\n\n\n\n\n\n\nOnce MFA has been installed, you have to install the MFA Manager, which is the LaBB-CAT module that provides MFA with all the data it needs, and then saves to alignments MFA produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link.\nFind MFA Manager in the list, and press its Install button and then press Install again.\nAs long as MFA has been installed for all users, you should see a box that‚Äôs already filled in with the location that MFA was installed to.\nClick Configure to continue the layer manager installation.\nYou will see a window open with some information about integrating with MFA, including the information you‚Äôve already read above.\n\n\n\n\nThe labels used for phonemes layer (or whichever layer tags each word token with its pronunciation) will use a specific encoding for the phonemes. Encodings include:\n\nCELEX DISC: Exactly one ASCII character per phoneme,\ne.g.¬†there‚Äôll ‚Üí D8r@l\nUnicode IPA: One or more Unicode character per phoneme, possibly including diacritics, delimited by spaces:\ne.g.¬†there‚Äôll ‚Üí √∞ …õ…ô …π lÃ©\nARPAbet: Phonemes are one or two uppercase ASCII characters, possibly suffixed with a digit indicating stress, delimited by spaces:\ne.g.¬†there‚Äôll ‚Üí DH EH1 R AX0 L\n\nIf it uses CELEX DISC encoding, the phonemes layer should have its Type set to Phonological on the word layers page. Otherwise its Type should be set to Text.\nIn order to ensure that the labels that the MFA Manager will create on the segment layer use the same encoding, the segment layer must have the same Type as the phonemes layer. In order to ensure that:\n\nSelect the segment layers option on the menu.\nThe segment layer is the first on the list (and may be the only layer there).\nCheck the Type of the segment layer. If it‚Äôs not the same as the phonemes layer, change the Type so that it matches, and press the Save button that appears.\n\n\n\n\nOnce you‚Äôve installed MFA and the MFA Layer Manager, you need to create a new layer for triggering and controlling forced alignment. This layer will itself contain a timestamp for each line/utterance it has force-aligned (and so it‚Äôs a ‚Äòphrase‚Äô layer), but during that process, the word and phone alignments will also be set on other layers.\n\nSelect the phrase layers option on the menu\nFill in the form at the top of the page (which doubles as column headings) with the following details:\n\nLayer ID: mfa\nType: Text\nAlignment: Intervals\nManager: MFA Manager\nGenerate: never (this is because we will manually select utterance for forced alignment, to ensure there is enough data to train acoustic models)\nDescription: MFA alignment time\n\nWhen you configure the layer, set the following options:\n\nPronunciation Layer: select the phonemes layer (or whichever word layer that tags each word with its pronunciation)\nDictionary Name: [none]\nPretrained Acoustic Models: [none] (this ensures that the train/align procedure is used)\nThe rest of the options can be left as their default values.\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a `tool tip‚Äô that describes what the option is for.\n\nPress Set Parameters\n\n\n\n\nMFA is data-hungry when training acoustic models for forced alignment, and needs 3-5 hours‚Äô speech\nTo start a forced-alignment process for a batch of selected participants, you need to first select the participants who will be aligned. Then you need to list all their utterances, and MFA will first training acoustic models from scratch from them, and then using those acoustic models, align those same utterances.\n\nIn LaBB-CAT, select the participants link on the menu\nFilter the list to display the desired participants, and tick the checkbox next to each participant you want to include\nPress the All Utterances button above\nPress List to list all of their utterances.\nA progress bar will appear while LaBB-CAT identifies all the selected participant‚Äôs utterances. Once this is done, the first twenty utterances will be listed (like search results, the first twenty are listed for convenience, but you can process all matching utterances)\nClick the Mfa button below the list.\nA progress bar will appear while MFA gathers up all the utterance data, trains acoustic models, force-aligns the utterances, and then saves the resulting alignments back to LaBB-CAT. This process may take some time.\n\nOnce the progress bar reaches 100% and the process is complete, the selected utterances will have word start/end times set, and aligned phones will have been added to the segment layer, using the same labels as appear in the phonemes layer",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-train-align.html#prerequisites",
    "href": "howto/forced-alignment/mfa-train-align.html#prerequisites",
    "title": "MFA: Train-and-Align",
    "section": "",
    "text": "In order to be able to force-align transcripts to the word and/or segment level, you first need the following:\n\nTranscripts that are aligned at the utterance level (i.e.¬†there‚Äôs a known time-point every 20 or so words), whch have been uploaded into LaBB-CAT\nA WAV file for each transcript, on the LaBB-CAT server\nA phonemic transcription word layer, that has at least one pronunciation for every word. If there are some lines/utterances that contain words with missing pronunciations, those lines will be ignored by the HTK Layer Manager.\n\nDepending on your speech data, there are several ways to obtain phonemic transcriptions for words:\n\nLexical tagging\n\nCELEX - for British English, German, Dutch, using one of the CELEX layer managers.\nCMU Pronouncing Dictionary - for US English, using th CMU Pronouncing Dictionary layer manager.\nUnisyn - for various English varieties, using the Unisyn layer manager.\nDefine your own lexicon, and use the Flat File Dictionary layer manager to integrate it into LaBB-CAT.\n\nInferring pronunciation from orthography\n\nSpanish, using the Spanish Phonological Transcriber layer manager\nBas Web Service: G2P - for various languages.\nDefine your own simple mapping rules from orthography to phonology, using the Character Mapper layer manager.\n\n\nIf the speech corpus includes data in more than one language, it is possible to ensure that the utterances are phonemically tagged in a way that‚Äôs sensitive to the language of the specific utterance, using the language layers and attributes, and auxiliary layer managers.\nWhichever method you choose, you need a phonemes ‚Äòword layer‚Äô on which each word token is tagged with its pronunciation, before you can proceed with the forced-alignment steps below.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-train-align.html#procedure-for-mfa-forced-alignment",
    "href": "howto/forced-alignment/mfa-train-align.html#procedure-for-mfa-forced-alignment",
    "title": "MFA: Train-and-Align",
    "section": "",
    "text": "The broad steps for getting forced-alignments from MFA are:\n\nInstall MFA on the same computer that LaBB-CAT is installed on\nInstall the MFA Layer Manager, which integrates LaBB-CAT with MFA\nCreate and configure a new MFA layer in LaBB-CAT\nPick a speakers/participants in your database and identify their utterances\nFill in the missing pronunciations for those utterances\nRun forced alignment\nRepeat steps 4-6 for all the participants in your database",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-train-align.html#mfa-installation",
    "href": "howto/forced-alignment/mfa-train-align.html#mfa-installation",
    "title": "MFA: Train-and-Align",
    "section": "",
    "text": "MFA is not included as part of LaBB-CAT, and so it must be installed on the server you have installed LaBB-CAT on before you can integrate LaBB-CAT with it.\nIf MFA has not been installed already, please follow the following steps, depending on the operatings system of your LaBB-CAT server:\n\n\n\n\n\n\nNoteLinux\n\n\n\n\n\nTo install the Montreal Forced Aligner on Linux systems for all users, so that your web server can access it if required:\n\nDownload Miniconda:\nwget https://repo.anaconda.com/miniconda/Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nStart the installer:\nsudo bash Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nWhen asked the location to install Miniconda, use:\n/opt/conda\nWhen asked whether the installer should initialize Miniconda, this is unnecessary so you can respond no\nChange ownership of the conda files):\nsudo chown -R $USERNAME:$USERNAME /opt/conda\nMake conda accessible to all users (so you web server can access MFA):\nchmod -R go-w /opt/conda\nchmod -R go+rX /opt/conda\nInstall the Montreal Forced Aligner\n/opt/conda/bin/conda create -n aligner -c conda-forge montreal-forced-aligner=3.2.1\n\nIf you see errors when trying to use MFA, you may find that one of the following resolves the issue:\n/opt/conda/envs/aligner/bin/pip install joblib==1.3.2\nand/or\n/opt/conda/envs/aligner/bin/pip uninstall setuptools\n/opt/conda/envs/aligner/bin/pip install setuptools==66.1.1\n\n\n\n\n\n\n\n\n\n\nNoteWindows\n\n\n\n\n\nTo install the Montreal Forced Aligner on Windows systems for all users, so that your web server can access it if required:\n\nDownload the Miniconda installer:¬†¬†¬†\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\nStart the installer by double-clicking it.\nWhen asked, select the ‚ÄúInstall for all users‚Äù option. This will install conda somewhere like\nC:\\ProgramData\\Miniconda3\nWhen asked, tick the add to PATH option.\nInstall the Montreal Forced Aligner by specifying a path to the environment\nconda create -c conda-forge -p C:\\ProgramData\\Miniconda3\\envs\\aligner montreal-forced-aligner=3.2.1\n\n\n\n\n\n\n\n\n\n\nWarningWindows Troubleshooting\n\n\n\n\n\nThe 3rd party MFA software requires:\n\nthe possibility of running command-line programs during installation and forced alignement\nthe possibility that these programs can download data from the internet\n\nOn Windows, this can sometimes be complicated by the fact that Apache Tomcat and LaBB-CAT are installed as a ‚ÄòWindows Service‚Äô. Windows Services usually run using the permissions of a special anonymous login account called ‚ÄòLocal System‚Äô, which in some environments has restricted permissions to access different resources.\nIf you install the MFA Manager LaBB-CAT integration module, but you find it returns errors when trying to interact with MFA, the problem may be that the Windows Service:\n\ndoes not have permission to access the folder where MFA is installed, or\nis not allowed to execute other programs, or\ncannot access the internet.\n\nSometimes problems can be resolved by:\n\nrunning the Apache Tomcat Windows Service as a different user other than ‚ÄòLocal System‚Äô. (or if it was running as some other used, try setting it back to ‚ÄòLocal System‚Äô), or\nadjusting the permissions of the Windows Service users, or\nadjusting the permissions of the folders where MFA is installed\nconfiguring the service to use the local Internet Proxy settings to enable connecting to the internet.\n\nPSexec is a tool that can be used to diagnose and solve problems on Windows.\n\n\n\nDownload PStool.zip from Microsoft:\nhttp://technet.microsoft.com/en-us/sysinternals/bb897553.aspx\nUnzip it\nPut PSexec.exe into C:\\Windows\\System32\nOpen cmd using ‚ÄúRun as Administrator‚Äù\nRun the command:\nPsexec.exe -i -s cmd.exe\nThis opens a new command prompt for local system account\nIn the new command prompt window, check you have the correct account type with the command:\nwhomai\n\nThen you can use the command prompt to run MFA commands to diagnose errors - e.g.:\n\nconda activate montreal-forced-aligner - activates the MFA environment\nmfa version - ensures MFA is installed and accessible, and confirms the version\nmfa model download dictionary - ensures MFA can connect to the internet to get models etc.; this command should return a long list of language dictionaries, and not report errors.\n\n\n\n\nTo update proxy server settings:\n\ntype inetcpl.cpl\ngoto Connections tab\nclick on the LAN Settings button\nFill in the Proxy section with the correct details\n\n\n\n\n\n\n\n\n\n\n\nNoteDocker Container\n\n\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, it can download and install Miniconda and MFA itself, as part of the process of installing the MFA Manager LaBB-CAT module.\nThere is no need for a separate installation of the MFA software.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-train-align.html#layer-manager-installation",
    "href": "howto/forced-alignment/mfa-train-align.html#layer-manager-installation",
    "title": "MFA: Train-and-Align",
    "section": "",
    "text": "Once MFA has been installed, you have to install the MFA Manager, which is the LaBB-CAT module that provides MFA with all the data it needs, and then saves to alignments MFA produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link.\nFind MFA Manager in the list, and press its Install button and then press Install again.\nAs long as MFA has been installed for all users, you should see a box that‚Äôs already filled in with the location that MFA was installed to.\nClick Configure to continue the layer manager installation.\nYou will see a window open with some information about integrating with MFA, including the information you‚Äôve already read above.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-train-align.html#dictionary-and-segment-layer-labels",
    "href": "howto/forced-alignment/mfa-train-align.html#dictionary-and-segment-layer-labels",
    "title": "MFA: Train-and-Align",
    "section": "",
    "text": "The labels used for phonemes layer (or whichever layer tags each word token with its pronunciation) will use a specific encoding for the phonemes. Encodings include:\n\nCELEX DISC: Exactly one ASCII character per phoneme,\ne.g.¬†there‚Äôll ‚Üí D8r@l\nUnicode IPA: One or more Unicode character per phoneme, possibly including diacritics, delimited by spaces:\ne.g.¬†there‚Äôll ‚Üí √∞ …õ…ô …π lÃ©\nARPAbet: Phonemes are one or two uppercase ASCII characters, possibly suffixed with a digit indicating stress, delimited by spaces:\ne.g.¬†there‚Äôll ‚Üí DH EH1 R AX0 L\n\nIf it uses CELEX DISC encoding, the phonemes layer should have its Type set to Phonological on the word layers page. Otherwise its Type should be set to Text.\nIn order to ensure that the labels that the MFA Manager will create on the segment layer use the same encoding, the segment layer must have the same Type as the phonemes layer. In order to ensure that:\n\nSelect the segment layers option on the menu.\nThe segment layer is the first on the list (and may be the only layer there).\nCheck the Type of the segment layer. If it‚Äôs not the same as the phonemes layer, change the Type so that it matches, and press the Save button that appears.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-train-align.html#create-the-mfa-layer",
    "href": "howto/forced-alignment/mfa-train-align.html#create-the-mfa-layer",
    "title": "MFA: Train-and-Align",
    "section": "",
    "text": "Once you‚Äôve installed MFA and the MFA Layer Manager, you need to create a new layer for triggering and controlling forced alignment. This layer will itself contain a timestamp for each line/utterance it has force-aligned (and so it‚Äôs a ‚Äòphrase‚Äô layer), but during that process, the word and phone alignments will also be set on other layers.\n\nSelect the phrase layers option on the menu\nFill in the form at the top of the page (which doubles as column headings) with the following details:\n\nLayer ID: mfa\nType: Text\nAlignment: Intervals\nManager: MFA Manager\nGenerate: never (this is because we will manually select utterance for forced alignment, to ensure there is enough data to train acoustic models)\nDescription: MFA alignment time\n\nWhen you configure the layer, set the following options:\n\nPronunciation Layer: select the phonemes layer (or whichever word layer that tags each word with its pronunciation)\nDictionary Name: [none]\nPretrained Acoustic Models: [none] (this ensures that the train/align procedure is used)\nThe rest of the options can be left as their default values.\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a `tool tip‚Äô that describes what the option is for.\n\nPress Set Parameters",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-train-align.html#batch-alignment",
    "href": "howto/forced-alignment/mfa-train-align.html#batch-alignment",
    "title": "MFA: Train-and-Align",
    "section": "",
    "text": "MFA is data-hungry when training acoustic models for forced alignment, and needs 3-5 hours‚Äô speech\nTo start a forced-alignment process for a batch of selected participants, you need to first select the participants who will be aligned. Then you need to list all their utterances, and MFA will first training acoustic models from scratch from them, and then using those acoustic models, align those same utterances.\n\nIn LaBB-CAT, select the participants link on the menu\nFilter the list to display the desired participants, and tick the checkbox next to each participant you want to include\nPress the All Utterances button above\nPress List to list all of their utterances.\nA progress bar will appear while LaBB-CAT identifies all the selected participant‚Äôs utterances. Once this is done, the first twenty utterances will be listed (like search results, the first twenty are listed for convenience, but you can process all matching utterances)\nClick the Mfa button below the list.\nA progress bar will appear while MFA gathers up all the utterance data, trains acoustic models, force-aligns the utterances, and then saves the resulting alignments back to LaBB-CAT. This process may take some time.\n\nOnce the progress bar reaches 100% and the process is complete, the selected utterances will have word start/end times set, and aligned phones will have been added to the segment layer, using the same labels as appear in the phonemes layer",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/htk-train-align.html",
    "href": "howto/forced-alignment/htk-train-align.html",
    "title": "HTK: Train-and-Align",
    "section": "",
    "text": "You can use ‚ÄòHTK‚Äô to train new speaker-specific acoustic models on your speech data, and then to force align the data on those models. You may decide to do this if:\n\nYou can‚Äôt share your data with third parties and so can‚Äôt use WebMAUS.\nYour data isn‚Äôt US English (or similar) and so you can‚Äôt use HTK with the P2FA pre-trained models.\nYou have at least 5 minutes‚Äô speech for each speaker.\n\nThe general process is illustrated in Figure¬†1\n\n\n\n\n\n\nFigure¬†1: Pronunciations are generated from transcripts, and then combined with the recordings to train acoustic models, which are then used to compute phone-level alignements, which are saved to LaBB-CAT‚Äôs database\n\n\n\n\n\nIn order to be able to force-align transcripts to the word and/or segment level, you first need the following:\n\nTranscripts that are aligned at the utterance level (i.e.¬†there‚Äôs a known time-point every 20 or so words), whch have been uploaded into LaBB-CAT\nA WAV file for each transcript, on the LaBB-CAT server\nA phonemic transcription word layer, that has at least one pronunciation for every word. If there are some lines/utterances that contain words with missing pronunciations, those lines will be ignored by the HTK Layer Manager.\n\nDepending on your speech data, there are several ways to obtain phonemic transcriptions for words:\n\nLexical tagging\n\nCELEX - for British English, German, Dutch, using one of the CELEX layer managers.\nCMU Pronouncing Dictionary - for US English, using th CMU Pronouncing Dictionary layer manager.\nUnisyn - for various English varieties, using the Unisyn layer manager.\nDefine your own lexicon, and use the Flat File Dictionary layer manager to integrate it into LaBB-CAT.\n\nInferring pronunciation from orthography\n\nSpanish, using the Spanish Phonological Transcriber layer manager\nBas Web Service: G2P - for various languages.\nDefine your own simple mapping rules from orthography to phonology, using the Character Mapper layer manager.\n\n\nIf the speech corpus includes data in more than one language, it is possible to ensure that the utterances are phonemically tagged in a way that‚Äôs sensitive to the language of the specific utterance, using the language layers and attributes, and auxiliary layer managers.\nWhichever method you choose, you need a phonemes ‚Äòword layer‚Äô on which each word token is tagged with its pronunciation, before you can proceed with the forced-alignment steps below.\n\n\n\nThe broad steps for getting forced-alignments from HTK are:\n\nInstall HTK on the same computer that LaBB-CAT is installed on\nInstall the HTK Layer Manager, which integrates LaBB-CAT with HTK\nCreate and configure a new HTK layer in LaBB-CAT\nPick a speaker/participant in your database\nFill in the missing pronunciations for that participant\nRun forced alignment\nRepeat steps 4-6 for all the participants in your database\n\n\n\nHTK is a 3rd-party tool that you must download and install from the Cambridge University website.\n\nRegister at http://htk.eng.cam.ac.uk/register.shtml\nDownload the version of HTK that is appropriate for the computer that LaBB-CAT is install on:\nFor Windows systems, there are pre-compiled .exe files that you can download. For Unix-like systems, you need to download the source code, which you will then install following the provided instructions (you may also need to install the xorg-dev package before it will successfully compile).\nUnzip (for Windows) or compile and install (for Unix-like systems) the downloaded files on the computer that LaBB-CAT is installed on.\n\n\n\n\nThe HTK Layer Manager is a LaBB-CAT module that integrates LaBB-CAT with HTK.\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for HTK in the list, and press it‚Äôs Install button.\nYou will see a form with boxes for filling in information.\n\nHTK Path must be set to the location where the HTK files are installed on your system. If this is already filled in, it‚Äôs probably correct. If it‚Äôs blank, you have to enter the full path for the HTK programs:\n\nOn Windows systems, this is where you unzipped the HTK .exe files - e.g.¬†something like C:\\Downloads\\HTK\nOn Unix-like systems, this is probably /usr/local/bin, but you can verify this by entering which HCopy at a command shell prompt.\n\nHTK Working Folder will already have a default value, which is probably best left as-is\n\nPress Install Layer Manager\n\n\n\n\nOnce you‚Äôve installed HTK and the HTK Layer Manager, you need to create a new layer for triggering and controlling forced alignment. This layer will itself contain a timestamp for each line/utterance it has force-aligned (and so it‚Äôs a ‚Äòphrase‚Äô layer), but during that process, the word and phone alignments will also be set on other layers.\n\nIn LaBB-CAT, select the phrase layers option\nAt the top of the page, there‚Äôs a blank form for creating a new layer; fill in the following details:\n\nLayer ID: HTK\nType: Text\nManager: HTK Manager\nAlignment: Time Intervals\nGenerate: Always\n\nPress New.\nYou will see the layer configuration page.\nCheck the online help if you want information about all the options, however, most likely the default options are approriate, except:\n\nPronunciaton Layer: this is the layer that provides the phonemic transcriptions for all the words; ensure you select the phonemes layer you created above.\nNB If you have created this layer but it doesn‚Äôt appear here as an option, it‚Äôs probably because the ‚Äòlayer type‚Äô of your pronunciation layer is not set to ‚ÄòPhonological‚Äô, which will need to be changed in order for it to appear as an option here.\nNB In the list of options there‚Äôs also a layer called ‚Äúpronounce‚Äù; this is a system layer for manually-added pronunciations, and you would only select that layer here if you have manually annotated pronunciations against every single word in your transcripts. You probably haven‚Äôt done that, so you don‚Äôt want to select the ‚Äúpronounce‚Äù layer here.\nUse P2FA models: ensure this option is un-ticked.\n\nPress Save.\nIf you are confident all your transcripts include all pronunciations for all words, you can press Regenerate to force-align your whole corpus now. However, most likely you‚Äôll need to proceed per-speaker, described below, in order to fill in missing pronunciations.\n\n\n\n\nTo start a forced-alignment process per-speaker, you need to first select a speaker who will be aligned. Then you will fill in any missing pronunciations. After that, HTK will automatically force-align their utterances.\n\nIn LaBB-CAT, select the participants option on the menu\nTick a speaker, and press the All Utterances button\nClick List\nOnce the paginated list of utterances appears, press the HTK button below.\nBasically you need to fill in the boxes with the pronunciations and click Save Pronunciations.\n\n\n\n\n\n\n\nNote\n\n\n\n\nYou don‚Äôt have to fill them all in at once, you can do a few, and click Save, which will save your work and list what‚Äôs left.\nYou don‚Äôt have to fill them all in, you can leave some empty and continue with the HTK forced-alignment by clicking Start (HTK will ignore any lines where the remaining unknown words appear, but the ones you filled in will be included).\nSome of the boxes will be initially filled in with a suggestion from the lexicon layer manager - these may or may not be correct, and aren‚Äôt saved until you save them.\nThe pronunciations have to be in the ‚ÄòDISC‚Äô format - i.e.¬†one character per phoneme, with no spaces. There‚Äôs a ‚Äòhelper‚Äô link on the right of each pronunciation box - if you click it, it expands into a list of clickable phonemes - just the ones that aren‚Äôt ordinary letters, and diphthongs etc.\nThe search button lets you look up the lexicon for similar words - this probably won‚Äôt help for place names, but for words like ‚Äútarseal‚Äù, you can click the lookup button, enter ‚Äútar seal‚Äù in the box as two separate words, and you‚Äôll get back the DISC pronunciation of each word, with clickable buttons to copy the given pronunciation into the box. This is useful for digits and numbers too, which may not be in the lexicon - so for ‚Äú1‚Äù, search for ‚Äúone‚Äù and copy the pronunciation.\nIf you click on the word itself, the transcript for the first instance of that word is opened, in case you want to listen to it, or in case it‚Äôs actually just a typo and you want to correct the transcript.\nIf you‚Äôre using CELEX, when you specify the pronunciations, it‚Äôs recommended to put syllable separators (-) and primary stress markers (‚Äô) too - e.g.¬†for ‚Äútarseal‚Äù you can put t#sil but it would actually be better to put t#-‚Äôsil. These markers are entered into the dictionary even though they‚Äôre stripped out for HTK, and they may come in handy later (e.g.¬†the syllable separators are used by the CELEX layer manager to count syllables).\n\n\n\nWhen you add pronunciations this way, they‚Äôre added to the dictionary and all the instances of those words in LaBB-CAT are updated with the pronunciations - not just the participant you‚Äôre looking at, but all participants in the database. So you only have to come up with a pronunciation for each word once.\n\nOnce you‚Äôve filled in all the missing pronunciations, forced alignment will start automatically. If you want to start forced alignment before you‚Äôve entered all pronunciations, click the Start button at the bottom of the page.\n\nYou should see a progress bar while the forced alignment is running. It will take a few minutes to complete.\n\nOnce HTK has produced the word and segment alignments, it:\n\nsets the start/end times of the words on the transcript layer accordingly,\nadds new phone annotations to the segments layer with the alignments of the phones, and\nsaves a timestamp in the htk layer.\n\nWhen the layer manager has finished, you‚Äôll see a message saying ‚ÄúComplete - words and phones from selected utterances are now aligned.‚Äù",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "HTK: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/htk-train-align.html#prerequisites",
    "href": "howto/forced-alignment/htk-train-align.html#prerequisites",
    "title": "HTK: Train-and-Align",
    "section": "",
    "text": "In order to be able to force-align transcripts to the word and/or segment level, you first need the following:\n\nTranscripts that are aligned at the utterance level (i.e.¬†there‚Äôs a known time-point every 20 or so words), whch have been uploaded into LaBB-CAT\nA WAV file for each transcript, on the LaBB-CAT server\nA phonemic transcription word layer, that has at least one pronunciation for every word. If there are some lines/utterances that contain words with missing pronunciations, those lines will be ignored by the HTK Layer Manager.\n\nDepending on your speech data, there are several ways to obtain phonemic transcriptions for words:\n\nLexical tagging\n\nCELEX - for British English, German, Dutch, using one of the CELEX layer managers.\nCMU Pronouncing Dictionary - for US English, using th CMU Pronouncing Dictionary layer manager.\nUnisyn - for various English varieties, using the Unisyn layer manager.\nDefine your own lexicon, and use the Flat File Dictionary layer manager to integrate it into LaBB-CAT.\n\nInferring pronunciation from orthography\n\nSpanish, using the Spanish Phonological Transcriber layer manager\nBas Web Service: G2P - for various languages.\nDefine your own simple mapping rules from orthography to phonology, using the Character Mapper layer manager.\n\n\nIf the speech corpus includes data in more than one language, it is possible to ensure that the utterances are phonemically tagged in a way that‚Äôs sensitive to the language of the specific utterance, using the language layers and attributes, and auxiliary layer managers.\nWhichever method you choose, you need a phonemes ‚Äòword layer‚Äô on which each word token is tagged with its pronunciation, before you can proceed with the forced-alignment steps below.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "HTK: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/htk-train-align.html#procedure-for-htk-forced-alignment",
    "href": "howto/forced-alignment/htk-train-align.html#procedure-for-htk-forced-alignment",
    "title": "HTK: Train-and-Align",
    "section": "",
    "text": "The broad steps for getting forced-alignments from HTK are:\n\nInstall HTK on the same computer that LaBB-CAT is installed on\nInstall the HTK Layer Manager, which integrates LaBB-CAT with HTK\nCreate and configure a new HTK layer in LaBB-CAT\nPick a speaker/participant in your database\nFill in the missing pronunciations for that participant\nRun forced alignment\nRepeat steps 4-6 for all the participants in your database\n\n\n\nHTK is a 3rd-party tool that you must download and install from the Cambridge University website.\n\nRegister at http://htk.eng.cam.ac.uk/register.shtml\nDownload the version of HTK that is appropriate for the computer that LaBB-CAT is install on:\nFor Windows systems, there are pre-compiled .exe files that you can download. For Unix-like systems, you need to download the source code, which you will then install following the provided instructions (you may also need to install the xorg-dev package before it will successfully compile).\nUnzip (for Windows) or compile and install (for Unix-like systems) the downloaded files on the computer that LaBB-CAT is installed on.\n\n\n\n\nThe HTK Layer Manager is a LaBB-CAT module that integrates LaBB-CAT with HTK.\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for HTK in the list, and press it‚Äôs Install button.\nYou will see a form with boxes for filling in information.\n\nHTK Path must be set to the location where the HTK files are installed on your system. If this is already filled in, it‚Äôs probably correct. If it‚Äôs blank, you have to enter the full path for the HTK programs:\n\nOn Windows systems, this is where you unzipped the HTK .exe files - e.g.¬†something like C:\\Downloads\\HTK\nOn Unix-like systems, this is probably /usr/local/bin, but you can verify this by entering which HCopy at a command shell prompt.\n\nHTK Working Folder will already have a default value, which is probably best left as-is\n\nPress Install Layer Manager\n\n\n\n\nOnce you‚Äôve installed HTK and the HTK Layer Manager, you need to create a new layer for triggering and controlling forced alignment. This layer will itself contain a timestamp for each line/utterance it has force-aligned (and so it‚Äôs a ‚Äòphrase‚Äô layer), but during that process, the word and phone alignments will also be set on other layers.\n\nIn LaBB-CAT, select the phrase layers option\nAt the top of the page, there‚Äôs a blank form for creating a new layer; fill in the following details:\n\nLayer ID: HTK\nType: Text\nManager: HTK Manager\nAlignment: Time Intervals\nGenerate: Always\n\nPress New.\nYou will see the layer configuration page.\nCheck the online help if you want information about all the options, however, most likely the default options are approriate, except:\n\nPronunciaton Layer: this is the layer that provides the phonemic transcriptions for all the words; ensure you select the phonemes layer you created above.\nNB If you have created this layer but it doesn‚Äôt appear here as an option, it‚Äôs probably because the ‚Äòlayer type‚Äô of your pronunciation layer is not set to ‚ÄòPhonological‚Äô, which will need to be changed in order for it to appear as an option here.\nNB In the list of options there‚Äôs also a layer called ‚Äúpronounce‚Äù; this is a system layer for manually-added pronunciations, and you would only select that layer here if you have manually annotated pronunciations against every single word in your transcripts. You probably haven‚Äôt done that, so you don‚Äôt want to select the ‚Äúpronounce‚Äù layer here.\nUse P2FA models: ensure this option is un-ticked.\n\nPress Save.\nIf you are confident all your transcripts include all pronunciations for all words, you can press Regenerate to force-align your whole corpus now. However, most likely you‚Äôll need to proceed per-speaker, described below, in order to fill in missing pronunciations.\n\n\n\n\nTo start a forced-alignment process per-speaker, you need to first select a speaker who will be aligned. Then you will fill in any missing pronunciations. After that, HTK will automatically force-align their utterances.\n\nIn LaBB-CAT, select the participants option on the menu\nTick a speaker, and press the All Utterances button\nClick List\nOnce the paginated list of utterances appears, press the HTK button below.\nBasically you need to fill in the boxes with the pronunciations and click Save Pronunciations.\n\n\n\n\n\n\n\nNote\n\n\n\n\nYou don‚Äôt have to fill them all in at once, you can do a few, and click Save, which will save your work and list what‚Äôs left.\nYou don‚Äôt have to fill them all in, you can leave some empty and continue with the HTK forced-alignment by clicking Start (HTK will ignore any lines where the remaining unknown words appear, but the ones you filled in will be included).\nSome of the boxes will be initially filled in with a suggestion from the lexicon layer manager - these may or may not be correct, and aren‚Äôt saved until you save them.\nThe pronunciations have to be in the ‚ÄòDISC‚Äô format - i.e.¬†one character per phoneme, with no spaces. There‚Äôs a ‚Äòhelper‚Äô link on the right of each pronunciation box - if you click it, it expands into a list of clickable phonemes - just the ones that aren‚Äôt ordinary letters, and diphthongs etc.\nThe search button lets you look up the lexicon for similar words - this probably won‚Äôt help for place names, but for words like ‚Äútarseal‚Äù, you can click the lookup button, enter ‚Äútar seal‚Äù in the box as two separate words, and you‚Äôll get back the DISC pronunciation of each word, with clickable buttons to copy the given pronunciation into the box. This is useful for digits and numbers too, which may not be in the lexicon - so for ‚Äú1‚Äù, search for ‚Äúone‚Äù and copy the pronunciation.\nIf you click on the word itself, the transcript for the first instance of that word is opened, in case you want to listen to it, or in case it‚Äôs actually just a typo and you want to correct the transcript.\nIf you‚Äôre using CELEX, when you specify the pronunciations, it‚Äôs recommended to put syllable separators (-) and primary stress markers (‚Äô) too - e.g.¬†for ‚Äútarseal‚Äù you can put t#sil but it would actually be better to put t#-‚Äôsil. These markers are entered into the dictionary even though they‚Äôre stripped out for HTK, and they may come in handy later (e.g.¬†the syllable separators are used by the CELEX layer manager to count syllables).\n\n\n\nWhen you add pronunciations this way, they‚Äôre added to the dictionary and all the instances of those words in LaBB-CAT are updated with the pronunciations - not just the participant you‚Äôre looking at, but all participants in the database. So you only have to come up with a pronunciation for each word once.\n\nOnce you‚Äôve filled in all the missing pronunciations, forced alignment will start automatically. If you want to start forced alignment before you‚Äôve entered all pronunciations, click the Start button at the bottom of the page.\n\nYou should see a progress bar while the forced alignment is running. It will take a few minutes to complete.\n\nOnce HTK has produced the word and segment alignments, it:\n\nsets the start/end times of the words on the transcript layer accordingly,\nadds new phone annotations to the segments layer with the alignments of the phones, and\nsaves a timestamp in the htk layer.\n\nWhen the layer manager has finished, you‚Äôll see a message saying ‚ÄúComplete - words and phones from selected utterances are now aligned.‚Äù",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "HTK: Train-and-Align"
    ]
  },
  {
    "objectID": "howto/forced-alignment/identifying-unaligned-utterances.html",
    "href": "howto/forced-alignment/identifying-unaligned-utterances.html",
    "title": "Identifying Unaligned Utterances",
    "section": "",
    "text": "Under some circumstances, forced alignment can fail to produce alignments for some utterances; i.e.¬†the utterance has no phone annotations created, the words are not aligned, and no htk annotation is created. This can happen because of the following factors:\n\nNot enough data (if you‚Äôre using the ‚Äòtrain-and-align‚Äô approach)\nPoor quality recording, background noises, etc.\nSimultaneous speech (ignored by default)\nInaccurate transcripts\nInaccurate utterance alignment\nLack of pause marking in the transcripts\nMismatched phonology between dictionary and speech\ne.g.¬†using a rhotic dictionary to align non-rhotic speech\n\nYou can identify the utterances for which alignment has failed using LaBB-CAT‚Äôs search and export functionality:\n\nClick search and select the speaker(s) you aligned.\nThe search should be ‚Äúthe first word of each utterance that doesn‚Äôt have an htk annotation‚Äù - i.e.:\n\northography layer: matches .+\nutterance layer: tick the left-hand checkbox that anchors the word to the beginning of the utterance\nhtk1 layer: doesn‚Äôt match .+. \n\nWhen the results are listed, click CSV Export\n\nThe resulting file has the start and end time of each utterance in the Line and LineEnd columns. If you want to know the total duration of the unaligned utterances, use Excel or R to calculate the difference between LineEnd and Line to get the line duration, and then sum these durations to get the total, which is in seconds.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "Identifying Unaligned Utterances"
    ]
  },
  {
    "objectID": "howto/forced-alignment/identifying-unaligned-utterances.html#footnotes",
    "href": "howto/forced-alignment/identifying-unaligned-utterances.html#footnotes",
    "title": "Identifying Unaligned Utterances",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhtk or whatever the phrase tag layer is in the forced alignment configuration‚Ü©Ô∏é",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "Identifying Unaligned Utterances"
    ]
  },
  {
    "objectID": "howto/forced-alignment/bas-services-manager.html",
    "href": "howto/forced-alignment/bas-services-manager.html",
    "title": "BAS Web Service Manager and WebMAUS",
    "section": "",
    "text": "The Bavarian Archive for Speech Signals (BAS), has kindly published a set of speech processing web services including one for for forced alignment called WebMAUS. You can use this service yourself directly, using your web browser, but LaBB-CAT also has a module for using it automatically, called the BAS Services Manager.\nThe general process is illustrated below:\n\n\n\nTranscripts/recordings from LaBB-CAT are sent to WebMAUS, and the resulting alignments are saved in LaBB-CAT\n\n\n\n\n\n\n\n\nCaution\n\n\n\nUsing WebMAUS for forced alignment requires LaBB-CAT to send your recordings and transcripts over the internet to a third party. Although point 3 of the BAS Web Services Terms of Service makes clear that uploaded data is deleted after 24 hours, using the service is only suitable in situations in which you have consent from participants to do so.\n\n\n\nAlbanian\nAustralian Aboriginal Languages\nAfrikaans\nAlbanian\nBasque\nCatalan\nDutch\nEnglish\nEstonian\nFinnish\nFrench\nGeorgian\nGerman\nHungarian\nItalian\nJapanese\nKunwinjku\nLuxembourgish\nMaltese\nNorwegian\nPolish\nRomanian\nRussian\nSpanish\nSwedish\nYol≈ãu Matha\n\nLaBB-CAT must be able to identify which language each transcript is in, so you must ensure the language is set either\n\nin the transcript‚Äôs Language transcript attribute, or\non the corpora page (where you can define the language for all transcripts each corpus).\n\nThe available language options can be set in LaBB-CAT by going to the transcript attributes page and clicking the Options button of the ‚Äúlanguage‚Äù attribute. The value must be a two-letter ISO639-1 code optionally appended with a two-letter country code - e.g.¬†‚Äúen‚Äù or ‚Äúen-NZ‚Äù.\n\n\n\nIn LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for BAS Web Services Manager in the list, and press it‚Äôs Install button.\nFollow the ‚Äúterms of usage‚Äù link and read the terms.\nClose the terms page, returning to LaBB-CAT.\nSelect true for the ‚ÄúAccept Terms of Usage‚Äù option\nPress Install.\nYou will see a page of information about the Layer Manager, including instructions on how to set up forced alignment.\n\n\n\n\n\nSelect the phrase layers option on the menu\nAt the top of the page, there‚Äôs a blank form for creating a new layer; fill in the following details:\n\nLayer ID: MAUS\nType: Text\nManager: BAS Web Services Manager\nAlignment: Time Intervals\nGenerate: Always\nDescription: WebMAUS Forced alignment\n\nPress New.\nYou will see a form that allows you to configure the layer; check the online help for that page to guide you. The main choice is the ‚ÄúPhoneme encoding‚Äù: the default option, DISC, is probably the best because using this phoneme encoding ensures the layer will work well with other modules, and will be easily searchable. However, it is possible to choose sampa instead, in which case the layer type of the segments layer should be set to Text.\nPress Save\nIf you want to immediately force-align all the recordings in your corpus, press Regenerate.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "BAS Web Service Manager and WebMAUS"
    ]
  },
  {
    "objectID": "howto/forced-alignment/bas-services-manager.html#install-the-layer-manager",
    "href": "howto/forced-alignment/bas-services-manager.html#install-the-layer-manager",
    "title": "BAS Web Service Manager and WebMAUS",
    "section": "",
    "text": "In LaBB-CAT, select the layer managers option on the menu, which gives you a list of the layer managers already installed.\nAt the bottom of the page, follow the List of layer managers that are not yet installed link.\nLook for BAS Web Services Manager in the list, and press it‚Äôs Install button.\nFollow the ‚Äúterms of usage‚Äù link and read the terms.\nClose the terms page, returning to LaBB-CAT.\nSelect true for the ‚ÄúAccept Terms of Usage‚Äù option\nPress Install.\nYou will see a page of information about the Layer Manager, including instructions on how to set up forced alignment.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "BAS Web Service Manager and WebMAUS"
    ]
  },
  {
    "objectID": "howto/forced-alignment/bas-services-manager.html#set-up-a-layer-for-triggering-forced-alignment",
    "href": "howto/forced-alignment/bas-services-manager.html#set-up-a-layer-for-triggering-forced-alignment",
    "title": "BAS Web Service Manager and WebMAUS",
    "section": "",
    "text": "Select the phrase layers option on the menu\nAt the top of the page, there‚Äôs a blank form for creating a new layer; fill in the following details:\n\nLayer ID: MAUS\nType: Text\nManager: BAS Web Services Manager\nAlignment: Time Intervals\nGenerate: Always\nDescription: WebMAUS Forced alignment\n\nPress New.\nYou will see a form that allows you to configure the layer; check the online help for that page to guide you. The main choice is the ‚ÄúPhoneme encoding‚Äù: the default option, DISC, is probably the best because using this phoneme encoding ensures the layer will work well with other modules, and will be easily searchable. However, it is possible to choose sampa instead, in which case the layer type of the segments layer should be set to Text.\nPress Save\nIf you want to immediately force-align all the recordings in your corpus, press Regenerate.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "BAS Web Service Manager and WebMAUS"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-pretrained-models.html",
    "href": "howto/forced-alignment/mfa-pretrained-models.html",
    "title": "MFA and Pretrained Acoustic Models",
    "section": "",
    "text": "The Montreal Forced Aligner (MFA) is a third-party tool developed by Michael McAuliffe and others for time aligning orthographic and phonological forms from a pronunciation dictionary to orthographically transcribed audio files. It is open source software based on the Kaldi ASR toolkit.\nLaBB-CAT includes a layer manager module called ‚ÄúMFA Manager‚Äù which integrates with MFA in order to facilitate forced alignment of LaBB-CAT corpus data.\nThe layer manager can work in two modes:\n\nTrain and Align - acoustic models are trained on the data you want to align, which can be in any language as long as you have a pronunciation dictionary for it.\nPre-trained Models/Dictionaries - pre-trained models and pronunciation dictionaries are supplied by the Montreal Forced Aligner and used for forced alignment. Languages for which dictionaries are available listed on the MFA website and include:\n\nEnglish\nFrench\nGerman\nBrazilian Portuguese\nSpanish\nCatalan\n\n\nThese instructions assume that your corpus is in one of these languages, and uses the Pre-trained Models/Dictionaries approach‚Ä¶\n\n\n\nMFA is not included as part of LaBB-CAT, and so it must be installed on the server you have installed LaBB-CAT on before you can integrate LaBB-CAT with it.\nIf MFA has not been installed already, please follow the following steps, depending on the operatings system of your LaBB-CAT server:\n\n\n\n\n\n\nNoteLinux\n\n\n\n\n\nTo install the Montreal Forced Aligner on Linux systems for all users, so that your web server can access it if required:\n\nDownload Miniconda:\nwget https://repo.anaconda.com/miniconda/Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nStart the installer:\nsudo bash Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nWhen asked the location to install Miniconda, use:\n/opt/conda\nWhen asked whether the installer should initialize Miniconda, this is unnecessary so you can respond no\nChange ownership of the conda files):\nsudo chown -R $USERNAME:$USERNAME /opt/conda\nMake conda accessible to all users (so you web server can access MFA):\nchmod -R go-w /opt/conda\nchmod -R go+rX /opt/conda\nInstall the Montreal Forced Aligner\n/opt/conda/bin/conda create -n aligner -c conda-forge montreal-forced-aligner=3.2.1\n\nIf you see errors when trying to use MFA, you may find that one of the following resolves the issue:\n/opt/conda/envs/aligner/bin/pip install joblib==1.3.2\nand/or\n/opt/conda/envs/aligner/bin/pip uninstall setuptools\n/opt/conda/envs/aligner/bin/pip install setuptools==66.1.1\n\n\n\n\n\n\n\n\n\n\nNoteWindows\n\n\n\n\n\nTo install the Montreal Forced Aligner on Windows systems for all users, so that your web server can access it if required:\n\nDownload the Miniconda installer:¬†¬†¬†\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\nStart the installer by double-clicking it.\nWhen asked, select the ‚ÄúInstall for all users‚Äù option. This will install conda somewhere like\nC:\\ProgramData\\Miniconda3\nWhen asked, tick the add to PATH option.\nInstall the Montreal Forced Aligner by specifying a path to the environment\nconda create -c conda-forge -p C:\\ProgramData\\Miniconda3\\envs\\aligner montreal-forced-aligner=3.2.1\n\n\n\n\n\n\n\n\n\n\nWarningWindows Troubleshooting\n\n\n\n\n\nThe 3rd party MFA software requires:\n\nthe possibility of running command-line programs during installation and forced alignement\nthe possibility that these programs can download data from the internet\n\nOn Windows, this can sometimes be complicated by the fact that Apache Tomcat and LaBB-CAT are installed as a ‚ÄòWindows Service‚Äô. Windows Services usually run using the permissions of a special anonymous login account called ‚ÄòLocal System‚Äô, which in some environments has restricted permissions to access different resources.\nIf you install the MFA Manager LaBB-CAT integration module, but you find it returns errors when trying to interact with MFA, the problem may be that the Windows Service:\n\ndoes not have permission to access the folder where MFA is installed, or\nis not allowed to execute other programs, or\ncannot access the internet.\n\nSometimes problems can be resolved by:\n\nrunning the Apache Tomcat Windows Service as a different user other than ‚ÄòLocal System‚Äô. (or if it was running as some other used, try setting it back to ‚ÄòLocal System‚Äô), or\nadjusting the permissions of the Windows Service users, or\nadjusting the permissions of the folders where MFA is installed\nconfiguring the service to use the local Internet Proxy settings to enable connecting to the internet.\n\nPSexec is a tool that can be used to diagnose and solve problems on Windows.\n\n\n\nDownload PStool.zip from Microsoft:\nhttp://technet.microsoft.com/en-us/sysinternals/bb897553.aspx\nUnzip it\nPut PSexec.exe into C:\\Windows\\System32\nOpen cmd using ‚ÄúRun as Administrator‚Äù\nRun the command:\nPsexec.exe -i -s cmd.exe\nThis opens a new command prompt for local system account\nIn the new command prompt window, check you have the correct account type with the command:\nwhomai\n\nThen you can use the command prompt to run MFA commands to diagnose errors - e.g.:\n\nconda activate montreal-forced-aligner - activates the MFA environment\nmfa version - ensures MFA is installed and accessible, and confirms the version\nmfa model download dictionary - ensures MFA can connect to the internet to get models etc.; this command should return a long list of language dictionaries, and not report errors.\n\n\n\n\nTo update proxy server settings:\n\ntype inetcpl.cpl\ngoto Connections tab\nclick on the LAN Settings button\nFill in the Proxy section with the correct details\n\n\n\n\n\n\n\n\n\n\n\nNoteDocker Container\n\n\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, it can download and install Miniconda and MFA itself, as part of the process of installing the MFA Manager LaBB-CAT module.\nThere is no need for a separate installation of the MFA software.\n\n\n\n\n\n\n\nOnce MFA has been installed, you have to install the MFA Manager, which is the LaBB-CAT module that provides MFA with all the data it needs, and then saves to alignments MFA produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link.\nFind MFA Manager in the list, and press its Install button and then press Install again.\nAs long as MFA has been installed for all users, you should see a box that‚Äôs already filled in with the location that MFA was installed to.\nClick Configure to continue the layer manager installation.\nYou will see a window open with some information about integrating with MFA, including the information you‚Äôve already read above.\n\n\n\n\nOnce you‚Äôve\n\nNow you need to add a phrase layer for the HTK configuration:\n\nLayer ID: mfa\nType: Text\nAlignment: Intervals\nManager: MFA Manager\nGenerate: always\nDescription: MFA alignment time\n\nWhen you configure the layer, set the following options:\n\nDictionary Name: the dictionary language, e.g.¬†english_uk_mfa\nPretrained Acoustic Models: the models language, e.g.¬†english_mfa\nThe rest of the options can be left as their default values.\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a `tool tip‚Äô that describes what the option is for.\n\nPress Set Parameters\nPress Regenerate\nYou will see a progress bar while LaBB-CAT force-aligns all the transcripts in the corpus, which may take a few minutes.\nWhen the layer manager has finished, you‚Äôll see a message saying:\nComplete - words and phones from selected utterances are now aligned.\n\n\n\n\n\n\n\nTip\n\n\n\nNot all MFA pre-trained acoustic models can be used with all dictionaries.\nApart from matching the language (e.g.¬†English-trained acoustic models should be used only with English dictionaries), the phoneme symbol sets must also match.\nMFA uses several symbol sets, including:\n\nIPA - model and dictionary names ending in ..._mfa\nARPAbet - model and dictionary names ending in ..._arpa\n\nSo if you use an acoustic model ending in ...arpa, then the dictionary you choose must also end in ...arpa.\nSee the MFA documentation on models and dictionaries for more detailed information:\nhttps://mfa-models.readthedocs.io",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA and Pretrained Acoustic Models"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-pretrained-models.html#mfa-installation",
    "href": "howto/forced-alignment/mfa-pretrained-models.html#mfa-installation",
    "title": "MFA and Pretrained Acoustic Models",
    "section": "",
    "text": "MFA is not included as part of LaBB-CAT, and so it must be installed on the server you have installed LaBB-CAT on before you can integrate LaBB-CAT with it.\nIf MFA has not been installed already, please follow the following steps, depending on the operatings system of your LaBB-CAT server:\n\n\n\n\n\n\nNoteLinux\n\n\n\n\n\nTo install the Montreal Forced Aligner on Linux systems for all users, so that your web server can access it if required:\n\nDownload Miniconda:\nwget https://repo.anaconda.com/miniconda/Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nStart the installer:\nsudo bash Miniconda3-py38\\_4.10.3-Linux-x86\\_64.sh\nWhen asked the location to install Miniconda, use:\n/opt/conda\nWhen asked whether the installer should initialize Miniconda, this is unnecessary so you can respond no\nChange ownership of the conda files):\nsudo chown -R $USERNAME:$USERNAME /opt/conda\nMake conda accessible to all users (so you web server can access MFA):\nchmod -R go-w /opt/conda\nchmod -R go+rX /opt/conda\nInstall the Montreal Forced Aligner\n/opt/conda/bin/conda create -n aligner -c conda-forge montreal-forced-aligner=3.2.1\n\nIf you see errors when trying to use MFA, you may find that one of the following resolves the issue:\n/opt/conda/envs/aligner/bin/pip install joblib==1.3.2\nand/or\n/opt/conda/envs/aligner/bin/pip uninstall setuptools\n/opt/conda/envs/aligner/bin/pip install setuptools==66.1.1\n\n\n\n\n\n\n\n\n\n\nNoteWindows\n\n\n\n\n\nTo install the Montreal Forced Aligner on Windows systems for all users, so that your web server can access it if required:\n\nDownload the Miniconda installer:¬†¬†¬†\nhttps://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe\nStart the installer by double-clicking it.\nWhen asked, select the ‚ÄúInstall for all users‚Äù option. This will install conda somewhere like\nC:\\ProgramData\\Miniconda3\nWhen asked, tick the add to PATH option.\nInstall the Montreal Forced Aligner by specifying a path to the environment\nconda create -c conda-forge -p C:\\ProgramData\\Miniconda3\\envs\\aligner montreal-forced-aligner=3.2.1\n\n\n\n\n\n\n\n\n\n\nWarningWindows Troubleshooting\n\n\n\n\n\nThe 3rd party MFA software requires:\n\nthe possibility of running command-line programs during installation and forced alignement\nthe possibility that these programs can download data from the internet\n\nOn Windows, this can sometimes be complicated by the fact that Apache Tomcat and LaBB-CAT are installed as a ‚ÄòWindows Service‚Äô. Windows Services usually run using the permissions of a special anonymous login account called ‚ÄòLocal System‚Äô, which in some environments has restricted permissions to access different resources.\nIf you install the MFA Manager LaBB-CAT integration module, but you find it returns errors when trying to interact with MFA, the problem may be that the Windows Service:\n\ndoes not have permission to access the folder where MFA is installed, or\nis not allowed to execute other programs, or\ncannot access the internet.\n\nSometimes problems can be resolved by:\n\nrunning the Apache Tomcat Windows Service as a different user other than ‚ÄòLocal System‚Äô. (or if it was running as some other used, try setting it back to ‚ÄòLocal System‚Äô), or\nadjusting the permissions of the Windows Service users, or\nadjusting the permissions of the folders where MFA is installed\nconfiguring the service to use the local Internet Proxy settings to enable connecting to the internet.\n\nPSexec is a tool that can be used to diagnose and solve problems on Windows.\n\n\n\nDownload PStool.zip from Microsoft:\nhttp://technet.microsoft.com/en-us/sysinternals/bb897553.aspx\nUnzip it\nPut PSexec.exe into C:\\Windows\\System32\nOpen cmd using ‚ÄúRun as Administrator‚Äù\nRun the command:\nPsexec.exe -i -s cmd.exe\nThis opens a new command prompt for local system account\nIn the new command prompt window, check you have the correct account type with the command:\nwhomai\n\nThen you can use the command prompt to run MFA commands to diagnose errors - e.g.:\n\nconda activate montreal-forced-aligner - activates the MFA environment\nmfa version - ensures MFA is installed and accessible, and confirms the version\nmfa model download dictionary - ensures MFA can connect to the internet to get models etc.; this command should return a long list of language dictionaries, and not report errors.\n\n\n\n\nTo update proxy server settings:\n\ntype inetcpl.cpl\ngoto Connections tab\nclick on the LAN Settings button\nFill in the Proxy section with the correct details\n\n\n\n\n\n\n\n\n\n\n\nNoteDocker Container\n\n\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, it can download and install Miniconda and MFA itself, as part of the process of installing the MFA Manager LaBB-CAT module.\nThere is no need for a separate installation of the MFA software.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA and Pretrained Acoustic Models"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-pretrained-models.html#layer-manager-installation",
    "href": "howto/forced-alignment/mfa-pretrained-models.html#layer-manager-installation",
    "title": "MFA and Pretrained Acoustic Models",
    "section": "",
    "text": "Once MFA has been installed, you have to install the MFA Manager, which is the LaBB-CAT module that provides MFA with all the data it needs, and then saves to alignments MFA produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link.\nFind MFA Manager in the list, and press its Install button and then press Install again.\nAs long as MFA has been installed for all users, you should see a box that‚Äôs already filled in with the location that MFA was installed to.\nClick Configure to continue the layer manager installation.\nYou will see a window open with some information about integrating with MFA, including the information you‚Äôve already read above.",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA and Pretrained Acoustic Models"
    ]
  },
  {
    "objectID": "howto/forced-alignment/mfa-pretrained-models.html#forced-alignment",
    "href": "howto/forced-alignment/mfa-pretrained-models.html#forced-alignment",
    "title": "MFA and Pretrained Acoustic Models",
    "section": "",
    "text": "Once you‚Äôve\n\nNow you need to add a phrase layer for the HTK configuration:\n\nLayer ID: mfa\nType: Text\nAlignment: Intervals\nManager: MFA Manager\nGenerate: always\nDescription: MFA alignment time\n\nWhen you configure the layer, set the following options:\n\nDictionary Name: the dictionary language, e.g.¬†english_uk_mfa\nPretrained Acoustic Models: the models language, e.g.¬†english_mfa\nThe rest of the options can be left as their default values.\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a `tool tip‚Äô that describes what the option is for.\n\nPress Set Parameters\nPress Regenerate\nYou will see a progress bar while LaBB-CAT force-aligns all the transcripts in the corpus, which may take a few minutes.\nWhen the layer manager has finished, you‚Äôll see a message saying:\nComplete - words and phones from selected utterances are now aligned.\n\n\n\n\n\n\n\nTip\n\n\n\nNot all MFA pre-trained acoustic models can be used with all dictionaries.\nApart from matching the language (e.g.¬†English-trained acoustic models should be used only with English dictionaries), the phoneme symbol sets must also match.\nMFA uses several symbol sets, including:\n\nIPA - model and dictionary names ending in ..._mfa\nARPAbet - model and dictionary names ending in ..._arpa\n\nSo if you use an acoustic model ending in ...arpa, then the dictionary you choose must also end in ...arpa.\nSee the MFA documentation on models and dictionaries for more detailed information:\nhttps://mfa-models.readthedocs.io",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "MFA and Pretrained Acoustic Models"
    ]
  },
  {
    "objectID": "howto/forced-alignment/correction-emu.html",
    "href": "howto/forced-alignment/correction-emu.html",
    "title": "Checking/Correcting Alignments: EMU-webApp",
    "section": "",
    "text": "Checking/Correcting Alignments: EMU-webApp\nDepending on how LaBB-CAT is configured, when the forced aligner finishes it may automatically open a new browser tab with a list of utterances on the left, and a representation of the first utterance in the centre.\nThis is the EMU-webApp annotation tool, which you can use to manually inspect, and correct, the phone alignments that HTK just produced.\n\n\n\nEMU-webApp\n\n\nThe left panel contains a list of all the utterances that were just processed by HTK. If you click on an utterance in the list, the selected utterance will be loaded into the central panel.\nThe central panel is split into two parts. The upper part represents the utterance‚Äôs recording with a wave-form and a spectrogram. The lower part contains the annotation tool that represents each phone, including its label and start/end time.\nBelow this are a series of buttons you can use to control which portion of the utterance is displayed, and control audio playback.\nTo correct the phone alignments:\n\nSelect a phone in the annotation panel by clicking on it.\nTap the CC key on your keyboard to play the audio for the selected phone.\nIf you want to change the start time, hover the mouse over the start time and hold down the ShiftShift key on your keyboard. Moving the mouse will move the phone boundary until you let go of the ShiftShift key. You can similarly correct end times. When you make changes, the utterance will turn red in the list on the left.\n\nTo save your corrections back to LaBB-CAT, press the round Save button in the utterance list panel.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Forced Alignment",
      "Checking/Correcting Alignments: EMU-webApp"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/index.html",
    "href": "howto/phonemic-tagging/index.html",
    "title": "Phonemic Tagging",
    "section": "",
    "text": "Phonemic Tagging\nDepending on your speech data, there are several ways to obtain phonemic transcriptions for words:\n\nLexical tagging\n\nCELEX - for British English, German, Dutch, using one of the CELEX layer managers.\nCMU Pronouncing Dictionary - for US English, using th CMU Pronouncing Dictionary layer manager.\nUnisyn - for various English varieties, using the Unisyn layer manager.\nDefine your own lexicon, and use the Flat File Dictionary layer manager to integrate it into LaBB-CAT.\n\nInferring pronunciation from orthography\n\nSpanish, using the Spanish Phonological Transcriber layer manager\nBas Web Service: G2P - for various languages.\nDefine your own simple mapping rules from orthography to phonology, using the Character Mapper layer manager.\n\n\nIf the speech corpus includes data in more than one language, it is possible to ensure that the utterances are phonemically tagged in a way that‚Äôs sensitive to the language of the specific utterance, using the language layers and attributes, and auxiliary layer managers.\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "How-to",
      "Phonemic Tagging"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/spanish.html",
    "href": "howto/phonemic-tagging/spanish.html",
    "title": "Phonemic Tagging with the Spanish Phonology Transcriber",
    "section": "",
    "text": "This layer manager annotates Spanish words their phonemic transcription, based on rules that map orthography to phonology.\nRule-based conversion is based on spanish-pronunciation-rules-php, an open-source PHP function that converts a Spanish word into IPA phonetic transcription symbols, written by Timur Baytukalov, http://easypronunciation.com/en/\n\n\nTo create a new layer with annotations from your dictionary:\n\nSelect the word layers option on the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID - enter a one- or two-word description - e.g.¬†phonemes\nType - select Phonological\nManager - select Spanish phonological transcriber\nAlignment - select None (as these are simply tags on the orthographic words)\nGenerate - select Always\n\nPress the New button to create the layer. You will see the layer configuration page. Check the online help for explanations of all options, but at least:\nEnsure the Source Layer is orthography\nSelect the desired Locale from the list.\n\nPress Save\nPress Regenerate.\nYou will see a progress bar while the layer manager annotates all the transcripts that have already been uploaded.\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, annotations will automatically be generated by using the mapping rules for the selected locale.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Spanish"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/spanish.html#creating-a-phonemes-layer",
    "href": "howto/phonemic-tagging/spanish.html#creating-a-phonemes-layer",
    "title": "Phonemic Tagging with the Spanish Phonology Transcriber",
    "section": "",
    "text": "To create a new layer with annotations from your dictionary:\n\nSelect the word layers option on the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID - enter a one- or two-word description - e.g.¬†phonemes\nType - select Phonological\nManager - select Spanish phonological transcriber\nAlignment - select None (as these are simply tags on the orthographic words)\nGenerate - select Always\n\nPress the New button to create the layer. You will see the layer configuration page. Check the online help for explanations of all options, but at least:\nEnsure the Source Layer is orthography\nSelect the desired Locale from the list.\n\nPress Save\nPress Regenerate.\nYou will see a progress bar while the layer manager annotates all the transcripts that have already been uploaded.\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, annotations will automatically be generated by using the mapping rules for the selected locale.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Spanish"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/cmudict.html",
    "href": "howto/phonemic-tagging/cmudict.html",
    "title": "Phonemic Tagging with CMU Pronouncing Dictionary",
    "section": "",
    "text": "LaBB-CAT can be integrated with the CMU Pronouncing Dictionary, which is a free pronouncing dictionary of English maintained by the Speech Group in the School of Computer Science at Carnegie Mellon University. The pronunciations are based on American English, so are suitable for American English recordings.\nIntegrating this lexicon with LaBB-CAT is achieved with the ‚ÄúCMU Dictionary Layer Manager‚Äù. As CMU has kindly granted permission to freely distribute the dictionary file, you don‚Äôt need to download the file from the CMU site; it‚Äôs included in the layer manager that you will install.\n\n\nFirst, the CMU Pronouncing Dictionary layer manager module must be installed:\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link near the bottom.\nFind ‚ÄúCMU Pronouncing Dictionary‚Äù in the list, and press its Install button, then Install again.\nPress Configure to install the default version of the dictionary.\n\nYou will see a progress bar while the layer manager loads the data from the dictionary file into the LaBB-CAT database. This will take a minute or so.\nOnce it‚Äôs finished, you will see a new window open with information about the CMU Pronouncing Dictionary layer manager. Reading this information page, you will see some instructions on how to create a pronunciation annotation layer.\n\n\n\nWhen tagging words with their pronunciations, the CMU Pronouncing Dictionary layer manager allows two possible options for the symbols used in the transcriptions:\n\nCMU ARPAbet\n\ne.g.¬†T R AE2 N S K R IH1 P SH AH0 N ‚Äì this is the original encoding used in the CMUdict file, and it‚Äôs also the symbol set used for the Penn Aligner pre-trained models. Each phoneme may be multiple characters long, and the transcriptions use a space delimiter between each phoneme, which can make searching using regular expressions more complicated.\n\nCELEX DISC\n\ne.g.¬†tr{nskrIpS@n ‚Äì this is one of the encodings used by the CELEX lexicon. Each phoneme is represented with exactly one ASCII character, so pattern matching with regular expressions is somewhat easier.\n\n\nBefore creating the layer to tag each word with its pronunciation(s), you must decide which encoding the layer will use.\nTo create a new layer with CMUdict annotations:\n\nSelect on the word layers menu option - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank forARPAm for creating a new layer - fill this form in:\n\nLayer ID: phonemes\nType: Text if you‚Äôre using the CMU ARPAbet encoding, or\nPhonological if you‚Äôre using the CELEX DISC encoding.\nManager: CMU Pronouncing Dictionary\nAlignment: None (as these are simply tags on the orthographic words)\nGenerate: Always\nDescription: All possible phonemic transcriptions, according to CMUdict\n\nPress the New button to create the layer\nYou will see a form that allows you to specify various options, including the Encoding to use for transcriptions.\nEnsure the Encoding is set to the option you prefer.\nPress Set Parameters\nPress Regenerate.\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, the CMUdict annotations will automatically be generated for it.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CMU Pronouncing Dictionary"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/cmudict.html#install-the-layer-manager",
    "href": "howto/phonemic-tagging/cmudict.html#install-the-layer-manager",
    "title": "Phonemic Tagging with CMU Pronouncing Dictionary",
    "section": "",
    "text": "First, the CMU Pronouncing Dictionary layer manager module must be installed:\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link near the bottom.\nFind ‚ÄúCMU Pronouncing Dictionary‚Äù in the list, and press its Install button, then Install again.\nPress Configure to install the default version of the dictionary.\n\nYou will see a progress bar while the layer manager loads the data from the dictionary file into the LaBB-CAT database. This will take a minute or so.\nOnce it‚Äôs finished, you will see a new window open with information about the CMU Pronouncing Dictionary layer manager. Reading this information page, you will see some instructions on how to create a pronunciation annotation layer.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CMU Pronouncing Dictionary"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/cmudict.html#create-an-annotation-layer",
    "href": "howto/phonemic-tagging/cmudict.html#create-an-annotation-layer",
    "title": "Phonemic Tagging with CMU Pronouncing Dictionary",
    "section": "",
    "text": "When tagging words with their pronunciations, the CMU Pronouncing Dictionary layer manager allows two possible options for the symbols used in the transcriptions:\n\nCMU ARPAbet\n\ne.g.¬†T R AE2 N S K R IH1 P SH AH0 N ‚Äì this is the original encoding used in the CMUdict file, and it‚Äôs also the symbol set used for the Penn Aligner pre-trained models. Each phoneme may be multiple characters long, and the transcriptions use a space delimiter between each phoneme, which can make searching using regular expressions more complicated.\n\nCELEX DISC\n\ne.g.¬†tr{nskrIpS@n ‚Äì this is one of the encodings used by the CELEX lexicon. Each phoneme is represented with exactly one ASCII character, so pattern matching with regular expressions is somewhat easier.\n\n\nBefore creating the layer to tag each word with its pronunciation(s), you must decide which encoding the layer will use.\nTo create a new layer with CMUdict annotations:\n\nSelect on the word layers menu option - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank forARPAm for creating a new layer - fill this form in:\n\nLayer ID: phonemes\nType: Text if you‚Äôre using the CMU ARPAbet encoding, or\nPhonological if you‚Äôre using the CELEX DISC encoding.\nManager: CMU Pronouncing Dictionary\nAlignment: None (as these are simply tags on the orthographic words)\nGenerate: Always\nDescription: All possible phonemic transcriptions, according to CMUdict\n\nPress the New button to create the layer\nYou will see a form that allows you to specify various options, including the Encoding to use for transcriptions.\nEnsure the Encoding is set to the option you prefer.\nPress Set Parameters\nPress Regenerate.\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nFrom now on, when you upload a new transcript, the CMUdict annotations will automatically be generated for it.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "CMU Pronouncing Dictionary"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/flat-file.html",
    "href": "howto/phonemic-tagging/flat-file.html",
    "title": "Phonemic Tagging using a Plain Text File",
    "section": "",
    "text": "The Flat Lexicon layer manager annotates words with data from a dictionary loaded from a plain text file (e.g.¬†a CSV file).\nThe dictionary file you supply may contain multiple fields, and multiple entries per word. It might include:\n\nword orthography\nlemma\npart-of-speech\npronunciation\nfrequency\n\n‚Ä¶or any other ‚Äútype‚Äù data you like.\n\n\nWhat dictionary file you want depends on what you want to annotate. For pronunciations, you might download some standard dictionary for your target language, such as Unisyn, the CMU Pronouncing dictionary, CELEX, etc. (although there are also specialised layer managers for these particular lexicons). Frequency lists include CELEX, SubtlexUS, and Adam Kilgarriff‚Äôs BNC Frequency Lists.\nAlternatively, you might have, or prepare, your own dictionary containing pronunciations, lemmata, etc. All you need is a CSV file with a column that includes the word orthography, and other columns that include the pronunciation and any other information you may have.\n\n\n\nExample of a custom pronunciation dictionary\n\n\nNB LaBB-CAT assumes that the text file uses ASCII or UTF-8 character encoding. If your dictionary file uses another encoding (e.g.¬†‚ÄúWestern‚Äù or ISO-8859, you will need to re-save the file using UTF-8 (in many text editors, the character encoding is an option available when you select ‚ÄúSave As‚Ä¶‚Äù from the ‚ÄúFile‚Äù menu).\n\n\n\nOnce you have a CSV or other text file, you need to upload it into LaBB-CAT:\n\nSelect the layer managers option in the LaBB-CAT menu.\nFind ‚ÄúFlat Lexicon Tagger‚Äù in the list and press its Extensions button.\nPress Choose File and select your dictionary file.\nYou many decide to change the default ‚ÄúName‚Äù that the lexicon will have.\nThe default file structure options will probably be correct, but you may change them if you need to - see the page‚Äôs online help for details.\nPress Load.\n\nYou can upload as many dictionaries as you like. Once you have at least one dictionary, you can configure a word layer to lookup the resulting lexicons, by selecting ‚ÄúFlat Lexicon Tagger‚Äù as the layer‚Äôs layer manager.\n\n\n\nTo create a new layer with annotations from your dictionary:\n\nSelect the word layers option on the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID: enter a one- or two-word description - e.g.¬†phonemes\nType: If your dictionary uses CELEX DISC symbols that are not space delimited, select Phonological, otherwise (e.g.¬†space-delimited IPA or ARPABET pronunciations) select Text\nAlignment: select None (as these are simply tags on the orthographic words)\nManager: select Flat Lexicon Tagger\nGenerate: select Always\nDescription: enter a description of the layer - e.g.¬†Pronunciation (text-file)\n\nPress the New button to create the layer.\nYou will see the layer configuration page. Check the online help for explanations of all options, but at least:\nEnsure the Source Layer is orthography\nSelect the desired Lexicon from the list (these relate to the file or files you uploaded above).\n\nPress Save\nPress Regenerate.\nYou will see a progress bar while the layer manager annotates all the transcripts that have already been uploaded.\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nOnce this is finished, be sure to open a transcript and tick the new phonemic tagging layer you just added, and make sure that each word is tagged with a corresponding pronunciation.\nFrom now on, when you upload a new transcript, annotations will automatically be generated by lookup up your lexicon.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Custom Lexicon"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/flat-file.html#getting-a-dictionary-file",
    "href": "howto/phonemic-tagging/flat-file.html#getting-a-dictionary-file",
    "title": "Phonemic Tagging using a Plain Text File",
    "section": "",
    "text": "What dictionary file you want depends on what you want to annotate. For pronunciations, you might download some standard dictionary for your target language, such as Unisyn, the CMU Pronouncing dictionary, CELEX, etc. (although there are also specialised layer managers for these particular lexicons). Frequency lists include CELEX, SubtlexUS, and Adam Kilgarriff‚Äôs BNC Frequency Lists.\nAlternatively, you might have, or prepare, your own dictionary containing pronunciations, lemmata, etc. All you need is a CSV file with a column that includes the word orthography, and other columns that include the pronunciation and any other information you may have.\n\n\n\nExample of a custom pronunciation dictionary\n\n\nNB LaBB-CAT assumes that the text file uses ASCII or UTF-8 character encoding. If your dictionary file uses another encoding (e.g.¬†‚ÄúWestern‚Äù or ISO-8859, you will need to re-save the file using UTF-8 (in many text editors, the character encoding is an option available when you select ‚ÄúSave As‚Ä¶‚Äù from the ‚ÄúFile‚Äù menu).",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Custom Lexicon"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/flat-file.html#installing-a-dictionary-file",
    "href": "howto/phonemic-tagging/flat-file.html#installing-a-dictionary-file",
    "title": "Phonemic Tagging using a Plain Text File",
    "section": "",
    "text": "Once you have a CSV or other text file, you need to upload it into LaBB-CAT:\n\nSelect the layer managers option in the LaBB-CAT menu.\nFind ‚ÄúFlat Lexicon Tagger‚Äù in the list and press its Extensions button.\nPress Choose File and select your dictionary file.\nYou many decide to change the default ‚ÄúName‚Äù that the lexicon will have.\nThe default file structure options will probably be correct, but you may change them if you need to - see the page‚Äôs online help for details.\nPress Load.\n\nYou can upload as many dictionaries as you like. Once you have at least one dictionary, you can configure a word layer to lookup the resulting lexicons, by selecting ‚ÄúFlat Lexicon Tagger‚Äù as the layer‚Äôs layer manager.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Custom Lexicon"
    ]
  },
  {
    "objectID": "howto/phonemic-tagging/flat-file.html#creating-a-phonemes-layer",
    "href": "howto/phonemic-tagging/flat-file.html#creating-a-phonemes-layer",
    "title": "Phonemic Tagging using a Plain Text File",
    "section": "",
    "text": "To create a new layer with annotations from your dictionary:\n\nSelect the word layers option on the menu - this will display a list of all the word layers you already have in the database.\nAt the top of the list, there‚Äôs a blank form for creating a new layer - fill this form in:\n\nLayer ID: enter a one- or two-word description - e.g.¬†phonemes\nType: If your dictionary uses CELEX DISC symbols that are not space delimited, select Phonological, otherwise (e.g.¬†space-delimited IPA or ARPABET pronunciations) select Text\nAlignment: select None (as these are simply tags on the orthographic words)\nManager: select Flat Lexicon Tagger\nGenerate: select Always\nDescription: enter a description of the layer - e.g.¬†Pronunciation (text-file)\n\nPress the New button to create the layer.\nYou will see the layer configuration page. Check the online help for explanations of all options, but at least:\nEnsure the Source Layer is orthography\nSelect the desired Lexicon from the list (these relate to the file or files you uploaded above).\n\nPress Save\nPress Regenerate.\nYou will see a progress bar while the layer manager annotates all the transcripts that have already been uploaded.\n\nLaBB-CAT will then generate annotations for all the transcripts you already have in your database. If you have a lot of data, this may take a while.\nOnce this is finished, be sure to open a transcript and tick the new phonemic tagging layer you just added, and make sure that each word is tagged with a corresponding pronunciation.\nFrom now on, when you upload a new transcript, annotations will automatically be generated by lookup up your lexicon.",
    "crumbs": [
      "How-to",
      "Phonemic Tagging",
      "Custom Lexicon"
    ]
  },
  {
    "objectID": "worksheets/index.html",
    "href": "worksheets/index.html",
    "title": "Worksheets",
    "section": "",
    "text": "Worksheets\nHere you will find various learning resources for LaBB-CAT, including:\n\na course for learning how to use LaBB-CAT, from scratch (3x2-hour sessions)\na series of worksheets for exploring the capabilities of LaBB-CAT using a demo corpus (one 2-hour session)\na brief hands-on introduction setting up a LaBB-CAT corpus from scratch, then annotating, and exploring it (one 1-hour session)\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/index.html",
    "href": "worksheets/express-tutorial/index.html",
    "title": "LaBB-CAT Express Tutorial",
    "section": "",
    "text": "LaBB-CAT Express Tutorial\nThis tutorial is a very brief introduction to the LaBB-CAT corpus analysis tool. There are four exercises, in which you:\n\ninstall LaBB-CAT on your personal computer,\nupload a small corpus of recordings into your database and explore the transcript page,\nadd autonmatically generateed part-of-speech tags and,\nadd autonmatically generateed pronunciation tags and,\ncompute the start/end times of each speech sound and extract automated formant measurements from vowels.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/4-cmudict.html",
    "href": "worksheets/express-tutorial/4-cmudict.html",
    "title": "Pronunciation Tags",
    "section": "",
    "text": "LaBB-CAT can be integrated with the CMU Pronouncing Dictionary, which is a free pronounciation dictionary of English maintained by the Speech Group in the School of Computer Science at Carnegie Mellon University (CMU). The pronunciations are based on American English, so are most suitable for recordings of North American speakers.\nThe dictionary‚Äôs suitability for other varieties of English depends on which variety and what specific aspects of pronunciation will be studied.\nIn this exercise you will:\n\ninstall the CMU Pronouncing Dictionary layer manager module, and\nuse it to tag each word with its pronunciations.\n\n\n\nThe first thing we‚Äôre going to to is install the CMU Pronouncing Dictionary layer manager, which is a LaBB-CAT module that integrates with the dictionary‚Ä¶\n\nIn LaBB-CAT, select the layer managers menu option.\nYou will see a list of pre-installed layer managers, which are modules that can perform automatic annotation tasks. The CMU Pronouncing Dictionary layer manager isn‚Äôt pre-installed, because it is language-specific.\nClick the List of layer managers that are not yet installed link near the bottom.\nFind CMU Pronouncing Dictionary in the list, and press its Install button.\nPress Install on the resulting information page.\nThis displays some further information about the layer manager, allowing you to optionally upload an alternative version of the dictionary file.\nWe won‚Äôt upload a file, we‚Äôll be using the standard file that is included in the layer manager.\nPress Configure.\nYou will see a progress bar while the layer manager loads the data from the dictionary file into the LaBB-CAT database. This will take a minute or so.\nOnce it‚Äôs finished, you will see a new window open with information about the CMU Pronouncing Dictionary layer manager.\n\n\n\n\nNow that we‚Äôve installed the layer manager, we‚Äôll create an annotation layer that tags words with their pronunciations.\n\nSelect the word layers option on the menu.\nYou will see a list of existing word layers, including the orthography layer, the lexical layer, etc.\nThe column headings are also a form for defining a new word layer. Fill in the following details in this form:\n\nLayer ID: cmudict\nType: Phonological\nAlignment: None\nManager: CMU Pronouncing Dictionary\nDescription: All possible phonemic transcriptions for each word.\n\nPress New to add the layer.\nYou will see the layer configuration form.\n\nThe CMUdict file contains pronunciations expressed using the ‚ÄòARPAbet‚Äô symbols, in which a phonemes are one or two uppercase letters, possibly suffixed with a digit indicating stress, and a space between each phoneme. e.g.¬†the pronunciation for the word ‚Äútranscription‚Äù is:\nT R AE2 N S K R IH1 P SH AH0 N\nThe layer manager can also convert the pronunciations to use an alternative set of symbols called ‚ÄòCELEX DISC‚Äô which uses exactly one character per phoneme no intervening spaces. e.g.¬†the pronunciation for the word ‚Äútranscription‚Äù is:\ntr{nskrIpS@n\nWhich set of symbols you choose depends somewhat on what you want to do with the labels; using ‚ÄòARPAbet‚Äô conserves stress information, but CELEX DISC can be easier for searching for pronunciation patterns. For this exercise, we‚Äôll use ‚ÄòCELEX DISC‚Äô.\n\nSet the Encoding field to CELEX DISC, and leave the default values for everything else.\n\n\n\n\n\n\n\nTip\n\n\n\n If you‚Äôre curious about what the configuration options do, hover your mouse over each one to see further information about what the setting does.\n\n\n\nPress Set Parameters.\nYou will see a message asking you if you want (re)generate the layer data now.\nPress Regenerate.\nYou will see a progress bar moving across the page while the annotations are being generated. When it is finished, you will see a message saying Layer complete.\nOnce the layer has finished generating, select the transcripts menu option, and open the first transcript in the list by clicking the transcript name.\nSelect the Layers tab at the top to show a list of tickable annotation layers.\nTick your new cmudict layer.\nThe tags will load and you‚Äôll see that each word is tagged with a phonemic transcription.\n\nThe IPA symbols are being displayed by LaBB-CAT to provide a linguist-friendly interpretation of the phonemic transcription. But you can see the underlying CELEX DISC characters by de-activating this ‚Äòinterpretation‚Äô.\n\nOn the Layers tab, to the right of the name of the cmudict layer, there is a small ‚Äòtags‚Äô üè∑ icon.\nHover your mouse over this icon to see what it does.\nClick the tags icon, to see what the layer manager is actually producing.\nYou may find that this is somewhat harder to read. It‚Äôs similar to the ‚ÄòSAMPA‚Äô system for encoding phonemes, which you may be familiar with, but diphthongs are generally represented by digits, and various other characters are used to represent affricates, etc.\nClick the tags icon again, to return to the IPA view of the labels.\n\n\n\n\n\nIt‚Äôs nice to display the IPA symbols, but it‚Äôs important to understand the ARPAbet symbols (shown in the table below), because they are what we have to use when searching on the phonemes layer, which we are going to try now.\nIn the table, there are gaps where no ARPABET version of the phoneme is shown; this means that the CMU Pronouncing Dictionary contains no entries that include that phoneme.\n\n\n\nIPA\nDISC\nARPABET\n¬†\n¬†\nIPA\nDISC\nARPABET\n¬†\n\n\np\np\nP\npat\n¬†\n…™\nI\nIH\nKIT\n\n\nb\nb\nB\nbad\n¬†\nŒµ\nE\nEH\nDRESS\n\n\nt\nt\nT\ntack\n¬†\n√¶\n{\nAE\nTRAP\n\n\nd\nd\nD\ndad\n¬†\n å\nV\nAH\nSTRUT\n\n\nk\nk\nK\ncad\n¬†\n…í\nQ\nAH\nLOT\n\n\ng\ng\nG\ngame\n¬†\n ä\nU\nUH\nFOOT\n\n\n≈ã\nN\nNG\nbang\n¬†\n…ô\n@\n[vowel ending in 0]\nanother\n\n\nm\nm\nM\nmat\n¬†\ni:\ni\nIY\nFLEECE\n\n\nn\nn\nN\nnat\n¬†\nŒ±:¬†\n#\nAA\nSTART\n\n\nl\nl\nL\nlad\n¬†\n…î:\n$\nAO\nTHOUGHT\n\n\nr\nr\nR\nrat\n¬†\nu:\nu\nUW\nGOOSE\n\n\nf\nf\nF\nfat\n¬†\n…ú:\n3\nER\nNURSE\n\n\nv\nv\nV\nvat\n¬†\ne…™\n1\nEY\nFACE\n\n\nŒ∏\nT\nTH\nthin\n¬†\nŒ±…™\n2\nAY\nPRICE\n\n\n√∞\nD\nDH\nthen\n¬†\n…î…™\n4\nOY\nCHOICE\n\n\ns\ns\nS\nsap\n¬†\n…ô ä\n5\nOW\nGOAT\n\n\nz\nz\nZ\nzap\n¬†\nŒ± ä\n6\nAW\nMOUTH\n\n\n‚à´\nS\nSH\nsheep\n¬†\n…™…ô\n7\n¬†\nNEAR\n\n\n í\nZ\nZH\nmeasure\n¬†\nŒµ…ô\n8\n¬†\nSQUARE\n\n\nj\nj\nY\nyank\n¬†\n ä…ô\n9\n¬†\nCURE\n\n\nx\nx\n¬†\nloch\n¬†\n√¶\nc\n¬†\ntimbre\n\n\nh\nh\nHH\nhad\n¬†\n…ëÃÉÀê\nq\n¬†\nd√©tente\n\n\nw\nw\nW\nwet\n¬†\n√¶ÃÉÀê\n0\n¬†\nlingerie\n\n\n ß\nJ\nCH\ncheap\n¬†\n…íÃÉÀê\n~\n¬†\nbouillon\n\n\n §\n_\nJH\njeep\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\n≈ãÃ©\nC\n¬†\nbacon\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nmÃ©\nF\n¬†\nidealism\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nnÃ©\nH\n¬†\nburden\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nlÃ©\nP\n¬†\n¬†dangle\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\n\n\nSelect the search option on the menu, which allows you to search all participants by default.\nTick the new cmudict layer.\nNow you will see that our search matrix is two layers high by one word wide.\n\nSearch your new cmudict layer for words that start with ‚Äúh‚Äù by entering h.* (i.e.¬†‚Äúh‚Äù followed by zero or more characters) in the cmudict box and hitting enterenter.\nIf the results page does not automatically open when the search is finished, click the Display results link that appears.\n\nYou will see that the results contain words that you might not expect, like ‚Äúwhere‚Äù, ‚Äúwhich‚Äù and ‚Äúwhen‚Äù.\n\nClick one of these unexpected results, to open the transcript.\nYou will see that, in the transcript, the pronunciation appears to start with /w/, not with /h/.\nHover your mouse over the cmudict layer tag of the word.\nYou will see a list of all the pronunciations for that word not just the first one, which is displayed in the transcript.\nYou will see that, in addition to the pronunciation that starts with /w/, there‚Äôs another annotation that starts with /h/, which is invisible on the transcript.\n\nThese are all the possible phonemic transcriptions for the word, in the order they are found in the CMUdict dictionary file. Only the first one is displayed in the transcript, but when you do searches, all of them are searched. This can result in unexpected matches like this, but it can be useful, as it ensures that when you search for a particular phonemic pattern, all possible tokens are returned, not just those that match on the most ‚Äònormal‚Äô transcription.\nNow we are going to search a multi-word, multi-layer pattern: ‚Äúthe‚Äù followed by a word starting with a vowel‚Ä¶\n\nGo to the search page.\nCreate a search matrix that‚Äôs two words wide by pressing the  button, and tick the orthography and cmudict layers.\nType the in the first orthography box.\nClick the second box on the cmudict layer, but don‚Äôt enter anything in the box yet.\nThe box has a  button to the right of it.\nHover the mouse over the button to see what it says, and then click it.\n\nYou will see that a section opens with a bunch of phoneme symbols on it; clicking on a phoneme adds its CELEX DISC representation to the search box.\nIn a regular expression, to match several single-letter symbols at once, you need to enclose the symbols in parentheses [].\nFor example, to match either the KIT vowel ‚Äì I in DISC ‚Äì or the FLEECE vowel ‚Äì i in DISC, you would need a regular expression like this:\n[Ii]\nWe want to match any vowel at all at the beginning of this second word, so you need to construct a regular expression for that.\nYou could use the square-brackets [ at the start of your pattern, and click each of the vowel symbols to add all possible vowels ‚Äì you should add in all the vowels you see in the list that appears when you expand the IPA helper, including all the diphthongs. Finally, you would need to add the closing square bracket ].\nAlternatively, you can simply click the VOWEL link in the ‚Äòphoneme symbol selector‚Äô, which will add all the DISC vowels for you, already enclosed in square-brackets.\n\nEnter the regular expression to match any vowel, using either of the methods just mentioned.\nBe sure to append your ‚Äòany vowel‚Äô regular expression with .* to ensure the search matches words that have phonemes after the initial vowel.\n\n\n\n\n\n\n\nTip\n\n\n\nSome regular expressions are so long that not all of the expression is visible in the text box. You can see the whole expression by hovering your mouse over the text box.\n\n\n\nRun the search and check that it‚Äôs giving you what you expect. Notice that now there are no ‚Äòfalse positives‚Äô like ‚Äúthe one‚Äù that we might get if we searched using orthographic spelling only.\n\nNow that you‚Äôve generated an annotation layer, and have seen how the search matrix works, you might want to try out some of the searches listed below, or invent some others:\n\n\n\n\n\n\nTip\n\n\n\nIf you need help with creating regular expressions, try the online help page, which is accessible via the help icon  at the top right of the page.\n\n\n\nWords which have the DRESS vowel as the second phoneme\nWords ending with a front vowel, followed by words beginning with /p/ or /b/\nWords that begin with ‚Äúk‚Äù in their spelling, but begin with the phoneme /n/\nWords that begin with ‚Äúk‚Äù in their spelling, but do not begin with the phoneme /n/",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Pronunciation Tags"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/4-cmudict.html#install-the-cmu-dictionary",
    "href": "worksheets/express-tutorial/4-cmudict.html#install-the-cmu-dictionary",
    "title": "Pronunciation Tags",
    "section": "",
    "text": "The first thing we‚Äôre going to to is install the CMU Pronouncing Dictionary layer manager, which is a LaBB-CAT module that integrates with the dictionary‚Ä¶\n\nIn LaBB-CAT, select the layer managers menu option.\nYou will see a list of pre-installed layer managers, which are modules that can perform automatic annotation tasks. The CMU Pronouncing Dictionary layer manager isn‚Äôt pre-installed, because it is language-specific.\nClick the List of layer managers that are not yet installed link near the bottom.\nFind CMU Pronouncing Dictionary in the list, and press its Install button.\nPress Install on the resulting information page.\nThis displays some further information about the layer manager, allowing you to optionally upload an alternative version of the dictionary file.\nWe won‚Äôt upload a file, we‚Äôll be using the standard file that is included in the layer manager.\nPress Configure.\nYou will see a progress bar while the layer manager loads the data from the dictionary file into the LaBB-CAT database. This will take a minute or so.\nOnce it‚Äôs finished, you will see a new window open with information about the CMU Pronouncing Dictionary layer manager.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Pronunciation Tags"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/4-cmudict.html#annotate-words-with-pronunciations",
    "href": "worksheets/express-tutorial/4-cmudict.html#annotate-words-with-pronunciations",
    "title": "Pronunciation Tags",
    "section": "",
    "text": "Now that we‚Äôve installed the layer manager, we‚Äôll create an annotation layer that tags words with their pronunciations.\n\nSelect the word layers option on the menu.\nYou will see a list of existing word layers, including the orthography layer, the lexical layer, etc.\nThe column headings are also a form for defining a new word layer. Fill in the following details in this form:\n\nLayer ID: cmudict\nType: Phonological\nAlignment: None\nManager: CMU Pronouncing Dictionary\nDescription: All possible phonemic transcriptions for each word.\n\nPress New to add the layer.\nYou will see the layer configuration form.\n\nThe CMUdict file contains pronunciations expressed using the ‚ÄòARPAbet‚Äô symbols, in which a phonemes are one or two uppercase letters, possibly suffixed with a digit indicating stress, and a space between each phoneme. e.g.¬†the pronunciation for the word ‚Äútranscription‚Äù is:\nT R AE2 N S K R IH1 P SH AH0 N\nThe layer manager can also convert the pronunciations to use an alternative set of symbols called ‚ÄòCELEX DISC‚Äô which uses exactly one character per phoneme no intervening spaces. e.g.¬†the pronunciation for the word ‚Äútranscription‚Äù is:\ntr{nskrIpS@n\nWhich set of symbols you choose depends somewhat on what you want to do with the labels; using ‚ÄòARPAbet‚Äô conserves stress information, but CELEX DISC can be easier for searching for pronunciation patterns. For this exercise, we‚Äôll use ‚ÄòCELEX DISC‚Äô.\n\nSet the Encoding field to CELEX DISC, and leave the default values for everything else.\n\n\n\n\n\n\n\nTip\n\n\n\n If you‚Äôre curious about what the configuration options do, hover your mouse over each one to see further information about what the setting does.\n\n\n\nPress Set Parameters.\nYou will see a message asking you if you want (re)generate the layer data now.\nPress Regenerate.\nYou will see a progress bar moving across the page while the annotations are being generated. When it is finished, you will see a message saying Layer complete.\nOnce the layer has finished generating, select the transcripts menu option, and open the first transcript in the list by clicking the transcript name.\nSelect the Layers tab at the top to show a list of tickable annotation layers.\nTick your new cmudict layer.\nThe tags will load and you‚Äôll see that each word is tagged with a phonemic transcription.\n\nThe IPA symbols are being displayed by LaBB-CAT to provide a linguist-friendly interpretation of the phonemic transcription. But you can see the underlying CELEX DISC characters by de-activating this ‚Äòinterpretation‚Äô.\n\nOn the Layers tab, to the right of the name of the cmudict layer, there is a small ‚Äòtags‚Äô üè∑ icon.\nHover your mouse over this icon to see what it does.\nClick the tags icon, to see what the layer manager is actually producing.\nYou may find that this is somewhat harder to read. It‚Äôs similar to the ‚ÄòSAMPA‚Äô system for encoding phonemes, which you may be familiar with, but diphthongs are generally represented by digits, and various other characters are used to represent affricates, etc.\nClick the tags icon again, to return to the IPA view of the labels.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Pronunciation Tags"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/4-cmudict.html#search-across-layers",
    "href": "worksheets/express-tutorial/4-cmudict.html#search-across-layers",
    "title": "Pronunciation Tags",
    "section": "",
    "text": "It‚Äôs nice to display the IPA symbols, but it‚Äôs important to understand the ARPAbet symbols (shown in the table below), because they are what we have to use when searching on the phonemes layer, which we are going to try now.\nIn the table, there are gaps where no ARPABET version of the phoneme is shown; this means that the CMU Pronouncing Dictionary contains no entries that include that phoneme.\n\n\n\nIPA\nDISC\nARPABET\n¬†\n¬†\nIPA\nDISC\nARPABET\n¬†\n\n\np\np\nP\npat\n¬†\n…™\nI\nIH\nKIT\n\n\nb\nb\nB\nbad\n¬†\nŒµ\nE\nEH\nDRESS\n\n\nt\nt\nT\ntack\n¬†\n√¶\n{\nAE\nTRAP\n\n\nd\nd\nD\ndad\n¬†\n å\nV\nAH\nSTRUT\n\n\nk\nk\nK\ncad\n¬†\n…í\nQ\nAH\nLOT\n\n\ng\ng\nG\ngame\n¬†\n ä\nU\nUH\nFOOT\n\n\n≈ã\nN\nNG\nbang\n¬†\n…ô\n@\n[vowel ending in 0]\nanother\n\n\nm\nm\nM\nmat\n¬†\ni:\ni\nIY\nFLEECE\n\n\nn\nn\nN\nnat\n¬†\nŒ±:¬†\n#\nAA\nSTART\n\n\nl\nl\nL\nlad\n¬†\n…î:\n$\nAO\nTHOUGHT\n\n\nr\nr\nR\nrat\n¬†\nu:\nu\nUW\nGOOSE\n\n\nf\nf\nF\nfat\n¬†\n…ú:\n3\nER\nNURSE\n\n\nv\nv\nV\nvat\n¬†\ne…™\n1\nEY\nFACE\n\n\nŒ∏\nT\nTH\nthin\n¬†\nŒ±…™\n2\nAY\nPRICE\n\n\n√∞\nD\nDH\nthen\n¬†\n…î…™\n4\nOY\nCHOICE\n\n\ns\ns\nS\nsap\n¬†\n…ô ä\n5\nOW\nGOAT\n\n\nz\nz\nZ\nzap\n¬†\nŒ± ä\n6\nAW\nMOUTH\n\n\n‚à´\nS\nSH\nsheep\n¬†\n…™…ô\n7\n¬†\nNEAR\n\n\n í\nZ\nZH\nmeasure\n¬†\nŒµ…ô\n8\n¬†\nSQUARE\n\n\nj\nj\nY\nyank\n¬†\n ä…ô\n9\n¬†\nCURE\n\n\nx\nx\n¬†\nloch\n¬†\n√¶\nc\n¬†\ntimbre\n\n\nh\nh\nHH\nhad\n¬†\n…ëÃÉÀê\nq\n¬†\nd√©tente\n\n\nw\nw\nW\nwet\n¬†\n√¶ÃÉÀê\n0\n¬†\nlingerie\n\n\n ß\nJ\nCH\ncheap\n¬†\n…íÃÉÀê\n~\n¬†\nbouillon\n\n\n §\n_\nJH\njeep\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\n≈ãÃ©\nC\n¬†\nbacon\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nmÃ©\nF\n¬†\nidealism\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nnÃ©\nH\n¬†\nburden\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\nlÃ©\nP\n¬†\n¬†dangle\n¬†\n¬†\n¬†\n¬†\n¬†\n\n\n\n\nSelect the search option on the menu, which allows you to search all participants by default.\nTick the new cmudict layer.\nNow you will see that our search matrix is two layers high by one word wide.\n\nSearch your new cmudict layer for words that start with ‚Äúh‚Äù by entering h.* (i.e.¬†‚Äúh‚Äù followed by zero or more characters) in the cmudict box and hitting enterenter.\nIf the results page does not automatically open when the search is finished, click the Display results link that appears.\n\nYou will see that the results contain words that you might not expect, like ‚Äúwhere‚Äù, ‚Äúwhich‚Äù and ‚Äúwhen‚Äù.\n\nClick one of these unexpected results, to open the transcript.\nYou will see that, in the transcript, the pronunciation appears to start with /w/, not with /h/.\nHover your mouse over the cmudict layer tag of the word.\nYou will see a list of all the pronunciations for that word not just the first one, which is displayed in the transcript.\nYou will see that, in addition to the pronunciation that starts with /w/, there‚Äôs another annotation that starts with /h/, which is invisible on the transcript.\n\nThese are all the possible phonemic transcriptions for the word, in the order they are found in the CMUdict dictionary file. Only the first one is displayed in the transcript, but when you do searches, all of them are searched. This can result in unexpected matches like this, but it can be useful, as it ensures that when you search for a particular phonemic pattern, all possible tokens are returned, not just those that match on the most ‚Äònormal‚Äô transcription.\nNow we are going to search a multi-word, multi-layer pattern: ‚Äúthe‚Äù followed by a word starting with a vowel‚Ä¶\n\nGo to the search page.\nCreate a search matrix that‚Äôs two words wide by pressing the  button, and tick the orthography and cmudict layers.\nType the in the first orthography box.\nClick the second box on the cmudict layer, but don‚Äôt enter anything in the box yet.\nThe box has a  button to the right of it.\nHover the mouse over the button to see what it says, and then click it.\n\nYou will see that a section opens with a bunch of phoneme symbols on it; clicking on a phoneme adds its CELEX DISC representation to the search box.\nIn a regular expression, to match several single-letter symbols at once, you need to enclose the symbols in parentheses [].\nFor example, to match either the KIT vowel ‚Äì I in DISC ‚Äì or the FLEECE vowel ‚Äì i in DISC, you would need a regular expression like this:\n[Ii]\nWe want to match any vowel at all at the beginning of this second word, so you need to construct a regular expression for that.\nYou could use the square-brackets [ at the start of your pattern, and click each of the vowel symbols to add all possible vowels ‚Äì you should add in all the vowels you see in the list that appears when you expand the IPA helper, including all the diphthongs. Finally, you would need to add the closing square bracket ].\nAlternatively, you can simply click the VOWEL link in the ‚Äòphoneme symbol selector‚Äô, which will add all the DISC vowels for you, already enclosed in square-brackets.\n\nEnter the regular expression to match any vowel, using either of the methods just mentioned.\nBe sure to append your ‚Äòany vowel‚Äô regular expression with .* to ensure the search matches words that have phonemes after the initial vowel.\n\n\n\n\n\n\n\nTip\n\n\n\nSome regular expressions are so long that not all of the expression is visible in the text box. You can see the whole expression by hovering your mouse over the text box.\n\n\n\nRun the search and check that it‚Äôs giving you what you expect. Notice that now there are no ‚Äòfalse positives‚Äô like ‚Äúthe one‚Äù that we might get if we searched using orthographic spelling only.\n\nNow that you‚Äôve generated an annotation layer, and have seen how the search matrix works, you might want to try out some of the searches listed below, or invent some others:\n\n\n\n\n\n\nTip\n\n\n\nIf you need help with creating regular expressions, try the online help page, which is accessible via the help icon  at the top right of the page.\n\n\n\nWords which have the DRESS vowel as the second phoneme\nWords ending with a front vowel, followed by words beginning with /p/ or /b/\nWords that begin with ‚Äúk‚Äù in their spelling, but begin with the phoneme /n/\nWords that begin with ‚Äúk‚Äù in their spelling, but do not begin with the phoneme /n/",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Pronunciation Tags"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/3-stanford-pos.html",
    "href": "worksheets/express-tutorial/3-stanford-pos.html",
    "title": "Part of Speech Tags",
    "section": "",
    "text": "LaBB-CAT can be integrated with the Stanford POS Tagger, which is free software developed by The Stanford Natural Languages Processing Group for tagging words in various languages with their parts of speech.\nIn this exercise you will:\n\ninstall the Stanford POS Tagger layer manager module, and\nuse it to tag each word with its part of speech.\n\n\n\nThe first thing we‚Äôre going to do is install the Stanford POS Tagger layer manager, which is a LaBB-CAT module that integrates with the Stanford NLP Group‚Äôs software‚Ä¶\n\nIn LaBB-CAT, select the layer managers menu option.\nYou will see a list of pre-installed layer managers, which are modules that can perform automatic annotation tasks. The Stanford POS Tagger layer manager isn‚Äôt pre-installed, because it is language-specific, and requires installation of further software.\nNear the bottom of the page there a link labelled:\nList of layer managers that are not yet installed ‚Äì click it.\nFind Stanford POS Tagger in the list, and press its Install button.\nPress Install on the resulting information page.\nThis displays some further information about the layer manager, allowing you to optionally upload an alternative version of Stanford‚Äôs software.\nWe won‚Äôt upload a file, we‚Äôll be using the standard file that is included in the layer manager.\nPress Configure.\nYou will see a progress bar while the layer manager downloads the software from the Stanford website. This will take a minute or so.\nOnce it‚Äôs finished, you will see a new window open with information about the Stanford POS Tagger layer manager.\n\n\n\n\nNow that we‚Äôve installed the layer manager, we‚Äôll create an annotation layer that tags words with their pronunciations.\n\nSelect the word layers option on the menu.\nYou will see a list of existing word layers, including the orthography layer, the lexical layer, etc.\nThe column headings are also a form for defining a new word layer. Fill in the following details in this form:\n\nLayer ID: pos\nType: Text\nAlignment: Intervals\nManager: Stanford POS Tagger\nDescription: Part of Speech tag(s) according to the Stanford POS Tagger.\n\nPress New to add the layer.\nYou will see the layer configuration form.\n\nThere are some word tokens we want the POS tagger to ignore:\n\nfilled pauses like ‚Äúum‚Äù, ‚Äúah‚Äù, and ‚Äúmm‚Äù, and\nhalf-finished words that the speaker interrupted before completing the full word - these are transcribed with a ~ at the end of the word, e.g.¬†if the speaker started saying ‚Äúnoise‚Äù but changed their mind before the end of the word, this might be transcribed as ‚Äúnoi~‚Äù.\n\nThis is what the Token Exclusion Pattern setting is for; it‚Äôs a regular expression that identified words that should be excluded from part-of-speech tagging.\n\nSet the Token Exclusion Pattern to be:\num|ah|mm|.*~\n\n\n\n\n\n\n\nTip\n\n\n\n If you‚Äôre curious about what the configuration options do, hover your mouse over each one to see further information about what the setting does.\n\n\n\nPress Set Parameters.\nYou will see a message asking you if you want (re)generate the layer data now.\nPress Regenerate.\nYou will see a progress bar moving across the page while the annotations are being generated. This will probably take a minute or so.\nWhen it is finished, you will see a message saying Finished.\nSelect the transcripts menu option, and open the first transcript in the list by clicking the transcript name.\nSelect the Layers tab at the top to reveal a list of tickable annotation layers.\nTick your new pos layer.\n\nYou‚Äôll see that each word is now tagged with at least on part-of-speech tag. Some words will have multiple tags, for example ‚ÄúI‚Äôve‚Äù includes\n\na PRP (personal pronoun) and\na VBP (present-tense verb).\n\nThese tags (like any annotations in LaBB-CAT) can be searched, extracted, and analysed.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Part of Speech Tags"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/3-stanford-pos.html#install-the-stanford-pos-tagger",
    "href": "worksheets/express-tutorial/3-stanford-pos.html#install-the-stanford-pos-tagger",
    "title": "Part of Speech Tags",
    "section": "",
    "text": "The first thing we‚Äôre going to do is install the Stanford POS Tagger layer manager, which is a LaBB-CAT module that integrates with the Stanford NLP Group‚Äôs software‚Ä¶\n\nIn LaBB-CAT, select the layer managers menu option.\nYou will see a list of pre-installed layer managers, which are modules that can perform automatic annotation tasks. The Stanford POS Tagger layer manager isn‚Äôt pre-installed, because it is language-specific, and requires installation of further software.\nNear the bottom of the page there a link labelled:\nList of layer managers that are not yet installed ‚Äì click it.\nFind Stanford POS Tagger in the list, and press its Install button.\nPress Install on the resulting information page.\nThis displays some further information about the layer manager, allowing you to optionally upload an alternative version of Stanford‚Äôs software.\nWe won‚Äôt upload a file, we‚Äôll be using the standard file that is included in the layer manager.\nPress Configure.\nYou will see a progress bar while the layer manager downloads the software from the Stanford website. This will take a minute or so.\nOnce it‚Äôs finished, you will see a new window open with information about the Stanford POS Tagger layer manager.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Part of Speech Tags"
    ]
  },
  {
    "objectID": "worksheets/express-tutorial/3-stanford-pos.html#annotate-words-with-part-of-speech-tags",
    "href": "worksheets/express-tutorial/3-stanford-pos.html#annotate-words-with-part-of-speech-tags",
    "title": "Part of Speech Tags",
    "section": "",
    "text": "Now that we‚Äôve installed the layer manager, we‚Äôll create an annotation layer that tags words with their pronunciations.\n\nSelect the word layers option on the menu.\nYou will see a list of existing word layers, including the orthography layer, the lexical layer, etc.\nThe column headings are also a form for defining a new word layer. Fill in the following details in this form:\n\nLayer ID: pos\nType: Text\nAlignment: Intervals\nManager: Stanford POS Tagger\nDescription: Part of Speech tag(s) according to the Stanford POS Tagger.\n\nPress New to add the layer.\nYou will see the layer configuration form.\n\nThere are some word tokens we want the POS tagger to ignore:\n\nfilled pauses like ‚Äúum‚Äù, ‚Äúah‚Äù, and ‚Äúmm‚Äù, and\nhalf-finished words that the speaker interrupted before completing the full word - these are transcribed with a ~ at the end of the word, e.g.¬†if the speaker started saying ‚Äúnoise‚Äù but changed their mind before the end of the word, this might be transcribed as ‚Äúnoi~‚Äù.\n\nThis is what the Token Exclusion Pattern setting is for; it‚Äôs a regular expression that identified words that should be excluded from part-of-speech tagging.\n\nSet the Token Exclusion Pattern to be:\num|ah|mm|.*~\n\n\n\n\n\n\n\nTip\n\n\n\n If you‚Äôre curious about what the configuration options do, hover your mouse over each one to see further information about what the setting does.\n\n\n\nPress Set Parameters.\nYou will see a message asking you if you want (re)generate the layer data now.\nPress Regenerate.\nYou will see a progress bar moving across the page while the annotations are being generated. This will probably take a minute or so.\nWhen it is finished, you will see a message saying Finished.\nSelect the transcripts menu option, and open the first transcript in the list by clicking the transcript name.\nSelect the Layers tab at the top to reveal a list of tickable annotation layers.\nTick your new pos layer.\n\nYou‚Äôll see that each word is now tagged with at least on part-of-speech tag. Some words will have multiple tags, for example ‚ÄúI‚Äôve‚Äù includes\n\na PRP (personal pronoun) and\na VBP (present-tense verb).\n\nThese tags (like any annotations in LaBB-CAT) can be searched, extracted, and analysed.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Express Tutorial",
      "Part of Speech Tags"
    ]
  },
  {
    "objectID": "worksheets/course/3-uploading-data.html",
    "href": "worksheets/course/3-uploading-data.html",
    "title": "3. Uploading Data",
    "section": "",
    "text": "In this exercise you will:\n\nUpload a transcript manually\nUpload many transcripts at once using the batch uploader\nImport participant data from a CSV file\nDefine a speech elicitation task for gathering data\n\nAfter this you will have a small corpus in your LaBB-CAT database.\nBefore you start, download and unzip QuakeStories.zip so you've got the demonstration data for uploading to your corpus.\n\n\n\n\nIn LaBB-CAT, select the transcripts option in the menu.\nPress the Upload Transcript icon.\n\nYou will see a page with some options to select on the top left, buttons on the top right, and in a middle, a rectangle with a dashed border; this is the ‚Äòupload queue‚Äô, which lists files we want to upload.\n\nIn the top left corner of the ‚Äòupload queue‚Äô rectangle, there‚Äôs a Choose Files button; press it, and select the file in the ‚ÄúQuakeStories‚Äù folder called BR178LK_MargaretSpencer.eaf\n\nYou will see that the transcript file is listed in the ‚Äòupload queue‚Äô. We want to upload not only the transcript, but also its associated media files. Each transcript has an audio file and a video file, and you want to upload both.\n\nPress Choose Files button again, and in the same ‚ÄúQuakeStories‚Äù folder click the file called BR178LK_MargaretSpencer.mp4, then hold down the  key on your keyboard and click the file called BR178LK_MargaretSpencer.wav so that both files are selected.\nThen press Open (or in some browsers the button to select files is labelled Upload).\nYou will see that next to the BR178LK_MargaretSpencer.eaf transcriopt, under the Media heading, two media types are now show; ‚Äúmp4‚Äù and ‚Äúwav‚Äù.\nTo the right of this, ensure the Corpus option is QB\nAlso ensure the Type option is interview\nLeave the other options with the default values and press the Upload button above.\nYou will see that, on the right, a progress bar shows 50% progress, and below the transcript in the upload queue, a number of options have appeared.\n\nEach ELAN transcript has a number of Tiers defined in it:\n\none for the participant's utterances,\nanother for an ‚Äòinterviewer‚Äô if there is one,‚Ä∫\none for noise annotations,\none for transcriber comments, and\none for topic annotations.\n\nEach tier must be mapped to a LaBB-CAT annotation layer.\nLaBB-CAT has analysed the structure of the ELAN transcript and pre-selected some default options for layer mappings. For this data, these defaults are correct, so you needn‚Äôt change anything.\n\n\nPress Save to continue.\nYou will see that the progress bar on the right continues, and after a short delay, the progress is complete, and the Status is listed as ‚ÄúFinished.‚Äù\nThe name of the transcript on the left, BR178LK_MargaretSpencer.eaf, is now a link. Click it.\n\nYou will see a page with transcript text, and the video appears in the top right corner of the page.\n\nPress the play button on the video.\nAs the video plays, you will see the current utterance highlighted in the transcript. You will also see that the current utterance appears as closed captions in the video. You can use the video controls as normal, including the full-screen button to make the video occupy the whole screen.\nPause the recording.\nClick one of the transcript lines further down the transcript.\nA menu will appear.\nSelect the ‚ÄòPlay‚Äô option on the menu.\nYou will see that playback starts at that line. Playback will stop when the participant finishes the utterance.\nSelect the Export tab at the top of the transcript.\nYou will see a list of formats for exporting the transcript to.\nSelect Plain Text Document\nSave the resulting file and then open it.\nYou will see the transcript in plain-text form.\nIf you have Praat installed on your computer, select the Praat Text Grid option on the Export tab. Save the resulting file on your desktop, and then open it with Praat.\nYou will see that the TextGrid has a couple of tiers, one for each speaker with utterance transcripts.\nBack on the transcript page, select the Attributes tab at the top.\nThis will display the attributes for the transcript (some of the attribute values are not set because the information was not in the .eaf transcript file)\nNow select the Participants tab at the top.\nThis will list both participants in the recording, the main participant, and the interviewer.\nClick the Attributes link for the main participant.\nThis will display the participant meta-data, except that there are no values because we haven‚Äôt entered them yet!\nBR178LK_MargaretSpencer is an ‚ÄòEnglish‚Äô-speaking ‚ÄòFemale‚Äô who is between ‚Äò66 and 75 years‚Äô old, who grew up in ‚ÄòChristchurch‚Äô, in the ‚ÄòNorth Canterbury‚Äô region of ‚ÄôNew Zealand'.\nSet her attributes to reflect that, and press Save.\n\nYou have now manually uploaded one transcript, checked the ELAN-tier to LaBB-CAT layer mappings and manually specified the meta-data for one participant.\n\n\n\nIf you already have a collection of transcripts and media files (which we have for these exercises), and they are systematically organized (which they are), you may be able to save some manual uploading work by uploading them using the ‚Äòautomated upload‚Äô option.\n\nWhen you clicked the name of the transcript to open it after uploading, a new browser tab was opened. Close that tab now to take you back to the upload queue.\nMost of the transcripts we are going to upload are monologues, so in the Defaults box on the top left, set Transcript Type to monologue.\nOpen Windows Explorer or Finder, and navigate to the LaBB-CAT Workshop data folder.\nDrag the folder called ‚ÄúQuakeStories‚Äù, and drop it on to LaBB-CAT, on to the upload queue area below the buttons (the rectangle with the dashed border).\n\nThe upload queue will now contain a longer list of transcripts. Each transcript should have a value filled in for each column - Transcript, Media, Corpus, Episode, and Type.\n\n\nThe first transcript, BR178LK_MargaretSpencer.eaf, has already been uploaded, and we don‚Äôt want to upload it again. Remove it from the list by using the ‚ûñ button on the right hand side of that row.\n\nWhen we uploaded manually before, we saw a list of ELAN tiers and their correspondences to LaBB-CAT layers. The options had default values, but we had to manually confirm the choices that LaBB-CAT had made about how to interpret the ELAN tiers.\nThe Automated Upload option allows LaBB-CAT to automatically use these default selections, instead of asking us to manually confirm them for every transcript. For this corpus, the default options that LaBB-CAT automatically selects will always be correct.\n\nTick the Automated Upload checkbox in the Defaults box on the top left.\nPress the Upload button above the list.\nYou will see that in the Status column, the text changes to ‚ÄúUploading‚Ä¶‚Äù for the first transcript. The progress bar progresses, and once it's complete, the next transcript changes to ‚ÄúTransferring‚Äù, and so on.\n\n\n\n\n\n\n\nTip\n\n\n\nWhile the files are uploading, click  the online help link at the top of the page to the right of the menu and check preconditions for uploading, and other functions the upload page can perform.\n\n\n\nOnce the uploader is finished, you will receive a CSV ‚Äòupload report‚Äô file that lists the files you uploaded and their upload status. (If there had been any problems with the upload, the resulting error messages would be included in this report for following up.)\nYou can verify that all the transcripts are there by selecting the transcripts option on the menu in LaBB-CAT.\nYou should see a list of nineteen transcripts.\nUse the Transcript box to find UC013AM_Dom.eaf\n(you can type just part of the name if you like).\nPress the Attributes icon for UC013AM_Dom.eaf\n(on the far right of the row).\nChange Transcript type to interview and press Save.\nSimilarly, the following transcripts are interviews, so change their type accordingly\n\nUC215YW_DanielaMaoate-Cox.eaf\nUC226AD.eaf\n\n\n\n\nThe transcripts are now in the database, but the meta-data for the participants hasn't been set yet (because it‚Äôs not contained in the ELAN files). We could manually add this for each speaker, but fortunately we have it stored in a spreadsheet (actually, a CSV text file) that we can upload in one go.\n\nIn LaBB-CAT, select the participants option on the menu.\nYou will see all the participants in the the transcripts you have uploaded, many of which include an interviewer as well as a main participant.\nPress the Upload Participant Data icon at the bottom.\nPress Choose File, and select the file in the LaBB-CAT Exercises data folder called participants.csv\nPress Upload\nYou will now see a list of the columns from the spreadsheet.\nFirstly, ensure that the Participant identity column is set to name. This ensures that the ‚Äúname‚Äù column in the spreadsheet will be used to match names of participants in the LaBB-CAT database.\nBelow that is listed each column from the spreadsheet, with an arrow pointing to a dropdown box. The box contains various options, including each of the participant attributes set up in LaBB-CAT, an ignore option, and create a new attribute option.\nMost likely, the correct options are already selected, as we‚Äôve already set up the correct participant attributes, but just check that they are as follows:\n\n\nThe CSV column name: ‚Üí ignore because it's the Participant Identity Column identified above\nThe CSV column gender: ‚Üí the Gender LaBB-CAT attribute\nThe CSV column ageCategory: ‚Üí the Age LaBB-CAT attribute\nThe CSV column ethnicity: ‚Üí the Ethnicity LaBB-CAT attribute\nThe CSV column grewUup: ‚Üí the grewUp LaBB-CAT attribute\nThe CSV column grewUpRegion: ‚Üí the grewUpRegion LaBB-CAT attribute\nThe CSV column grewUpTown: ‚Üí the grewUpTown LaBB-CAT attribute\nThe CSV column languagesSpoken: ‚Üí the languagesSpoken LaBB-CAT attribute\n\nPress import.\nYou should see a page with information about the import, including the columns that were ignored, and the number of participants that were added.\n\nTo check the participant attributes really are now set:\n\nSelect the participants option on the menu. You will see a list of speakers, and page links at the bottom.\nThe page also includes participant attribute values where they are known, and you will see that now the speakers who are main-participants have values filled in for their participant attributes.\n\nYou can also filter the list by these values, using the column headings above the list:\n\nUnder Gender, select the F option.\nThe page now lists only those with ‚ÄòFemale‚Äô set for the Gender attribute.\n\n\n\n\nLaBB-CAT can also make recordings of speech directly from the browser.\nLet‚Äôs suppose you want to record a number of participants reading lists of words. You can define an ‚ÄòElicitation Task‚Äô that includes a series of steps, one for each set of words you want participants to read.\nFirst we‚Äôre going to create a corpus to receive our recordings, and a transcript type to mark the recordings as word lists ‚Ä¶\n\nIn LaBB-CAT, select the corpora option on the menu.\nAdd a corpus called CC with a description Canterbury Corpus.\nClick the transcript types option on the menu.\nAdd a transcript type called wordlist.\n\nNow we‚Äôll create the elicitation task, which defines what prompts and texts the participant sees during the task.\n\nClick the elicitation tasks option on the menu. The page you see is a list of elicitation tasks defined, which is currently empty.\nFill in the blank form with the following details:\n\nID: nze-wordlist\ndescription: New Zealand English Word List\ncorpus: CC (the corpus you just created)\ntranscript type: wordlist (the transcript type you just created)\npreamble: ‚ÄúIn this task your speech will be recorded. Please ensure you‚Äôre in a quiet place.‚Äù\nThis is the first text the participant sees when they access the task, before giving consent or going through the steps.\nconsent: ‚ÄúI give consent for the use of my speech data for this research.‚Äù\nThis is the text of the participant's consent for their participation and the use of their data. Before starting the task steps, they must 'sign' this consent by typing their name in a box at the bottom. The text, with their name and the date incorporated, with be made into a PDF file which is uploaded with their recordings, and is made available for them to download.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor both the preamble and the consent form, you can format the text with bold, italic, and underlined text, etc. by using the controls above the text area.\n\n\n\n\n\n\n\n\nTip\n\n\n\n Check the online help on this page for further details about settings and important information about browser limitations.\n\n\n\nPress New to add the task.\nPress Define Steps.\n\nOn this page you are going to add steps for the task. The first step, called ‚ÄúWelcome‚Äù, has already been added, and we‚Äôll use it for giving the participant some detailed instructions about what follows. We'll add a series of steps after the ‚ÄúWelcome‚Äù step, one for each group of words we want the participant to read.\n\nThe form you can see defines the details of the first ‚ÄúWelcome‚Äù step.\n Check the online help on this page for further details about this page and the options on it.\nClose the online help page to return to the ‚Äúdefine elicitation steps‚Äù page.\nFill in the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: Instructions\nPrompt: Please read aloud the following sets of words. Press ‚ÄúNext‚Äù after each set.\nElicit: Nothing\nTranscript: (leave this box blank)\nImage/Video: no image/video\n\n\n\nNext we‚Äôll define what demographic information we will ask each participant before they start recording. In this case, we will ask for their gender and what languages they speak.\n\nPress the  button to add a new step.\nFill in the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: Languages\nPrompt: What languages do you speak?\nElicit: Attribute Value\nAttribute: participant_languagesSpoken\nImage/Video: no image/video\n\nPress the  button to add a new step\nFill in the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: Gender\nPrompt: What is your gender?\nElicit: Attribute Value\nAttribute: participant_gender\nImage/Video: no image/video\n\n\nNow we can defined some prompts for them to read aloud.\n\nPress the  button to add a new step\nFill in the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: (leave this box blank)\nPrompt: Please read the following aloud:\nElicit: Audio\nTranscript: 1. hit hid hint\nMax Seconds: 30\nNext Button: Shown\nRerecord Button: Hidden\nImage/Video: no image/video\n\nPress the  button to add a new step\nFill in the same details as the previous step, except:\nTranscript: 2. boot booed boo tune dune\nAdd a new step for Transcript: 3. bird curt burn\nAdd a new step for Transcript: 4. bat bad back bag ban\nAdd a new step for Transcript: 5. bet bed beck beg ben\nAdd one last step, with the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: Finished\nPrompt: Thanks for your participation!\nElicit: Nothing\nTranscript: (leave this box blank)\nImage/Video: no image/video\n\n\nThis last step is what is displayed to the participant when they‚Äôve finished all the steps.\n\nPress Save Changes\n\n\n\nYour task is almost ready. We just need to define which options for gender they can see.\n\nSelect the elicitation tasks option on the menu.\nPress Participant Attributes.\nSelect Options\nThis displays a list of the gender options that are visible to the participant. As you can see it's currently empty. In this case, we want to display all options for them to select.\nPress Add All\nYou will see that all the options (M, F, and ‚Äò(not specified)‚Äô) have been added to the list. If you wanted to, you could edit the ‚Äúdescription‚Äù of the individual items (e.g.¬†translate them to another language if your participants don‚Äôt speech English), or delete options you don‚Äôt want them to be able to select.\nPress the Delete button next to the ‚Äò(not specified)‚Äô option, and click OK to confirm.\nPress Save Changes.\n\nYour task is now fully defined and ready to go.\nNow you‚Äôre going to run through the elicitation task yourself ‚Ä¶\n\nSelect the elicitation tasks option on the menu.\nPress the Elicitation Task button on the bottom right.\nYou should see a page that displays the task‚Äôs ‚Äòpreamble‚Äô that you defined earlier.\nClick Next.\nYou should see a page that displays the task‚Äôs consent form that you defined earlier, with a box to enter your name in order to ‚Äòsign‚Äô the consent.\nEnter your name and click Next.\nYou will be given the chance to save your copy of the consent form.\nSave the consent form and open it to check the contents.\nClose the consent form to return to the task.\nYou will be asked for the demographic details you defined earlier.\n\nFill in your languages and press Next.\nFill in your gender and press Next.\n\nYou should see a page with some text about enabling your microphone.\nIf you don‚Äôt, and instead see a message about your browser not being supported, this means that your web browser doesn‚Äôt support recording sound. In this case, copy the address of the page at the top, and paste it into another browser (e.g.¬†Google Chrome or Mozilla Firefox).\nOnce you've enabled your browser for access to your microphone, the task steps will begin, and you should follow the instructions, reading the prompts aloud and clicking Next after each group of words.\nEach time somebody performs the task, they're assigned a unique Participant ID, which is linked to their demographic data and the recordings.\n\nPress the Back button on your browser to return to the define elicitation tasks page in LaBB-CAT.\nPress the participants option on the menu.\n\n\n\n\n\n\n\nTip\n\n\n\nLaBB-CAT remembers the last filters you used, so you may need to clear any filters you had previously applied.\nFor example, if the last time you accessed the participants page, you selected the F gender option to show only female participants, that filter may still be active.\nYou can press the ‚å´ button at the top, to the right of the page filters, to clear all filters.\n\n\n\nUnder the Corpus heading, select the CC option.\nYou will see one participant; the one you just created by doing the task.\nPress the participant ID to open their attributes page, and check that the demographic information you entered has been saved.\nClick the participant ID to open their attributes page, and check You will see that the participant has five transcripts, one for each of the task steps where audio was recorded.\nPress the Transcripts link at the bottom to list the transcripts.\nOpen the first transcript.\nYou will see that the transcript starts with a comment, which is the prompt text you were shown during the step, and that the transcript contains one utterance.\nPlay the audio to ensure it was recorded correctly.\n(If the last transcript you looked at had video, you may need to tick the checkbox next to the ‚Äúwav‚Äù option in the top right corner, in order to select audio for playback.)\nOn the right hand edge of the page, about halfway down, there is a green arrow icon .\nPress it.\nYou will see that this opens the next transcript in the ‚Äòepisode‚Äô that you just recorded- i.e.¬†the next set of words you read out. The green arrows on the left  and the right  of the screen allow you to navigate between the different transcripts in the same recording episode.\n\nAlthough these ‚Äòtask step‚Äô transcripts are very short, they behave the same as any other transcript; they can be exported, annotated, searched, etc.\n\nYou now have a small database with a number of speakers in it, so we can start creating some annotations and doing some searches ...",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "3. Uploading Data"
    ]
  },
  {
    "objectID": "worksheets/course/3-uploading-data.html#automated-upload",
    "href": "worksheets/course/3-uploading-data.html#automated-upload",
    "title": "3. Uploading Data",
    "section": "",
    "text": "If you already have a collection of transcripts and media files (which we have for these exercises), and they are systematically organized (which they are), you may be able to save some manual uploading work by uploading them using the ‚Äòautomated upload‚Äô option.\n\nWhen you clicked the name of the transcript to open it after uploading, a new browser tab was opened. Close that tab now to take you back to the upload queue.\nMost of the transcripts we are going to upload are monologues, so in the Defaults box on the top left, set Transcript Type to monologue.\nOpen Windows Explorer or Finder, and navigate to the LaBB-CAT Workshop data folder.\nDrag the folder called ‚ÄúQuakeStories‚Äù, and drop it on to LaBB-CAT, on to the upload queue area below the buttons (the rectangle with the dashed border).\n\nThe upload queue will now contain a longer list of transcripts. Each transcript should have a value filled in for each column - Transcript, Media, Corpus, Episode, and Type.\n\n\nThe first transcript, BR178LK_MargaretSpencer.eaf, has already been uploaded, and we don‚Äôt want to upload it again. Remove it from the list by using the ‚ûñ button on the right hand side of that row.\n\nWhen we uploaded manually before, we saw a list of ELAN tiers and their correspondences to LaBB-CAT layers. The options had default values, but we had to manually confirm the choices that LaBB-CAT had made about how to interpret the ELAN tiers.\nThe Automated Upload option allows LaBB-CAT to automatically use these default selections, instead of asking us to manually confirm them for every transcript. For this corpus, the default options that LaBB-CAT automatically selects will always be correct.\n\nTick the Automated Upload checkbox in the Defaults box on the top left.\nPress the Upload button above the list.\nYou will see that in the Status column, the text changes to ‚ÄúUploading‚Ä¶‚Äù for the first transcript. The progress bar progresses, and once it's complete, the next transcript changes to ‚ÄúTransferring‚Äù, and so on.\n\n\n\n\n\n\n\nTip\n\n\n\nWhile the files are uploading, click  the online help link at the top of the page to the right of the menu and check preconditions for uploading, and other functions the upload page can perform.\n\n\n\nOnce the uploader is finished, you will receive a CSV ‚Äòupload report‚Äô file that lists the files you uploaded and their upload status. (If there had been any problems with the upload, the resulting error messages would be included in this report for following up.)\nYou can verify that all the transcripts are there by selecting the transcripts option on the menu in LaBB-CAT.\nYou should see a list of nineteen transcripts.\nUse the Transcript box to find UC013AM_Dom.eaf\n(you can type just part of the name if you like).\nPress the Attributes icon for UC013AM_Dom.eaf\n(on the far right of the row).\nChange Transcript type to interview and press Save.\nSimilarly, the following transcripts are interviews, so change their type accordingly\n\nUC215YW_DanielaMaoate-Cox.eaf\nUC226AD.eaf\n\n\n\n\nThe transcripts are now in the database, but the meta-data for the participants hasn't been set yet (because it‚Äôs not contained in the ELAN files). We could manually add this for each speaker, but fortunately we have it stored in a spreadsheet (actually, a CSV text file) that we can upload in one go.\n\nIn LaBB-CAT, select the participants option on the menu.\nYou will see all the participants in the the transcripts you have uploaded, many of which include an interviewer as well as a main participant.\nPress the Upload Participant Data icon at the bottom.\nPress Choose File, and select the file in the LaBB-CAT Exercises data folder called participants.csv\nPress Upload\nYou will now see a list of the columns from the spreadsheet.\nFirstly, ensure that the Participant identity column is set to name. This ensures that the ‚Äúname‚Äù column in the spreadsheet will be used to match names of participants in the LaBB-CAT database.\nBelow that is listed each column from the spreadsheet, with an arrow pointing to a dropdown box. The box contains various options, including each of the participant attributes set up in LaBB-CAT, an ignore option, and create a new attribute option.\nMost likely, the correct options are already selected, as we‚Äôve already set up the correct participant attributes, but just check that they are as follows:\n\n\nThe CSV column name: ‚Üí ignore because it's the Participant Identity Column identified above\nThe CSV column gender: ‚Üí the Gender LaBB-CAT attribute\nThe CSV column ageCategory: ‚Üí the Age LaBB-CAT attribute\nThe CSV column ethnicity: ‚Üí the Ethnicity LaBB-CAT attribute\nThe CSV column grewUup: ‚Üí the grewUp LaBB-CAT attribute\nThe CSV column grewUpRegion: ‚Üí the grewUpRegion LaBB-CAT attribute\nThe CSV column grewUpTown: ‚Üí the grewUpTown LaBB-CAT attribute\nThe CSV column languagesSpoken: ‚Üí the languagesSpoken LaBB-CAT attribute\n\nPress import.\nYou should see a page with information about the import, including the columns that were ignored, and the number of participants that were added.\n\nTo check the participant attributes really are now set:\n\nSelect the participants option on the menu. You will see a list of speakers, and page links at the bottom.\nThe page also includes participant attribute values where they are known, and you will see that now the speakers who are main-participants have values filled in for their participant attributes.\n\nYou can also filter the list by these values, using the column headings above the list:\n\nUnder Gender, select the F option.\nThe page now lists only those with ‚ÄòFemale‚Äô set for the Gender attribute.\n\n\n\n\nLaBB-CAT can also make recordings of speech directly from the browser.\nLet‚Äôs suppose you want to record a number of participants reading lists of words. You can define an ‚ÄòElicitation Task‚Äô that includes a series of steps, one for each set of words you want participants to read.\nFirst we‚Äôre going to create a corpus to receive our recordings, and a transcript type to mark the recordings as word lists ‚Ä¶\n\nIn LaBB-CAT, select the corpora option on the menu.\nAdd a corpus called CC with a description Canterbury Corpus.\nClick the transcript types option on the menu.\nAdd a transcript type called wordlist.\n\nNow we‚Äôll create the elicitation task, which defines what prompts and texts the participant sees during the task.\n\nClick the elicitation tasks option on the menu. The page you see is a list of elicitation tasks defined, which is currently empty.\nFill in the blank form with the following details:\n\nID: nze-wordlist\ndescription: New Zealand English Word List\ncorpus: CC (the corpus you just created)\ntranscript type: wordlist (the transcript type you just created)\npreamble: ‚ÄúIn this task your speech will be recorded. Please ensure you‚Äôre in a quiet place.‚Äù\nThis is the first text the participant sees when they access the task, before giving consent or going through the steps.\nconsent: ‚ÄúI give consent for the use of my speech data for this research.‚Äù\nThis is the text of the participant's consent for their participation and the use of their data. Before starting the task steps, they must 'sign' this consent by typing their name in a box at the bottom. The text, with their name and the date incorporated, with be made into a PDF file which is uploaded with their recordings, and is made available for them to download.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor both the preamble and the consent form, you can format the text with bold, italic, and underlined text, etc. by using the controls above the text area.\n\n\n\n\n\n\n\n\nTip\n\n\n\n Check the online help on this page for further details about settings and important information about browser limitations.\n\n\n\nPress New to add the task.\nPress Define Steps.\n\nOn this page you are going to add steps for the task. The first step, called ‚ÄúWelcome‚Äù, has already been added, and we‚Äôll use it for giving the participant some detailed instructions about what follows. We'll add a series of steps after the ‚ÄúWelcome‚Äù step, one for each group of words we want the participant to read.\n\nThe form you can see defines the details of the first ‚ÄúWelcome‚Äù step.\n Check the online help on this page for further details about this page and the options on it.\nClose the online help page to return to the ‚Äúdefine elicitation steps‚Äù page.\nFill in the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: Instructions\nPrompt: Please read aloud the following sets of words. Press ‚ÄúNext‚Äù after each set.\nElicit: Nothing\nTranscript: (leave this box blank)\nImage/Video: no image/video\n\n\n\nNext we‚Äôll define what demographic information we will ask each participant before they start recording. In this case, we will ask for their gender and what languages they speak.\n\nPress the  button to add a new step.\nFill in the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: Languages\nPrompt: What languages do you speak?\nElicit: Attribute Value\nAttribute: participant_languagesSpoken\nImage/Video: no image/video\n\nPress the  button to add a new step\nFill in the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: Gender\nPrompt: What is your gender?\nElicit: Attribute Value\nAttribute: participant_gender\nImage/Video: no image/video\n\n\nNow we can defined some prompts for them to read aloud.\n\nPress the  button to add a new step\nFill in the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: (leave this box blank)\nPrompt: Please read the following aloud:\nElicit: Audio\nTranscript: 1. hit hid hint\nMax Seconds: 30\nNext Button: Shown\nRerecord Button: Hidden\nImage/Video: no image/video\n\nPress the  button to add a new step\nFill in the same details as the previous step, except:\nTranscript: 2. boot booed boo tune dune\nAdd a new step for Transcript: 3. bird curt burn\nAdd a new step for Transcript: 4. bat bad back bag ban\nAdd a new step for Transcript: 5. bet bed beck beg ben\nAdd one last step, with the following details:\n\nShow: Always\nCountdown Seconds: 0\nTitle: Finished\nPrompt: Thanks for your participation!\nElicit: Nothing\nTranscript: (leave this box blank)\nImage/Video: no image/video\n\n\nThis last step is what is displayed to the participant when they‚Äôve finished all the steps.\n\nPress Save Changes\n\n\n\nYour task is almost ready. We just need to define which options for gender they can see.\n\nSelect the elicitation tasks option on the menu.\nPress Participant Attributes.\nSelect Options\nThis displays a list of the gender options that are visible to the participant. As you can see it's currently empty. In this case, we want to display all options for them to select.\nPress Add All\nYou will see that all the options (M, F, and ‚Äò(not specified)‚Äô) have been added to the list. If you wanted to, you could edit the ‚Äúdescription‚Äù of the individual items (e.g.¬†translate them to another language if your participants don‚Äôt speech English), or delete options you don‚Äôt want them to be able to select.\nPress the Delete button next to the ‚Äò(not specified)‚Äô option, and click OK to confirm.\nPress Save Changes.\n\nYour task is now fully defined and ready to go.\nNow you‚Äôre going to run through the elicitation task yourself ‚Ä¶\n\nSelect the elicitation tasks option on the menu.\nPress the Elicitation Task button on the bottom right.\nYou should see a page that displays the task‚Äôs ‚Äòpreamble‚Äô that you defined earlier.\nClick Next.\nYou should see a page that displays the task‚Äôs consent form that you defined earlier, with a box to enter your name in order to ‚Äòsign‚Äô the consent.\nEnter your name and click Next.\nYou will be given the chance to save your copy of the consent form.\nSave the consent form and open it to check the contents.\nClose the consent form to return to the task.\nYou will be asked for the demographic details you defined earlier.\n\nFill in your languages and press Next.\nFill in your gender and press Next.\n\nYou should see a page with some text about enabling your microphone.\nIf you don‚Äôt, and instead see a message about your browser not being supported, this means that your web browser doesn‚Äôt support recording sound. In this case, copy the address of the page at the top, and paste it into another browser (e.g.¬†Google Chrome or Mozilla Firefox).\nOnce you've enabled your browser for access to your microphone, the task steps will begin, and you should follow the instructions, reading the prompts aloud and clicking Next after each group of words.\nEach time somebody performs the task, they're assigned a unique Participant ID, which is linked to their demographic data and the recordings.\n\nPress the Back button on your browser to return to the define elicitation tasks page in LaBB-CAT.\nPress the participants option on the menu.\n\n\n\n\n\n\n\nTip\n\n\n\nLaBB-CAT remembers the last filters you used, so you may need to clear any filters you had previously applied.\nFor example, if the last time you accessed the participants page, you selected the F gender option to show only female participants, that filter may still be active.\nYou can press the ‚å´ button at the top, to the right of the page filters, to clear all filters.\n\n\n\nUnder the Corpus heading, select the CC option.\nYou will see one participant; the one you just created by doing the task.\nPress the participant ID to open their attributes page, and check that the demographic information you entered has been saved.\nClick the participant ID to open their attributes page, and check You will see that the participant has five transcripts, one for each of the task steps where audio was recorded.\nPress the Transcripts link at the bottom to list the transcripts.\nOpen the first transcript.\nYou will see that the transcript starts with a comment, which is the prompt text you were shown during the step, and that the transcript contains one utterance.\nPlay the audio to ensure it was recorded correctly.\n(If the last transcript you looked at had video, you may need to tick the checkbox next to the ‚Äúwav‚Äù option in the top right corner, in order to select audio for playback.)\nOn the right hand edge of the page, about halfway down, there is a green arrow icon .\nPress it.\nYou will see that this opens the next transcript in the ‚Äòepisode‚Äô that you just recorded- i.e.¬†the next set of words you read out. The green arrows on the left  and the right  of the screen allow you to navigate between the different transcripts in the same recording episode.\n\nAlthough these ‚Äòtask step‚Äô transcripts are very short, they behave the same as any other transcript; they can be exported, annotated, searched, etc.\n\nYou now have a small database with a number of speakers in it, so we can start creating some annotations and doing some searches ...",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "3. Uploading Data"
    ]
  },
  {
    "objectID": "worksheets/course/index.html",
    "href": "worksheets/course/index.html",
    "title": "LaBB-CAT Course",
    "section": "",
    "text": "LaBB-CAT Course\nThis course is intended to teach participants how to use LaBB-CAT from scratch, including: - installing and setting up the software - uploading data - defining speech-elicitation tasks - manually annotating the transcripts - setting up automatic annotations of different types - forced alignment\nIt is designed to be taught in three two-hour sessions.\nMuch of this material is demonstrated in these YouTube videos\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course"
    ]
  },
  {
    "objectID": "worksheets/course/8a-forced-alignment-htk.html",
    "href": "worksheets/course/8a-forced-alignment-htk.html",
    "title": "8a. HTK",
    "section": "",
    "text": "The Hidden Markov Model Toolkit (HTK) is a speech recognition toolkit developed at Cambridge University. It is a set of programs that can be used to build speech recognition systems. Part of the process of building such systems involves force-aligning training data - i.e. automatically lining up phonemic-transcriptions of known words with the audio signal in the training recordings. LaBB-CAT takes advantage of this capability to facilitate forced-alignment for your transcripts.\nIn order to do this, HTK needs the following ingredients:\n\na set of recordings broken up into short utterances,\northographic transcriptions of each utterance, and\nphonemic transcriptions of each of the words in each utterance\n\nYou already have 1. and 2. - i.e.¬†a set of recordings with transcripts that include the start and end times of each line.\nYou also mostly have 3. as well, if you have done a previous exercise which included generating a pronunciation layer generated using a lexicon like CELEX or the CMU Pronunciation Dictionary. However, there are words in your transcripts that aren‚Äôt in CELEX, and so we will explore some mechanisms for filling in their pronunciations.\nIn this exercise you will\n\ninstall the HTK Layer Manager,\nprovide some pronunciations that are missing,\nforce-align the speech of one of the participants in your database, and\ncheck and manually correct the alignments.\n\n\n\n\n\n\n\nImportant\n\n\n\nIn this exercise, you will set up Praat Integration in your web browser. There is currently no Praat integration support for Microsoft‚Äôs Edge‚Äô browser, so if you normally use ‚ÄòEdge‚Äô on Windows, you may need to swap to another browser for this exercise - e.g. Google Chrome, or Mozilla Firefox.\n\n\n\n\nHTK is not free software in the ‚ÄúGNU‚Äù sense - i.e.¬†we can not distribute it with LaBB-CAT, instead you have to download it yourself from the Cambridge University website ‚Äì however it is free in the ‚Äúno cost‚Äù sense, you just need to register on the HTK website, and you can then download and use HTK free of charge.\n\nRegister at http://htk.eng.cam.ac.uk/register.shtml\n\n\n\n\n\n\n\nNote\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, LaBB-CAT can itself download and compile HTK (i.e.¬†steps 2 and 3), as long has you have a username and password for the HTK website. In this case, these steps are automatically attempted when you install the HTK layer manager (from step 4).\n\n\n\nDownload the version of HTK that is appropriate for the computer that LaBB-CAT is installed on:\n\nFor Windows systems, there are pre-compiled .exe files that you can download.\nFor Unix-like systems including OS X, you need to download the source code, which you will then install following the provided instructions.\n\nUnzip (for Windows) or compile and install (for Unix-like systems) the downloaded files on the computer that LaBB-CAT is installed on.\n\nNow, you have to install the HTK Layer Manager, which is the LaBB-CAT module that provides HTK with all the data it needs, and then saves to alignments HTK produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link at the bottom.\nFind HTK Manager in the list, and press its Install button, then press Install again.\nYou will see a form with boxes that may already be filled in.\nThe layer manager needs to know where the HTK programs have been saved, which is what you need to enter in the blank Path to HTK tools box.\nIf this box is not blank, it means that LaBB-CAT has already found HTK for you, so you should leave the default value already set.\n\n\n\n\n\n\n\nNote\n\n\n\nThe other two boxes you may see are for the username and password you registered on the HTK website. On some systems, if you have not already installed the HTK tools on your LaBB-CAT computer, providing the username and password allows LaBB-CAT to attempt to download and install HTK itself. This may not work in all cases, as LaBB-CAT may not have the resources or privileges it requires to compile or install software.\n\n\n\nPress Configure.\nYou will see a window open with some information about the HTK Layer Manager.\nNow you need to add a phrase layer for the HTK configuration:\n\nLayer ID: htk\nType: Text\nAlignment: Intervals\nManager: HTK Manager\nGenerate: Never (note that this may see counter-intuitive, but we will be running HTK manually rather than allowing it to run automatically when transcripts are uploaded.)\nDescription: HTK alignment time\n\nWhen you configure the layer:\n\nYour Pronunciation Layer will be the phonemes layer you created in an earlier exercise.\nTo the list of Pause Markers you should add a full-stop (period).\nThis is because the exercise transcripts use . as a ‚Äòshort-pause‚Äô marker, not an ‚Äòend of sentence‚Äô marker. i.e. your Pause Markers should be:\n- .\n(a hyphen, then a space, then a full-stop/period)\nThe rest of the settings should be left with the default values.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a ‚Äòtool tip‚Äô that describes what the option is for.\n\n\nWe configure the layer to ‚Äònever‚Äô generate, because we‚Äôre going to trigger forced-alignments manually, one speaker at a time, once we‚Äôre happy that the phonemic transcriptions are in place.\n\n\n\nNow we‚Äôre going to check the situation of our pronunciations on the phonemes layer more carefully‚Ä¶\n\nGo to the transcripts page and open the transcript UC207YW\nTick the phonemes layer.\nHave a look through the transcript to see where the missing phonemic transcriptions are.\n\nYou‚Äôll see they divide into various broad types:\n\nTypos like ‚ÄúFebuary‚Äù\nSpecialist or invented words like ‚Äútarseal‚Äù\nContractions like ‚Äúme‚Äôs‚Äù and ‚Äúthing‚Äôs‚Äù\nProper names like ‚ÄúBealey‚Äù\nPossibly filled pauses like ‚Äúum‚Äù\nHesitations and interrupted words like ‚Äúexac~‚Äù, etc.\n\n\nHTK needs a phonemic transcription for every word on a line in order to force-align that line. So every line where there‚Äôs a gap on the phonemes layer would be ignored by the HTK layer manager.\n\nThere‚Äôs another problem in this transcript, which isn‚Äôt necessarily immediately obvious.\nLook for the hesitiation ‚Äúw-‚Äù and the filled-pause ‚Äúmm‚Äù to see if you can see what it is.\n\n‚ÄòFalse positives‚Äô from the lexicon will also play havoc with forced alignment, as HTK believes what it‚Äôs told about the pronunciations given to it, and will do it‚Äôs best to find an alignment that includes every phoneme.\n\nEach of these problems needs to be addressed before we do forced alignment, although the solution for each will vary. Some involve improving the transcript, others will involve adding new words to our dictionary.\n\nFor false-positives like ‚Äúw-‚Äù and ‚Äúmm‚Äù, the easiest solution is to transcribe these differently. Hesitations like ‚Äúw-‚Äù are discussed below. We will use ‚Äúmmm‚Äù instead of ‚Äúmm‚Äù.\nFor very short false-starts like ‚Äúw-‚Äù, the CELEX layer manager has been built to give a helping hand. In addition to looking up phonemic transcriptions in CELEX, it will also compute them for very short tagged false-starts. The tag it recognizes is a trailing tilde ~, so we need to change ‚Äúw-‚Äù to ‚Äúw~‚Äù etc. Then the CELEX layer manager will append a schwa to the initial consonant, and save that as the pronunciation (i.e.¬†/…ô/).\nFor invented or misspoken words, or longer interrupted words, which we‚Äôre not likely to see again in any other transcript like, ‚Äúme‚Äôs‚Äù and ‚Äúexac~‚Äù, we will add a ‚Äòpronounce‚Äô tag in the transcript, which includes the correct pronunciation. Again, the CELEX layer manager knows to check for pronounce annotations, and uses the given phonemic transcription instead of looking up the CELEX data.\nFor proper names and contractions like ‚Äúthing‚Äôs‚Äù that we‚Äôre likely to see over and over again in different transcripts, instead of tagging each one individually, we will add them to the dictionary of pronunciations that the lexicon layer manager looks up.\n\nAs you can see, the first three methods involve editing the transcript. This can be done by editing the original file in ELAN, and then re-uploading it into the database for processing.\nAlternatively, LaBB-CAT has a mechanism for editing the transcript ‚Äòin-situ‚Äô; this doesn‚Äôt update the original file, but it‚Äôs sometimes much more convenient, and this is the method we‚Äôll use for this exercise.\n\nClick on the word ‚ÄúFebuary‚Äù, and select the Edit Transcript option from the menu.\nA text box will appear that allows you to edit that line in the transcript.\nCorrect the spelling of the word to be ‚ÄúFebruary‚Äù\nPress the save button to the right of the text box .\nAfter a short delay, the transcript will re-load, and you will see that the corrected word now has a pronunciation.\nSimilarly change ‚Äúw-‚Äù to be ‚Äúw~‚Äù and ‚Äúmm‚Äù to be ‚Äúmmm‚Äù\nClick on the word ‚Äúme‚Äôs‚Äù, and select the Edit Transcript option from the menu.\nIt seems unlikely that anyone else will say ‚Äúme‚Äôs‚Äù, so instead of adding it to the lexicon, we‚Äôre simply going to tag this token with a pronounce tag. This is achieved by adding the pronunciation we want to tag it with in square brackets, using the DISC phoneme symbols. We have to add the pronounce tag immediately after the word, with no intervening space. (This transcription convention also works if you edit the original transcript in ELAN)\nChange the line text from ‚Äú...bit of me‚Äôs a bit ‚Ä¶‚Äù to be ‚Äú‚Ä¶bit of me‚Äôs[miz] a bit ‚Ä¶‚Äù instead.\nSave the utterance.\nThe pronounce annotation you‚Äôve just added isn‚Äôt displayed in the transcript. It‚Äôs added to the pronounce layer, which is for this type of manual pronunciation tagging.\nScroll to the top of the transcript, open the Layers tab and tick the pronounce layer so that it will be displayed.\nWhen the transcript is reloaded, you will be able to see ‚Äúmiz‚Äù as an annotation on ‚Äúme‚Äôs‚Äù, and that this has been copied into the phonemes layer by its layer manager.\nSimilarly you should tag the word ‚Äúexac~‚Äù with the pronunciation Igz{k\n\nThis method takes care of instances where the transcript is incorrect, and ‚Äòone off‚Äô missing pronunciations. However, for missing words that are likely to appear over and again in the corpus, including names like ‚ÄúBealey‚Äù, ‚ÄúWainoni‚Äù, and ‚ÄúLyttleton‚Äù, and filled pauses like ‚Äúmmm‚Äù, ‚Äúum‚Äù, etc. it‚Äôs not efficient to tag every token. Instead, we add these to the lexicon.\n\nSelect the participants menu option.\nFind UC207YW in the list, and tick the checkbox before their name.\nPress the All Utterances button above the list of participants.\nLeave the default selections and press List.\nThis displays a page with a list of all the speaker‚Äôs utterances, from which you can do various things with all the utterances of a particular participant in the database.\nPress the Htk button.\nYou will see a progress bar while LaBB-CAT identifies missing words. Then a page will appear that lists unknown words.\nBasically you need to fill in the boxes with the pronunciations and click Save Pronunciations.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nYou don‚Äôt have to fill them all in at once, you can do a few, and click Save, which will save your work and list what‚Äôs left.\nYou don‚Äôt have to fill them all in, you can leave some empty and continue with the HTK forced-alignment by clicking Start (HTK will ignore any lines where the remaining unknown words appear, but the ones you filled in will be included).\nSome of the boxes will be initially filled in with a suggestion from the lexicon layer manager - these may or may not be correct, and aren‚Äôt saved until you save them.\nThe pronunciations have to be in the ‚ÄòDISC‚Äô format - i.e.¬†one character per phoneme, with no spaces. There‚Äôs a ‚Äòhelper‚Äô link on the right of each pronunciation box - if you click it, it expands into a list of clickable phonemes - just the ones that aren‚Äôt ordinary letters, and diphthongs etc.\nThe search button lets you look up the lexicon for similar words - this probably won‚Äôt help for place names, but for words like ‚Äútarseal‚Äù, you can click the lookup button, enter ‚Äútar seal‚Äù in the box as two separate words, and you‚Äôll get back the DISC pronunciation of each word, with clickable buttons to copy the given pronunciation into the box. This is useful for digits and numbers too, which may not be in the lexicon - so for ‚Äú1‚Äù, search for ‚Äúone‚Äù and copy the pronunciation.\nIf you click on the word itself, the transcript for the first instance of that word is opened, in case you want to listen to it, or in case it‚Äôs actually just a typo and you want to correct the transcript.\nIf you‚Äôre using CELEX, when you specify the pronunciations, it‚Äôs recommended to put syllable separators (-) and primary stress markers (‚Äô) too - e.g.¬†for ‚Äútarseal‚Äù you can put t#sil but it would actually be better to put t#-‚Äôsil. These markers are entered into the dictionary even though they‚Äôre stripped out for HTK, and they may come in handy later (e.g.¬†the syllable separators are used by the CELEX layer manager to count syllables).\n\n\n\nWhen you add pronunciations this way, they‚Äôre added to the dictionary and all the instances of those words in LaBB-CAT are updated with the pronunciations - not just the participant you‚Äôre looking at, but all participants in the database. So you only have to come up with a pronunciation for each word once.\n\n\n\n\nOnce you‚Äôve filled in all the missing pronunciations, forced alignment will start automatically. If you want to start forced alignment before you‚Äôve entered all pronunciations, click the Start button at the bottom of the page.\n\nYou should see a progress bar while the forced alignment is running. It will take a few minutes to complete.\n\nOnce HTK has produced the word and segment alignments, it:\n\nsets the start/end times of the words on the transcript layer accordingly,\nadds new phone annotations to the segments layer with the alignments of the phones, and\nsaves a timestamp in the htk layer.\n\nWhen the layer manager has finished, you‚Äôll see a message saying ‚ÄúComplete - words and phones from selected utterances are now aligned.‚Äù\n\n\n\nYou can inspect/correct alignments using LaBB-CAT‚Äôs integration with Praat.\n\nGo back to the UC207YW.eaf transcript.\nTick both the htk layer and the segments layer.\nYou will see which lines have been force-aligned, as they have an HTK timestamp, and have the segments layer filled in. If it has missed some lines, this is most likely because there is an unknown word, another speaker speaking at the same time, or possibly HTK simply failed to align the line (there are various reasons this happens, including not enough data for training, noisy recordings, inaccurate transcription, etc.).\n\nThe interactive transcript page doesn‚Äôt show you the alignments of the words or phones, but you can see those using Praat. You can open individual utterances in Praat directly from the transcript page, but first, the LaBB-CAT/Praat integration has to be set up; this only has to be done once:\n\nOn the top-right of the page, above the playback controls, there‚Äôs a Praat icon ¬†- click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\nYou may be asked whether to allow the ‚ÄúLaBB-CAT Integration Applet‚Äù to run. If you tick the ‚ÄúDo not show this again‚Äù option, then this message will not appear every time you open a transcript.\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\n\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶\n\nClick on a line that has been aligned, and select the Open TextGrid option on the menu.\nYou may be asked you if want to allow access to the ‚ÄúLaBB-CAT Integration Applet‚Äù - if so, tick ‚ÄúDo not show this again‚Äù, and click Allow.\n\nPraat should open, and show you a spectrogram of the line‚Äôs audio, with a TextGrid below that includes the words and the segments.\n\nIf you click on a word, and hit the tabtab key, the word‚Äôs interval is played. Try out various words, and see what you think about how accurate HTK has been with its alignment.\nTry this out with different lines in the transcript.\nYou will see that in some cases the alignment is pretty good, and in other cases, it‚Äôs not so good. In the not-so-good cases, see if you can figure out why HTK got it wrong.\n\nYou may have noticed that, each time you open an utterance in Praat, a button appears in the transcript to the left of the line, labelled Import Changes. This button allows you to save any adjustments you might want to make to the alignments back into the LaBB-CAT database.\n\nIf you feel confident using Praat, open an utterance TextGrid, adjust the alignments of the words an phones so that they‚Äôre more accurate, and then click the Import Changes button in the transcript.\n\n\n\n\n\n\n\nWarning\n\n\n\nThese changes are flagged as manual edits, so if forced-alignment is run again, they will not be over-written with new bad alignments. Therefore it‚Äôs important that the changes you make are actually improvements, because HTK will never change them again.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThere are some rules about what you can change:\n\nYou‚Äôre not allowed to add or delete words (if this is necessary, it should be done by correcting the transcript instead).\nAll the phones must be within the bounds of their own word.\nThe start of the first phone should line up with the start of the word, and the end of the last phone should line up with the end of the word.\nYou should not change the alignment of the utterance itself (which would only be possible if you select the Open Text Grid incl.¬†¬± 1 utterance in Praat option).\n\n\n\nIn this exercise, you have seen how HTK can be used to compute word and phone alignments automatically from your data, but that there is a fair amount of careful transcription, tagging, and dictionary filling required. Even after all that work, perfect automatic alignments are not guaranteed, but LaBB-CAT has a mechanism for manually correcting poor alignments.\nAll this manual annotation and correction means a lot of work, but obviously somewhat less work than would be involved in aligning by hand the transcripts from scratch!",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8a. HTK"
    ]
  },
  {
    "objectID": "worksheets/course/8a-forced-alignment-htk.html#installation",
    "href": "worksheets/course/8a-forced-alignment-htk.html#installation",
    "title": "8a. HTK",
    "section": "",
    "text": "HTK is not free software in the ‚ÄúGNU‚Äù sense - i.e.¬†we can not distribute it with LaBB-CAT, instead you have to download it yourself from the Cambridge University website ‚Äì however it is free in the ‚Äúno cost‚Äù sense, you just need to register on the HTK website, and you can then download and use HTK free of charge.\n\nRegister at http://htk.eng.cam.ac.uk/register.shtml\n\n\n\n\n\n\n\nNote\n\n\n\nIf your LaBB-CAT server is installed in a Docker Container, LaBB-CAT can itself download and compile HTK (i.e.¬†steps 2 and 3), as long has you have a username and password for the HTK website. In this case, these steps are automatically attempted when you install the HTK layer manager (from step 4).\n\n\n\nDownload the version of HTK that is appropriate for the computer that LaBB-CAT is installed on:\n\nFor Windows systems, there are pre-compiled .exe files that you can download.\nFor Unix-like systems including OS X, you need to download the source code, which you will then install following the provided instructions.\n\nUnzip (for Windows) or compile and install (for Unix-like systems) the downloaded files on the computer that LaBB-CAT is installed on.\n\nNow, you have to install the HTK Layer Manager, which is the LaBB-CAT module that provides HTK with all the data it needs, and then saves to alignments HTK produces back to your database.\n\nSelect the layer managers menu option.\nFollow the List of layer managers that are not yet installed link at the bottom.\nFind HTK Manager in the list, and press its Install button, then press Install again.\nYou will see a form with boxes that may already be filled in.\nThe layer manager needs to know where the HTK programs have been saved, which is what you need to enter in the blank Path to HTK tools box.\nIf this box is not blank, it means that LaBB-CAT has already found HTK for you, so you should leave the default value already set.\n\n\n\n\n\n\n\nNote\n\n\n\nThe other two boxes you may see are for the username and password you registered on the HTK website. On some systems, if you have not already installed the HTK tools on your LaBB-CAT computer, providing the username and password allows LaBB-CAT to attempt to download and install HTK itself. This may not work in all cases, as LaBB-CAT may not have the resources or privileges it requires to compile or install software.\n\n\n\nPress Configure.\nYou will see a window open with some information about the HTK Layer Manager.\nNow you need to add a phrase layer for the HTK configuration:\n\nLayer ID: htk\nType: Text\nAlignment: Intervals\nManager: HTK Manager\nGenerate: Never (note that this may see counter-intuitive, but we will be running HTK manually rather than allowing it to run automatically when transcripts are uploaded.)\nDescription: HTK alignment time\n\nWhen you configure the layer:\n\nYour Pronunciation Layer will be the phonemes layer you created in an earlier exercise.\nTo the list of Pause Markers you should add a full-stop (period).\nThis is because the exercise transcripts use . as a ‚Äòshort-pause‚Äô marker, not an ‚Äòend of sentence‚Äô marker. i.e. your Pause Markers should be:\n- .\n(a hyphen, then a space, then a full-stop/period)\nThe rest of the settings should be left with the default values.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you‚Äôre curious about what the configuration options do, hover your mouse over each option to see a ‚Äòtool tip‚Äô that describes what the option is for.\n\n\nWe configure the layer to ‚Äònever‚Äô generate, because we‚Äôre going to trigger forced-alignments manually, one speaker at a time, once we‚Äôre happy that the phonemic transcriptions are in place.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8a. HTK"
    ]
  },
  {
    "objectID": "worksheets/course/8a-forced-alignment-htk.html#missing-pronunciations",
    "href": "worksheets/course/8a-forced-alignment-htk.html#missing-pronunciations",
    "title": "8a. HTK",
    "section": "",
    "text": "Now we‚Äôre going to check the situation of our pronunciations on the phonemes layer more carefully‚Ä¶\n\nGo to the transcripts page and open the transcript UC207YW\nTick the phonemes layer.\nHave a look through the transcript to see where the missing phonemic transcriptions are.\n\nYou‚Äôll see they divide into various broad types:\n\nTypos like ‚ÄúFebuary‚Äù\nSpecialist or invented words like ‚Äútarseal‚Äù\nContractions like ‚Äúme‚Äôs‚Äù and ‚Äúthing‚Äôs‚Äù\nProper names like ‚ÄúBealey‚Äù\nPossibly filled pauses like ‚Äúum‚Äù\nHesitations and interrupted words like ‚Äúexac~‚Äù, etc.\n\n\nHTK needs a phonemic transcription for every word on a line in order to force-align that line. So every line where there‚Äôs a gap on the phonemes layer would be ignored by the HTK layer manager.\n\nThere‚Äôs another problem in this transcript, which isn‚Äôt necessarily immediately obvious.\nLook for the hesitiation ‚Äúw-‚Äù and the filled-pause ‚Äúmm‚Äù to see if you can see what it is.\n\n‚ÄòFalse positives‚Äô from the lexicon will also play havoc with forced alignment, as HTK believes what it‚Äôs told about the pronunciations given to it, and will do it‚Äôs best to find an alignment that includes every phoneme.\n\nEach of these problems needs to be addressed before we do forced alignment, although the solution for each will vary. Some involve improving the transcript, others will involve adding new words to our dictionary.\n\nFor false-positives like ‚Äúw-‚Äù and ‚Äúmm‚Äù, the easiest solution is to transcribe these differently. Hesitations like ‚Äúw-‚Äù are discussed below. We will use ‚Äúmmm‚Äù instead of ‚Äúmm‚Äù.\nFor very short false-starts like ‚Äúw-‚Äù, the CELEX layer manager has been built to give a helping hand. In addition to looking up phonemic transcriptions in CELEX, it will also compute them for very short tagged false-starts. The tag it recognizes is a trailing tilde ~, so we need to change ‚Äúw-‚Äù to ‚Äúw~‚Äù etc. Then the CELEX layer manager will append a schwa to the initial consonant, and save that as the pronunciation (i.e.¬†/…ô/).\nFor invented or misspoken words, or longer interrupted words, which we‚Äôre not likely to see again in any other transcript like, ‚Äúme‚Äôs‚Äù and ‚Äúexac~‚Äù, we will add a ‚Äòpronounce‚Äô tag in the transcript, which includes the correct pronunciation. Again, the CELEX layer manager knows to check for pronounce annotations, and uses the given phonemic transcription instead of looking up the CELEX data.\nFor proper names and contractions like ‚Äúthing‚Äôs‚Äù that we‚Äôre likely to see over and over again in different transcripts, instead of tagging each one individually, we will add them to the dictionary of pronunciations that the lexicon layer manager looks up.\n\nAs you can see, the first three methods involve editing the transcript. This can be done by editing the original file in ELAN, and then re-uploading it into the database for processing.\nAlternatively, LaBB-CAT has a mechanism for editing the transcript ‚Äòin-situ‚Äô; this doesn‚Äôt update the original file, but it‚Äôs sometimes much more convenient, and this is the method we‚Äôll use for this exercise.\n\nClick on the word ‚ÄúFebuary‚Äù, and select the Edit Transcript option from the menu.\nA text box will appear that allows you to edit that line in the transcript.\nCorrect the spelling of the word to be ‚ÄúFebruary‚Äù\nPress the save button to the right of the text box .\nAfter a short delay, the transcript will re-load, and you will see that the corrected word now has a pronunciation.\nSimilarly change ‚Äúw-‚Äù to be ‚Äúw~‚Äù and ‚Äúmm‚Äù to be ‚Äúmmm‚Äù\nClick on the word ‚Äúme‚Äôs‚Äù, and select the Edit Transcript option from the menu.\nIt seems unlikely that anyone else will say ‚Äúme‚Äôs‚Äù, so instead of adding it to the lexicon, we‚Äôre simply going to tag this token with a pronounce tag. This is achieved by adding the pronunciation we want to tag it with in square brackets, using the DISC phoneme symbols. We have to add the pronounce tag immediately after the word, with no intervening space. (This transcription convention also works if you edit the original transcript in ELAN)\nChange the line text from ‚Äú...bit of me‚Äôs a bit ‚Ä¶‚Äù to be ‚Äú‚Ä¶bit of me‚Äôs[miz] a bit ‚Ä¶‚Äù instead.\nSave the utterance.\nThe pronounce annotation you‚Äôve just added isn‚Äôt displayed in the transcript. It‚Äôs added to the pronounce layer, which is for this type of manual pronunciation tagging.\nScroll to the top of the transcript, open the Layers tab and tick the pronounce layer so that it will be displayed.\nWhen the transcript is reloaded, you will be able to see ‚Äúmiz‚Äù as an annotation on ‚Äúme‚Äôs‚Äù, and that this has been copied into the phonemes layer by its layer manager.\nSimilarly you should tag the word ‚Äúexac~‚Äù with the pronunciation Igz{k\n\nThis method takes care of instances where the transcript is incorrect, and ‚Äòone off‚Äô missing pronunciations. However, for missing words that are likely to appear over and again in the corpus, including names like ‚ÄúBealey‚Äù, ‚ÄúWainoni‚Äù, and ‚ÄúLyttleton‚Äù, and filled pauses like ‚Äúmmm‚Äù, ‚Äúum‚Äù, etc. it‚Äôs not efficient to tag every token. Instead, we add these to the lexicon.\n\nSelect the participants menu option.\nFind UC207YW in the list, and tick the checkbox before their name.\nPress the All Utterances button above the list of participants.\nLeave the default selections and press List.\nThis displays a page with a list of all the speaker‚Äôs utterances, from which you can do various things with all the utterances of a particular participant in the database.\nPress the Htk button.\nYou will see a progress bar while LaBB-CAT identifies missing words. Then a page will appear that lists unknown words.\nBasically you need to fill in the boxes with the pronunciations and click Save Pronunciations.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nYou don‚Äôt have to fill them all in at once, you can do a few, and click Save, which will save your work and list what‚Äôs left.\nYou don‚Äôt have to fill them all in, you can leave some empty and continue with the HTK forced-alignment by clicking Start (HTK will ignore any lines where the remaining unknown words appear, but the ones you filled in will be included).\nSome of the boxes will be initially filled in with a suggestion from the lexicon layer manager - these may or may not be correct, and aren‚Äôt saved until you save them.\nThe pronunciations have to be in the ‚ÄòDISC‚Äô format - i.e.¬†one character per phoneme, with no spaces. There‚Äôs a ‚Äòhelper‚Äô link on the right of each pronunciation box - if you click it, it expands into a list of clickable phonemes - just the ones that aren‚Äôt ordinary letters, and diphthongs etc.\nThe search button lets you look up the lexicon for similar words - this probably won‚Äôt help for place names, but for words like ‚Äútarseal‚Äù, you can click the lookup button, enter ‚Äútar seal‚Äù in the box as two separate words, and you‚Äôll get back the DISC pronunciation of each word, with clickable buttons to copy the given pronunciation into the box. This is useful for digits and numbers too, which may not be in the lexicon - so for ‚Äú1‚Äù, search for ‚Äúone‚Äù and copy the pronunciation.\nIf you click on the word itself, the transcript for the first instance of that word is opened, in case you want to listen to it, or in case it‚Äôs actually just a typo and you want to correct the transcript.\nIf you‚Äôre using CELEX, when you specify the pronunciations, it‚Äôs recommended to put syllable separators (-) and primary stress markers (‚Äô) too - e.g.¬†for ‚Äútarseal‚Äù you can put t#sil but it would actually be better to put t#-‚Äôsil. These markers are entered into the dictionary even though they‚Äôre stripped out for HTK, and they may come in handy later (e.g.¬†the syllable separators are used by the CELEX layer manager to count syllables).\n\n\n\nWhen you add pronunciations this way, they‚Äôre added to the dictionary and all the instances of those words in LaBB-CAT are updated with the pronunciations - not just the participant you‚Äôre looking at, but all participants in the database. So you only have to come up with a pronunciation for each word once.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8a. HTK"
    ]
  },
  {
    "objectID": "worksheets/course/8a-forced-alignment-htk.html#alignment",
    "href": "worksheets/course/8a-forced-alignment-htk.html#alignment",
    "title": "8a. HTK",
    "section": "",
    "text": "Once you‚Äôve filled in all the missing pronunciations, forced alignment will start automatically. If you want to start forced alignment before you‚Äôve entered all pronunciations, click the Start button at the bottom of the page.\n\nYou should see a progress bar while the forced alignment is running. It will take a few minutes to complete.\n\nOnce HTK has produced the word and segment alignments, it:\n\nsets the start/end times of the words on the transcript layer accordingly,\nadds new phone annotations to the segments layer with the alignments of the phones, and\nsaves a timestamp in the htk layer.\n\nWhen the layer manager has finished, you‚Äôll see a message saying ‚ÄúComplete - words and phones from selected utterances are now aligned.‚Äù",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8a. HTK"
    ]
  },
  {
    "objectID": "worksheets/course/8a-forced-alignment-htk.html#inspectioncorrection",
    "href": "worksheets/course/8a-forced-alignment-htk.html#inspectioncorrection",
    "title": "8a. HTK",
    "section": "",
    "text": "You can inspect/correct alignments using LaBB-CAT‚Äôs integration with Praat.\n\nGo back to the UC207YW.eaf transcript.\nTick both the htk layer and the segments layer.\nYou will see which lines have been force-aligned, as they have an HTK timestamp, and have the segments layer filled in. If it has missed some lines, this is most likely because there is an unknown word, another speaker speaking at the same time, or possibly HTK simply failed to align the line (there are various reasons this happens, including not enough data for training, noisy recordings, inaccurate transcription, etc.).\n\nThe interactive transcript page doesn‚Äôt show you the alignments of the words or phones, but you can see those using Praat. You can open individual utterances in Praat directly from the transcript page, but first, the LaBB-CAT/Praat integration has to be set up; this only has to be done once:\n\nOn the top-right of the page, above the playback controls, there‚Äôs a Praat icon ¬†- click it.\nFollow the instructions that appear (these vary depending on what web browser you use).\nYou may be asked whether to allow the ‚ÄúLaBB-CAT Integration Applet‚Äù to run. If you tick the ‚ÄúDo not show this again‚Äù option, then this message will not appear every time you open a transcript.\nYou may need to grant a browser extension permission to install, and it‚Äôs possible you will need a connection to the internet in order to download this extension.\nYou also may be asked where Praat is installed; Navigate to the location where Praat is installed, and double-click the ‚ÄúPraat.exe‚Äù file (on some systems the file may simply be called ‚ÄúPraat‚Äù). The Praat program may open, and then immediately close, as LaBB-CAT tests it can communicate with Praat.\n\nNow Praat integration has been set up, and you should be able to access Praat options in the transcript page from now on‚Ä¶\n\nClick on a line that has been aligned, and select the Open TextGrid option on the menu.\nYou may be asked you if want to allow access to the ‚ÄúLaBB-CAT Integration Applet‚Äù - if so, tick ‚ÄúDo not show this again‚Äù, and click Allow.\n\nPraat should open, and show you a spectrogram of the line‚Äôs audio, with a TextGrid below that includes the words and the segments.\n\nIf you click on a word, and hit the tabtab key, the word‚Äôs interval is played. Try out various words, and see what you think about how accurate HTK has been with its alignment.\nTry this out with different lines in the transcript.\nYou will see that in some cases the alignment is pretty good, and in other cases, it‚Äôs not so good. In the not-so-good cases, see if you can figure out why HTK got it wrong.\n\nYou may have noticed that, each time you open an utterance in Praat, a button appears in the transcript to the left of the line, labelled Import Changes. This button allows you to save any adjustments you might want to make to the alignments back into the LaBB-CAT database.\n\nIf you feel confident using Praat, open an utterance TextGrid, adjust the alignments of the words an phones so that they‚Äôre more accurate, and then click the Import Changes button in the transcript.\n\n\n\n\n\n\n\nWarning\n\n\n\nThese changes are flagged as manual edits, so if forced-alignment is run again, they will not be over-written with new bad alignments. Therefore it‚Äôs important that the changes you make are actually improvements, because HTK will never change them again.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThere are some rules about what you can change:\n\nYou‚Äôre not allowed to add or delete words (if this is necessary, it should be done by correcting the transcript instead).\nAll the phones must be within the bounds of their own word.\nThe start of the first phone should line up with the start of the word, and the end of the last phone should line up with the end of the word.\nYou should not change the alignment of the utterance itself (which would only be possible if you select the Open Text Grid incl.¬†¬± 1 utterance in Praat option).\n\n\n\nIn this exercise, you have seen how HTK can be used to compute word and phone alignments automatically from your data, but that there is a fair amount of careful transcription, tagging, and dictionary filling required. Even after all that work, perfect automatic alignments are not guaranteed, but LaBB-CAT has a mechanism for manually correcting poor alignments.\nAll this manual annotation and correction means a lot of work, but obviously somewhat less work than would be involved in aligning by hand the transcripts from scratch!",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "8. Forced Alignment",
      "8a. HTK"
    ]
  },
  {
    "objectID": "worksheets/course/7-lexicon.html",
    "href": "worksheets/course/7-lexicon.html",
    "title": "7. Lexicons",
    "section": "",
    "text": "7. Lexicons\nLaBB-CAT can be integrated with various lexicon to facilitate automatic tagging of word tokens.\nFor our English data, there are two main options:\n\nCELEX, a ‚ÄòBritish English‚Äô lexicon which must be purchased from the LDC, and\nThe CMU Pronouncing Dictionary, an ‚ÄòAmerican English‚Äô lexicon that's free to download.\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "7. Lexicons"
    ]
  },
  {
    "objectID": "worksheets/course/4-searching.html",
    "href": "worksheets/course/4-searching.html",
    "title": "4. Searching",
    "section": "",
    "text": "4. Searching\nNow that you have some transcripts in your database, we‚Äôll try out LaBB-CAT‚Äôs search functions a little.\nSearching broadly involves the following steps:\n\nSelecting participants whose utterances you want to search,\nSpecifying one or more patterns to search for, and\nExploring or extracting the search results.\n\n\nWe‚Äôll start with a very simple search - all the instances of the word ‚Äúthe‚Äù uttered by monolingual English-speaking males.\n\nIn LaBB-CAT, select the participants option on the menu.\nThis takes you to a page listing all participants, where you can filter participants by their attributes. You can see various participant attributes listed across the top of page.\n\n\n\n\n\n\n\nTip\n\n\n\nLaBB-CAT remembers the last filters you used, so you may need to clear any filters you had previously applied.\nFor example, if the last time you accessed the participants page, you selected the CC corpus to show only CC participants, that filter may still be active. To remove that filter, just press CC again to de-select that option, or you can press the ‚å´ button at the top, to the right of the page filters, to clear all filters.\n\n\n\nWe‚Äôre interested in male participants, so under the Gender attribute, select M.\nAfter a short delay the page will display a list of all the male participants in the database.\nWe want the participants who speak only English, so enter English under Languages Spoken\nThe page will then display a list of male participants who include English in their languages. It also includes participants who speak other languages, and we want to eliminate these.\nThe Languages filter box accepts a ‚Äòregular expression‚Äô for matching patterns, so if we enter ^English$ in the box, only those with English as their sole language will be listed. This is because, in regular expressions, ^ means ‚Äúthe beginning‚Äù and $ means ‚Äúthe end‚Äù, so ^English$ means, ‚ÄúEnglish at the beginning, and at the end‚Äù\nPress the Layered Search button at the top of the list.\nYou will see the participants you selected listed at the top, above a list of annotation layers. Below that, there‚Äôs a ‚ÄúSearch Matrix‚Äù, although it doesn‚Äôt look much like a matrix yet, because it‚Äôs only one layer high and one word wide‚Ä¶\nIn the box under the word ‚Äúorthography‚Äù type the word the\n\nNow press the Search button at the bottom (or hit EnterEnter).\nA progress bar will appear, and then shortly after that, a new browser tab will open, which has a list of search results in it. Your browser‚Äôs popup-blocker might prevent the results page from opening ‚Äì you can fix that either by allowing the popups in your browser, or by clicking the Display results link that appears after the search finishes.\nEach match is highlighted and shown with some context (the previous word and the following word in the transcript). The amount of context is controlled by a drop-down list at the top.\nSelect 5 words to see more context around each match.\nClick on the first match.\nYou will see that the interactive transcript page opens in a new tab, with the match at the top, and highlighted. You will also see that all the other matches from the same transcript are also highlighted.\nWe‚Äôve already seen what can be done in the interactive transcript page, so close the tab to return to the results page.\nEach result line has a ticked checkbox next to it. Scroll to the bottom of the list.\nYou‚Äôll see that there are buttons at the bottom, which perform operations on the ticked results, including CSV Export, Utterance Export, and Audio Export.\nUn-tick the ‚ÄúSelect all results‚Äù checkbox, and then tick a handful of results in the list.\n\n\n\n\n\n\n\nTip\n\n\n\nYou can select a group of matches by ticking the first one, and then holding down the ShiftShift key while ticking the last one.\n\n\n\nPress the Audio Export button.\nSave and open the resulting zip file.\nYou‚Äôll see that the files are systematically named to include:\n\nthe name of the transcript\nthe start and end time of the extracted utterance\n\nNow go back to the results page and press the expand ‚ñæ button to the right of the Audio Export button, to reveal further options.\nTick the Prefix Names checkbox that has been revealed.\nPress the Audio Export button again.\nSave and open the resulting zip file.\nThis time you‚Äôll see that the files are also prefixed by the result number.\nYou may notice that there are more audio files this time; that‚Äôs because there were multiple results in the same utterance. Previously, only one copy of the utterance was exported, but this time, each match has its own copy of the utterance audio, prefixed by the result number.\nNow go back to the results page and un-tick the Prefix Names checkbox.\nPress the Utterance Export button.\nSave and open the resulting zip file.\nYou‚Äôll see that the TextGrid names match the audio file names in the first zip file.\nOpen one of the TextGrids in Praat.\nYou‚Äôll see that the TextGrid includes a tier named target‚Ä¶ which indicates which token(s) in the word‚Ä¶ tier matched the search pattern.\nBack on the results page, press the CSV Export button.\nSave the resulting file, and open it.\nYou may have to specify some import options, in which case it may be handy to know that the field separator is comma, and the fields are quoted by speech marks.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you‚Äôre using Microsoft Excel and you find it doesn‚Äôt open all the columns correctly:\n\nCreate a new workbook in Excel.\nClick the ‚ÄòData‚Äô tab.\nOn the ‚ÄúGet External Data‚Äù ribbon click ‚ÄòFrom Text‚Äô.\nSelect the CSV file you downloaded.\nSelect ‚ÄòDelimited‚Äô and click Next.\nEnsure ‚ÄòComma‚Äô is the only delimiter ticked and click Next.\nClick Finish and then OK.\n\n\n\nYou will see a spreadsheet with one line per selected result, and various columns containing information about the speaker, the corpus, the match line and word, and a URL to the interactive transcript for the match.\nWith this spreadsheet, you can work ‚Äòoffline‚Äô with the results, tagging them, computing statistics in Excel, R, or any other program that can work with CSV files. We‚Äôll look at a few more uses for the CSV results files later‚Ä¶\n\nClose the CSV file, and the results page, and go back to the search matrix page.\n\nWe‚Äôve seen that you can search for exact word matches, but you can also¬†search for patterns, using ‚Äòregular expressions‚Äô. Now we‚Äôre going to search for words beginning with ‚Äúthe‚Ä¶‚Äù\n\nChange the orthography search text to the.* (i.e.¬†after the word ‚Äúthe‚Äù, append a full-stop and an asterisk.\n\nThe full-stop means ‚Äúany character at all‚Äù, and the asterisk means ‚Äúzero or more of the previous thing‚Äù, so .* means ‚Äúzero or more characters‚Äù.\nPress Search.\nYou will see that now the search results include the word ‚Äúthe‚Äù and also words like ‚Äúthen‚Äù, ‚Äúthere‚Äù, ‚Äúthey‚Äù, etc.\nNow go back to the search page, and change the asterisk to a plus-sign, which means ‚Äúone or more of the previous thing‚Äù\n\nPress Search\nYou will see that now the search results exclude the word ‚Äúthe‚Äù, only including words where the initial ‚Äúthe...‚Äù is followed by at least one character.\nNow change your search by replacing the e in ‚Äúthe‚Äù with [aeiou] - so your search pattern will be:\nth[aeiou].+\nThe square-brackets mean ‚Äúany one of the things inside the brackets‚Äù, so [aeiou] means ‚Äúany vowel‚Äù\n\n\n\n\n\n\n\nNote\n\n\n\nWhile you are typing the regular expression, you may notice that the text goes red; this means that what‚Äôs currently in the box is not a valid regular expression. That‚Äôs fine while you‚Äôre still typing, but when you‚Äôre ready to search, if the text is red, the search will likely fail. If the regular expression text is red, you can see what the problem with it is by hovering your mouse over the red text; a ‚Äòtip‚Äô will appear showing an error message\n\n\n\nPress Search.\nYou will now see that the results include words like ‚Äúthink‚Äù, ‚Äúthat‚Äù, ‚Äúthought‚Äù, etc.\n\n\n\n\n\n\n\nTip\n\n\n\n You can get more information about regular expressions by using the online help on the search page.\n\n\nUp until now, we‚Äôve only been matching against one word at a time. Now¬†we‚Äôre going to include patterns for a chain of words‚Ä¶\n\n\nOn the search page, to the right of the search matrix, there‚Äôs a + button. Click it.\n ¬†¬†¬†\nNow you will see that our search matrix is one layer high by two words wide.\nChange the entries on the orthography layer so that it will match the word ‚Äúthe‚Äù followed immediately by a word that starts with a vowel, and press Search.\nCheck the search results are giving you what you expected.\nNow search for ‚Äúthe‚Äù followed, within two words, by a word that starts with a vowel.\nDream up some other searches that interest you, and try out other options on the search page.\n\n\n\n\n\n\n\nTip\n\n\n\n If in doubt about a search option, try the online help page.\n\n\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "4. Searching"
    ]
  },
  {
    "objectID": "worksheets/course/9-aligned-data.html",
    "href": "worksheets/course/9-aligned-data.html",
    "title": "9. Aligned Data",
    "section": "",
    "text": "In a previous exercise, we force-aligned words and their segments, and also did a little hand-correction of the alignments. Now that we‚Äôve got some relatively reliable phone-level alignments, we‚Äôre going to explore their search and annotation possibilities.\nIn this exercise you will\n\nsee how the alignments affect speech rate computations,\nautomatically annotate pauses between words,\nsearch for tokens of individual, time-aligned segments,\ncreate time-aligned segment annotations via Praat, and\nautomatically extract features from search-result intervals using Praat\n\n\n\n\nWhen inspecting alignments on the segment layer, you will have noticed that the forced aligner introduces pauses between the words ‚Äì almost always at the beginnings and ends of utterances, and also sometimes in between. These pauses will affect the speech-rate statistics that are computed by the Statistics layer manager for the speech rate layer that we set up earlier. Now that there are pauses, these are excluded (i.e.¬†not counted as speech) for the speech-rate statistics.\nHowever, for this change to be affected, the speech rate layer needs to be regenerated.\n\nGo to the transcripts page and open the transcript we force-aligned earlier, UC207YW.eaf, if you don‚Äôt still have it open.\nTick the speechRate layer for display, and make a note of some of the speech rate annotations (which ones are there depends on what you selected as the scopes for the layer).\nIn the bottom right corner of the Layers tab is a button labelled Generate\nPress it.\nThis will display a dropdown list to the left of the Generate button, with All layers selected.\nSelect the speechRate option in this dropdown list and press Generate again.\nYou will see a progress bar while the statistics for the transcript are computed again.\nOnce that‚Äôs finished, go back to the transcript and check the speech rate annotations again. You should see that at least some of them are different.\n\nThese pauses can also be directly annotated, in case you‚Äôre interesting in finding them for analysis.\n\nAdd a new word layer with the following attributes:\n\nLayer ID: previousPause\nType: Number\nAlignment: None\nManager: Context Layer Manager\nGenerate: Always\nProject: pauses\nDescription: Length in seconds of the preceding pause\n\nConfigure the layer with the following settings:\n\nSource layer: word\nSelect the Pause Detection option\nMinimum Pause Length: unticked\nMaximum Pause Length: unticked\nOnly pauses within the same turn: unticked\nLeave the Annotate the word following the pause option selected.\n\n\n\n\n\n\n\n\nTip\n\n\n\n You may be interested in looking at the online help to find out what kinds of annotations the Context layermanager can create.\n\n\n\nPress Save and then Regenerate.\nOnce the layer is generated, go back to the UC207YW.eaf transcript and display the previousPause layer (you might have to tick the pauses project to make the layer option visible).\n(You also might want to un-tick some of the other layers, to avoid clutter.)\nYou should see that a subset of words are annotated with a number, which is the length of the pause before that word.\nOpen one or two such utterances in Praat to check that the lengths are accurate.\n\nYou may notice that pauses in the middle of utterances are always right, but the pause before the first word in the utterance seems wrong. See if you can figure out why.\n\n\n\nNow we‚Äôre going to search for some instances of vowels of interest (the FLEECE vowel in this case), and annotate them with formant measurements.\n\nFirst of all, create a new project called formants\n\nWe‚Äôre going to add a layer that annotates segments - i.e. individual phones within words.\n\nNow select the segment layers menu option.\nFill in the new-layer form at the top with the following details:\n\nLayer ID: F1\nType: Number\nAlignment: Instants\nManager: (don‚Äôt select any of the options, this is a manual annotation layer)\nGenerate: (not relevant as it‚Äôs not a managed layer)\nProject: formants\nDescription: First Formant\nPress New.\n\nSelect search on the menu.\nTick the segment layer.\n\nThe segments layer contains annotations at the sub-word level - i.e. there are potentially multiple annotations per word, each annotation representing a phone of the word. You will see that, as with other layers, there is a box on the segments layer for a regular expression.\nAs with other patterns in the search matrix, the pattern that you enter in the box is matched against individual annotations. So if you enter i in the in the box, it will match each FLEECE vowel segment in each word in the database.\n\n\n\n\n\n\nImportant\n\n\n\nIt‚Äôs important to realise that if you enter a pattern that would match more than a single phoneme symbol on this layer then no search results will be returned, because each annotation on this layer is only a single character long (remember the DISC encoding uses one character per phoneme).\nFor example, if you enter .*IN for your search, intending to match all words ending in ‚Äú‚Ä¶ing‚Äù, then no results will be returned, because no single segment will ever match that pattern.\n\n\n\nWe want to search for all instances of the FLEECE vowel, so use the symbol selector ‚Äì the  button ‚Äì to find the right symbol for the FLEECE vowel and click it.\nIf you used HTK for forced alignment, this will be i\nIf you used MFA for forced alignment, this will be iÀê\n\nIn our particular database, if there‚Äôs any annotation on the segments layer, then we can be sure that it‚Äôs been aligned at least by HTK or MFA (if not manually corrected). However, there are configurations of CELEX layers that would put unaligned annotations on that layer.\n\nTo make sure we only get words that have been aligned by HTK/MFA or manually, in the Options tab, tick the Only match words that are aligned option.\nPress Search.\nOnce the search is finished, you should notice that the only transcripts returned are those that include speakers you‚Äôve done force-alignment on.\nClick on the first result, to open its transcript.\nScroll to the top and tick the include empty layers option.\nOn the Layers tab, tick the formants project option.\nThis will reveal the (empty) F1 layer below segments in the list of layers.\nTick the F1 layer.\nThe transcript will reload to include that layer (even though it‚Äôs currently empty).\nAlso tick the segments layer if it‚Äôs currently un-ticked.\nClick on the first search result (which is highlighted in green).\nSelect the Open TextGrid option.\nThis will open the audio of the line, with a TextGrid that includes the aligned words and segments.\nThere‚Äôs also a tier for the F1 layer.\n\n\n\n\n\n\n\nTip\n\n\n\nIf there‚Äôs no F1 tier in the TextGrid, it‚Äôs because the alignment setting for the layer is set to Not aligned instead of Instants.\nYou can fix that using the segments layers option in the menu.\n\n\n\nIn Praat, find our instance of the FLEECE vowel, and click on a good point in the spectrogram for measuring it‚Äôs F1 value.\nGet the F1 value (hit the F1F1 key on your keyboard)\nCopy the value that is displayed on to the clipboard (i.e.¬†select it and hit CtrlCtrl + CC on your keyboard)\nBack in the TextGrid, add a boundary on the F1 tier at that point (if it‚Äôs the fourth tier, hit CtrlCtrl + F4F4 on your keyboard)\nPaste the F1 value that you copied earlier (i.e.¬†hit CtrlCtrl + VV on your keyboard)\nNow you‚Äôve annotated the vowel with its F1 value, and we want to save that annotation back to the LaBB-CAT database.\nGo back to the LaBB-CAT transcript window.\nPress the Import Changes button that has appeared to the left of the line with the first match.\nYou should see a message indicating that the annotations has been saved.\nRepeat the above steps for the next few matches in the transcript.\nOnce you‚Äôve added at least a handful of annotations on the F1 layer, refresh the interactive transcript page (i.e.¬†use the reload button in your browser, or the F5F5 key).\nYou will see that for each match you‚Äôve annotated, the F1 value you entered appears below the corresponding word. The transcript doesn‚Äôt display the time-alignment information, but that is also stored in the database.\nOpen the TextGrid for one of the lines you‚Äôve annotated.\nYou should see the annotation that you made is in the TextGrid, at the corresponding point in time.\n\nThese manual annotations are also searchable (so for example you could search for all the FLEECE vowels with an F1 measure within a particular range), and can be exported in CSV search results. To see that in action:\n\nRepeat the segment search we did before (i.e.¬†all aligned FLEECE vowels).\nOnce you see the results page, click the ‚ñº button next to the CSV Export button link, and tick the F1 layer.\nPress CVS Export.\nSave and open the resulting file.\nYou will see that there are two columns, one called ‚ÄúTarget F1‚Äù, which contains the annotations you have made, and the other called ‚ÄúTarget F1 start‚Äù, which contains the time of the annotation, in seconds from the beginning of the recording.\n\n\n\n\nWe will now see that you can use Praat to automatically extract certain measurements, given start and end times from search results. In order for this to work, we first need to ensure that the LaBB-CAT server knows where Praat is installed:\n\nIn LaBB-CAT, select the system attributes menu option.\nThis shows a form with various options on it, one of which is Praat Path\nIf the Praat Path option is blank, enter the location of Praat on your LaBB-CAT server, and click Save. The setting should be the path to the folder that contains praat, e.g.\n\non Windows, this might be C:\\Program Files\\Praat\non OS X, this might be /Applications\n\n\nLet‚Äôs say we want to extract F1 and F2 from all our aligned FLEECE vowels.\nWe are going to use the CSV file you just extracted.\nIf you don‚Äôt have it any more, repeat the search and export the results to CSV.\nThe CSV file includes a column called ‚ÄúTarget segment‚Äù, which contains the annotation that matched the pattern (in this case they will all be ‚Äúi‚Äù), and columns called ‚ÄúTarget segment start‚Äù and ‚ÄúTarget segment end‚Äù - these are the start and end times of each matching FLEECE vowel.\nWe are going to use these start/end times to get Praat to take formant measurements for us.\n\nIn LaBB-CAT, click the extract menu option.\nClick the process with praat option.\n\n\n\n\n\n\n\nTip\n\n\n\nIf the option process with praat is not there, it means that the Praat Path attribute is not set. Go back to the steps above and ensure that Praat Path is set before continuing‚Ä¶\n\n\n\nClick Choose File and select the CSV results that you saved above.\nYou will see a form to fill in, and the first couple of settings (Transcript Name column and Participant column should be already filled in.\nFor the Start Time column ensure that the Target segment start option is selected.\nFor the End Time column ensure the Target segment end option is selected.\nThese two settings define the start/end times of the phone.\n\nFor some measurements you might extract from Praat, processing signal that includes surrounding context is usually a good idea. You‚Äôll see there‚Äôs a setting for that (which you can leave at the default of 0.025s), and you will see options for various measurements.\nThe default options are for F1 and F2 only, but if you feel like getting other measurements, feel free to tick those options too. You can expand the advanced settings section by clicking the triangular bullet next to ‚ÄúFormants‚Äù and other measurements, which allow you to specify more detail about how Praat should do its computations. Again, feel free to look at those and try different settings.\n\nClick Process.\nYou will see a progress bar while LaBB-CAT generates a Praat scripts and runs them with Praat.\nOnce Praat has finished processing the intervals, you will get a CSV file (you might have to click the CSV file with measurements link) - save and open it.\nYou will see that it‚Äôs a copy of the CSV file you uploaded, with some extra columns added on the right.\n\nDepending on your settings, this will include at least one column per measurement you selected (the formant columns also include on that contains the time at which the measurements were taken), and a final column called ‚ÄúError‚Äù which is hopefully blank, but which might contain errors reported back by Praat (e.g.¬†if it couldn‚Äôt find the audio file or ran into any other problem during processing).\n\n\nDuring this exercise, you have seen that the inter-word pauses created by forced alignment introduce the possibility of more accurate speech-rate statistics, and can themselves be automatically annotated, in case they are of interest for search or analysis.\nYou‚Äôve also seen that you can create manual time-aligned annotation layers, which can be used to annotate phones (they can also be used for words or spans of words, by creating word layers or phrase/span layers), and that you can also use intervals from CSV search results to extract acoustic measurements automatically using Praat.\nObviously these measurements are as reliable as the intervals themselves, so care needs to be taken to maximise the likelihood of good HTK alignments, and to check and possibly manually-correct those alignments.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "9. Aligned Data"
    ]
  },
  {
    "objectID": "worksheets/course/9-aligned-data.html#pauses-and-speech-rate",
    "href": "worksheets/course/9-aligned-data.html#pauses-and-speech-rate",
    "title": "9. Aligned Data",
    "section": "",
    "text": "When inspecting alignments on the segment layer, you will have noticed that the forced aligner introduces pauses between the words ‚Äì almost always at the beginnings and ends of utterances, and also sometimes in between. These pauses will affect the speech-rate statistics that are computed by the Statistics layer manager for the speech rate layer that we set up earlier. Now that there are pauses, these are excluded (i.e.¬†not counted as speech) for the speech-rate statistics.\nHowever, for this change to be affected, the speech rate layer needs to be regenerated.\n\nGo to the transcripts page and open the transcript we force-aligned earlier, UC207YW.eaf, if you don‚Äôt still have it open.\nTick the speechRate layer for display, and make a note of some of the speech rate annotations (which ones are there depends on what you selected as the scopes for the layer).\nIn the bottom right corner of the Layers tab is a button labelled Generate\nPress it.\nThis will display a dropdown list to the left of the Generate button, with All layers selected.\nSelect the speechRate option in this dropdown list and press Generate again.\nYou will see a progress bar while the statistics for the transcript are computed again.\nOnce that‚Äôs finished, go back to the transcript and check the speech rate annotations again. You should see that at least some of them are different.\n\nThese pauses can also be directly annotated, in case you‚Äôre interesting in finding them for analysis.\n\nAdd a new word layer with the following attributes:\n\nLayer ID: previousPause\nType: Number\nAlignment: None\nManager: Context Layer Manager\nGenerate: Always\nProject: pauses\nDescription: Length in seconds of the preceding pause\n\nConfigure the layer with the following settings:\n\nSource layer: word\nSelect the Pause Detection option\nMinimum Pause Length: unticked\nMaximum Pause Length: unticked\nOnly pauses within the same turn: unticked\nLeave the Annotate the word following the pause option selected.\n\n\n\n\n\n\n\n\nTip\n\n\n\n You may be interested in looking at the online help to find out what kinds of annotations the Context layermanager can create.\n\n\n\nPress Save and then Regenerate.\nOnce the layer is generated, go back to the UC207YW.eaf transcript and display the previousPause layer (you might have to tick the pauses project to make the layer option visible).\n(You also might want to un-tick some of the other layers, to avoid clutter.)\nYou should see that a subset of words are annotated with a number, which is the length of the pause before that word.\nOpen one or two such utterances in Praat to check that the lengths are accurate.\n\nYou may notice that pauses in the middle of utterances are always right, but the pause before the first word in the utterance seems wrong. See if you can figure out why.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "9. Aligned Data"
    ]
  },
  {
    "objectID": "worksheets/course/9-aligned-data.html#time-aligned-segment-annotations",
    "href": "worksheets/course/9-aligned-data.html#time-aligned-segment-annotations",
    "title": "9. Aligned Data",
    "section": "",
    "text": "Now we‚Äôre going to search for some instances of vowels of interest (the FLEECE vowel in this case), and annotate them with formant measurements.\n\nFirst of all, create a new project called formants\n\nWe‚Äôre going to add a layer that annotates segments - i.e. individual phones within words.\n\nNow select the segment layers menu option.\nFill in the new-layer form at the top with the following details:\n\nLayer ID: F1\nType: Number\nAlignment: Instants\nManager: (don‚Äôt select any of the options, this is a manual annotation layer)\nGenerate: (not relevant as it‚Äôs not a managed layer)\nProject: formants\nDescription: First Formant\nPress New.\n\nSelect search on the menu.\nTick the segment layer.\n\nThe segments layer contains annotations at the sub-word level - i.e. there are potentially multiple annotations per word, each annotation representing a phone of the word. You will see that, as with other layers, there is a box on the segments layer for a regular expression.\nAs with other patterns in the search matrix, the pattern that you enter in the box is matched against individual annotations. So if you enter i in the in the box, it will match each FLEECE vowel segment in each word in the database.\n\n\n\n\n\n\nImportant\n\n\n\nIt‚Äôs important to realise that if you enter a pattern that would match more than a single phoneme symbol on this layer then no search results will be returned, because each annotation on this layer is only a single character long (remember the DISC encoding uses one character per phoneme).\nFor example, if you enter .*IN for your search, intending to match all words ending in ‚Äú‚Ä¶ing‚Äù, then no results will be returned, because no single segment will ever match that pattern.\n\n\n\nWe want to search for all instances of the FLEECE vowel, so use the symbol selector ‚Äì the  button ‚Äì to find the right symbol for the FLEECE vowel and click it.\nIf you used HTK for forced alignment, this will be i\nIf you used MFA for forced alignment, this will be iÀê\n\nIn our particular database, if there‚Äôs any annotation on the segments layer, then we can be sure that it‚Äôs been aligned at least by HTK or MFA (if not manually corrected). However, there are configurations of CELEX layers that would put unaligned annotations on that layer.\n\nTo make sure we only get words that have been aligned by HTK/MFA or manually, in the Options tab, tick the Only match words that are aligned option.\nPress Search.\nOnce the search is finished, you should notice that the only transcripts returned are those that include speakers you‚Äôve done force-alignment on.\nClick on the first result, to open its transcript.\nScroll to the top and tick the include empty layers option.\nOn the Layers tab, tick the formants project option.\nThis will reveal the (empty) F1 layer below segments in the list of layers.\nTick the F1 layer.\nThe transcript will reload to include that layer (even though it‚Äôs currently empty).\nAlso tick the segments layer if it‚Äôs currently un-ticked.\nClick on the first search result (which is highlighted in green).\nSelect the Open TextGrid option.\nThis will open the audio of the line, with a TextGrid that includes the aligned words and segments.\nThere‚Äôs also a tier for the F1 layer.\n\n\n\n\n\n\n\nTip\n\n\n\nIf there‚Äôs no F1 tier in the TextGrid, it‚Äôs because the alignment setting for the layer is set to Not aligned instead of Instants.\nYou can fix that using the segments layers option in the menu.\n\n\n\nIn Praat, find our instance of the FLEECE vowel, and click on a good point in the spectrogram for measuring it‚Äôs F1 value.\nGet the F1 value (hit the F1F1 key on your keyboard)\nCopy the value that is displayed on to the clipboard (i.e.¬†select it and hit CtrlCtrl + CC on your keyboard)\nBack in the TextGrid, add a boundary on the F1 tier at that point (if it‚Äôs the fourth tier, hit CtrlCtrl + F4F4 on your keyboard)\nPaste the F1 value that you copied earlier (i.e.¬†hit CtrlCtrl + VV on your keyboard)\nNow you‚Äôve annotated the vowel with its F1 value, and we want to save that annotation back to the LaBB-CAT database.\nGo back to the LaBB-CAT transcript window.\nPress the Import Changes button that has appeared to the left of the line with the first match.\nYou should see a message indicating that the annotations has been saved.\nRepeat the above steps for the next few matches in the transcript.\nOnce you‚Äôve added at least a handful of annotations on the F1 layer, refresh the interactive transcript page (i.e.¬†use the reload button in your browser, or the F5F5 key).\nYou will see that for each match you‚Äôve annotated, the F1 value you entered appears below the corresponding word. The transcript doesn‚Äôt display the time-alignment information, but that is also stored in the database.\nOpen the TextGrid for one of the lines you‚Äôve annotated.\nYou should see the annotation that you made is in the TextGrid, at the corresponding point in time.\n\nThese manual annotations are also searchable (so for example you could search for all the FLEECE vowels with an F1 measure within a particular range), and can be exported in CSV search results. To see that in action:\n\nRepeat the segment search we did before (i.e.¬†all aligned FLEECE vowels).\nOnce you see the results page, click the ‚ñº button next to the CSV Export button link, and tick the F1 layer.\nPress CVS Export.\nSave and open the resulting file.\nYou will see that there are two columns, one called ‚ÄúTarget F1‚Äù, which contains the annotations you have made, and the other called ‚ÄúTarget F1 start‚Äù, which contains the time of the annotation, in seconds from the beginning of the recording.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "9. Aligned Data"
    ]
  },
  {
    "objectID": "worksheets/course/9-aligned-data.html#process-with-praat",
    "href": "worksheets/course/9-aligned-data.html#process-with-praat",
    "title": "9. Aligned Data",
    "section": "",
    "text": "We will now see that you can use Praat to automatically extract certain measurements, given start and end times from search results. In order for this to work, we first need to ensure that the LaBB-CAT server knows where Praat is installed:\n\nIn LaBB-CAT, select the system attributes menu option.\nThis shows a form with various options on it, one of which is Praat Path\nIf the Praat Path option is blank, enter the location of Praat on your LaBB-CAT server, and click Save. The setting should be the path to the folder that contains praat, e.g.\n\non Windows, this might be C:\\Program Files\\Praat\non OS X, this might be /Applications\n\n\nLet‚Äôs say we want to extract F1 and F2 from all our aligned FLEECE vowels.\nWe are going to use the CSV file you just extracted.\nIf you don‚Äôt have it any more, repeat the search and export the results to CSV.\nThe CSV file includes a column called ‚ÄúTarget segment‚Äù, which contains the annotation that matched the pattern (in this case they will all be ‚Äúi‚Äù), and columns called ‚ÄúTarget segment start‚Äù and ‚ÄúTarget segment end‚Äù - these are the start and end times of each matching FLEECE vowel.\nWe are going to use these start/end times to get Praat to take formant measurements for us.\n\nIn LaBB-CAT, click the extract menu option.\nClick the process with praat option.\n\n\n\n\n\n\n\nTip\n\n\n\nIf the option process with praat is not there, it means that the Praat Path attribute is not set. Go back to the steps above and ensure that Praat Path is set before continuing‚Ä¶\n\n\n\nClick Choose File and select the CSV results that you saved above.\nYou will see a form to fill in, and the first couple of settings (Transcript Name column and Participant column should be already filled in.\nFor the Start Time column ensure that the Target segment start option is selected.\nFor the End Time column ensure the Target segment end option is selected.\nThese two settings define the start/end times of the phone.\n\nFor some measurements you might extract from Praat, processing signal that includes surrounding context is usually a good idea. You‚Äôll see there‚Äôs a setting for that (which you can leave at the default of 0.025s), and you will see options for various measurements.\nThe default options are for F1 and F2 only, but if you feel like getting other measurements, feel free to tick those options too. You can expand the advanced settings section by clicking the triangular bullet next to ‚ÄúFormants‚Äù and other measurements, which allow you to specify more detail about how Praat should do its computations. Again, feel free to look at those and try different settings.\n\nClick Process.\nYou will see a progress bar while LaBB-CAT generates a Praat scripts and runs them with Praat.\nOnce Praat has finished processing the intervals, you will get a CSV file (you might have to click the CSV file with measurements link) - save and open it.\nYou will see that it‚Äôs a copy of the CSV file you uploaded, with some extra columns added on the right.\n\nDepending on your settings, this will include at least one column per measurement you selected (the formant columns also include on that contains the time at which the measurements were taken), and a final column called ‚ÄúError‚Äù which is hopefully blank, but which might contain errors reported back by Praat (e.g.¬†if it couldn‚Äôt find the audio file or ran into any other problem during processing).\n\n\nDuring this exercise, you have seen that the inter-word pauses created by forced alignment introduce the possibility of more accurate speech-rate statistics, and can themselves be automatically annotated, in case they are of interest for search or analysis.\nYou‚Äôve also seen that you can create manual time-aligned annotation layers, which can be used to annotate phones (they can also be used for words or spans of words, by creating word layers or phrase/span layers), and that you can also use intervals from CSV search results to extract acoustic measurements automatically using Praat.\nObviously these measurements are as reliable as the intervals themselves, so care needs to be taken to maximise the likelihood of good HTK alignments, and to check and possibly manually-correct those alignments.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "9. Aligned Data"
    ]
  },
  {
    "objectID": "worksheets/course/6-automatic-annotation.html",
    "href": "worksheets/course/6-automatic-annotation.html",
    "title": "6. Automatic Annotation",
    "section": "",
    "text": "You can configure LaBB-CAT to automatically generate annotations, using ‚Äòlayer managers‚Äô. Basically, layer managers are automatic annotation modules that take data in one annotation layer, do some kind of computation on it, and save the result to another annotation layer.\nIn this exercise, we will use the following layer managers:\n\nFrequency Layer Manager, which counts tokens of each word type, over a configurable scope.\nPorter Stemmer, which applies the Porter algorithm to word orthographies to compute word stems.\nPattern Matcher, which creates annotations based on matching regular expressions against words.\nStatistics Layer Manager, which computes aggregated information, like word count or duration, over groups of words.\n\nLaBB-CAT comes with number of layer managers pre-installed; you can see a list of installed layer managers by selecting the layer managers menu option. Other layer managers have to be manually installed.\n\nFor this exercise, we‚Äôll pretend we‚Äôve got a couple more mini-research¬†projects:\n\nwe‚Äôre interested in looking at how rare or common words are in our data, and\nwe want to study ‚Äòfilled pauses‚Äô like ‚Äúum‚Äù, ‚Äúah‚Äù, etc.\n\n\n\nTo start with, we‚Äôll simply annotate each word token in the database with the count of how many times that word appears in the database...\n\nFirst of all, create a new project called frequency, using the steps we saw before.\nSelect the word layers menu option.\nYou will see a list of word layers (including the ‚Äòcustom‚Äô layer for the ‚Äúthe‚Äù project we created earlier).\nAdd a new layer, with the following settings:\n\nLayer ID: frequency\nType: Number\nAlignment: None\nManager: Frequency Layer Manager\nGenerate: Always\nProject: frequency\nDescription: Count of tokens of the same type within each corpus\nPress the New button\n\nYou will see the layer configuration form. Fill it in with the following details:\n\nSummary: Raw Count\nLayer to summarize: orthography\nScope of Summary: Corpus (leave the box next to that with the [each corpus] option selected)\nMain participants only: ticked\nParticipants: un-ticked\nFilter Layer: un-ticked\nWord pairs: un-ticked\nPause Markers: [leave this blank]\nTranscript types: un-tick wordlist (as counting word list tokens would artificially inflate frequencies of those words)\nAnnotate tokens: ticked\n\n\n\n\n\n\n\n\nNote\n\n\n\n If you want more information about what these options mean, check the online help page.\n\n\n\nPress Save\nYou will see a message asking you if you want generate the layer data now.\nPress Regenerate.\nYou will see a progress bar moving across the page while the counts are being generated. When it is finished, you will see a message saying ‚ÄúLayer complete‚Ä¶‚Äù\n\nNow each word in each transcript is annotated with the count of the number of instances of that word with the corpus of the transcript.\nTo see what that looks like‚Ä¶\n\nSelect the transcripts menu option.\nSelect the name of the first transcript in the list.\nSelect the Layers tab at the top of the transcript, where there is now a list of projects. Tick the ‚Äúfrequency‚Äù project.\nThis will reveal the frequency layer in the list of layers.\nTick the frequency layer.\nAbove each word a number appears. That number is the number of times that word appears in the transcript‚Äôs corpus.\ne.g.¬†if the word ‚Äúand‚Äù has 669 above it, and the transcript is in the QB corpus, that means that the word ‚Äúand‚Äù appears in the QB corpus 669 times.\n\nThe newly-generated annotations are also searchable‚Ä¶\n\nSelect the search menu option.\nIf the frequency project and layer are not already ticked, tick them to add the frequency layer to the search matrix.\n\nIn the search matrix, you will notice that, unlike the orthography layer, which has one box for a regular expression, the frequency layer has two boxes, marked ‚Äú‚â•‚Äù and ‚Äú&lt;‚Äù. For a layer of type Number (which is what you specified above), instead of a regular expression, you can match by numeric range.\nWe want all the words that appeared only once in their corpus. Enter a number or numbers in the appropriate box (you can leave either box blank) and press Search.\nPress ‚ñº 20 More Matches a couple of times, to get a good idea of the range of results.\n\nThe results you see may contain words that don‚Äôt seem rare at all. That they only appear once is a product of two factors:\n\nthere isn‚Äôt that much data in our example database, and\n\nthese are counts of ‚Äòwordforms‚Äô - i.e.¬†the surface spelling of the word; e.g.¬†the word ‚Äúdamaging‚Äù might be quite rare, even though there are more instances of words from the same stem like ‚Äúdamage‚Äù, and ‚Äúdamaged‚Äù. This second factor will be addressed soon‚Ä¶\n\nYou can also extract the annotations into CSV results from other searches‚Ä¶\n\nOn the search page, do a search for ‚Äúthe‚Äù followed by a word that starts with a vowel.\nWhen the results page appears, press the ‚ñº button next to the CSV Export button.\nUnder the list of Word layers, tick the frequency layer.\nPress the CSV Export button.\nSave and open the resulting CSV file.\nYou will notice that in the spreadsheet there are two columns:\n\nMatch frequency: this lists the frequency of each word that matched, in order. i.e.¬†in this case two numbers, the frequency of ‚Äúthe‚Äù, followed by the frequency of the word after it.\nTarget frequency: this contains a single frequency, in this case the frequency of the first word that matched a pattern - i.e.¬†‚Äúthe‚Äù\n\nAs an aside, you can also select other layers to include in the CSV file. For example, some of the transcripts include topic-tags that were made in the original ELAN transcript.\nExport your search results to CSV again, this time including the topic layer, and see what that looks like.\n\n\nThe Frequency Layer Manager also keeps a word-list with token counts for each corpus‚Ä¶\n\nSelect the layer managers menu option.\nOn the ‚ÄúFrequency Layer Manager‚Äù row, press the Extensions button.\nYou will see a drop-down box with each corpus in it.\nSelect QB and press Export.\nSave and open the resulting CSV file.\nYou will see an alphabetical list of all the distinct word types in the QB corpus, and next to each, a count of the number of tokens of that type in the QB corpus.\n\n\n\n\nAs pointed out above, although the ‚Äòwordform‚Äô counts might be useful, it also may be useful to lump together different forms of the same stem for the counts. e.g.¬†if there‚Äôs 1 ‚Äúdamaging‚Äù token, 28 ‚Äúdamage‚Äù token, and 18 ‚Äúdamaged‚Äù token, it may be useful to count these all together as 47 tokens of the same stem.\nIn order to achieve this, we first need to ‚Äòstem‚Äô all the words in the database - i.e.¬†reduce all the wordforms so that tokens like ‚Äúdamaging‚Äù, ‚Äúdamage‚Äù, ‚Äúdamaged‚Äù, and ‚Äúdamages‚Äù all have the same ‚Äòstem‚Äô annotation. Then we can gather frequency statistics on the stems.\nThe Porter Stemmer Layer Manager is one way to achieve this. First, we need to install this layer manager (which only works on English data, so it‚Äôs not installed by default).\n\nSelect the layer managers menu option.\nNear the bottom of the page, select the List of layer managers that are not yet installed link.\nFind the ‚ÄúPorter Stemmer‚Äù in the list, and press its Install button, and then Install again to continue.\nAfter it is installed, a tab appears with some information about what the layer manager does. You may wish to read this page for your information. Afterwards, you can close the tab to take you back to the LaBB-CAT browser tab.\nSelect the word layers menu option.\nAdd a new layer with the following attributes:\n\nLayer ID: stem\nType: Text\nAlignment: None\nManager: Porter Stemmer\nGenerate: Always\nProject: frequency\nDescription: The stem of the word according to the Porter algorithm\n\nPress the New button.\n\nThe Porter Stemmer‚Äôs default configuration is fine for our purposes, so press Set Parameters.\nPress Regenerate.\nYou will see a progress bar, and once it‚Äôs finished, you will see a message saying ‚ÄúLayer complete‚Ä¶‚Äù\nSelect the transcripts menu option.\nClick the name of the first transcript.\nOn the Layers tab tick the stem layer we just added (you may need to tick the frequency project to reveal the stem layer).\nWhen the transcript refreshes, you will see, above each word, its ‚Äòstem‚Äô according to the Porter algorithm.\n\nYou will notice that, although the stems are not what you might regard as being the ‚Äòlemma‚Äô of each word (i.e.¬†not necessarily valid words of English in themselves), they nevertheless generally strip off plural and 3rd-person-present suffixes, such that different wordforms of the same lemma will have the same ‚Äòstem‚Äô.\nNow that we have generated a layer of ‚Äòstems‚Äô for the wordforms on the orthography layer, we can generate frequency data from the stem layer as well‚Ä¶\n\nClick the word layers menu option.\nAdd a new layer with the following attributes:\n\nLayer ID: stemFrequency\nType: Number\nAlignment: None\nManager: Frequency Layer Manager\nProject: frequency\nDescription: Count of tokens of the same stem within each corpus\n\nPress the New button.\n\nConfigure the layer exactly as before, except this time, set the Layer to Summarize setting to the stem layer we created above. Save your settings and press Regenerate.\nThe layer will be generated.\nDo a search of all speakers, for words with a value of 1 on your frequency layer, but a value of more than 1 on your new stemFrequency layer.\nYou will see all the words that were previously shown as ‚Äòrare‚Äô, but are actually more common if you count all the tokens with the same stem together.\n\n\n\n\nWe will now create some automatic annotations of a different kind. Let‚Äôs suppose that we‚Äôre interested in ‚Äòfilled pauses‚Äô ‚Äì words like ‚Äúum‚Äù, ‚Äúah‚Äù, ‚Äúer‚Äù, ‚Äúmmm‚Äù, etc. You can actually identify them using regular expressions‚Ä¶\n\nSelect search on the menu.\nSelect the Options tab at the top.\nTick the No matches, only a summary of results option.\nDo a search for the word ah.\nNote the number of results you get back.\nNow do a similar search, for the pattern: a+h+ i.e.¬†1 or more a‚Äôs followed by one or more h‚Äôs.\nNote the number of result you get back is more than in the previous search. It turns out the transcribers, when transcribing the word ‚Äúah‚Äù weren‚Äôt entirely consistent in their spelling of that word. That‚Äôs ok, because with a little imagination, we can invent searches that will identify filled pauses like ‚Äúum‚Äù, ‚Äúah‚Äù, and ‚Äúmm‚Äù, even if they‚Äôve been spelt ‚Äúumm‚Äù, ‚Äúahh‚Äù, or ‚Äúmmm‚Äù.\n(It turns out that there‚Äôs a good reason to prefer ‚Äúmmm‚Äù over ‚Äúmm‚Äù, but we‚Äôll see that in a later exercise)\nTry out a few different searches to see if you can identify different ways that transcribers have spelt filled pauses like this.\n\nWe could annotate these as filled pauses by searching, annotating a CSV file, and uploading the CSV annotations, as we did previously. However, there is a layer manager that can do this for us, for all the existing data, and for any new transcripts that might be uploaded in the future: the ‚ÄúPattern Matcher‚Äù layer manager.\n\nFirst of all, create a new project called pauses.\nNow create a new word layer, with the following attributes:\n\nLayer ID: pause\nType: Text\nAlignment: None\nManager: Pattern Matcher\nGenerate: Always\nProject: pauses\nDescription: Filled pauses annotated by regular expression\n\nPress the New button\n\nSet the Source Layer to be orthography.\nThe Destination Layer and language-related settings can be left with their default values.\n\nBelow this, there is a currently empty list of ‚ÄúMappings‚Äù. We are going to add regular expressions to this list, which will identify filled pauses.\n\nOn the new empty row that‚Äôs already in the list by default, select the box labelled ‚ÄúSource pattern‚Äù, and enter: u+m+\nTo the right of this, select the ‚ÄúDestination Label‚Äù box and enter: um\n\nThis will make the layer manager find any instances of words that match the pattern ‚Äúu+m+‚Äù on the orthography layer, and in each case, save the annotation‚Äùum‚Äù on our new pause layer.\n\nPress the + button to add a new blank row, and add another regular expression:\n\nSource Pattern: a+h+\nDestination Label: ah\n\nPress the + button again, and add another regular expression:\n\nSource Pattern: mm+\nDestination Label: mm\n\nAdd any more regular expressions you think might help identify filled pauses.\nUnder the patterns, select the option to Delete annotations in target layer whose source matches no pattern\n\n\n\n\n\n\n\nTip\n\n\n\n‚ìò If you would like more information about the pattern configuration and what kinds of target annotations you can create, you will find that clicking on the brief description of the layer manager above the form expands to provide more detail.\n\n\n\nPress Set Parameters and Regenerate to generate the layer.\nYou will see a progress bar while the layer manager annotates all the filled pauses in the database.\nTo see what this looks like in a transcript, perform a search for um on your new pause layer, and click on the first match.\nYou should see that each instance of the word ‚Äúum‚Äù (or its variants) has been annotated, as have instances of ‚Äúah‚Äù and ‚Äúmm‚Äù.\n\nNow that these filled pauses are automatically annotated, there are various things you might do with the annotations. You could:\n\ninclude them in the context of multi-word searches, for example you might want to study the effects of a filled pause on the following or preceding word, or\nsearch for only the pauses themselves, for selected speakers, in order to study what kinds of filled pauses are used by which speakers in what contexts, what their durations are, etc.\n\n\n\n\nIn fact, we can use another layer manager to automatically count them for each speaker, and for each utterance in the transcript. In order to do this, we are going to create a ‚Äòphrase layer‚Äô, which is a layer that can contain annotations over groups of words (as opposed to against individual words). The layer manager we will use can also annotate participants‚Ä¶\n\nSelect the phrase layers option on the menu.\nYou will see a list of phrase layers that are already set up, including language and (named) entity.\nAdd a new layer with the following characteristics:\n\nLayer ID: pauseCount\nType: Number\nAlignment: Intervals\nManager: Statistics Layer Manager\nGenerate: Always\nProject: pauses\nDescription: Count of filled pauses, for the utterance and the speaker\n\nPress New\n\nYou will see a form for the layer‚Äôs configuration. Fill in the details as follows:\n\nLayer to summarize: pause\nStatistic: Token Count\nPattern to match: [leave this blank]\nContext: [leave this blank]\nPause Threshold: [leave this blank]\nMain-participant utterances only: ticked\nScopes: tick Utterances, and under Participants:, select the option add new attribute called pauseCount\nTranscript types: leave all the options ticked\n\n\n\n\n\n\n\n\nTip\n\n\n\n If you would like more information about what these settings and the other options do, try the online help for this page.\n\n\n\nSave the layer configuration, and then press Regenerate.\nYou will see a progress bar while the layer manager annotates all the transcripts in the database.\nTo see what this looks like in the transcripts, select the transcripts option on the menu, clear all filters, and open the first transcript in the list.\nOn the Layers tab under the list of projects, if the pauses project isn‚Äôt already ticked, tick it, which will reveal the pauseCount layer in the list of layers.\nTick the pauseCount layer.\nScrolling down the transcript, you will see that, wherever there is a filled pause like ‚Äúum‚Äù, the entire utterance in which it appears has a bracket across the top of the words, labelled with the number of filled-pauses that occurs in that utterance.\nScroll to the top of the transcript, select the Participants tab, and click the Attributes link for the main participant.\nYou will see the participant‚Äôs attributes page, which now includes the participant‚Äôs pauseCount attribute.\nBoth the local utterance count, and the participant‚Äôs overall count, can also be exported to CSV search results files.\nSelect search and perform a search involving the pause layer.\nAt the bottom of the results page, press the ‚ñº button next to the CSV Export button, to reveal the layer options.\nUnder Participant layers tick the pauseCount attribute.\nUnder Phrase layers tick the pauseCount layer.\nPress CSV Export, and save and open the resulting file.\nYou will notice that there is a column called ‚Äúparticipant_pauseCount‚Äù with the participant‚Äôs global count, and another called ‚ÄúTarget pauseCount‚Äù with the local utterance count.\n\nThe Statistics Layer Manager can also incorporate time information in its computation, so it can be used to compute speech-rate. We could use it on our example database to compute words-per-minute for utterances, turns, speakers, etc.\nIf you like, you can try to figure out how to set up a ‚Äúwords-per-minute‚Äù layer now.\nHowever, normally speech-rate is expressed in syllables per minute. We don‚Äôt have any way to get syllable-counts for our words yet, but we will be doing that in a later exercise...\nIn this exercise, you‚Äôve seen how layer managers can be used to compute new annotations automatically from existing annotations, e.g.\n\nWords can be tagged with their frequency in the LaBB-CAT database, or its corpora.\nWords can be tagged with their ‚Äòstem‚Äô using the Porter Stemmer.\nWords can be tagged with annotations on the basis of regular expressions.\nGroups of words can be tagged with aggregated information like word count or rate over time.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "6. Automatic Annotation"
    ]
  },
  {
    "objectID": "worksheets/course/6-automatic-annotation.html#frequency",
    "href": "worksheets/course/6-automatic-annotation.html#frequency",
    "title": "6. Automatic Annotation",
    "section": "",
    "text": "To start with, we‚Äôll simply annotate each word token in the database with the count of how many times that word appears in the database...\n\nFirst of all, create a new project called frequency, using the steps we saw before.\nSelect the word layers menu option.\nYou will see a list of word layers (including the ‚Äòcustom‚Äô layer for the ‚Äúthe‚Äù project we created earlier).\nAdd a new layer, with the following settings:\n\nLayer ID: frequency\nType: Number\nAlignment: None\nManager: Frequency Layer Manager\nGenerate: Always\nProject: frequency\nDescription: Count of tokens of the same type within each corpus\nPress the New button\n\nYou will see the layer configuration form. Fill it in with the following details:\n\nSummary: Raw Count\nLayer to summarize: orthography\nScope of Summary: Corpus (leave the box next to that with the [each corpus] option selected)\nMain participants only: ticked\nParticipants: un-ticked\nFilter Layer: un-ticked\nWord pairs: un-ticked\nPause Markers: [leave this blank]\nTranscript types: un-tick wordlist (as counting word list tokens would artificially inflate frequencies of those words)\nAnnotate tokens: ticked\n\n\n\n\n\n\n\n\nNote\n\n\n\n If you want more information about what these options mean, check the online help page.\n\n\n\nPress Save\nYou will see a message asking you if you want generate the layer data now.\nPress Regenerate.\nYou will see a progress bar moving across the page while the counts are being generated. When it is finished, you will see a message saying ‚ÄúLayer complete‚Ä¶‚Äù\n\nNow each word in each transcript is annotated with the count of the number of instances of that word with the corpus of the transcript.\nTo see what that looks like‚Ä¶\n\nSelect the transcripts menu option.\nSelect the name of the first transcript in the list.\nSelect the Layers tab at the top of the transcript, where there is now a list of projects. Tick the ‚Äúfrequency‚Äù project.\nThis will reveal the frequency layer in the list of layers.\nTick the frequency layer.\nAbove each word a number appears. That number is the number of times that word appears in the transcript‚Äôs corpus.\ne.g.¬†if the word ‚Äúand‚Äù has 669 above it, and the transcript is in the QB corpus, that means that the word ‚Äúand‚Äù appears in the QB corpus 669 times.\n\nThe newly-generated annotations are also searchable‚Ä¶\n\nSelect the search menu option.\nIf the frequency project and layer are not already ticked, tick them to add the frequency layer to the search matrix.\n\nIn the search matrix, you will notice that, unlike the orthography layer, which has one box for a regular expression, the frequency layer has two boxes, marked ‚Äú‚â•‚Äù and ‚Äú&lt;‚Äù. For a layer of type Number (which is what you specified above), instead of a regular expression, you can match by numeric range.\nWe want all the words that appeared only once in their corpus. Enter a number or numbers in the appropriate box (you can leave either box blank) and press Search.\nPress ‚ñº 20 More Matches a couple of times, to get a good idea of the range of results.\n\nThe results you see may contain words that don‚Äôt seem rare at all. That they only appear once is a product of two factors:\n\nthere isn‚Äôt that much data in our example database, and\n\nthese are counts of ‚Äòwordforms‚Äô - i.e.¬†the surface spelling of the word; e.g.¬†the word ‚Äúdamaging‚Äù might be quite rare, even though there are more instances of words from the same stem like ‚Äúdamage‚Äù, and ‚Äúdamaged‚Äù. This second factor will be addressed soon‚Ä¶\n\nYou can also extract the annotations into CSV results from other searches‚Ä¶\n\nOn the search page, do a search for ‚Äúthe‚Äù followed by a word that starts with a vowel.\nWhen the results page appears, press the ‚ñº button next to the CSV Export button.\nUnder the list of Word layers, tick the frequency layer.\nPress the CSV Export button.\nSave and open the resulting CSV file.\nYou will notice that in the spreadsheet there are two columns:\n\nMatch frequency: this lists the frequency of each word that matched, in order. i.e.¬†in this case two numbers, the frequency of ‚Äúthe‚Äù, followed by the frequency of the word after it.\nTarget frequency: this contains a single frequency, in this case the frequency of the first word that matched a pattern - i.e.¬†‚Äúthe‚Äù\n\nAs an aside, you can also select other layers to include in the CSV file. For example, some of the transcripts include topic-tags that were made in the original ELAN transcript.\nExport your search results to CSV again, this time including the topic layer, and see what that looks like.\n\n\nThe Frequency Layer Manager also keeps a word-list with token counts for each corpus‚Ä¶\n\nSelect the layer managers menu option.\nOn the ‚ÄúFrequency Layer Manager‚Äù row, press the Extensions button.\nYou will see a drop-down box with each corpus in it.\nSelect QB and press Export.\nSave and open the resulting CSV file.\nYou will see an alphabetical list of all the distinct word types in the QB corpus, and next to each, a count of the number of tokens of that type in the QB corpus.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "6. Automatic Annotation"
    ]
  },
  {
    "objectID": "worksheets/course/6-automatic-annotation.html#porter-stemmer",
    "href": "worksheets/course/6-automatic-annotation.html#porter-stemmer",
    "title": "6. Automatic Annotation",
    "section": "",
    "text": "As pointed out above, although the ‚Äòwordform‚Äô counts might be useful, it also may be useful to lump together different forms of the same stem for the counts. e.g.¬†if there‚Äôs 1 ‚Äúdamaging‚Äù token, 28 ‚Äúdamage‚Äù token, and 18 ‚Äúdamaged‚Äù token, it may be useful to count these all together as 47 tokens of the same stem.\nIn order to achieve this, we first need to ‚Äòstem‚Äô all the words in the database - i.e.¬†reduce all the wordforms so that tokens like ‚Äúdamaging‚Äù, ‚Äúdamage‚Äù, ‚Äúdamaged‚Äù, and ‚Äúdamages‚Äù all have the same ‚Äòstem‚Äô annotation. Then we can gather frequency statistics on the stems.\nThe Porter Stemmer Layer Manager is one way to achieve this. First, we need to install this layer manager (which only works on English data, so it‚Äôs not installed by default).\n\nSelect the layer managers menu option.\nNear the bottom of the page, select the List of layer managers that are not yet installed link.\nFind the ‚ÄúPorter Stemmer‚Äù in the list, and press its Install button, and then Install again to continue.\nAfter it is installed, a tab appears with some information about what the layer manager does. You may wish to read this page for your information. Afterwards, you can close the tab to take you back to the LaBB-CAT browser tab.\nSelect the word layers menu option.\nAdd a new layer with the following attributes:\n\nLayer ID: stem\nType: Text\nAlignment: None\nManager: Porter Stemmer\nGenerate: Always\nProject: frequency\nDescription: The stem of the word according to the Porter algorithm\n\nPress the New button.\n\nThe Porter Stemmer‚Äôs default configuration is fine for our purposes, so press Set Parameters.\nPress Regenerate.\nYou will see a progress bar, and once it‚Äôs finished, you will see a message saying ‚ÄúLayer complete‚Ä¶‚Äù\nSelect the transcripts menu option.\nClick the name of the first transcript.\nOn the Layers tab tick the stem layer we just added (you may need to tick the frequency project to reveal the stem layer).\nWhen the transcript refreshes, you will see, above each word, its ‚Äòstem‚Äô according to the Porter algorithm.\n\nYou will notice that, although the stems are not what you might regard as being the ‚Äòlemma‚Äô of each word (i.e.¬†not necessarily valid words of English in themselves), they nevertheless generally strip off plural and 3rd-person-present suffixes, such that different wordforms of the same lemma will have the same ‚Äòstem‚Äô.\nNow that we have generated a layer of ‚Äòstems‚Äô for the wordforms on the orthography layer, we can generate frequency data from the stem layer as well‚Ä¶\n\nClick the word layers menu option.\nAdd a new layer with the following attributes:\n\nLayer ID: stemFrequency\nType: Number\nAlignment: None\nManager: Frequency Layer Manager\nProject: frequency\nDescription: Count of tokens of the same stem within each corpus\n\nPress the New button.\n\nConfigure the layer exactly as before, except this time, set the Layer to Summarize setting to the stem layer we created above. Save your settings and press Regenerate.\nThe layer will be generated.\nDo a search of all speakers, for words with a value of 1 on your frequency layer, but a value of more than 1 on your new stemFrequency layer.\nYou will see all the words that were previously shown as ‚Äòrare‚Äô, but are actually more common if you count all the tokens with the same stem together.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "6. Automatic Annotation"
    ]
  },
  {
    "objectID": "worksheets/course/6-automatic-annotation.html#pattern-matcher",
    "href": "worksheets/course/6-automatic-annotation.html#pattern-matcher",
    "title": "6. Automatic Annotation",
    "section": "",
    "text": "We will now create some automatic annotations of a different kind. Let‚Äôs suppose that we‚Äôre interested in ‚Äòfilled pauses‚Äô ‚Äì words like ‚Äúum‚Äù, ‚Äúah‚Äù, ‚Äúer‚Äù, ‚Äúmmm‚Äù, etc. You can actually identify them using regular expressions‚Ä¶\n\nSelect search on the menu.\nSelect the Options tab at the top.\nTick the No matches, only a summary of results option.\nDo a search for the word ah.\nNote the number of results you get back.\nNow do a similar search, for the pattern: a+h+ i.e.¬†1 or more a‚Äôs followed by one or more h‚Äôs.\nNote the number of result you get back is more than in the previous search. It turns out the transcribers, when transcribing the word ‚Äúah‚Äù weren‚Äôt entirely consistent in their spelling of that word. That‚Äôs ok, because with a little imagination, we can invent searches that will identify filled pauses like ‚Äúum‚Äù, ‚Äúah‚Äù, and ‚Äúmm‚Äù, even if they‚Äôve been spelt ‚Äúumm‚Äù, ‚Äúahh‚Äù, or ‚Äúmmm‚Äù.\n(It turns out that there‚Äôs a good reason to prefer ‚Äúmmm‚Äù over ‚Äúmm‚Äù, but we‚Äôll see that in a later exercise)\nTry out a few different searches to see if you can identify different ways that transcribers have spelt filled pauses like this.\n\nWe could annotate these as filled pauses by searching, annotating a CSV file, and uploading the CSV annotations, as we did previously. However, there is a layer manager that can do this for us, for all the existing data, and for any new transcripts that might be uploaded in the future: the ‚ÄúPattern Matcher‚Äù layer manager.\n\nFirst of all, create a new project called pauses.\nNow create a new word layer, with the following attributes:\n\nLayer ID: pause\nType: Text\nAlignment: None\nManager: Pattern Matcher\nGenerate: Always\nProject: pauses\nDescription: Filled pauses annotated by regular expression\n\nPress the New button\n\nSet the Source Layer to be orthography.\nThe Destination Layer and language-related settings can be left with their default values.\n\nBelow this, there is a currently empty list of ‚ÄúMappings‚Äù. We are going to add regular expressions to this list, which will identify filled pauses.\n\nOn the new empty row that‚Äôs already in the list by default, select the box labelled ‚ÄúSource pattern‚Äù, and enter: u+m+\nTo the right of this, select the ‚ÄúDestination Label‚Äù box and enter: um\n\nThis will make the layer manager find any instances of words that match the pattern ‚Äúu+m+‚Äù on the orthography layer, and in each case, save the annotation‚Äùum‚Äù on our new pause layer.\n\nPress the + button to add a new blank row, and add another regular expression:\n\nSource Pattern: a+h+\nDestination Label: ah\n\nPress the + button again, and add another regular expression:\n\nSource Pattern: mm+\nDestination Label: mm\n\nAdd any more regular expressions you think might help identify filled pauses.\nUnder the patterns, select the option to Delete annotations in target layer whose source matches no pattern\n\n\n\n\n\n\n\nTip\n\n\n\n‚ìò If you would like more information about the pattern configuration and what kinds of target annotations you can create, you will find that clicking on the brief description of the layer manager above the form expands to provide more detail.\n\n\n\nPress Set Parameters and Regenerate to generate the layer.\nYou will see a progress bar while the layer manager annotates all the filled pauses in the database.\nTo see what this looks like in a transcript, perform a search for um on your new pause layer, and click on the first match.\nYou should see that each instance of the word ‚Äúum‚Äù (or its variants) has been annotated, as have instances of ‚Äúah‚Äù and ‚Äúmm‚Äù.\n\nNow that these filled pauses are automatically annotated, there are various things you might do with the annotations. You could:\n\ninclude them in the context of multi-word searches, for example you might want to study the effects of a filled pause on the following or preceding word, or\nsearch for only the pauses themselves, for selected speakers, in order to study what kinds of filled pauses are used by which speakers in what contexts, what their durations are, etc.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "6. Automatic Annotation"
    ]
  },
  {
    "objectID": "worksheets/course/6-automatic-annotation.html#statistics-layer-manager",
    "href": "worksheets/course/6-automatic-annotation.html#statistics-layer-manager",
    "title": "6. Automatic Annotation",
    "section": "",
    "text": "In fact, we can use another layer manager to automatically count them for each speaker, and for each utterance in the transcript. In order to do this, we are going to create a ‚Äòphrase layer‚Äô, which is a layer that can contain annotations over groups of words (as opposed to against individual words). The layer manager we will use can also annotate participants‚Ä¶\n\nSelect the phrase layers option on the menu.\nYou will see a list of phrase layers that are already set up, including language and (named) entity.\nAdd a new layer with the following characteristics:\n\nLayer ID: pauseCount\nType: Number\nAlignment: Intervals\nManager: Statistics Layer Manager\nGenerate: Always\nProject: pauses\nDescription: Count of filled pauses, for the utterance and the speaker\n\nPress New\n\nYou will see a form for the layer‚Äôs configuration. Fill in the details as follows:\n\nLayer to summarize: pause\nStatistic: Token Count\nPattern to match: [leave this blank]\nContext: [leave this blank]\nPause Threshold: [leave this blank]\nMain-participant utterances only: ticked\nScopes: tick Utterances, and under Participants:, select the option add new attribute called pauseCount\nTranscript types: leave all the options ticked\n\n\n\n\n\n\n\n\nTip\n\n\n\n If you would like more information about what these settings and the other options do, try the online help for this page.\n\n\n\nSave the layer configuration, and then press Regenerate.\nYou will see a progress bar while the layer manager annotates all the transcripts in the database.\nTo see what this looks like in the transcripts, select the transcripts option on the menu, clear all filters, and open the first transcript in the list.\nOn the Layers tab under the list of projects, if the pauses project isn‚Äôt already ticked, tick it, which will reveal the pauseCount layer in the list of layers.\nTick the pauseCount layer.\nScrolling down the transcript, you will see that, wherever there is a filled pause like ‚Äúum‚Äù, the entire utterance in which it appears has a bracket across the top of the words, labelled with the number of filled-pauses that occurs in that utterance.\nScroll to the top of the transcript, select the Participants tab, and click the Attributes link for the main participant.\nYou will see the participant‚Äôs attributes page, which now includes the participant‚Äôs pauseCount attribute.\nBoth the local utterance count, and the participant‚Äôs overall count, can also be exported to CSV search results files.\nSelect search and perform a search involving the pause layer.\nAt the bottom of the results page, press the ‚ñº button next to the CSV Export button, to reveal the layer options.\nUnder Participant layers tick the pauseCount attribute.\nUnder Phrase layers tick the pauseCount layer.\nPress CSV Export, and save and open the resulting file.\nYou will notice that there is a column called ‚Äúparticipant_pauseCount‚Äù with the participant‚Äôs global count, and another called ‚ÄúTarget pauseCount‚Äù with the local utterance count.\n\nThe Statistics Layer Manager can also incorporate time information in its computation, so it can be used to compute speech-rate. We could use it on our example database to compute words-per-minute for utterances, turns, speakers, etc.\nIf you like, you can try to figure out how to set up a ‚Äúwords-per-minute‚Äù layer now.\nHowever, normally speech-rate is expressed in syllables per minute. We don‚Äôt have any way to get syllable-counts for our words yet, but we will be doing that in a later exercise...\nIn this exercise, you‚Äôve seen how layer managers can be used to compute new annotations automatically from existing annotations, e.g.\n\nWords can be tagged with their frequency in the LaBB-CAT database, or its corpora.\nWords can be tagged with their ‚Äòstem‚Äô using the Porter Stemmer.\nWords can be tagged with annotations on the basis of regular expressions.\nGroups of words can be tagged with aggregated information like word count or rate over time.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Course",
      "6. Automatic Annotation"
    ]
  },
  {
    "objectID": "worksheets/demo/index.html",
    "href": "worksheets/demo/index.html",
    "title": "LaBB-CAT Demo Session",
    "section": "",
    "text": "LaBB-CAT Demo Session\n1 - Exploration\n2 - Annotation Layers\n\n\n\n\nReuseCC BY-SA 4.0Copyright¬© 2023-2024 NZILBB",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session"
    ]
  },
  {
    "objectID": "worksheets/demo/1-exploration.html",
    "href": "worksheets/demo/1-exploration.html",
    "title": "1 - Exploration",
    "section": "",
    "text": "LaBB-CAT is a speech/language corpus management system that:\n\nstores transcripts with audio/video\n\nsupporting a variety of upload formats\nand the definition of speech elicitation tasks;\n\nallows the addition of different layers of annotation, which can\n\nbe manual or automatic, and\nhave different granularities, from topic tagging to individual speech sounds;\n\nsupports forced alignment to phone level using a speech recognition toolkit called HTK, or the Montreal Forced Aligner, or the WebMAUS service provided by BAS Web Services;\nallows cross-layer regular-expression search;\nsearch results are exportable to CSV for further analysis;\nbatch acoustic measurement of segments using Praat is also supported, and\ntranscripts and fragments of them are exportable in a variety of formats.\n\nIn this worksheet you will start exploring a demo LaBB-CAT corpus, to get a general idea of how to find your way around LaBB-CAT and how the language data is presented.\nThe demo corpus contains a collection of videos of people telling stories about their experiences during the earthquakes that struck Canterbury during 2010 and 2011. They have been orthographically transcribed using a tool called ELAN, so they have been time aligned to the utterance level; i.e.¬†the start and end time of each line in the transcript has been manually synchronized with the recording. The ELAN transcripts, and their video and audio files, have been uploaded into LaBB-CAT.\nLaBB-CAT is a browser-based system so the first thing to do is access it with your web browser. Generally, any modern browser should be fine (although some features you‚Äôll see in later worksheets are only supported by Mozilla Firefox or Google Chrome).\n\nIn your web browser, type in the following URL:\nhttps://labbcat.canterbury.ac.nz/demo\nYou will be asked for a username and password.\nThe username is demo and the password is demo\nThe very first time you access LaBB-CAT, you will see the licence agreement for accessing the corpus data.\nPress I Agree to continue.\nYou will see a page called ‚ÄúLaBB-CAT Demo‚Äù which has a menu of links along the top and a number of icons. Below the icons is some information about the corpus. This is the LaBB-CAT home page.\nClick the where do I start? icon on the left.\nThe help page that pops up includes a brief description of LaBB-CAT and some tips for navigation and getting more information.\nRead through at least the top section of the page to get some helpful tips, and then close the browser tab to return to the home page.\n\n\n\nFirst we will look at ways to manually browse the corpus data.\n\nOn the LaBB-CAT home page, select the transcripts option on the menu at the top.\nYou will see a list of transcripts in LaBB-CAT, together with some meta-data. The first twenty transcripts are listed, and there are controls at the bottom of the page to list others.\nClick the name of the first transcript listed: AP2505_Nelson.eaf\nYou will see a page with transcript text, and the video appears in the top right corner of the page. \nPress the play button on the video.\nAs the video plays, you will see the current utterance highlighted in the transcript. You will also see that the current utterance appears as closed captions in the video. You can use the video controls as normal, including the full-screen button in the bottom right, to make the video occupy the whole screen.\nPause the recording.\nClick one of the transcript lines further down the transcript.\nA menu will appear.\nSelect the ‚ÄòPlay‚Äô option on the menu.\nYou will see that playback starts at that line. Playback will stop when the participant finishes the utterance.\nSelect the Formats tab at the top of the page.\nYou will see a list of formats for exporting the transcript.\nSelect Plain Text Document\nSave the resulting file and then open it.\nYou will see the transcript in plain-text form.\n\nPlain text is a format supported by many language analysis tools, so exporting text transcript allows you to use your favourite tools for whatever research you‚Äôre doing.\n\nIf you have Praat installed on your computer, select the Praat Text Grid option. Save the resulting file on your desktop, and then open it with Praat.\n\nYou will see that the TextGrid has a couple of tiers, one for whole utterances, and one for individual words.\n\n\nNow select the participants option on the menu at the top.\nYou will see a list that looks similar to the ‚Äòtranscripts‚Äô list we saw earlier, but this page lists names and meta-data of speakers rather than the recordings in which they appear.\n\n\n\n\nSearching is often a two-step process: first you select which participants you want to search, using their participant attributes, and then you specify the pattern you want to search for.\nThe participants page you‚Äôve got open has a number of filters listed across the top, which allow you to filter the list below.\n\nSelect ‚ÄòF‚Äô in the Gender box by clicking it.\nYou will see a list of the female participants only.\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that each participant has a check-box; if we wanted to, we could select specific participants from the list by checking/unchecking the boxes.\n(But in this case, let‚Äôs search all of them, so leave all the boxes un-ticked.)\n\n\n\nPress the Layered Search button at the top of the list.\nYou will see a page that lists the speakers at the top, a number of tickable annotation layers in the middle, and an empty text box labelled ‚Äòorthography‚Äô below.\nIn the box labelled ‚Äòorthography‚Äô enter the word:\nquake\nNow press the Search button at the bottom (or hit EnterEnter).\nA progress bar will appear below, and then shortly after that, a new tab will open, which has a list of search results in it.\n\n\n\n\n\n\n\nTip\n\n\n\nYour browser‚Äôs popup-blocker might prevent the results page from opening - you can fix that either by allowing the popups in your browser, or by clicking the Display results link that appears after the search finishes.\n\n\nEach match is highlighted and shown within a few words context.\n\n\nClick the first result in the list.\nYou will see the transcript page, which we have already seen, but with each match from the search highlighted (you will need to scroll down to see the second match).\nThe transcript page has opened in its own new browser tab.\nClose that tab now to return to the results list.\nPress the Audio Export button at the bottom.\nSave and open the resulting zip file.\n\nThe zip file contains the audio for the utterance that contained the word that matched your search.\nYou‚Äôll see that extracted wav files are systematically named to include:\n\nthe name of the transcript\nthe start and end time of the extracted utterance\n\n\nIf you also have Praat installed on your computer, go back to the results page and press Utterance Export button. Save and open the resulting zip file.\n\nYou‚Äôll see that the TextGrid names match the audio file names in the previous zip file.\nIf you open a TextGrid in Praat, you‚Äôll see it includes a tier for the whole utterance transcript, a tier with an interval for each word, and a target‚Ä¶ tier which tags the word that matched the word you searched for.\nExporting similarly-named utterance wav files and Praat TextGrids provides a possible way to process or analyse search results offline in Praat.\n\nBack on the results page, click the CSV Export button.\nSave the resulting file, and open it.\nYou may have to specify some import options, in which case it may be handy to know that the field separator is comma, and the fields are quoted by speech marks.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you‚Äôre using Microsoft Excel and you find it doesn‚Äôt open all the columns correctly:\n\nCreate a new workbook in Excel.\nClick the ‚ÄòData‚Äô tab.\nOn the ‚ÄúGet External Data‚Äù ribbon click ‚ÄòFrom Text‚Äô.\nSelect the CSV file you downloaded.\nSelect ‚ÄòDelimited‚Äô and click Next.\nEnsure ‚ÄòComma‚Äô is the only delimiter ticked and click Next.\nClick Finish and then OK.\n\n\n\nYou will see a spreadsheet with one line per selected result, and various columns containing information about the speaker, the corpus, the match line and word, and a URL to the interactive transcript for the match.\nWith this spreadsheet, you can work ‚Äòoffline‚Äô with the results, tagging them, computing statistics in Excel, R, or any other program that can work with CSV files.\n\nClose the CSV file, and got back to the results page.\nClose the results page, and you‚Äôll return to the search page.\n\n\n\n\n\nOn the search page, in the orthography box, prefix the word ‚Äúquake‚Äù with .* i.e.:\n.*quake\n\nThis is a ‚Äòregular expression‚Äô that allows you to search for patterns instead of matching exact text:\n\n. means ‚Äúany letter, number, or other character‚Äù\n* means ‚Äúzero or more of the previous thing‚Äù,\nso .* means ‚Äúany number of characters of any kind‚Äù\nquake means literally the sequence of letters ‚Äòquake‚Äô\nso .*quake means ‚Äúany word ending in ‚Äòquake‚Äô‚Äù\n\n\nPress Search.\nDepending on your browser, you may have to click the Display results link to see the results page.\nNow your results include all the instances of the word ‚Äúearthquake‚Äù, plus instances of ‚Äúquake‚Äù as well.\n\nUp until now, we‚Äôve only been matching against one word at a time. Now we‚Äôre going to create a search pattern for a chain of words.\n\nClose the results tab of the previous search.\nBack on the search page, next to the orthography box where you entered the regular expression, there‚Äôs a  button for adding a column to the ‚Äòsearch matrix‚Äô. Click it.\n\nNow you will see that our ‚Äòsearch matrix‚Äô is two words wide.\nIn the new orthography box on the right, enter the regular expression:\nis|was\n\nThis regular expression is:\n\nis means ‚Äúthe word ‚Äòis‚Äô‚Äù\n| (the vertical bar character) means or\nwas means ‚Äúthe word ‚Äòwas‚Äô‚Äù\nso is|was means ‚Äúthe word ‚Äòis‚Äô or the word ‚Äòwas‚Äô‚Äù\n\n\nPress Search.\nYou should see results are now words ending in ‚Äòquake‚Äô followed by either ‚Äòis‚Äô or ‚Äòwas‚Äô.\n\n\n\n\n\n\n\nTip\n\n\n\n You can get more information about regular expressions by using the online help back on the search page.\n\n\n\n\nIn this worksheet you have seen that:\n\nLaBB-CAT is a repository for recordings and their transcripts;\nTranscripts can be exported in a variety of formats;\nMeta-data can be attached to transcripts (transcript attributes) and to participants (participant attributes);\nYou can filter lists of participant (or transcripts) on the basis of meta-data;\nYou can search the texts of the transcripts for patterns using ‚Äòregular expressions‚Äô;\nSearch results can be exported to CSV files for further processing;",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "1 - Exploration"
    ]
  },
  {
    "objectID": "worksheets/demo/1-exploration.html#transcripts-and-participants",
    "href": "worksheets/demo/1-exploration.html#transcripts-and-participants",
    "title": "1 - Exploration",
    "section": "",
    "text": "First we will look at ways to manually browse the corpus data.\n\nOn the LaBB-CAT home page, select the transcripts option on the menu at the top.\nYou will see a list of transcripts in LaBB-CAT, together with some meta-data. The first twenty transcripts are listed, and there are controls at the bottom of the page to list others.\nClick the name of the first transcript listed: AP2505_Nelson.eaf\nYou will see a page with transcript text, and the video appears in the top right corner of the page. \nPress the play button on the video.\nAs the video plays, you will see the current utterance highlighted in the transcript. You will also see that the current utterance appears as closed captions in the video. You can use the video controls as normal, including the full-screen button in the bottom right, to make the video occupy the whole screen.\nPause the recording.\nClick one of the transcript lines further down the transcript.\nA menu will appear.\nSelect the ‚ÄòPlay‚Äô option on the menu.\nYou will see that playback starts at that line. Playback will stop when the participant finishes the utterance.\nSelect the Formats tab at the top of the page.\nYou will see a list of formats for exporting the transcript.\nSelect Plain Text Document\nSave the resulting file and then open it.\nYou will see the transcript in plain-text form.\n\nPlain text is a format supported by many language analysis tools, so exporting text transcript allows you to use your favourite tools for whatever research you‚Äôre doing.\n\nIf you have Praat installed on your computer, select the Praat Text Grid option. Save the resulting file on your desktop, and then open it with Praat.\n\nYou will see that the TextGrid has a couple of tiers, one for whole utterances, and one for individual words.\n\n\nNow select the participants option on the menu at the top.\nYou will see a list that looks similar to the ‚Äòtranscripts‚Äô list we saw earlier, but this page lists names and meta-data of speakers rather than the recordings in which they appear.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "1 - Exploration"
    ]
  },
  {
    "objectID": "worksheets/demo/1-exploration.html#basic-search",
    "href": "worksheets/demo/1-exploration.html#basic-search",
    "title": "1 - Exploration",
    "section": "",
    "text": "Searching is often a two-step process: first you select which participants you want to search, using their participant attributes, and then you specify the pattern you want to search for.\nThe participants page you‚Äôve got open has a number of filters listed across the top, which allow you to filter the list below.\n\nSelect ‚ÄòF‚Äô in the Gender box by clicking it.\nYou will see a list of the female participants only.\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that each participant has a check-box; if we wanted to, we could select specific participants from the list by checking/unchecking the boxes.\n(But in this case, let‚Äôs search all of them, so leave all the boxes un-ticked.)\n\n\n\nPress the Layered Search button at the top of the list.\nYou will see a page that lists the speakers at the top, a number of tickable annotation layers in the middle, and an empty text box labelled ‚Äòorthography‚Äô below.\nIn the box labelled ‚Äòorthography‚Äô enter the word:\nquake\nNow press the Search button at the bottom (or hit EnterEnter).\nA progress bar will appear below, and then shortly after that, a new tab will open, which has a list of search results in it.\n\n\n\n\n\n\n\nTip\n\n\n\nYour browser‚Äôs popup-blocker might prevent the results page from opening - you can fix that either by allowing the popups in your browser, or by clicking the Display results link that appears after the search finishes.\n\n\nEach match is highlighted and shown within a few words context.\n\n\nClick the first result in the list.\nYou will see the transcript page, which we have already seen, but with each match from the search highlighted (you will need to scroll down to see the second match).\nThe transcript page has opened in its own new browser tab.\nClose that tab now to return to the results list.\nPress the Audio Export button at the bottom.\nSave and open the resulting zip file.\n\nThe zip file contains the audio for the utterance that contained the word that matched your search.\nYou‚Äôll see that extracted wav files are systematically named to include:\n\nthe name of the transcript\nthe start and end time of the extracted utterance\n\n\nIf you also have Praat installed on your computer, go back to the results page and press Utterance Export button. Save and open the resulting zip file.\n\nYou‚Äôll see that the TextGrid names match the audio file names in the previous zip file.\nIf you open a TextGrid in Praat, you‚Äôll see it includes a tier for the whole utterance transcript, a tier with an interval for each word, and a target‚Ä¶ tier which tags the word that matched the word you searched for.\nExporting similarly-named utterance wav files and Praat TextGrids provides a possible way to process or analyse search results offline in Praat.\n\nBack on the results page, click the CSV Export button.\nSave the resulting file, and open it.\nYou may have to specify some import options, in which case it may be handy to know that the field separator is comma, and the fields are quoted by speech marks.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you‚Äôre using Microsoft Excel and you find it doesn‚Äôt open all the columns correctly:\n\nCreate a new workbook in Excel.\nClick the ‚ÄòData‚Äô tab.\nOn the ‚ÄúGet External Data‚Äù ribbon click ‚ÄòFrom Text‚Äô.\nSelect the CSV file you downloaded.\nSelect ‚ÄòDelimited‚Äô and click Next.\nEnsure ‚ÄòComma‚Äô is the only delimiter ticked and click Next.\nClick Finish and then OK.\n\n\n\nYou will see a spreadsheet with one line per selected result, and various columns containing information about the speaker, the corpus, the match line and word, and a URL to the interactive transcript for the match.\nWith this spreadsheet, you can work ‚Äòoffline‚Äô with the results, tagging them, computing statistics in Excel, R, or any other program that can work with CSV files.\n\nClose the CSV file, and got back to the results page.\nClose the results page, and you‚Äôll return to the search page.",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "1 - Exploration"
    ]
  },
  {
    "objectID": "worksheets/demo/1-exploration.html#regular-expressions",
    "href": "worksheets/demo/1-exploration.html#regular-expressions",
    "title": "1 - Exploration",
    "section": "",
    "text": "On the search page, in the orthography box, prefix the word ‚Äúquake‚Äù with .* i.e.:\n.*quake\n\nThis is a ‚Äòregular expression‚Äô that allows you to search for patterns instead of matching exact text:\n\n. means ‚Äúany letter, number, or other character‚Äù\n* means ‚Äúzero or more of the previous thing‚Äù,\nso .* means ‚Äúany number of characters of any kind‚Äù\nquake means literally the sequence of letters ‚Äòquake‚Äô\nso .*quake means ‚Äúany word ending in ‚Äòquake‚Äô‚Äù\n\n\nPress Search.\nDepending on your browser, you may have to click the Display results link to see the results page.\nNow your results include all the instances of the word ‚Äúearthquake‚Äù, plus instances of ‚Äúquake‚Äù as well.\n\nUp until now, we‚Äôve only been matching against one word at a time. Now we‚Äôre going to create a search pattern for a chain of words.\n\nClose the results tab of the previous search.\nBack on the search page, next to the orthography box where you entered the regular expression, there‚Äôs a  button for adding a column to the ‚Äòsearch matrix‚Äô. Click it.\n\nNow you will see that our ‚Äòsearch matrix‚Äô is two words wide.\nIn the new orthography box on the right, enter the regular expression:\nis|was\n\nThis regular expression is:\n\nis means ‚Äúthe word ‚Äòis‚Äô‚Äù\n| (the vertical bar character) means or\nwas means ‚Äúthe word ‚Äòwas‚Äô‚Äù\nso is|was means ‚Äúthe word ‚Äòis‚Äô or the word ‚Äòwas‚Äô‚Äù\n\n\nPress Search.\nYou should see results are now words ending in ‚Äòquake‚Äô followed by either ‚Äòis‚Äô or ‚Äòwas‚Äô.\n\n\n\n\n\n\n\nTip\n\n\n\n You can get more information about regular expressions by using the online help back on the search page.\n\n\n\n\nIn this worksheet you have seen that:\n\nLaBB-CAT is a repository for recordings and their transcripts;\nTranscripts can be exported in a variety of formats;\nMeta-data can be attached to transcripts (transcript attributes) and to participants (participant attributes);\nYou can filter lists of participant (or transcripts) on the basis of meta-data;\nYou can search the texts of the transcripts for patterns using ‚Äòregular expressions‚Äô;\nSearch results can be exported to CSV files for further processing;",
    "crumbs": [
      "Worksheets",
      "LaBB-CAT Demo Session",
      "1 - Exploration"
    ]
  }
]